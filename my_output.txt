File: LICENSE
```text
MIT License

Copyright (c) 2025 Kagami's Adjmatrix

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

--------------------------------------------------------------------------------

File: RAG_POC_README.md
```markdown
# RAGæ£€ç´¢å¼•æ“ (FAISS) POC ä½¿ç”¨æ–‡æ¡£

## é¡¹ç›®æ¦‚è¿°

æœ¬POCï¼ˆæ¦‚å¿µéªŒè¯ï¼‰é¡¹ç›®å®ç°äº†ä¸€ä¸ªåŸºäºFAISSçš„å‘é‡æ£€ç´¢å¼•æ“ï¼Œä¸“é—¨ç”¨äºè¯­éŸ³è¯†åˆ«ç³»ç»Ÿä¸­çš„çƒ­è¯é¢„æµ‹å’Œå¢å¼ºåŠŸèƒ½ã€‚è¯¥æœåŠ¡é‡‡ç”¨è½»é‡çº§çš„å¾®æœåŠ¡æ¶æ„ï¼Œæä¾›é«˜æ•ˆçš„è¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢èƒ½åŠ›ã€‚

## æ ¸å¿ƒç‰¹æ€§

### ğŸ” **å‘é‡æ£€ç´¢èƒ½åŠ›**

- åŸºäº **sentence-transformers/all-MiniLM-L6-v2** æ¨¡å‹è¿›è¡Œæ–‡æœ¬å‘é‡åŒ–
- ä½¿ç”¨ **FAISS IndexFlatIP** å®ç°é«˜æ•ˆçš„ä½™å¼¦ç›¸ä¼¼åº¦æœç´¢
- æ”¯æŒå¤šç”¨æˆ·éš”ç¦»çš„ç´¢å¼•ç®¡ç†

### ğŸ’¾ **ç´¢å¼•æŒä¹…åŒ–**

- è‡ªåŠ¨ä¿å­˜/åŠ è½½ç”¨æˆ·å‘é‡ç´¢å¼•åˆ°æœ¬åœ°æ–‡ä»¶
- æ™ºèƒ½ç¼“å­˜æœºåˆ¶ï¼Œé¿å…é‡å¤è®¡ç®—
- æ”¯æŒå¢é‡æ›´æ–°å’Œç´¢å¼•é‡å»º

### ğŸš€ **é«˜æ€§èƒ½è®¾è®¡**

- å†…å­˜ä¸­ç´¢å¼•ç¡®ä¿æ¯«ç§’çº§æŸ¥è¯¢å“åº”
- æ‰¹é‡å‘é‡åŒ–å¤„ç†æå‡æ„å»ºæ•ˆç‡
- è½»é‡çº§æ¨¡å‹ï¼ˆ~90MBï¼‰å¹³è¡¡é€Ÿåº¦ä¸å‡†ç¡®æ€§

### ğŸ”’ **å®‰å…¨ä¸éš”ç¦»**

- åŸºäºJWTçš„ç”¨æˆ·è®¤è¯
- ç”¨æˆ·é—´æ•°æ®å®Œå…¨éš”ç¦»
- RESTful APIè®¾è®¡ï¼Œæ˜“äºé›†æˆ

## æŠ€æœ¯æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAGæ£€ç´¢å¼•æ“æ¶æ„                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  FastAPI Router (/rag/*)                                   â”‚
â”‚  â”œâ”€â”€ /search          - å‘é‡ç›¸ä¼¼åº¦æœç´¢                      â”‚
â”‚  â”œâ”€â”€ /suggestions     - æ™ºèƒ½çƒ­è¯å»ºè®®                        â”‚
â”‚  â”œâ”€â”€ /index/stats     - ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯                        â”‚
â”‚  â”œâ”€â”€ /index/rebuild   - é‡å»ºç”¨æˆ·ç´¢å¼•                        â”‚
â”‚  â””â”€â”€ /model/info      - æ¨¡å‹ä¿¡æ¯æŸ¥è¯¢                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  RAGService (æ ¸å¿ƒæœåŠ¡å±‚)                                    â”‚
â”‚  â”œâ”€â”€ SentenceTransformer  - æ–‡æœ¬å‘é‡åŒ–                     â”‚
â”‚  â”œâ”€â”€ FAISS IndexFlatIP   - å‘é‡ç´¢å¼•ä¸æœç´¢                   â”‚
â”‚  â”œâ”€â”€ ç´¢å¼•æŒä¹…åŒ–ç®¡ç†        - æ–‡ä»¶å­˜å‚¨ä¸åŠ è½½                  â”‚
â”‚  â””â”€â”€ ç”¨æˆ·æ•°æ®éš”ç¦»         - å¤šç”¨æˆ·æ”¯æŒ                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å­˜å‚¨å±‚                                                     â”‚
â”‚  â”œâ”€â”€ temp/rag_indices/   - ç´¢å¼•æ–‡ä»¶å­˜å‚¨                     â”‚
â”‚  â”‚   â”œâ”€â”€ user_xxx.index     - FAISSç´¢å¼•æ–‡ä»¶                 â”‚
â”‚  â”‚   â””â”€â”€ user_xxx.metadata  - å…ƒæ•°æ®JSONæ–‡ä»¶                â”‚
â”‚  â””â”€â”€ SQLite Database     - çƒ­è¯æ•°æ®æŒä¹…åŒ–                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

ç¡®ä¿å·²å®‰è£…å¿…è¦çš„ä¾èµ–ï¼š

```bash
# è¿›å…¥åç«¯ç›®å½•
cd asr_system_backend

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 2. å¯åŠ¨æœåŠ¡

```bash
# å¯åŠ¨FastAPIæœåŠ¡
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 3. éªŒè¯æœåŠ¡çŠ¶æ€

```bash
# æ£€æŸ¥RAGæœåŠ¡å¥åº·çŠ¶æ€
curl http://localhost:8000/rag/health
```

é¢„æœŸå“åº”ï¼š

```json
{
  "status": "healthy",
  "service": "RAG Vector Search Engine", 
  "version": "1.0.0",
  "initialized": true
}
```

## APIæ¥å£è¯¦ç»†è¯´æ˜

### ğŸ” å‘é‡æœç´¢æ¥å£

**POST** `/rag/search`

æ ¹æ®æŸ¥è¯¢æ–‡æœ¬è¿›è¡Œå‘é‡ç›¸ä¼¼åº¦æœç´¢ï¼Œè¿”å›æœ€ç›¸å…³çš„çƒ­è¯ã€‚

**è¯·æ±‚å‚æ•°ï¼š**

```json
{
  "query": "äººå·¥æ™ºèƒ½æŠ€æœ¯",
  "top_k": 5,
  "threshold": 0.3
}
```

**å“åº”ç¤ºä¾‹ï¼š**

```json
{
  "query": "äººå·¥æ™ºèƒ½æŠ€æœ¯",
  "results": [
    {
      "word": "æœºå™¨å­¦ä¹ ",
      "weight": 8,
      "similarity": 0.85,
      "rank": 1
    },
    {
      "word": "æ·±åº¦å­¦ä¹ ",
      "weight": 9,
      "similarity": 0.82,
      "rank": 2
    }
  ],
  "total_found": 2,
  "processing_time_ms": 12.5
}
```

### ğŸ“Š ç´¢å¼•ç»Ÿè®¡æ¥å£

**GET** `/rag/index/stats`

è·å–å½“å‰ç”¨æˆ·çš„ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯ã€‚

**å“åº”ç¤ºä¾‹ï¼š**

```json
{
  "user_id": "user123",
  "total_hotwords": 156,
  "index_dimension": 384,
  "is_initialized": true,
  "last_updated": "2025-07-11T15:30:00"
}
```

### ğŸ”„ ç´¢å¼•ç®¡ç†æ¥å£

**POST** `/rag/index/rebuild`

å¼ºåˆ¶é‡å»ºç”¨æˆ·çš„å‘é‡ç´¢å¼•ã€‚

**å“åº”ç¤ºä¾‹ï¼š**

```json
{
  "success": true,
  "message": "ç´¢å¼•é‡å»ºæˆåŠŸï¼ŒåŒ…å« 156 ä¸ªçƒ­è¯",
  "details": {
    "user_id": "user123",
    "hotword_count": 156,
    "dimension": 384
  }
}
```

### ğŸ’¡ æ™ºèƒ½å»ºè®®æ¥å£

**GET** `/rag/suggestions?partial_text=æœºå™¨&max_suggestions=5`

æ ¹æ®éƒ¨åˆ†è¾“å…¥æ–‡æœ¬è·å–çƒ­è¯è¡¥å…¨å»ºè®®ã€‚

**å“åº”ç¤ºä¾‹ï¼š**

```json
{
  "partial_text": "æœºå™¨",
  "suggestions": [
    "æœºå™¨å­¦ä¹ ",
    "æœºå™¨äºº",
    "æœºå™¨è§†è§‰",
    "æœºå™¨ç¿»è¯‘"
  ],
  "count": 4
}
```

### ğŸ“‹ æ‰¹é‡æ“ä½œæ¥å£

**POST** `/rag/index/bulk-add`

æ‰¹é‡æ·»åŠ çƒ­è¯åˆ°ç´¢å¼•ä¸­ã€‚

**è¯·æ±‚å‚æ•°ï¼š**

```json
{
  "words": [
    {"word": "è‡ªç„¶è¯­è¨€å¤„ç†", "weight": 8},
    {"word": "è®¡ç®—æœºè§†è§‰", "weight": 7},
    {"word": "è¯­éŸ³è¯†åˆ«", "weight": 9}
  ]
}
```

**å“åº”ç¤ºä¾‹ï¼š**

```json
{
  "success": true,
  "message": "æ‰¹é‡æ·»åŠ å®Œæˆï¼šæ–°å¢ 3 ä¸ªï¼Œè·³è¿‡ 0 ä¸ª",
  "details": {
    "added": 3,
    "skipped": 0,
    "total_processed": 3
  }
}
```

### ğŸ”§ æ¨¡å‹ä¿¡æ¯æ¥å£

**GET** `/rag/model/info`

è·å–å½“å‰ä½¿ç”¨çš„å‘é‡åŒ–æ¨¡å‹è¯¦ç»†ä¿¡æ¯ã€‚

**å“åº”ç¤ºä¾‹ï¼š**

```json
{
  "model_name": "sentence-transformers/all-MiniLM-L6-v2",
  "dimension": 384,
  "max_sequence_length": 256,
  "languages": ["zh", "en", "multilingual"],
  "description": "è½»é‡çº§å¤šè¯­è¨€å¥å­åµŒå…¥æ¨¡å‹ï¼Œé€‚åˆä¸­è‹±æ–‡æ··åˆåœºæ™¯",
  "performance": {
    "embedding_speed": "~1000 sentences/sec (CPU)",
    "model_size": "~90MB",
    "accuracy": "é€‚ä¸­ï¼Œå¹³è¡¡é€Ÿåº¦ä¸å‡†ç¡®æ€§"
  }
}
```

## ä½¿ç”¨åœºæ™¯ç¤ºä¾‹

### åœºæ™¯1ï¼šå®æ—¶è½¬å†™ä¸­çš„çƒ­è¯é¢„æµ‹

```python
import requests

# ç”¨æˆ·è¯´è¯å†…å®¹
transcription = "ä»Šå¤©æˆ‘ä»¬è®¨è®ºäººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨"

# æœç´¢ç›¸å…³çƒ­è¯
response = requests.post("http://localhost:8000/rag/search", 
    headers={"Authorization": "Bearer YOUR_JWT_TOKEN"},
    json={
        "query": transcription,
        "top_k": 10,
        "threshold": 0.4
    }
)

results = response.json()
# æ ¹æ®æœç´¢ç»“æœè¿›è¡Œè½¬å†™å¢å¼º...
```

### åœºæ™¯2ï¼šçƒ­è¯è¾“å…¥è‡ªåŠ¨è¡¥å…¨

```python
# ç”¨æˆ·è¾“å…¥éƒ¨åˆ†æ–‡æœ¬
partial_input = "æ·±åº¦"

# è·å–è¡¥å…¨å»ºè®®
response = requests.get(
    f"http://localhost:8000/rag/suggestions?partial_text={partial_input}&max_suggestions=5",
    headers={"Authorization": "Bearer YOUR_JWT_TOKEN"}
)

suggestions = response.json()["suggestions"]
# ["æ·±åº¦å­¦ä¹ ", "æ·±åº¦ç¥ç»ç½‘ç»œ", "æ·±åº¦å¼ºåŒ–å­¦ä¹ ", ...]
```

### åœºæ™¯3ï¼šç³»ç»Ÿæ€§èƒ½ç›‘æ§

```python
# è·å–ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯
stats_response = requests.get("http://localhost:8000/rag/index/stats",
    headers={"Authorization": "Bearer YOUR_JWT_TOKEN"})

stats = stats_response.json()
print(f"ç”¨æˆ·çƒ­è¯æ•°é‡: {stats['total_hotwords']}")
print(f"ç´¢å¼•ç»´åº¦: {stats['index_dimension']}")
print(f"ç´¢å¼•çŠ¶æ€: {'å·²åˆå§‹åŒ–' if stats['is_initialized'] else 'æœªåˆå§‹åŒ–'}")
```

## æ€§èƒ½ç‰¹æ€§

### ğŸš€ **æŸ¥è¯¢æ€§èƒ½**

- **å“åº”æ—¶é—´**: < 50ms (å…¸å‹åœºæ™¯)
- **ååé‡**: > 100 QPS (å•å®ä¾‹)
- **å†…å­˜å ç”¨**: ~200MB (1000ä¸ªçƒ­è¯)

### ğŸ“ˆ **æ‰©å±•æ€§**

- **çƒ­è¯æ•°é‡**: æ”¯æŒæ¯ç”¨æˆ·1000+çƒ­è¯
- **å¹¶å‘ç”¨æˆ·**: æ”¯æŒ100+å¹¶å‘ç”¨æˆ·
- **ç´¢å¼•å¤§å°**: æ¯1000ä¸ªçƒ­è¯çº¦1.5MBå­˜å‚¨

### ğŸ”§ **é…ç½®ä¼˜åŒ–**

åœ¨ `asr_system_backend/env.example` ä¸­å¯è°ƒæ•´ä»¥ä¸‹å‚æ•°ï¼š

```bash
# RAGæœåŠ¡é…ç½®
RAG_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
RAG_SIMILARITY_THRESHOLD=0.5

# æ€§èƒ½é…ç½®  
BACKGROUND_TASK_WORKERS=2
```

## éƒ¨ç½²å»ºè®®

### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

1. **ä½¿ç”¨æ›´å¼ºå¤§çš„ç¡¬ä»¶**

   ```bash
   # æ¨èé…ç½®
   CPU: 4æ ¸å¿ƒä»¥ä¸Š
   å†…å­˜: 8GBä»¥ä¸Š
   å­˜å‚¨: SSDå­˜å‚¨æå‡ç´¢å¼•I/Oæ€§èƒ½
   ```
2. **æ¨¡å‹ç¼“å­˜ä¼˜åŒ–**

   ```bash
   # é¢„ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°
   export TRANSFORMERS_CACHE=/path/to/model/cache
   ```
3. **ç´¢å¼•æ–‡ä»¶å¤‡ä»½**

   ```bash
   # å®šæœŸå¤‡ä»½ç´¢å¼•ç›®å½•
   cp -r temp/rag_indices/ /backup/rag_indices_$(date +%Y%m%d)/
   ```

### ç›‘æ§ä¸ç»´æŠ¤

1. **å¥åº·æ£€æŸ¥**

   ```bash
   # æ·»åŠ åˆ°ç›‘æ§ç³»ç»Ÿ
   curl -f http://localhost:8000/rag/health || exit 1
   ```
2. **æ—¥å¿—ç›‘æ§**

   ```bash
   # å…³æ³¨å…³é”®æ—¥å¿—
   grep "RAGæœåŠ¡" app.log
   grep "ç´¢å¼•é‡å»º" app.log
   ```
3. **æ€§èƒ½ç›‘æ§**

   ```python
   # å®šæœŸæ£€æŸ¥æœåŠ¡ç»Ÿè®¡
   GET /rag/index/stats
   ```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**Q: æœåŠ¡å¯åŠ¨æ—¶æç¤º"æ¨¡å‹ä¸‹è½½å¤±è´¥"**

```bash
# è§£å†³æ–¹æ¡ˆï¼šæ‰‹åŠ¨ä¸‹è½½æ¨¡å‹
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
```

**Q: æœç´¢ç»“æœä¸ºç©º**

```bash
# æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰çƒ­è¯æ•°æ®
GET /rag/index/stats

# å¦‚æœçƒ­è¯ä¸º0ï¼Œå…ˆæ·»åŠ çƒ­è¯
POST /hotwords
```

**Q: ç´¢å¼•æ–‡ä»¶æŸå**

```bash
# å¼ºåˆ¶é‡å»ºç´¢å¼•
POST /rag/index/rebuild
```

## æŠ€æœ¯ç»†èŠ‚

### å‘é‡åŒ–æ¨¡å‹é€‰æ‹©

é€‰æ‹© `all-MiniLM-L6-v2` çš„åŸå› ï¼š

- **å¤šè¯­è¨€æ”¯æŒ**: æ”¯æŒä¸­è‹±æ–‡æ··åˆåœºæ™¯
- **æ¨¡å‹å¤§å°**: ä»…90MBï¼Œé€‚åˆéƒ¨ç½²
- **å‡†ç¡®æ€§**: åœ¨å¥å­ç›¸ä¼¼åº¦ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜ç§€
- **é€Ÿåº¦**: CPUä¸Šå¯è¾¾1000å¥/ç§’çš„å¤„ç†é€Ÿåº¦

### FAISSç´¢å¼•ç­–ç•¥

ä½¿ç”¨ `IndexFlatIP` çš„è€ƒè™‘ï¼š

- **ç²¾ç¡®æœç´¢**: ä¿è¯100%å‡†ç¡®çš„ç›¸ä¼¼åº¦è®¡ç®—
- **ç®€å•å¯é **: æ— éœ€è°ƒå‚ï¼Œç¨³å®šæ€§å¥½
- **å†…å­˜æ•ˆç‡**: å¯¹äºä¸­å°è§„æ¨¡æ•°æ®é›†æœ€ä¼˜

### æ•°æ®éš”ç¦»è®¾è®¡

æ¯ä¸ªç”¨æˆ·çš„æ•°æ®å®Œå…¨éš”ç¦»ï¼š

- **ç´¢å¼•æ–‡ä»¶**: `user_{user_id}.index`
- **å…ƒæ•°æ®æ–‡ä»¶**: `user_{user_id}.metadata`
- **å†…å­˜ç»“æ„**: æŒ‰ç”¨æˆ·IDåˆ†åˆ«å­˜å‚¨

## å¼€å‘ä¸è´¡çŒ®

### æœ¬åœ°å¼€å‘

```bash
# å…‹éš†é¡¹ç›®
git clone <project-url>

# å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements.txt

# è¿è¡Œæµ‹è¯•
pytest test/test_rag.py

# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
uvicorn app.main:app --reload
```

### ä»£ç ç»“æ„

```
asr_system_backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â””â”€â”€ rag.py           # RAG APIè·¯ç”±
â”‚   â”œâ”€â”€ rag_service.py       # æ ¸å¿ƒRAGæœåŠ¡
â”‚   â””â”€â”€ main.py             # ä¸»åº”ç”¨å…¥å£
â”œâ”€â”€ temp/
â”‚   â””â”€â”€ rag_indices/        # ç´¢å¼•æ–‡ä»¶å­˜å‚¨
â””â”€â”€ test/
    â””â”€â”€ test_rag.py         # RAGåŠŸèƒ½æµ‹è¯•
```

## ç‰ˆæœ¬å†å²

- **v1.0.0** (2025-07-11)
  - åˆå§‹POCç‰ˆæœ¬å‘å¸ƒ
  - åŸºç¡€å‘é‡æœç´¢åŠŸèƒ½
  - ç´¢å¼•æŒä¹…åŒ–æ”¯æŒ
  - å¤šç”¨æˆ·éš”ç¦»æœºåˆ¶

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ï¼Œè¯¦è§LICENSEæ–‡ä»¶ã€‚

---

**è‡´è°¢**
æ„Ÿè°¢sentence-transformerså’ŒFAISSå¼€æºé¡¹ç›®ä¸ºæœ¬POCæä¾›çš„æŠ€æœ¯åŸºç¡€ã€‚
```

--------------------------------------------------------------------------------

File: run.sh
```shell
#!/bin/bash

# é¢œè‰²å®šä¹‰
GREEN='\033[0;32m'
BLUE='\033[0;34m'
RED='\033[0;31m'
YELLOW='\033[0;33m'
NC='\033[0m' # No Color

# ç«¯å£é…ç½®
BACKEND_PORT=${BACKEND_PORT:-8080}
FRONTEND_PORT=${FRONTEND_PORT:-2956}
BACKEND_HOST=${BACKEND_HOST:-localhost}

# PIDæ–‡ä»¶
BACKEND_PID_FILE=".backend.pid"
FRONTEND_PID_FILE=".frontend.pid"

# æ£€æŸ¥å¹¶æ¸…ç†è¢«å ç”¨çš„ç«¯å£
check_and_clean_port() {
    local port=$1
    local pid=$(lsof -ti:${port})
    if [ ! -z "$pid" ]; then
        echo -e "${YELLOW}ç«¯å£ ${port} è¢«è¿›ç¨‹ ${pid} å ç”¨ï¼Œæ­£åœ¨æ¸…ç†...${NC}"
        kill -9 $pid
        sleep 1
    fi
}

start_services() {
    echo -e "${BLUE}=== æ”¯æŒçƒ­è¯é¢„æµ‹çš„è¯­éŸ³è¯†åˆ«ç³»ç»Ÿå¯åŠ¨è„šæœ¬ ===${NC}"
    
    # æ£€æŸ¥å¹¶æ¸…ç†ç«¯å£
    check_and_clean_port $BACKEND_PORT
    check_and_clean_port $FRONTEND_PORT
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»è¿è¡Œ
    if [ -f "$BACKEND_PID_FILE" ]; then
        echo -e "${RED}åç«¯æœåŠ¡ä¼¼ä¹å·²åœ¨è¿è¡Œï¼Œè¯·å…ˆåœæ­¢æœåŠ¡ã€‚${NC}"
        return 1
    fi
    
    if [ -f "$FRONTEND_PID_FILE" ]; then
        echo -e "${RED}å‰ç«¯æœåŠ¡ä¼¼ä¹å·²åœ¨è¿è¡Œï¼Œè¯·å…ˆåœæ­¢æœåŠ¡ã€‚${NC}"
        return 1
    fi
    
    # å¯åŠ¨åç«¯æœåŠ¡
    echo -e "${GREEN}>>> å¯åŠ¨åç«¯æœåŠ¡...${NC}"
    cd asr_system_backend
    nohup uvicorn app.main:app --reload --host 0.0.0.0 --port $BACKEND_PORT > ../backend.log 2>&1 &
    BACKEND_PID=$!
    echo $BACKEND_PID > ../$BACKEND_PID_FILE
    cd ..
    
    # å¯åŠ¨å‰ç«¯æœåŠ¡
    echo -e "${GREEN}>>> å¯åŠ¨å‰ç«¯æœåŠ¡...${NC}"
    cd asr_system_frontend
    nohup npm run dev -- --port $FRONTEND_PORT --host > ../frontend.log 2>&1 &
    FRONTEND_PID=$!
    echo $FRONTEND_PID > ../$FRONTEND_PID_FILE
    cd ..
    
    echo -e "${BLUE}=== æœåŠ¡å·²å¯åŠ¨! ===${NC}"
    echo -e "${GREEN}åç«¯æœåŠ¡è¿è¡Œäº: ${YELLOW}http://localhost:$BACKEND_PORT${NC}"
    echo -e "${GREEN}å‰ç«¯æœåŠ¡è¿è¡Œäº: ${YELLOW}http://localhost:$FRONTEND_PORT${NC}"
    echo -e "${GREEN}APIæ–‡æ¡£: ${YELLOW}http://localhost:$BACKEND_PORT/docs${NC}"
    echo -e "${BLUE}=== ä½¿ç”¨ ./run.sh logs æŸ¥çœ‹æ—¥å¿— ===${NC}"
    echo -e "${BLUE}=== ä½¿ç”¨ ./run.sh stop åœæ­¢æœåŠ¡ ===${NC}"
}

stop_services() {
    echo -e "${BLUE}=== åœæ­¢æœåŠ¡... ===${NC}"
    
    # åœæ­¢åç«¯
    if [ -f "$BACKEND_PID_FILE" ]; then
        BACKEND_PID=$(cat $BACKEND_PID_FILE)
        echo -e "${GREEN}>>> åœæ­¢åç«¯æœåŠ¡ (PID: $BACKEND_PID)...${NC}"
        kill $BACKEND_PID 2>/dev/null || true
        rm $BACKEND_PID_FILE
    else
        echo -e "${YELLOW}æœªæ‰¾åˆ°åç«¯æœåŠ¡PIDæ–‡ä»¶ï¼ŒæœåŠ¡å¯èƒ½æœªè¿è¡Œã€‚${NC}"
    fi
    
    # åœæ­¢å‰ç«¯
    if [ -f "$FRONTEND_PID_FILE" ]; then
        FRONTEND_PID=$(cat $FRONTEND_PID_FILE)
        echo -e "${GREEN}>>> åœæ­¢å‰ç«¯æœåŠ¡ (PID: $FRONTEND_PID)...${NC}"
        kill $FRONTEND_PID 2>/dev/null || true
        rm $FRONTEND_PID_FILE
    else
        echo -e "${YELLOW}æœªæ‰¾åˆ°å‰ç«¯æœåŠ¡PIDæ–‡ä»¶ï¼ŒæœåŠ¡å¯èƒ½æœªè¿è¡Œã€‚${NC}"
    fi
    
    echo -e "${BLUE}=== æœåŠ¡å·²åœæ­¢ ===${NC}"
}

show_logs() {
    case $1 in
        backend)
            echo -e "${BLUE}=== æ˜¾ç¤ºåç«¯æ—¥å¿— (æŒ‰ Ctrl+C é€€å‡º) ===${NC}"
            tail -f backend.log
            ;;
        frontend)
            echo -e "${BLUE}=== æ˜¾ç¤ºå‰ç«¯æ—¥å¿— (æŒ‰ Ctrl+C é€€å‡º) ===${NC}"
            tail -f frontend.log
            ;;
        *)
            echo -e "${BLUE}=== æ˜¾ç¤ºæ‰€æœ‰æ—¥å¿— (æŒ‰ Ctrl+C é€€å‡º) ===${NC}"
            tail -f backend.log frontend.log
            ;;
    esac
}

# ä¸»å‘½ä»¤å¤„ç†
case $1 in
    stop)
        stop_services
        ;;
    logs)
        show_logs $2
        ;;
    *)
        start_services
        ;;
esac
```

--------------------------------------------------------------------------------

File: setup.py
```python
#!/usr/bin/env python3
"""
æ”¯æŒçƒ­è¯é¢„æµ‹çš„è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ - åˆå§‹åŒ–è®¾ç½®è„šæœ¬
ä½œè€…ï¼šæä¿Šæ´ (é¡¹ç›®ç»„é•¿)
æ—¥æœŸï¼š2025å¹´7æœˆ8æ—¥

æ­¤è„šæœ¬ç”¨äºåˆå§‹åŒ–ç³»ç»Ÿç¯å¢ƒï¼ŒåŒ…æ‹¬ï¼š
1. æ£€æŸ¥å¹¶å®‰è£…Pythonå’ŒNode.jsä¾èµ–
2. é…ç½®æ•°æ®åº“
3. åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„
4. ç”Ÿæˆé»˜è®¤é…ç½®æ–‡ä»¶
"""

import os
import sys
import subprocess
import shutil
import secrets
from pathlib import Path

class ASRSystemSetup:
    def __init__(self):
        self.project_root = Path(__file__).parent.absolute()
        self.backend_dir = self.project_root / "asr_system_backend"
        self.frontend_dir = self.project_root / "asr_system_frontend"
        
    def print_banner(self):
        """æ˜¾ç¤ºè®¾ç½®æ¨ªå¹…"""
        print("=" * 60)
        print("    æ”¯æŒçƒ­è¯é¢„æµ‹çš„è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ")
        print("    ASR System with Hotword Prediction")
        print("=" * 60)
        print("æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿç¯å¢ƒ...\n")
        
    def check_prerequisites(self):
        """æ£€æŸ¥ç³»ç»Ÿå…ˆå†³æ¡ä»¶"""
        print("ğŸ” æ£€æŸ¥ç³»ç»Ÿå…ˆå†³æ¡ä»¶...")
        
        # æ£€æŸ¥Pythonç‰ˆæœ¬
        python_version = sys.version_info
        if python_version.major < 3 or (python_version.major == 3 and python_version.minor < 8):
            print("âŒ é”™è¯¯ï¼šéœ€è¦Python 3.8æˆ–æ›´é«˜ç‰ˆæœ¬")
            return False
        print(f"âœ… Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
        
        # æ£€æŸ¥Node.js
        try:
            result = subprocess.run(['node', '--version'], capture_output=True, text=True)
            if result.returncode == 0:
                print(f"âœ… Node.jsç‰ˆæœ¬: {result.stdout.strip()}")
            else:
                print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°Node.jsï¼Œè¯·å…ˆå®‰è£…Node.js")
                return False
        except FileNotFoundError:
            print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°Node.jsï¼Œè¯·å…ˆå®‰è£…Node.js")
            return False
        
        # æ£€æŸ¥npm
        try:
            result = subprocess.run(['npm', '--version'], capture_output=True, text=True)
            if result.returncode == 0:
                print(f"âœ… npmç‰ˆæœ¬: {result.stdout.strip()}")
            else:
                print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°npm")
                return False
        except FileNotFoundError:
            print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°npm")
            return False
            
        return True

if __name__ == "__main__":
    setup = ASRSystemSetup()
    setup.print_banner()
    if setup.check_prerequisites():
        print("âœ… ç³»ç»Ÿå…ˆå†³æ¡ä»¶æ£€æŸ¥é€šè¿‡")
        print("è¯·è¿è¡Œå®Œæ•´çš„æ„å»ºè„šæœ¬: python -m build æˆ–ä½¿ç”¨ build.sh")
    else:
        print("âŒ ç³»ç»Ÿå…ˆå†³æ¡ä»¶æ£€æŸ¥å¤±è´¥")
        sys.exit(1)
```

--------------------------------------------------------------------------------

File: docker.md
```markdown
## æœ¬åœ°éƒ¨ç½²Docker

é€šè¿‡è¯¥æ–¹æ³•ä¸ç”¨è°ƒç”¨APIï¼Œç›´æ¥åœ¨æœ¬åœ°éƒ¨ç½²ã€‚
```bash
sudo docker rm -f 055c5f54c1b13cf0f5eea0c23a5a53f650c656cc2a6e159da3620ec1b3de580a
# æˆ–ä½¿ç”¨å®¹å™¨å
sudo docker rm -f funasr_server
```

### docker build

é¦–å…ˆéœ€è¦æœ‰docker

ç¬¬äºŒæ­¥ï¼šæ‹‰å– FunASR å¹¶ä¸”å¯åŠ¨ç¦»çº¿æœåŠ¡é•œåƒ

ç°åœ¨æ‚¨å·²ç»åœ¨å®¹å™¨å†…éƒ¨äº†ï¼Œè¿™é‡Œæ˜¯ä¸€ä¸ªçº¯å‡€ä¸”é…ç½®å¥½çš„ç¯å¢ƒã€‚è¯·åœ¨å®¹å™¨çš„å‘½ä»¤è¡Œä¸­æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æ¥å¯åŠ¨åç«¯çš„è¯†åˆ«æœåŠ¡ï¼š

```bash
sudo docker pull registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-cpu-0.4.5
```

ç¬¬ä¸‰æ­¥ï¼šå¯åŠ¨ FunASR æœåŠ¡ç«¯å®¹å™¨
å½“é•œåƒä¸‹è½½å®Œæˆåï¼Œæˆ‘ä»¬å°±å¯ä»¥ç”¨å®ƒå¯åŠ¨ä¸€ä¸ªæœåŠ¡å®¹å™¨äº†ã€‚è¯·åœ¨æ‚¨çš„ Paraformer-ASR ç›®å½•ä¸‹ï¼ˆæˆ–è€…ä»»ä½•æ‚¨æ–¹ä¾¿çš„åœ°æ–¹ï¼‰è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
# è¿™ä¸ªå‘½ä»¤ä¼šå…ˆåˆ›å»ºä¸€ä¸ªæœ¬åœ°ç›®å½•ï¼Œç”¨äºå­˜æ”¾å°†æ¥ä»ç½‘ä¸Šä¸‹è½½çš„æ¨¡å‹
mkdir -p ./funasr-runtime-resources/models

# å¯åŠ¨å®¹å™¨ï¼Œå¹¶å°†æˆ‘ä»¬åˆšåˆ›å»ºçš„ç›®å½•æ˜ å°„åˆ°å®¹å™¨å†…éƒ¨
sudo docker run --name funasr_server -p 10095:10095 -it --privileged=true \
  -v $PWD/funasr-runtime-resources/models:/workspace/models \
  registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-cpu-0.4.5

```

å½“æ‚¨è¿è¡Œè¿™ä¸ªå‘½ä»¤åï¼Œæ‚¨çš„ç»ˆç«¯ä¼šè¿›å…¥åˆ° Docker å®¹å™¨çš„å†…éƒ¨ï¼Œæ‚¨ä¼šçœ‹åˆ°ä¸€ä¸ªæ–°çš„å‘½ä»¤è¡Œæç¤ºç¬¦ï¼Œç±»ä¼¼ root@xxxxxx:/workspace#ã€‚

ç¬¬å››æ­¥ï¼šåœ¨å®¹å™¨å†…å¯åŠ¨è¯†åˆ«æœåŠ¡
ç°åœ¨æ‚¨å·²ç»åœ¨å®¹å™¨å†…éƒ¨äº†ï¼Œè¿™é‡Œæ˜¯ä¸€ä¸ªçº¯å‡€ä¸”é…ç½®å¥½çš„ç¯å¢ƒã€‚è¯·åœ¨å®¹å™¨çš„å‘½ä»¤è¡Œä¸­æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æ¥å¯åŠ¨åç«¯çš„è¯†åˆ«æœåŠ¡ï¼š

```bash
# è¿›å…¥æ­£ç¡®çš„ç›®å½•
cd FunASR/runtime

# å¯åŠ¨æœåŠ¡è„šæœ¬ï¼Œå®ƒä¼šè‡ªåŠ¨ä¸‹è½½æ‰€éœ€çš„æ¨¡å‹åˆ° /workspace/models ç›®å½•
nohup bash run_server.sh \
  --download-model-dir /workspace/models \
  --vad-dir damo/speech_fsmn_vad_zh-cn-16k-common-onnx \
  --model-dir damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-onnx  \
  --punc-dir damo/punc_ct-transformer_cn-en-common-vocab471067-large-onnx \
  --lm-dir damo/speech_ngram_lm_zh-cn-ai-wesp-fst \
  --itn-dir thuduj12/fst_itn_zh \
  --hotword /workspace/models/hotwords.txt > log.txt 2>&1 &
```

æœåŠ¡ä¼šåœ¨åå°å¯åŠ¨ã€‚æ‚¨å¯ä»¥è¿è¡Œ tail -f log.txt æ¥æŸ¥çœ‹æ¨¡å‹çš„ä¸‹è½½å’ŒåŠ è½½è¿‡ç¨‹ã€‚å½“æ‚¨çœ‹åˆ°ç±»ä¼¼ "Started server on 0.0.0.0:10095" çš„æ—¥å¿—æ—¶ï¼Œå°±ä»£è¡¨æœåŠ¡ç«¯å·²ç»å‡†å¤‡å°±ç»ªäº†ã€‚

ä¸‹ä¸€æ­¥ï¼šç¡®è®¤æœåŠ¡çŠ¶æ€ï¼ˆåœ¨å½“å‰å®¹å™¨ç»ˆç«¯ï¼‰

ä¸ºäº†ç¡®ä¿æœåŠ¡å·²ç»å®Œå…¨å‡†å¤‡å°±ç»ªï¼Œæ‚¨å¯ä»¥åœ¨å½“å‰è¿™ä¸ªå®¹å™¨çš„ç»ˆç«¯ (root@dca31...) é‡Œï¼Œè¾“å…¥ä¸‹é¢çš„å‘½ä»¤æŸ¥çœ‹æ—¥å¿—ï¼š
```bash
tail -f log.txt
```

è¿™ä¸ªå‘½ä»¤ä¼šæŒç»­æ˜¾ç¤ºæ—¥å¿—çš„æœ€æ–°å†…å®¹ã€‚è¯·è§‚å¯Ÿä¸€ä¸‹ï¼Œå½“æ‚¨çœ‹åˆ°ç±»ä¼¼ Started server on 0.0.0.0:10095 æˆ–è€…æ¨¡å‹åŠ è½½å®Œæˆçš„æ—¥å¿—æ—¶ï¼Œå°±è¯´æ˜æœåŠ¡ç«¯å·²ç»å‡†å¤‡å¥½æ¥æ”¶è¯·æ±‚äº†ã€‚
ç¡®è®¤å®Œæ¯•åï¼Œæ‚¨å¯ä»¥æŒ‰ Ctrl + C é€€å‡ºæ—¥å¿—æŸ¥çœ‹ï¼Œä½†è¯·ä¸è¦å…³é—­è¿™ä¸ªç»ˆç«¯çª—å£ï¼Œè®©æœåŠ¡ç»§ç»­åœ¨åå°è¿è¡Œã€‚

### docker run

ä¹‹åï¼Œå†è¿›å…¥dockerå¯ä»¥ä½¿ç”¨ï¼š

å¦‚æœå®¹å™¨æ­£åœ¨è¿è¡Œ (Up): è¿™æ˜¯æœ€ç†æƒ³çš„æƒ…å†µï¼è¯´æ˜æ‚¨çš„è¯†åˆ«æœåŠ¡è¿˜åœ¨åå°è¿è¡Œã€‚æ‚¨åªéœ€è¦ç”¨ exec å‘½ä»¤åœ¨å®¹å™¨é‡Œæ‰“å¼€ä¸€ä¸ªæ–°çš„ç»ˆç«¯çª—å£å³å¯â€œè¿›å…¥â€ï¼š
```bash
sudo docker exec -it funasr_server /bin/bash
```
æ‰§è¡Œåï¼Œæ‚¨å°±ä¼šç«‹åˆ»å›åˆ°ç†Ÿæ‚‰çš„ root@... å‘½ä»¤è¡Œç•Œé¢ã€‚
å¦‚æœå®¹å™¨å·²ç»åœæ­¢ (Exited): è¿™è¯´æ˜æ‚¨å¯èƒ½å…³é—­äº†å®ƒã€‚æ²¡å…³ç³»ï¼Œæˆ‘ä»¬åˆ†ä¸¤æ­¥èµ°ï¼šå…ˆå¯åŠ¨å®ƒï¼Œå†è¿›å…¥å®ƒã€‚
```bash
# ç¬¬ä¸€æ­¥ï¼šé‡å¯å®¹å™¨
sudo docker start funasr_server

# ç¬¬äºŒæ­¥ï¼šè¿›å…¥å®¹å™¨
sudo docker exec -it funasr_server /bin/bash
```
```

--------------------------------------------------------------------------------

File: experiments.py
```python
import csv
import matplotlib.pyplot as plt
import numpy as np
from scipy.interpolate import make_interp_spline
from multiprocessing import Queue, Process
import websockets, ssl, asyncio, json, os, argparse

# DEBUG=8
DEBUG = float('inf')

parser = argparse.ArgumentParser()
parser.add_argument("--host", type=str, default="localhost", required=False, help="host ip, localhost, 0.0.0.0")
parser.add_argument("--port", type=int, default=10095, required=False, help="grpc server port")

args = parser.parse_args()
args.chunk_size = [5, 10, 5]
args.chunk_interval = 10
args.audio_fs = 16000
args.thread_num = 1
args.ssl = 1
args.use_itn = 1

voices = Queue()
offline_msg_done=False

async def record_microphone():
    import pyaudio
    global voices
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    chunk_size = 60 * args.chunk_size[1] / args.chunk_interval
    CHUNK = int(RATE / 1000 * chunk_size)

    p = pyaudio.PyAudio()

    stream = p.open(format=FORMAT,
                    channels=CHANNELS,
                    rate=RATE,
                    input=True,
                    frames_per_buffer=CHUNK)
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        f_scp = open(args.hotword)
        hot_lines = f_scp.readlines()
        for line in hot_lines:
            words = line.strip().split(" ")
            if len(words) < 2:
                continue
            try:
                fst_dict[" ".join(words[:-1])] = int(words[-1])
            except ValueError:
                continue
        hotword_msg=json.dumps(fst_dict)

    use_itn=True
    if args.use_itn == 0:
        use_itn=False
    
    message = json.dumps({"mode": "offline", "chunk_size": args.chunk_size, "chunk_interval": args.chunk_interval, "wav_name": "microphone", "is_speaking": True, "hotwords":hotword_msg, "itn": use_itn})
    await websocket.send(message)
    while True:
        data = stream.read(CHUNK)
        message = data
        await websocket.send(message)
        await asyncio.sleep(0.005)

async def record_from_scp(chunk_begin, chunk_size):
    global voices
    if args.audio_in.endswith(".scp"):
        f_scp = open(args.audio_in)
        wavs = f_scp.readlines()
    else:
        wavs = [args.audio_in]

    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        f_scp = open(args.hotword)
        hot_lines = f_scp.readlines()
        for line in hot_lines:
            words = line.strip().split(" ")
            if len(words) < 2:
                continue
            try:
                fst_dict[" ".join(words[:-1])] = int(words[-1])
            except ValueError:
                continue
        hotword_msg=json.dumps(fst_dict)

    sample_rate = args.audio_fs
    wav_format = "pcm"
    use_itn=True
    if args.use_itn == 0:
        use_itn=False
    if chunk_size > 0:
        wavs = wavs[chunk_begin:chunk_begin + chunk_size]
    for wav in wavs:
        wav_splits = wav.strip().split()
        wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
        wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
        if not len(wav_path.strip()) > 0:
            continue
        if wav_path.endswith(".pcm"):
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()
        elif wav_path.endswith(".wav"):
            import wave
            with wave.open(wav_path, "rb") as wav_file:
                sample_rate = wav_file.getframerate()
                frames = wav_file.readframes(wav_file.getnframes())
                audio_bytes = bytes(frames)        
        else:
            wav_format = "others"
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()

        stride = int(60 * args.chunk_size[1] / args.chunk_interval / 1000 * sample_rate * 2)
        chunk_num = (len(audio_bytes) - 1) // stride + 1
        message = json.dumps({"mode": "offline", "chunk_size": args.chunk_size, "chunk_interval": args.chunk_interval, "audio_fs":sample_rate, "wav_name": wav_name, "wav_format": wav_format, "is_speaking": True, "hotwords":hotword_msg, "itn": use_itn})
        await websocket.send(message)
        is_speaking = True
        for i in range(chunk_num):
            beg = i * stride
            data = audio_bytes[beg:beg + stride]
            message = data
            await websocket.send(message)
            if i == chunk_num - 1:
                is_speaking = False
                message = json.dumps({"is_speaking": is_speaking})
                await websocket.send(message)
            
            sleep_duration = 0.001
            await asyncio.sleep(sleep_duration)
    
    global offline_msg_done
    while not offline_msg_done:
        await asyncio.sleep(1)
    
    await websocket.close()

async def message(id, result_queue):
    global websocket, voices, offline_msg_done
    try:
        while True:
            meg = await websocket.recv()
            meg = json.loads(meg)
            text = meg["text"]
            offline_msg_done = meg.get("is_final", False)
            result_queue.put(text)
            if 'mode' not in meg:
                continue
            if meg["mode"] == "offline":
                result_queue.put(text)
                offline_msg_done = True
    except Exception as e:
        print("Exception:", e)

async def ws_client(id, chunk_begin, chunk_size, result_queue):
    global websocket, voices, offline_msg_done
    for i in range(chunk_begin, chunk_begin+chunk_size):
        offline_msg_done=False
        voices = Queue()
        if args.ssl == 1:
            ssl_context = ssl.SSLContext()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE
            uri = "wss://{}:{}".format(args.host, args.port)
        else:
            uri = "ws://{}:{}".format(args.host, args.port)
            ssl_context = None
        async with websockets.connect(uri, subprotocols=["binary"], ping_interval=None, ssl=ssl_context) as websocket:
            if args.audio_in is not None:
                task = asyncio.create_task(record_from_scp(i, 1))
            else:
                task = asyncio.create_task(record_microphone())
            task3 = asyncio.create_task(message(str(id)+"_"+str(i), result_queue))
            await asyncio.gather(task, task3)
    exit(0)
    
def one_thread(id, chunk_begin, chunk_size, result_queue):
    asyncio.get_event_loop().run_until_complete(ws_client(id, chunk_begin, chunk_size, result_queue))
    asyncio.get_event_loop().run_forever()


def run_audio(audio_file, hotwords=""):
    args.audio_in = audio_file
    args.hotword = hotwords
    result_queue = Queue()

    if args.audio_in is None:
        p = Process(target=one_thread, args=(0, 0, 0, result_queue))
        p.start()
        p.join()
    else:
        if args.audio_in.endswith(".scp"):
            with open(args.audio_in) as f_scp:
                wavs = f_scp.readlines()
        else:
            wavs = [args.audio_in]
        total_len = len(wavs)
        
        if total_len >= args.thread_num:
            chunk_size = int(total_len / args.thread_num)
            remain_wavs = total_len - chunk_size * args.thread_num
        else:
            chunk_size = 1
            remain_wavs = 0
        
        process_list = []
        chunk_begin = 0
        for i in range(args.thread_num):
            now_chunk_size = chunk_size
            if remain_wavs > 0:
                now_chunk_size = chunk_size + 1
                remain_wavs -= 1
            p = Process(target=one_thread, args=(i, chunk_begin, now_chunk_size, result_queue))
            chunk_begin += now_chunk_size
            p.start()
            process_list.append(p)
        
        for p in process_list:
            p.join()
    result = []
    while not result_queue.empty():
        result.append(result_queue.get())
    return "\n".join(set(result))

class Experiments:
    def __init__(self):
        self.hotwords_path  = './samples/python/speech_asr_aishell_hotwords_testsets/hotwords.txt'
        self.reference_path = './samples/python/speech_asr_aishell_hotwords_testsets/speech_asr_aishell_hotwords_testsets.csv'
        self.reference = []
        self.results   = []
        self.cnt = 0
        
        self.hotwords = self.load_hotwords(self.hotwords_path)
        self.pre_process()
    
    def load_hotwords(self, path):
        hotwords = set()
        with open(path, 'r', encoding='utf-8') as f:
            for line in f:
                word = line.strip().split()[0]
                hotwords.add(word)
        return hotwords
    
    @staticmethod
    def min_distance(word1: str, word2: str) -> int:
        row = len(word1) + 1
        column = len(word2) + 1
        cache = [ [0]*column for _ in range(row) ]
        for i in range(row):
            for j in range(column):
                if i ==0 and j ==0:
                    cache[i][j] = 0
                elif i == 0 and j!=0:
                    cache[i][j] = j
                elif j == 0 and i!=0:
                    cache[i][j] = i
                else:
                    if word1[i-1] == word2[j-1]:
                        cache[i][j] = cache[i-1][j-1]
                    else:
                        replace = cache[i-1][j-1] + 1
                        insert = cache[i][j-1] + 1
                        remove = cache[i-1][j] + 1
                        cache[i][j] = min(replace, insert, remove)
        return cache[row-1][column-1]

    def pre_process(self):
        ...

    def process_data(self):
        with open(self.reference_path, 'r', encoding='utf-8') as file:
            reader = csv.reader(file)
            next(reader)
            for i, row in enumerate(reader):
                if i >= DEBUG:
                    break
                input_audio, reference = row
                input_audio = input_audio
                reference = reference.replace(' ', '')
                result_no_hotword, result_with_hotword = self.generate(input_audio)
                cer_no_hotword, ref_len_no_hotword = self.calculate_cer(reference, result_no_hotword)
                cer_with_hotword, ref_len_with_hotword = self.calculate_cer(reference, result_with_hotword)
                precision_no_hotword, recall_no_hotword = self.calculate_precision_recall(reference, result_no_hotword)
                precision_with_hotword, recall_with_hotword = self.calculate_precision_recall(reference, result_with_hotword)
                self.results.append({
                    "input_audio": input_audio,
                    "reference": reference,
                    "result_no_hotword": result_no_hotword,
                    "result_with_hotword": result_with_hotword,
                    "cer_no_hotword": cer_no_hotword,
                    "cer_with_hotword": cer_with_hotword,
                    "ref_len_no_hotword": ref_len_no_hotword,
                    "ref_len_with_hotword": ref_len_with_hotword,
                    "precision_no_hotword": precision_no_hotword,
                    "recall_no_hotword": recall_no_hotword,
                    "precision_with_hotword": precision_with_hotword,
                    "recall_with_hotword": recall_with_hotword,
                })

    def generate(self, input_audio: str):
        try:
            print(str(self.cnt)+": "+input_audio)
            self.cnt += 1
            result_no_hotword = run_audio(input_audio).replace('ï¼Œ', '')
            result_with_hotword = run_audio(input_audio, self.hotwords_path).replace('ï¼Œ', '')
            return result_no_hotword.replace(' ', '').split("\n")[0], result_with_hotword.replace(' ', '').split("\n")[0]
        except Exception as e:
            print(f"Error generating ASR results: {e}")
            return "", ""

    def calculate_precision_recall(self, reference: str, hypothesis: str):
        ref_hotwords = set([word for word in self.hotwords if word in reference])
        hyp_hotwords = set([word for word in self.hotwords if word in hypothesis])
        true_positives = len(ref_hotwords & hyp_hotwords)
        precision = true_positives / len(hyp_hotwords) if hyp_hotwords else 0
        recall = true_positives / len(ref_hotwords) if ref_hotwords else 0
        return precision, recall

    def calculate_cer(self, reference: str, hypothesis: str):
        distance = self.min_distance(reference, hypothesis)
        len_ref = len(reference)
        if len_ref == 0:
            return 0, 0
        return (distance / len(reference)) * 100, len(reference)

    def post_process(self):
        # Calculate total CER
        avg_no_hotword = sum(result["ref_len_no_hotword"] for result in self.results)
        avg_with_hotword = sum(result["ref_len_with_hotword"] for result in self.results)
        self.sum_data = len(self.results)
        self.avg_cer_no_hotword = 0.0 if self.sum_data < 1 else sum(result["cer_no_hotword"] for result in self.results) / self.sum_data
        self.avg_cer_with_hotword = 0.0 if self.sum_data < 1 else sum(result["cer_with_hotword"] for result in self.results) / self.sum_data
        self.weighted_cer_no_hotword = 0.0 if avg_no_hotword < 1 else sum(result["cer_no_hotword"] * result["ref_len_no_hotword"] for result in self.results) / avg_no_hotword
        self.weighted_cer_with_hotword = 0.0 if avg_with_hotword < 1 else sum(result["cer_with_hotword"] * result["ref_len_with_hotword"] for result in self.results) / avg_with_hotword

        # Calculate Precision, Recall, and F1-Score
        self.avg_precision_no_hotword = sum(result["precision_no_hotword"] for result in self.results) / self.sum_data
        self.avg_recall_no_hotword = sum(result["recall_no_hotword"] for result in self.results) / self.sum_data
        self.avg_precision_with_hotword = sum(result["precision_with_hotword"] for result in self.results) / self.sum_data
        self.avg_recall_with_hotword = sum(result["recall_with_hotword"] for result in self.results) / self.sum_data
        self.f1_score_no_hotword = 2 * (self.avg_precision_no_hotword * self.avg_recall_no_hotword) / (self.avg_precision_no_hotword + self.avg_recall_no_hotword) if (self.avg_precision_no_hotword + self.avg_recall_no_hotword) > 0 else 0
        self.f1_score_with_hotword = 2 * (self.avg_precision_with_hotword * self.avg_recall_with_hotword) / (self.avg_precision_with_hotword + self.avg_recall_with_hotword) if (self.avg_precision_with_hotword + self.avg_recall_with_hotword) > 0 else 0

        # Plot image
        self.plot('output.png')
        self.plot('output_new.png', True)

    def plot(self, filename, smooth=False):
        cer_no_hotword = [result["cer_no_hotword"] for result in self.results]
        cer_with_hotword = [result["cer_with_hotword"] for result in self.results]
        bins = np.arange(0, max(cer_no_hotword + cer_with_hotword) + 5, 5)
        count_no_hotword, _ = np.histogram(cer_no_hotword, bins=bins)
        count_with_hotword, _ = np.histogram(cer_with_hotword, bins=bins)
        x = bins[:-1] + 2.5
        plt.figure(figsize=(12, 6))

        if smooth:
            x_smooth = np.linspace(x.min(), x.max(), 300)
            spl_no_hotword = make_interp_spline(x, count_no_hotword, k=3)
            spl_with_hotword = make_interp_spline(x, count_with_hotword, k=3)
            count_no_hotword_smooth = spl_no_hotword(x_smooth)
            count_with_hotword_smooth = spl_with_hotword(x_smooth)
            plt.plot(x_smooth, count_no_hotword_smooth, label='No Hotword', color='blue')
            plt.plot(x_smooth, count_with_hotword_smooth, label='With Hotword', color='red')
        else:
            plt.scatter(x, count_no_hotword, label='No Hotword', color='blue')
            plt.scatter(x, count_with_hotword, label='With Hotword', color='red')

        plt.xlabel('CER Range')
        plt.ylabel('Count')
        plt.legend(loc='lower left', title=f'Counts of data: {self.sum_data}')
        plt.title('CER Distribution')
        plt.savefig('./images/' + filename)
        plt.show()

    def show(self):
        print()
        for result in self.results:
            print(f"\nInput Audio: {result['input_audio']}")
            print(f"Reference:         {result['reference']}")
            print(f"No Hotwords:       {result['result_no_hotword']}")
            print(f"With Hotwords:     {result['result_with_hotword']}")
            print(f"CER(%) no hotwords:   {result['cer_no_hotword']:.4f}")
            print(f"CER(%) with hotwords: {result['cer_with_hotword']:.4f}")

        print()
        print(f"Average CER(%) no hotwords:    {self.avg_cer_no_hotword:.4f}")
        print(f"Average CER(%) with hotwords:  {self.avg_cer_with_hotword:.4f}")
        print(f"Weighted CER(%) no hotwords:   {self.weighted_cer_no_hotword:.4f}")
        print(f"Weighted CER(%) with hotwords: {self.weighted_cer_with_hotword:.4f}")
        print(f"Counts of data:                {self.sum_data}")

        print(f"\nHotwords Metrics (No Hotwords):")
        print(f"Precision: {self.avg_precision_no_hotword:.4f}")
        print(f"Recall:    {self.avg_recall_no_hotword:.4f}")
        print(f"F1-Score: {self.f1_score_no_hotword:.4f}")

        print(f"\nHotwords Metrics (With Hotwords):")
        print(f"Precision: {self.avg_precision_with_hotword:.4f}")
        print(f"Recall:    {self.avg_recall_with_hotword:.4f}")
        print(f"F1-Score: {self.f1_score_with_hotword:.4f}")

if __name__ == '__main__':
    e = Experiments()
    e.process_data()
    e.post_process()
    e.show()
```

--------------------------------------------------------------------------------

File: pytest.ini
```ini
[pytest]
pythonpath = .
```

--------------------------------------------------------------------------------

File: build.ps1
```powershell
# ASR System with Hotword Prediction - Build Script (PowerShell)

# Color definitions
$Green = 'Green'
$Blue = 'Cyan'
$Red = 'Red'
$Yellow = 'Yellow'

Write-Host "=== ASR System with Hotword Prediction - Build Script ===" -ForegroundColor $Blue
Write-Host "=== Starting build process... ===" -ForegroundColor $Blue

# Create virtual environment
Write-Host ">>> Creating Python virtual environment..." -ForegroundColor $Green
python -m venv venv
if (-not $?) {
    Write-Host "Failed to create virtual environment! Please make sure Python 3.6+ is installed." -ForegroundColor $Red
    exit 1
}

# Activate virtual environment
Write-Host ">>> Activating Python virtual environment..." -ForegroundColor $Green
.\venv\Scripts\Activate.ps1
if (-not $?) {
    Write-Host "Failed to activate virtual environment!" -ForegroundColor $Red
    exit 1
}

# Create upload directory
Write-Host ">>> Creating necessary directories..." -ForegroundColor $Green
New-Item -ItemType Directory -Force -Path .\asr_system_backend\uploads | Out-Null

# Install backend dependencies
Write-Host ">>> Installing backend dependencies..." -ForegroundColor $Green
Push-Location .\asr_system_backend
pip install -r requirements.txt
if (-not $?) {
    Write-Host "Failed to install backend dependencies!" -ForegroundColor $Red
    Pop-Location
    exit 1
}
Pop-Location

# Install frontend dependencies
Write-Host ">>> Installing frontend dependencies..." -ForegroundColor $Green
Push-Location .\asr_system_frontend

# Copy environment file if it doesn't exist
if (-not (Test-Path ".env")) {
    Write-Host ">>> Creating frontend environment configuration..." -ForegroundColor $Green
    Copy-Item "env.example" ".env"
    Write-Host "âš ï¸  Please edit asr_system_frontend\.env file to set your configuration parameters" -ForegroundColor $Yellow
}

npm install
if (-not $?) {
    Write-Host "Failed to install frontend dependencies! You may need to install Node.js first." -ForegroundColor $Red
    Pop-Location
    exit 1
}
Pop-Location

# Run database migrations
Write-Host ">>> Initializing database..." -ForegroundColor $Green
Push-Location .\asr_system_backend

# Copy environment file if it doesn't exist
if (-not (Test-Path ".env")) {
    Write-Host ">>> Creating backend environment configuration..." -ForegroundColor $Green
    Copy-Item "env.example" ".env"
    Write-Host "âš ï¸  Please edit asr_system_backend\.env file to set your configuration parameters" -ForegroundColor $Yellow
}

# Use our initialization script
python init_db.py
if (-not $?) {
    Write-Host "Database initialization failed!" -ForegroundColor $Red
    Pop-Location
    exit 1
}

# Run Alembic migrations
$env:PYTHONPATH = "$($env:PYTHONPATH);$(Get-Location)"
alembic upgrade head
if (-not $?) {
    Write-Host "Database migration failed!" -ForegroundColor $Red
    Pop-Location
    exit 1
}
Pop-Location

Write-Host "=== Build completed successfully! ===" -ForegroundColor $Blue
Write-Host "=== Use .\run.ps1 to start the application ===" -ForegroundColor $Blue
```

--------------------------------------------------------------------------------

File: .gitignore
```text
.markdown
asr_system_frontend/node_modules
asr_system_frontend/package-lock.json
funasr-runtime-resources

asr_system.db
.backend_info.txt
.backend.pid
.frontend_info.txt
.frontend.pid

*.pt

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[codz]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py.cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# UV
#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#uv.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock
#poetry.toml

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#   pdm recommends including project-wide configuration in pdm.toml, but excluding .pdm-python.
#   https://pdm-project.org/en/latest/usage/project/#working-with-version-control
#pdm.lock
#pdm.toml
.pdm-python
.pdm-build/

# pixi
#   Similar to Pipfile.lock, it is generally recommended to include pixi.lock in version control.
#pixi.lock
#   Pixi creates a virtual environment in the .pixi directory, just like venv module creates one
#   in the .venv directory. It is recommended not to include this directory in version control.
.pixi

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.env.local
.env.development
.env.production
.envrc
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# æ•æ„Ÿé…ç½®æ–‡ä»¶
*/config/local.py
*/config/production.py
*/.env
*/.env.local

# ä¸Šä¼ æ–‡ä»¶å’Œä¸´æ—¶æ–‡ä»¶
uploads/
temp/
*/uploads/
*/temp/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

# Abstra
# Abstra is an AI-powered process automation framework.
# Ignore directories containing user credentials, local state, and settings.
# Learn more at https://abstra.io/docs
.abstra/

# Visual Studio Code
#  Visual Studio Code specific template is maintained in a separate VisualStudioCode.gitignore 
#  that can be found at https://github.com/github/gitignore/blob/main/Global/VisualStudioCode.gitignore
#  and can be added to the global gitignore or merged into this file. However, if you prefer, 
#  you could uncomment the following to ignore the entire vscode folder
# .vscode/

# Ruff stuff:
.ruff_cache/

# PyPI configuration file
.pypirc

# Cursor
#  Cursor is an AI-powered code editor. `.cursorignore` specifies files/directories to
#  exclude from AI features like autocomplete and code analysis. Recommended for sensitive data
#  refer to https://docs.cursor.com/context/ignore-files
.cursorignore
.cursorindexingignore

# Marimo
marimo/_static/
marimo/_lsp/
__marimo__/
# å¿½ç•¥æ‰€æœ‰ .msc åç¼€çš„æ–‡ä»¶
**/.msc
```

--------------------------------------------------------------------------------

File: verify_system.py
```python
#!/usr/bin/env python3
"""
ç³»ç»ŸåŠŸèƒ½éªŒè¯è„šæœ¬
ç”¨äºå¿«é€Ÿæ£€æŸ¥ASRç³»ç»Ÿçš„å„é¡¹åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
import time
import requests
import json
from pathlib import Path

class SystemVerifier:
    def __init__(self):
        self.base_url = "http://localhost:8080"
        self.frontend_url = "http://localhost:2956"
        self.token = None
        self.test_user = {
            "username": "test_user_" + str(int(time.time())),
            "password": "test123456"
        }
    
    def print_banner(self):
        print("=" * 60)
        print("     ASRç³»ç»ŸåŠŸèƒ½éªŒè¯")
        print("=" * 60)
        print()
    
    def check_backend_health(self):
        """æ£€æŸ¥åç«¯æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ"""
        print("ğŸ” æ£€æŸ¥åç«¯æœåŠ¡å¥åº·çŠ¶æ€...")
        try:
            response = requests.get(f"{self.base_url}/docs", timeout=5)
            if response.status_code == 200:
                print("âœ… åç«¯æœåŠ¡è¿è¡Œæ­£å¸¸")
                return True
            else:
                print("âŒ åç«¯æœåŠ¡å“åº”å¼‚å¸¸")
                return False
        except requests.exceptions.RequestException as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ°åç«¯æœåŠ¡: {e}")
            print("è¯·ç¡®ä¿åç«¯æœåŠ¡å·²å¯åŠ¨ (è¿è¡Œ ./run.sh æˆ– .\run.ps1)")
            return False
    
    def check_frontend_health(self):
        """æ£€æŸ¥å‰ç«¯æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ"""
        print("ğŸ” æ£€æŸ¥å‰ç«¯æœåŠ¡å¥åº·çŠ¶æ€...")
        try:
            response = requests.get(self.frontend_url, timeout=5)
            if response.status_code == 200:
                print("âœ… å‰ç«¯æœåŠ¡è¿è¡Œæ­£å¸¸")
                return True
            else:
                print("âŒ å‰ç«¯æœåŠ¡å“åº”å¼‚å¸¸")
                return False
        except requests.exceptions.RequestException as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ°å‰ç«¯æœåŠ¡: {e}")
            print("è¯·ç¡®ä¿å‰ç«¯æœåŠ¡å·²å¯åŠ¨")
            return False
    
    def test_user_registration(self):
        """æµ‹è¯•ç”¨æˆ·æ³¨å†ŒåŠŸèƒ½"""
        print("ğŸ” æµ‹è¯•ç”¨æˆ·æ³¨å†ŒåŠŸèƒ½...")
        try:
            response = requests.post(
                f"{self.base_url}/auth/register",
                json=self.test_user,
                timeout=10
            )
            if response.status_code == 200:
                print("âœ… ç”¨æˆ·æ³¨å†ŒåŠŸèƒ½æ­£å¸¸")
                return True
            else:
                print(f"âŒ ç”¨æˆ·æ³¨å†Œå¤±è´¥: {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ ç”¨æˆ·æ³¨å†Œæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_user_login(self):
        """æµ‹è¯•ç”¨æˆ·ç™»å½•åŠŸèƒ½"""
        print("ğŸ” æµ‹è¯•ç”¨æˆ·ç™»å½•åŠŸèƒ½...")
        try:
            # å‡†å¤‡è¡¨å•æ•°æ®æ ¼å¼
            login_data = {
                "username": self.test_user["username"],
                "password": self.test_user["password"]
            }
            
            response = requests.post(
                f"{self.base_url}/auth/login",
                data=login_data,
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                if "access_token" in result:
                    self.token = result["access_token"]
                    print("âœ… ç”¨æˆ·ç™»å½•åŠŸèƒ½æ­£å¸¸")
                    return True
                else:
                    print("âŒ ç™»å½•å“åº”ä¸­ç¼ºå°‘token")
                    return False
            else:
                print(f"âŒ ç”¨æˆ·ç™»å½•å¤±è´¥: {response.status_code}")
                print(f"å“åº”å†…å®¹: {response.text}")
                return False
        except Exception as e:
            print(f"âŒ ç”¨æˆ·ç™»å½•æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_hotword_management(self):
        """æµ‹è¯•çƒ­è¯ç®¡ç†åŠŸèƒ½"""
        print("ğŸ” æµ‹è¯•çƒ­è¯ç®¡ç†åŠŸèƒ½...")
        if not self.token:
            print("âŒ éœ€è¦å…ˆç™»å½•æ‰èƒ½æµ‹è¯•çƒ­è¯ç®¡ç†")
            return False
        
        headers = {"Authorization": f"Bearer {self.token}"}
        
        try:
            # æµ‹è¯•åˆ›å»ºçƒ­è¯
            hotword_data = {"word": "æµ‹è¯•çƒ­è¯", "weight": 8}
            response = requests.post(
                f"{self.base_url}/hotwords",
                json=hotword_data,
                headers=headers,
                timeout=10
            )
            
            if response.status_code == 200:
                hotword = response.json()
                hotword_id = hotword["id"]
                
                # æµ‹è¯•è·å–çƒ­è¯åˆ—è¡¨
                response = requests.get(
                    f"{self.base_url}/hotwords",
                    headers=headers,
                    timeout=10
                )
                
                if response.status_code == 200:
                    hotwords = response.json()
                    if len(hotwords) > 0:
                        print("âœ… çƒ­è¯ç®¡ç†åŠŸèƒ½æ­£å¸¸")
                        
                        # æ¸…ç†æµ‹è¯•æ•°æ®
                        requests.delete(
                            f"{self.base_url}/hotwords/{hotword_id}",
                            headers=headers
                        )
                        return True
                    else:
                        print("âŒ çƒ­è¯åˆ—è¡¨ä¸ºç©º")
                        return False
                else:
                    print("âŒ è·å–çƒ­è¯åˆ—è¡¨å¤±è´¥")
                    return False
            else:
                print(f"âŒ åˆ›å»ºçƒ­è¯å¤±è´¥: {response.status_code}")
                return False
                
        except Exception as e:
            print(f"âŒ çƒ­è¯ç®¡ç†æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_transcription_api(self):
        """æµ‹è¯•è½¬å†™APIï¼ˆä¸ä¸Šä¼ çœŸå®æ–‡ä»¶ï¼‰"""
        print("ğŸ” æµ‹è¯•è½¬å†™APIç«¯ç‚¹...")
        if not self.token:
            print("âŒ éœ€è¦å…ˆç™»å½•æ‰èƒ½æµ‹è¯•è½¬å†™API")
            return False
        
        headers = {"Authorization": f"Bearer {self.token}"}
        
        try:
            # æµ‹è¯•è·å–ä»»åŠ¡åˆ—è¡¨API
            response = requests.get(
                f"{self.base_url}/asr/tasks",
                headers=headers,
                timeout=10
            )
            
            if response.status_code == 200:
                print("âœ… è½¬å†™APIç«¯ç‚¹æ­£å¸¸")
                return True
            else:
                print(f"âŒ è½¬å†™APIæµ‹è¯•å¤±è´¥: {response.status_code}")
                return False
                
        except Exception as e:
            print(f"âŒ è½¬å†™APIæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def check_database(self):
        """æ£€æŸ¥æ•°æ®åº“è¿æ¥"""
        print("ğŸ” æ£€æŸ¥æ•°æ®åº“è¿æ¥...")
        try:
            # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            db_path = Path("asr_system_backend/asr_system.db")
            if db_path.exists():
                print("âœ… æ•°æ®åº“æ–‡ä»¶å­˜åœ¨")
                return True
            else:
                print("âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
                print("è¯·è¿è¡Œæ•°æ®åº“åˆå§‹åŒ–: cd asr_system_backend && python init_db.py")
                return False
        except Exception as e:
            print(f"âŒ æ•°æ®åº“æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def check_required_files(self):
        """æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        print("ğŸ” æ£€æŸ¥å¿…è¦æ–‡ä»¶...")
        
        required_files = [
            "asr_system_backend/app/main.py",
            "asr_system_backend/app/models.py",
            "asr_system_backend/app/asr_engine.py",
            "asr_system_backend/app/rag_service.py",
            "asr_system_frontend/src/main.js",
            "asr_system_frontend/src/App.vue",
        ]
        
        all_exist = True
        for file_path in required_files:
            if Path(file_path).exists():
                print(f"âœ… {file_path}")
            else:
                print(f"âŒ {file_path} ç¼ºå¤±")
                all_exist = False
        
        return all_exist
    
    def print_summary(self, results):
        """æ‰“å°æµ‹è¯•ç»“æœæ‘˜è¦"""
        print("\n" + "=" * 60)
        print("     æµ‹è¯•ç»“æœæ‘˜è¦")
        print("=" * 60)
        
        passed = sum(results.values())
        total = len(results)
        
        for test_name, result in results.items():
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"{test_name:<20} {status}")
        
        print("-" * 60)
        print(f"æ€»è®¡: {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡")
        
        if passed == total:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼")
            print("\nğŸš€ æ‚¨ç°åœ¨å¯ä»¥ï¼š")
            print("   - è®¿é—®å‰ç«¯ç•Œé¢: http://localhost:2956")
            print("   - æŸ¥çœ‹APIæ–‡æ¡£: http://localhost:8080/docs")
            print("   - å¼€å§‹ä½¿ç”¨è¯­éŸ³è¯†åˆ«åŠŸèƒ½")
        else:
            print(f"\nâš ï¸  æœ‰ {total - passed} é¡¹æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ç»„ä»¶")
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        self.print_banner()
        
        results = {}
        
        # åŸºç¡€ç¯å¢ƒæ£€æŸ¥
        results["å¿…è¦æ–‡ä»¶æ£€æŸ¥"] = self.check_required_files()
        results["æ•°æ®åº“æ£€æŸ¥"] = self.check_database()
        results["åç«¯æœåŠ¡"] = self.check_backend_health()
        results["å‰ç«¯æœåŠ¡"] = self.check_frontend_health()
        
        # åŠŸèƒ½æµ‹è¯•ï¼ˆåªæœ‰åœ¨æœåŠ¡æ­£å¸¸æ—¶æ‰æ‰§è¡Œï¼‰
        if results["åç«¯æœåŠ¡"]:
            results["ç”¨æˆ·æ³¨å†Œ"] = self.test_user_registration()
            results["ç”¨æˆ·ç™»å½•"] = self.test_user_login()
            results["çƒ­è¯ç®¡ç†"] = self.test_hotword_management()
            results["è½¬å†™API"] = self.test_transcription_api()
        
        self.print_summary(results)
        
        return all(results.values())

def main():
    verifier = SystemVerifier()
    success = verifier.run_all_tests()
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
```

--------------------------------------------------------------------------------

File: test_transcription.py
```python
import requests
import json
import os
import time

# é…ç½®
API_BASE = "http://localhost:8080/api"
TEST_AUDIO = "client/BAC009S0764W0179.wav"
TEST_USER = {
    "username": "testuser",
    "password": "testpass123"
}

def register_user():
    """æ³¨å†Œæµ‹è¯•ç”¨æˆ·"""
    try:
        response = requests.post(f"{API_BASE}/auth/register", json=TEST_USER)
        print("æ³¨å†Œç»“æœ:", response.json())
    except:
        print("ç”¨æˆ·å¯èƒ½å·²å­˜åœ¨,ç»§ç»­ç™»å½•")

def login():
    """ç™»å½•å¹¶è·å–token"""
    response = requests.post(f"{API_BASE}/auth/login", data=TEST_USER)
    return response.json()["access_token"]

def upload_and_transcribe(token):
    """ä¸Šä¼ éŸ³é¢‘å¹¶è·å–è½¬å†™ç»“æœ"""
    headers = {"Authorization": f"Bearer {token}"}
    
    # ä¸Šä¼ æ–‡ä»¶
    print("æ­£åœ¨ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶...")
    with open(TEST_AUDIO, "rb") as f:
        files = {"file": (os.path.basename(TEST_AUDIO), f)}
        response = requests.post(
            f"{API_BASE}/asr/transcribe/file",
            headers=headers,
            files=files
        )
        
        if not response.ok:
            print("ä¸Šä¼ å¤±è´¥:", response.text)
            return
            
        task_id = response.json()["id"]
        print(f"ä¸Šä¼ æˆåŠŸ,ä»»åŠ¡ID: {task_id}")
    
    # ç­‰å¾…å¤„ç†å®Œæˆå¹¶è·å–ç»“æœ
    print("ç­‰å¾…è½¬å†™å®Œæˆ...")
    time.sleep(2)  # ç»™ä¸€äº›å¤„ç†æ—¶é—´
    
    response = requests.get(
        f"{API_BASE}/asr/tasks/{task_id}/output",
        headers=headers
    )
    
    if response.ok:
        result = response.json()
        print("\nè½¬å†™ç»“æœ:")
        print("-" * 50)
        print(result["terminal_output"])
        print("-" * 50)
    else:
        print("è·å–ç»“æœå¤±è´¥:", response.text)

def main():
    print("å¼€å§‹æµ‹è¯•è½¬å†™åŠŸèƒ½...")
    register_user()
    token = login()
    upload_and_transcribe(token)

if __name__ == "__main__":
    main()
```

--------------------------------------------------------------------------------

File: prompt.py
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import argparse
from pathlib import Path
import pathspec
from tqdm import tqdm

# --- é…ç½®éƒ¨åˆ† (æ— å˜åŒ–) ---
DEFAULT_EXCLUDE_PATTERNS = [
    "*.pyc", "__pycache__/", "*.o", "*.a", "*.so", "*.lib", "*.dll", "*.exe",
    ".idea/", ".vscode/", ".project", ".classpath", ".settings/", "node_modules/", "venv/", ".venv/",
    "*.log", "*.tmp", "*.bak", "*.swp",
    "*.png", "*.jpg", "*.jpeg", "*.gif", "*.bmp", "*.svg", "*.ico",
    "*.mp4", "*.mov", "*.avi", "*.mkv", "*.mp3", "*.wav", "*.flac",
    "*.zip", "*.tar.gz", "*.rar", "*.7z", "*.gz", "*.bz2",
    "*.pdf", "*.doc", "*.docx", "*.xls", "*.xlsx", "*.ppt", "*.pptx", "*.db", "*.sqlite3",
    "*.txt", "*.json"
]
DEFAULT_MAX_FILE_SIZE = 200 * 1024
LANGUAGE_MAP = {
    ".py": "python", ".pyw": "python", ".js": "javascript", ".jsx": "javascript",
    ".ts": "typescript", ".tsx": "typescript", ".c": "c", ".h": "c", ".cpp": "cpp",
    ".hpp": "cpp", ".cxx": "cpp", ".java": "java", ".go": "go", ".rs": "rust",
    ".rb": "ruby", ".php": "php", ".cs": "csharp", ".swift": "swift", ".kt": "kotlin",
    ".scala": "scala", ".sh": "shell", ".bash": "shell", ".ps1": "powershell",
    ".bat": "batch", ".sql": "sql", ".html": "html", ".htm": "html", ".css": "css",
    ".json": "json", ".xml": "xml", ".yaml": "yaml", ".yml": "yaml", ".toml": "toml",
    ".md": "markdown", ".markdown": "markdown", ".rst": "rst", ".txt": "text",
    "Dockerfile": "dockerfile", ".env": "ini", ".ini": "ini", ".conf": "ini",
}

# --- è¾…åŠ©å‡½æ•° ---
def get_language_identifier(filepath: Path) -> str:
    if filepath.name in LANGUAGE_MAP: return LANGUAGE_MAP[filepath.name]
    return LANGUAGE_MAP.get(filepath.suffix.lower(), "text")

def is_likely_binary(filepath: Path, chunk_size=1024) -> bool:
    try:
        with open(filepath, 'rb') as f: return b'\0' in f.read(chunk_size)
    except IOError: return True

def find_git_root(start_path: Path) -> Path:
    current_path = start_path.resolve()
    while current_path != current_path.parent:
        if (current_path / ".git").is_dir(): return current_path
        current_path = current_path.parent
    return start_path.resolve()

# ã€ã€ã€BUGå·²å½»åº•ä¿®å¤çš„å‡½æ•°ã€‘ã€‘ã€‘
def load_gitignore_rules(git_root: Path) -> pathspec.PathSpec:
    """
    åªåŠ è½½é¡¹ç›®æ ¹ç›®å½•çš„.gitignoreæ–‡ä»¶ã€‚è¿™é¿å…äº†å­ç›®å½•ä¸­
    çš„.gitignoreæ–‡ä»¶ï¼ˆå¦‚submoduleæˆ–ä¾èµ–åŒ…ï¼‰çš„è§„åˆ™å¯¹æ•´ä¸ªé¡¹ç›®é€ æˆæ±¡æŸ“ã€‚
    """
    gitignore_path = git_root / '.gitignore'
    rules = []
    if gitignore_path.is_file():
        try:
            with open(gitignore_path, 'r', encoding='utf-8', errors='ignore') as f:
                rules = [line for line in (l.strip() for l in f) if line and not line.startswith('#')]
        except IOError:
            pass # æ— æ³•è¯»å–åˆ™å¿½ç•¥
    return pathspec.PathSpec.from_lines('gitwildmatch', rules)

# --- ä¸»å¤„ç†å‡½æ•° (é€»è¾‘å·²éªŒè¯æ­£ç¡®) ---
def process_project(project_root: str, output_file: str, extra_excludes: list, max_size: int,
                    include_exts: set = None, verbose: bool = False):
    root_path = Path(project_root).resolve()
    if not root_path.is_dir():
        print(f"é”™è¯¯: è·¯å¾„ '{project_root}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ç›®å½•ã€‚", file=sys.stderr); sys.exit(1)

    git_root = find_git_root(root_path)
    if verbose:
        print(f"é¡¹ç›®æ ¹ç›®å½•: {root_path}", file=sys.stderr)
        print(f"Gitæ ¹ç›®å½•: {git_root}", file=sys.stderr)
        print("ğŸ” æ­£åœ¨åŠ è½½ .gitignore è§„åˆ™...", file=sys.stderr)
    
    gitignore_spec = load_gitignore_rules(git_root)
    custom_spec = pathspec.PathSpec.from_lines('gitwildmatch', extra_excludes)

    if verbose: print("ğŸ“‚ æ­£åœ¨æ‰«æé¡¹ç›®æ–‡ä»¶...", file=sys.stderr)
    
    filtered_files = []
    # ä½¿ç”¨os.walkè¿›è¡Œéå†ï¼Œæ€§èƒ½å’Œæ§åˆ¶åŠ›éƒ½å¾ˆå¥½
    for dirpath, dirnames, filenames in os.walk(root_path, topdown=True, followlinks=False):
        current_dir_path = Path(dirpath)
        
        # è¿‡æ»¤ç›®å½•ï¼šåŸåœ°ä¿®æ”¹dirnamesåˆ—è¡¨ï¼Œos.walkå°±ä¸ä¼šå†è¿›å…¥è¿™äº›ç›®å½•
        dirs_to_keep = []
        for d in dirnames:
            dir_path_for_check = current_dir_path.relative_to(root_path) / d
            dir_path_str = dir_path_for_check.as_posix()
            
            # æ£€æŸ¥ç›®å½•æ—¶ï¼Œåœ¨æœ«å°¾æ·»åŠ æ–œæ '/'
            if gitignore_spec.match_file(dir_path_str + '/') or custom_spec.match_file(dir_path_str + '/'):
                continue
            else:
                dirs_to_keep.append(d)
        dirnames[:] = dirs_to_keep

        # è¿‡æ»¤æ–‡ä»¶
        for f in filenames:
            file_path = current_dir_path / f
            file_path_for_check = file_path.relative_to(root_path)
            file_path_str = file_path_for_check.as_posix()
            
            if gitignore_spec.match_file(file_path_str) or custom_spec.match_file(file_path_str):
                continue
            else:
                filtered_files.append(file_path)

    # å‡†å¤‡è¾“å‡º
    output_stream = open(output_file, 'w', encoding='utf-8') if output_file else sys.stdout
    try:
        file_iterator = tqdm(filtered_files, desc="ğŸš€ å¤„ç†æ–‡ä»¶ä¸­", unit="file", disable=not verbose, bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]")
        
        for filepath in file_iterator:
            if include_exts and filepath.suffix.lower() not in include_exts: continue
            
            relative_path_str = filepath.relative_to(root_path).as_posix()
            
            try:
                file_size = filepath.stat().st_size
                if file_size > max_size:
                    print(f"File: {relative_path_str}  (Skipped, size > {max_size / 1024:.0f}KB)", file=output_stream); print("\n" + "-"*80 + "\n", file=output_stream)
                    continue
                
                content = ""
                if file_size > 0:
                    if is_likely_binary(filepath): continue
                    content = filepath.read_text(encoding='utf-8')

            except (IOError, OSError, UnicodeDecodeError): continue
            
            language = get_language_identifier(filepath)
            print(f"File: {relative_path_str}", file=output_stream)
            print(f"```{language}", file=output_stream); print(content.strip(), file=output_stream); print("```", file=output_stream)
            print("\n" + "-"*80 + "\n", file=output_stream)
    finally:
        if output_file:
            output_stream.close()
            if verbose: print(f"âœ… å¤„ç†å®Œæˆï¼Œè¾“å‡ºå·²ä¿å­˜åˆ°: {output_file}", file=sys.stderr)

def main():
    parser = argparse.ArgumentParser(description="ä»é¡¹ç›®ç›®å½•ä¸­æå–å¯è¯»æºä»£ç å’Œæ–‡æœ¬æ–‡ä»¶ï¼Œæ ¼å¼åŒ–åè¾“å‡ºä»¥ä¾›LLMåˆ†æã€‚", formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument("project_root", help="è¦æ‰«æçš„é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ã€‚")
    parser.add_argument("-o", "--output", help="è¾“å‡ºæ–‡ä»¶çš„è·¯å¾„ã€‚å¦‚æœæœªæŒ‡å®šï¼Œåˆ™è¾“å‡ºåˆ°æ ‡å‡†è¾“å‡º (stdout)ã€‚")
    parser.add_argument("--exclude", nargs='*', default=DEFAULT_EXCLUDE_PATTERNS, help="è¦é¢å¤–æ’é™¤çš„æ–‡ä»¶/ç›®å½•çš„ glob æ¨¡å¼åˆ—è¡¨ã€‚")
    parser.add_argument("--include-ext", nargs='*', help="ä»…åŒ…å«æŒ‡å®šæ‰©å±•åçš„æ–‡ä»¶ (ç™½åå•æ¨¡å¼)ã€‚")
    parser.add_argument("--max-size", type=int, default=DEFAULT_MAX_FILE_SIZE, help=f"æ–‡ä»¶å†…å®¹çš„æœ€å¤§å¤§å°ï¼ˆå­—èŠ‚ï¼‰ã€‚")
    parser.add_argument("-v", "--verbose", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†å¤„ç†ä¿¡æ¯å’Œè¿›åº¦æ¡ã€‚")
    
    args = parser.parse_args()
    include_exts_set = {ext if ext.startswith('.') else '.' + ext.lower() for ext in args.include_ext} if args.include_ext else None

    process_project(project_root=args.project_root, output_file=args.output, extra_excludes=args.exclude,
                    max_size=args.max_size, include_exts=include_exts_set, verbose=args.verbose)

if __name__ == "__main__":
    main()
```

--------------------------------------------------------------------------------

File: build.sh
```shell
#!/bin/bash

# é¢œè‰²å®šä¹‰
GREEN='\033[0;32m'
BLUE='\033[0;34m'
RED='\033[0;31m'
NC='\033[0m' # No Color

echo -e "${BLUE}=== æ”¯æŒçƒ­è¯é¢„æµ‹çš„è¯­éŸ³è¯†åˆ«ç³»ç»Ÿæ„å»ºè„šæœ¬ ===${NC}"
echo -e "${BLUE}=== å¼€å§‹æ„å»ºé¡¹ç›®... ===${NC}"

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
echo -e "${GREEN}>>> åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ...${NC}"
python -m venv venv
source venv/bin/activate

# åˆ›å»ºä¸Šä¼ ç›®å½•
echo -e "${GREEN}>>> åˆ›å»ºå¿…è¦çš„ç›®å½•...${NC}"
mkdir -p asr_system_backend/uploads

# å®‰è£…åç«¯ä¾èµ–
echo -e "${GREEN}>>> å®‰è£…åç«¯ä¾èµ–...${NC}"
cd asr_system_backend
pip install -r requirements.txt
cd ..

# å®‰è£…å‰ç«¯ä¾èµ–
echo -e "${GREEN}>>> å®‰è£…å‰ç«¯ä¾èµ–...${NC}"
cd asr_system_frontend

# å¤åˆ¶ç¯å¢ƒå˜é‡æ–‡ä»¶ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
if [ ! -f ".env" ]; then
    echo -e "${GREEN}>>> åˆ›å»ºå‰ç«¯ç¯å¢ƒé…ç½®æ–‡ä»¶...${NC}"
    cp env.example .env
    echo -e "${YELLOW}âš ï¸  è¯·ç¼–è¾‘ asr_system_frontend/.env æ–‡ä»¶ï¼Œè®¾ç½®æ‚¨çš„é…ç½®å‚æ•°${NC}"
fi

npm install
cd ..

# è¿è¡Œæ•°æ®åº“è¿ç§»
echo -e "${GREEN}>>> åˆå§‹åŒ–æ•°æ®åº“...${NC}"
cd asr_system_backend

# å¤åˆ¶ç¯å¢ƒå˜é‡æ–‡ä»¶ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
if [ ! -f ".env" ]; then
    echo -e "${GREEN}>>> åˆ›å»ºåç«¯ç¯å¢ƒé…ç½®æ–‡ä»¶...${NC}"
    cp env.example .env
    echo -e "${YELLOW}âš ï¸  è¯·ç¼–è¾‘ asr_system_backend/.env æ–‡ä»¶ï¼Œè®¾ç½®æ‚¨çš„é…ç½®å‚æ•°${NC}"
fi

# ä½¿ç”¨æˆ‘ä»¬çš„åˆå§‹åŒ–è„šæœ¬
python init_db.py

# è¿è¡ŒAlembicè¿ç§»
export PYTHONPATH=$PYTHONPATH:$(pwd)
alembic upgrade head
cd ..

echo -e "${BLUE}=== æ„å»ºå®Œæˆ! ===${NC}"
echo -e "${BLUE}=== ä½¿ç”¨ run.sh æ¥å¯åŠ¨åº”ç”¨ ===${NC}"
```

--------------------------------------------------------------------------------

File: README.md
```markdown
# æ”¯æŒçƒ­è¯é¢„æµ‹çš„è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ

ä¸€ä¸ªé›†æˆäº†çƒ­è¯é¢„æµ‹å’Œå¢å¼ºåŠŸèƒ½çš„æ™ºèƒ½è¯­éŸ³è¯†åˆ«ç³»ç»Ÿï¼Œä¸“ä¸ºæå‡ç‰¹å®šé¢†åŸŸè¯­éŸ³è¯†åˆ«å‡†ç¡®ç‡è€Œè®¾è®¡ã€‚

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬ç³»ç»Ÿæ˜¯ä¸€ä¸ªå®Œæ•´çš„è¯­éŸ³è¯†åˆ«è§£å†³æ–¹æ¡ˆï¼ŒåŒ…å«ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š

- **æ™ºèƒ½è¯­éŸ³è¯†åˆ«**ï¼šåŸºäºOpenAI Whisperçš„é«˜ç²¾åº¦è¯­éŸ³è½¬å†™
- **çƒ­è¯é¢„æµ‹ä¸å¢å¼º**ï¼šåˆ©ç”¨RAGæŠ€æœ¯æå‡ç‰¹å®šé¢†åŸŸæœ¯è¯­è¯†åˆ«ç‡
- **ç”¨æˆ·ç®¡ç†ç³»ç»Ÿ**ï¼šå®Œæ•´çš„æ³¨å†Œã€ç™»å½•å’Œæƒé™ç®¡ç†
- **æ–‡ä»¶æ‰¹é‡å¤„ç†**ï¼šæ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼çš„æ‰¹é‡è½¬å†™
- **å®æ—¶äº¤äº’ç•Œé¢**ï¼šç°ä»£åŒ–çš„Vue.jså‰ç«¯ç•Œé¢

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç³»ç»Ÿè¦æ±‚

- **Python**: 3.8+
- **Node.js**: 16+
- **npm**: 7+
- **æ“ä½œç³»ç»Ÿ**: Windows 10+, macOS 10.14+, Ubuntu 18.04+

### ä¸€é”®å®‰è£…

1. **å…‹éš†é¡¹ç›®**

   ```bash
   git clone <repository-url>
   cd asr-system
   ```
2. **è¿è¡Œè®¾ç½®è„šæœ¬**

   ```bash
   # æ£€æŸ¥ç³»ç»Ÿå…ˆå†³æ¡ä»¶
   python setup.py

   # Linux/Mac - å®Œæ•´æ„å»º
   ./build.sh

   # Windows - å®Œæ•´æ„å»º
   .\build.ps1
   ```
3. **å¯åŠ¨æœåŠ¡**

   ```bash
   # Linux/Mac
   ./run.sh

   # Windows
   .\run.ps1
   ```
4. **è®¿é—®åº”ç”¨**

   - ğŸŒ **å‰ç«¯ç•Œé¢**: http://localhost:5173
   - ğŸ”§ **APIæœåŠ¡**: http://localhost:8000
   - ğŸ“š **APIæ–‡æ¡£**: http://localhost:8000/docs

## ğŸ“ é¡¹ç›®æ¶æ„

```
asr-system/
â”œâ”€â”€ ğŸ”¥ asr_system_backend/          # FastAPIåç«¯æœåŠ¡
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                 # åº”ç”¨å…¥å£
â”‚   â”‚   â”œâ”€â”€ models.py               # æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ schemas.py              # APIæ¨¡å¼
â”‚   â”‚   â”œâ”€â”€ config.py               # é…ç½®ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ asr_engine.py           # ASRå¼•æ“
â”‚   â”‚   â”œâ”€â”€ rag_service.py          # RAGçƒ­è¯æœåŠ¡
â”‚   â”‚   â””â”€â”€ routers/                # APIè·¯ç”±
â”‚   â”œâ”€â”€ alembic/                    # æ•°æ®åº“è¿ç§»
â”‚   â”œâ”€â”€ requirements.txt            # Pythonä¾èµ–
â”‚   â””â”€â”€ env.example                 # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”œâ”€â”€ ğŸ¨ asr_system_frontend/         # Vue.jså‰ç«¯åº”ç”¨
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ views/                  # é¡µé¢ç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ router/                 # è·¯ç”±é…ç½®
â”‚   â”‚   â””â”€â”€ services/               # APIæœåŠ¡
â”‚   â”œâ”€â”€ tests/e2e/                  # E2Eæµ‹è¯•
â”‚   â”œâ”€â”€ package.json                # Node.jsä¾èµ–
â”‚   â””â”€â”€ env.example                 # å‰ç«¯ç¯å¢ƒå˜é‡
â”œâ”€â”€ ğŸ—„ï¸ sql/                        # æ•°æ®åº“ç»“æ„
â”œâ”€â”€ ğŸ§ª test/                       # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ ğŸ“ setup.py                    # ç³»ç»Ÿè®¾ç½®è„šæœ¬
â”œâ”€â”€ ğŸš€ build.sh/.ps1               # æ„å»ºè„šæœ¬
â”œâ”€â”€ â–¶ï¸ run.sh/.ps1                 # å¯åŠ¨è„šæœ¬
â””â”€â”€ ğŸ“– README.md                   # é¡¹ç›®æ–‡æ¡£
```

## âœ¨ æ ¸å¿ƒåŠŸèƒ½

### ğŸ¤ è¯­éŸ³è¯†åˆ«å¼•æ“

- **åŸºäºWhisper**ï¼šé‡‡ç”¨OpenAIæœ€æ–°Whisperæ¨¡å‹
- **å¤šæ ¼å¼æ”¯æŒ**ï¼šwav, mp3, m4a, flac, aac, ogg
- **æ‰¹é‡å¤„ç†**ï¼šæ”¯æŒå¤§æ‰¹é‡éŸ³é¢‘æ–‡ä»¶å¤„ç†
- **é«˜ç²¾åº¦è¯†åˆ«**ï¼šé’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–çš„è¯†åˆ«ç®—æ³•

### ğŸ” çƒ­è¯é¢„æµ‹ç³»ç»Ÿ

- **æ™ºèƒ½é¢„æµ‹**ï¼šåŸºäºRAGæŠ€æœ¯çš„çƒ­è¯å…³è”
- **æƒé‡è°ƒèŠ‚**ï¼š1-10çº§å¯è°ƒæƒé‡ç³»ç»Ÿ
- **æ‰¹é‡å¯¼å…¥**ï¼šæ”¯æŒCSV/TXTæ ¼å¼æ‰¹é‡å¯¼å…¥
- **å®æ—¶å¢å¼º**ï¼šè½¬å†™ç»“æœå®æ—¶çƒ­è¯å¢å¼º

### ğŸ‘¤ ç”¨æˆ·ç®¡ç†

- **å®‰å…¨è®¤è¯**ï¼šJWT Tokenè®¤è¯æœºåˆ¶
- **æƒé™éš”ç¦»**ï¼šç”¨æˆ·æ•°æ®å®Œå…¨éš”ç¦»
- **ä¼šè¯ç®¡ç†**ï¼šè‡ªåŠ¨ç™»å½•çŠ¶æ€ç®¡ç†

### ğŸ›ï¸ ç®¡ç†ç•Œé¢

- **å“åº”å¼è®¾è®¡**ï¼šæ”¯æŒæ¡Œé¢å’Œç§»åŠ¨è®¾å¤‡
- **å®æ—¶åé¦ˆ**ï¼šè½¬å†™è¿›åº¦å®æ—¶æ˜¾ç¤º
- **æ•°æ®å¯è§†åŒ–**ï¼šè½¬å†™ç»“æœç»Ÿè®¡å›¾è¡¨

## ğŸ”§ é…ç½®æŒ‡å—

### ç¯å¢ƒé…ç½®

1. **å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿**

   ```bash
   # åç«¯é…ç½®
   cp asr_system_backend/env.example asr_system_backend/.env

   # å‰ç«¯é…ç½®  
   cp asr_system_frontend/env.example asr_system_frontend/.env
   ```
2. **ç¼–è¾‘é…ç½®æ–‡ä»¶**

   ```bash
   # ç¼–è¾‘åç«¯é…ç½®
   nano asr_system_backend/.env

   # ç¼–è¾‘å‰ç«¯é…ç½®
   nano asr_system_frontend/.env
   ```

### é‡è¦é…ç½®é¡¹

**åç«¯é…ç½® (.env)**

```bash
# JWTå®‰å…¨å¯†é’¥ (è¯·ä¿®æ”¹ä¸ºéšæœºå­—ç¬¦ä¸²)
JWT_SECRET_KEY=your_secret_key_here

# ASRå¼•æ“é…ç½®
ASR_MODEL_SIZE=base          # tiny/base/small/medium/large
ASR_LANGUAGE=zh              # è¯†åˆ«è¯­è¨€
ASR_ENABLE_GPU=true          # æ˜¯å¦å¯ç”¨GPUåŠ é€Ÿ
```

**å‰ç«¯é…ç½® (.env)**

```bash
# APIæœåŠ¡åœ°å€
VITE_API_BASE_URL=http://localhost:8000
```

## ğŸ§ª æµ‹è¯•

### E2Eæµ‹è¯•

```bash
cd asr_system_frontend
npm run test:e2e
```

### åç«¯æµ‹è¯•

```bash
cd asr_system_backend
python -m pytest
```

## ğŸ“Š æ€§èƒ½ç‰¹ç‚¹

- **è¯†åˆ«å‡†ç¡®ç‡**: 95%+ (ä¸­æ–‡é€šç”¨åœºæ™¯)
- **çƒ­è¯å¢å¼º**: ç‰¹å®šé¢†åŸŸæå‡10-20%å‡†ç¡®ç‡
- **å¤„ç†é€Ÿåº¦**: å®æ—¶ç³»æ•° < 0.3 (GPUåŠ é€Ÿ)
- **å¹¶å‘æ”¯æŒ**: æ”¯æŒå¤šç”¨æˆ·åŒæ—¶ä½¿ç”¨
- **æ–‡ä»¶æ”¯æŒ**: æœ€å¤§100MBéŸ³é¢‘æ–‡ä»¶

## ğŸ› å¸¸è§é—®é¢˜

### Q: é¦–æ¬¡å¯åŠ¨æ—¶æ¨¡å‹ä¸‹è½½å¾ˆæ…¢ï¼Ÿ

A: ç³»ç»Ÿä¼šè‡ªåŠ¨ä¸‹è½½Whisperå’Œsentence-transformersæ¨¡å‹ï¼Œè¯·ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®šã€‚

### Q: GPUåŠ é€Ÿä¸ç”Ÿæ•ˆï¼Ÿ

A: è¯·ç¡®ä¿å®‰è£…äº†CUDAå’ŒPyTorch GPUç‰ˆæœ¬ã€‚

### Q: çƒ­è¯é¢„æµ‹ä¸å‡†ç¡®ï¼Ÿ

A: è¯·æ£€æŸ¥çƒ­è¯æƒé‡è®¾ç½®ï¼Œå»ºè®®é‡è¦æœ¯è¯­è®¾ç½®è¾ƒé«˜æƒé‡(8-10)ã€‚

### Q: æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Ÿ

A: æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒï¼Œä»¥åŠæ–‡ä»¶å¤§å°æ˜¯å¦è¶…è¿‡é™åˆ¶ã€‚

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.0.0 (2025-07-08)

- âœ… å®Œæˆæ ¸å¿ƒASRå¼•æ“é›†æˆ
- âœ… å®ç°çƒ­è¯ç®¡ç†CRUDåŠŸèƒ½
- âœ… å®Œæˆå‰ç«¯E2Eæµ‹è¯•æ¡†æ¶
- âœ… ç”¨æˆ·è®¤è¯ç³»ç»Ÿä¸Šçº¿
- âœ… RAGçƒ­è¯é¢„æµ‹æœåŠ¡

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

---

**æ³¨æ„**: æœ¬ç³»ç»Ÿä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ï¼Œç”Ÿäº§ç¯å¢ƒä½¿ç”¨å‰è¯·è¿›è¡Œå……åˆ†æµ‹è¯•ã€‚
```

--------------------------------------------------------------------------------

File: asr_system_frontend/env.example
```text
# å‰ç«¯ç¯å¢ƒå˜é‡é…ç½®æ¨¡æ¿
# è¯·å¤åˆ¶æ­¤æ–‡ä»¶ä¸º.envå¹¶å¡«å…¥çœŸå®å€¼

# APIæœåŠ¡å™¨åœ°å€
VITE_API_BASE_URL=http://localhost:8000

# åº”ç”¨åç§°
VITE_APP_NAME=æ”¯æŒçƒ­è¯é¢„æµ‹çš„è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ

# åº”ç”¨ç‰ˆæœ¬
VITE_APP_VERSION=1.0.0

# å¼€å‘æ¨¡å¼
VITE_DEV_MODE=true

# æ–‡ä»¶ä¸Šä¼ é™åˆ¶ï¼ˆMBï¼‰
VITE_MAX_FILE_SIZE=100

# æ”¯æŒçš„éŸ³é¢‘æ ¼å¼
VITE_SUPPORTED_AUDIO_FORMATS=.wav,.mp3,.m4a,.flac,.aac,.ogg

# çƒ­è¯æœ€å¤§æ•°é‡
VITE_MAX_HOTWORDS=1000

# å®æ—¶è½¬å†™WebSocketåœ°å€
VITE_WS_BASE_URL=ws://localhost:8000

# æ—¥å¿—çº§åˆ«
VITE_LOG_LEVEL=info
```

--------------------------------------------------------------------------------

File: asr_system_frontend/index.html
```html
<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>æ”¯æŒçƒ­è¯é¢„æµ‹çš„è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ</title>
    <meta name="description" content="æå¤§æ— å…³ç»„ - æ”¯æŒçƒ­è¯é¢„æµ‹çš„è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ" />
    <link rel="icon" type="image/svg+xml" href="/favicon.svg" />
    <style>
      body {
        background: #121212;
        color: #e0e0e0;
        min-height: 100vh;
        margin: 0;
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
      }
    </style>
  </head>
  <body>
    <div id="app"></div>
    <script type="module" src="/src/main.js"></script>
  </body>
</html>
```

--------------------------------------------------------------------------------

File: asr_system_frontend/postcss.config.js
```javascript
module.exports = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
};
```

--------------------------------------------------------------------------------

File: asr_system_frontend/.eslintrc.js
```javascript
module.exports = {
  root: true,
  env: {
    node: true,
  },
  extends: [
    'plugin:vue/vue3-essential',
    'eslint:recommended',
    'prettier',
  ],
  parserOptions: {
    ecmaVersion: 2020,
    sourceType: 'module',
  },
  rules: {
    'vue/multi-word-component-names': 0,
  },
};
```

--------------------------------------------------------------------------------

File: asr_system_frontend/playwright.config.ts
```typescript
import { defineConfig, devices } from '@playwright/test';

/**
 * @see https://playwright.dev/docs/test-configuration
 */
export default defineConfig({
  testDir: './tests/e2e',
  /* Run tests in files in parallel */
  fullyParallel: true,
  /* Fail the build on CI if you accidentally left test.only in the source code. */
  forbidOnly: !!process.env.CI,
  /* Retry on CI only */
  retries: process.env.CI ? 2 : 0,
  /* Opt out of parallel tests on CI. */
  workers: process.env.CI ? 1 : undefined,
  /* Reporter to use. See https://playwright.dev/docs/test-reporters */
  reporter: 'html',
  /* Shared settings for all the projects below. See https://playwright.dev/docs/api/class-testoptions. */
  use: {
    /* Base URL to use in actions like `await page.goto('/')`. */
    baseURL: 'http://localhost:2956',

    /* Collect trace when retrying the failed test. See https://playwright.dev/docs/trace-viewer */
    trace: 'on-first-retry',
    
    /* Take screenshot only when test fails */
    screenshot: 'only-on-failure',
    
    /* Record video only when test fails */
    video: 'retain-on-failure',
  },

  /* Configure projects for major browsers */
  projects: [
    {
      name: 'chromium',
      use: { ...devices['Desktop Chrome'] },
    },

    {
      name: 'firefox',
      use: { ...devices['Desktop Firefox'] },
    },

    {
      name: 'webkit',
      use: { ...devices['Desktop Safari'] },
    },

    /* Test against mobile viewports. */
    {
      name: 'Mobile Chrome',
      use: { ...devices['Pixel 5'] },
    },
    {
      name: 'Mobile Safari',
      use: { ...devices['iPhone 12'] },
    },
  ],

  /* Run your local dev server before starting the tests */
  webServer: {
    command: 'npm run dev',
    url: 'http://localhost:2956',
    reuseExistingServer: !process.env.CI,
  },
});
```

--------------------------------------------------------------------------------

File: asr_system_frontend/tailwind.config.js
```javascript
module.exports = {
  content: [
    './index.html',
    './src/**/*.{vue,js,ts,jsx,tsx}'
  ],
  theme: {
    extend: {},
  },
  plugins: [],
};
```

--------------------------------------------------------------------------------

File: asr_system_frontend/.prettierrc
```text
{
  "singleQuote": true,
  "semi": true,
  "trailingComma": "es5"
}
```

--------------------------------------------------------------------------------

File: asr_system_frontend/vite.config.js
```javascript
import { defineConfig } from 'vite';
import vue from '@vitejs/plugin-vue';

// ä»ç¯å¢ƒå˜é‡è·å–ç«¯å£é…ç½®
const FRONTEND_PORT = process.env.FRONTEND_PORT || 2956;
const BACKEND_PORT = process.env.BACKEND_PORT || 8080;
const BACKEND_HOST = process.env.BACKEND_HOST || 'localhost';

export default defineConfig({
  plugins: [vue()],
  server: {
    port: FRONTEND_PORT,
    strictPort: true, // å¦‚æœç«¯å£è¢«å ç”¨ï¼Œä¸è¦å°è¯•ä¸‹ä¸€ä¸ªç«¯å£
    proxy: {
      '^/api': {
        target: `http://${BACKEND_HOST}:${BACKEND_PORT}`,
        changeOrigin: true
      },
      '^/auth': {
        target: `http://${BACKEND_HOST}:${BACKEND_PORT}`,
        changeOrigin: true
      },
      '^/asr': {
        target: `http://${BACKEND_HOST}:${BACKEND_PORT}`,
        changeOrigin: true
      },
      '^/ws': {
        target: `ws://${BACKEND_HOST}:${BACKEND_PORT}`,
        changeOrigin: true,
        ws: true
      }
    }
  },
  define: {
    'process.env': {
      VITE_API_BASE_URL: JSON.stringify(`http://${BACKEND_HOST}:${BACKEND_PORT}`),
      VITE_WS_BASE_URL: JSON.stringify(`ws://${BACKEND_HOST}:${BACKEND_PORT}`)
    }
  }
});
```

--------------------------------------------------------------------------------

File: asr_system_frontend/README.md
```markdown
# ASR System å‰ç«¯

## æœ¬åœ°å¼€å‘

1. å®‰è£…ä¾èµ–
   ```
   npm install
   ```
2. å¯åŠ¨å¼€å‘æœåŠ¡å™¨
   ```
   npm run dev
   ```
3. ç”Ÿäº§ç¯å¢ƒæ‰“åŒ…
   ```
   npm run build
   ```

## ä»£ç è§„èŒƒ

- ä½¿ç”¨ ESLint/Prettier ç»Ÿä¸€ä»£ç é£æ ¼
- ç»„ä»¶å¼€å‘å»ºè®®å‚è€ƒ Element Plus å®˜æ–¹æ–‡æ¡£
```

--------------------------------------------------------------------------------

File: asr_system_frontend/tests/e2e/features.spec.ts
```typescript
import { test, expect } from '@playwright/test';

test.describe('æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•', () => {
  // ç™»å½•æµ‹è¯•ç”¨æˆ·
  test.beforeEach(async ({ page }) => {
    await page.goto('/login');
    await page.fill('input[placeholder*="ç”¨æˆ·å"]', 'testuser');
    await page.fill('input[placeholder*="å¯†ç "]', 'password123');
    await page.click('button:has-text("ç™»å½•")');
    
    // ç­‰å¾…ç™»å½•æˆåŠŸ
    await page.waitForURL(/\/dashboard|\//, { timeout: 10000 });
  });

  test('çƒ­è¯ç®¡ç†åŠŸèƒ½', async ({ page }) => {
    // å¯¼èˆªåˆ°çƒ­è¯ç®¡ç†é¡µé¢
    await page.click('text=çƒ­è¯ç®¡ç†');
    await expect(page).toHaveURL(/\/hotwords/);
    
    // éªŒè¯é¡µé¢å…ƒç´ 
    await expect(page.locator('text=æ·»åŠ çƒ­è¯')).toBeVisible();
    await expect(page.locator('text=æ‰¹é‡å¯¼å…¥')).toBeVisible();
    
    // æ·»åŠ æ–°çƒ­è¯
    await page.click('button:has-text("æ·»åŠ çƒ­è¯")');
    
    // å¡«å†™çƒ­è¯è¡¨å•
    await page.fill('input[placeholder*="çƒ­è¯"]', 'æœºå™¨å­¦ä¹ ');
    
    // è®¾ç½®æƒé‡ - æ‰¾åˆ°æ»‘å—å¹¶è®¾ç½®
    const slider = page.locator('.el-slider__runway');
    if (await slider.isVisible()) {
      await slider.click({ position: { x: 80, y: 0 } }); // ç‚¹å‡»æ»‘å—ä½ç½®è®¾ç½®æƒé‡
    }
    
    // ä¿å­˜çƒ­è¯
    await page.click('button:has-text("æ·»åŠ ")');
    
    // éªŒè¯çƒ­è¯æ·»åŠ æˆåŠŸ
    await expect(page.locator('text=æœºå™¨å­¦ä¹ ')).toBeVisible({ timeout: 5000 });
    
    // æµ‹è¯•æœç´¢åŠŸèƒ½
    await page.fill('input[placeholder*="æœç´¢çƒ­è¯"]', 'æœºå™¨');
    await expect(page.locator('text=æœºå™¨å­¦ä¹ ')).toBeVisible();
    
    // æ¸…ç©ºæœç´¢
    await page.fill('input[placeholder*="æœç´¢çƒ­è¯"]', '');
  });

  test('æ–‡ä»¶è½¬å†™åŠŸèƒ½é¡µé¢', async ({ page }) => {
    // å¯¼èˆªåˆ°æ–‡ä»¶è½¬å†™é¡µé¢
    await page.click('text=æ–‡ä»¶è½¬å†™');
    await expect(page).toHaveURL(/\/transcription/);
    
    // éªŒè¯é¡µé¢å…ƒç´ 
    await expect(page.locator('text=éŸ³é¢‘æ–‡ä»¶ä¸Šä¼ ')).toBeVisible();
    await expect(page.locator('text=çƒ­è¯è®¾ç½®')).toBeVisible();
    
    // éªŒè¯æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    await expect(page.locator('.el-upload-dragger')).toBeVisible();
    
    // éªŒè¯çƒ­è¯å¼€å…³
    await expect(page.locator('.el-switch')).toBeVisible();
    
    // æµ‹è¯•çƒ­è¯å¼€å…³åˆ‡æ¢
    const hotwordSwitch = page.locator('.el-switch');
    await hotwordSwitch.click();
    
    // éªŒè¯çƒ­è¯ç®¡ç†é“¾æ¥
    await expect(page.locator('text=ç®¡ç†æˆ‘çš„çƒ­è¯')).toBeVisible();
  });

  test('ä»»åŠ¡è¯¦æƒ…é¡µé¢å¯¼èˆª', async ({ page }) => {
    // å¯¼èˆªåˆ°é¦–é¡µ
    await page.goto('/');
    
    // å¦‚æœæœ‰ä»»åŠ¡åˆ—è¡¨ï¼Œæµ‹è¯•ç‚¹å‡»æŸ¥çœ‹è¯¦æƒ…
    const taskLinks = page.locator('text=æŸ¥çœ‹è¯¦æƒ…');
    const taskCount = await taskLinks.count();
    
    if (taskCount > 0) {
      await taskLinks.first().click();
      
      // éªŒè¯è¿›å…¥ä»»åŠ¡è¯¦æƒ…é¡µé¢
      await expect(page).toHaveURL(/\/task\//);
      await expect(page.locator('text=ä»»åŠ¡è¯¦æƒ…')).toBeVisible();
    }
  });

  test('å¯¼èˆªåŠŸèƒ½æµ‹è¯•', async ({ page }) => {
    // æµ‹è¯•å„é¡µé¢é—´çš„å¯¼èˆª
    const pages = [
      { text: 'é¦–é¡µ', url: '/' },
      { text: 'æ–‡ä»¶è½¬å†™', url: '/transcription' },
      { text: 'çƒ­è¯ç®¡ç†', url: '/hotwords' }
    ];

    for (const testPage of pages) {
      if (await page.locator(`text=${testPage.text}`).isVisible()) {
        await page.click(`text=${testPage.text}`);
        await expect(page).toHaveURL(new RegExp(testPage.url.replace('/', '\\/')));
        
        // éªŒè¯é¡µé¢åŠ è½½å®Œæˆ
        await page.waitForLoadState('networkidle');
      }
    }
  });

  test('å“åº”å¼è®¾è®¡æµ‹è¯•', async ({ page }) => {
    // æµ‹è¯•ä¸åŒå±å¹•å°ºå¯¸
    const viewports = [
      { width: 1920, height: 1080 }, // æ¡Œé¢
      { width: 768, height: 1024 },  // å¹³æ¿
      { width: 375, height: 667 }    // æ‰‹æœº
    ];

    for (const viewport of viewports) {
      await page.setViewportSize(viewport);
      
      // éªŒè¯é¡µé¢åœ¨ä¸åŒå°ºå¯¸ä¸‹æ­£å¸¸æ˜¾ç¤º
      await page.goto('/');
      await expect(page.locator('header')).toBeVisible();
      
      // åœ¨å°å±å¹•ä¸Šå¯èƒ½æœ‰æ±‰å ¡èœå•
      if (viewport.width < 768) {
        // æ£€æŸ¥æ˜¯å¦æœ‰ç§»åŠ¨ç«¯èœå•
        const mobileMenu = page.locator('.mobile-menu');
        if (await mobileMenu.isVisible()) {
          await mobileMenu.click();
        }
      }
    }
  });
});
```

--------------------------------------------------------------------------------

File: asr_system_frontend/tests/e2e/auth.spec.ts
```typescript
import { test, expect } from '@playwright/test';

test.describe('ç”¨æˆ·è®¤è¯æµç¨‹', () => {
  const testUser = {
    username: `testuser_${Date.now()}`,
    password: 'password123'
  };

  test('ç”¨æˆ·æ³¨å†Œæµç¨‹', async ({ page }) => {
    await page.goto('/register');
    
    // å¡«å†™æ³¨å†Œè¡¨å•
    await page.fill('input[placeholder*="ç”¨æˆ·å"]', testUser.username);
    await page.fill('input[placeholder*="å¯†ç "]', testUser.password);
    
    // æäº¤æ³¨å†Œ
    await page.click('button:has-text("æ³¨å†Œ")');
    
    // éªŒè¯æ³¨å†ŒæˆåŠŸ - å¯èƒ½è·³è½¬åˆ°ç™»å½•é¡µé¢æˆ–æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
    await expect(page.locator('text=æ³¨å†ŒæˆåŠŸ')).toBeVisible({ timeout: 10000 });
  });

  test('ç”¨æˆ·ç™»å½•æµç¨‹', async ({ page }) => {
    await page.goto('/login');
    
    // å¡«å†™ç™»å½•è¡¨å•
    await page.fill('input[placeholder*="ç”¨æˆ·å"]', testUser.username);
    await page.fill('input[placeholder*="å¯†ç "]', testUser.password);
    
    // æäº¤ç™»å½•
    await page.click('button:has-text("ç™»å½•")');
    
    // éªŒè¯ç™»å½•æˆåŠŸ - è·³è½¬åˆ°ä¸»é¡µé¢
    await expect(page).toHaveURL(/\/dashboard|\/$/);
    
    // éªŒè¯ç”¨æˆ·ä¿¡æ¯æ˜¾ç¤º
    await expect(page.locator(`text=${testUser.username}`)).toBeVisible({ timeout: 10000 });
  });

  test('ç™»å½•å¤±è´¥å¤„ç†', async ({ page }) => {
    await page.goto('/login');
    
    // ä½¿ç”¨é”™è¯¯å¯†ç ç™»å½•
    await page.fill('input[placeholder*="ç”¨æˆ·å"]', 'wronguser');
    await page.fill('input[placeholder*="å¯†ç "]', 'wrongpassword');
    
    await page.click('button:has-text("ç™»å½•")');
    
    // éªŒè¯é”™è¯¯æ¶ˆæ¯æ˜¾ç¤º
    await expect(page.locator('text=ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯')).toBeVisible({ timeout: 5000 });
  });

  test('å®Œæ•´ç”¨æˆ·æµç¨‹ï¼šæ³¨å†Œ->ç™»å½•->è®¿é—®åŠŸèƒ½', async ({ page }) => {
    const uniqueUser = {
      username: `e2euser_${Date.now()}`,
      password: 'test123456'
    };

    // æ­¥éª¤1ï¼šæ³¨å†Œ
    await page.goto('/register');
    await page.fill('input[placeholder*="ç”¨æˆ·å"]', uniqueUser.username);
    await page.fill('input[placeholder*="å¯†ç "]', uniqueUser.password);
    await page.click('button:has-text("æ³¨å†Œ")');
    
    // ç­‰å¾…æ³¨å†ŒæˆåŠŸ
    await expect(page.locator('text=æ³¨å†ŒæˆåŠŸ')).toBeVisible({ timeout: 10000 });

    // æ­¥éª¤2ï¼šç™»å½•
    await page.goto('/login');
    await page.fill('input[placeholder*="ç”¨æˆ·å"]', uniqueUser.username);
    await page.fill('input[placeholder*="å¯†ç "]', uniqueUser.password);
    await page.click('button:has-text("ç™»å½•")');
    
    // ç­‰å¾…è¿›å…¥ä¸»é¡µé¢
    await page.waitForURL(/\/dashboard|\//, { timeout: 10000 });

    // æ­¥éª¤3ï¼šéªŒè¯å¯ä»¥è®¿é—®åŠŸèƒ½é¡µé¢
    if (await page.locator('text=æ–‡ä»¶è½¬å†™').isVisible()) {
      await page.click('text=æ–‡ä»¶è½¬å†™');
      await expect(page.locator('text=éŸ³é¢‘æ–‡ä»¶ä¸Šä¼ ')).toBeVisible({ timeout: 5000 });
    }

    if (await page.locator('text=çƒ­è¯ç®¡ç†').isVisible()) {
      await page.click('text=çƒ­è¯ç®¡ç†');
      await expect(page.locator('text=æ·»åŠ çƒ­è¯')).toBeVisible({ timeout: 5000 });
    }
  });
});
```

--------------------------------------------------------------------------------

File: asr_system_frontend/tests/e2e/hotwords.spec.ts
```typescript
import { test, expect } from '@playwright/test';

// æµ‹è¯•å‰çš„å‡†å¤‡å·¥ä½œ
test.beforeEach(async ({ page }) => {
  // è®¿é—®ç™»å½•é¡µé¢
  await page.goto('/login');
  
  // æ‰§è¡Œç™»å½•
  await page.fill('input[placeholder="è¯·è¾“å…¥ç”¨æˆ·å/é‚®ç®±"]', 'testuser');
  await page.fill('input[placeholder="è¯·è¾“å…¥å¯†ç "]', 'testpass123');
  
  // è·å–å¹¶è¾“å…¥éªŒè¯ç 
  const captchaText = await page.textContent('.captcha-box');
  await page.fill('input[placeholder="è¾“å…¥éªŒè¯ç "]', captchaText);
  
  // ç‚¹å‡»ç™»å½•æŒ‰é’®
  await page.click('button:has-text("ç™»å½•")');
  
  // ç­‰å¾…ç™»å½•æˆåŠŸï¼Œè·³è½¬åˆ°ä¸»é¡µ
  await page.waitForURL('/');
  
  // å¯¼èˆªåˆ°çƒ­è¯ç®¡ç†é¡µé¢
  await page.goto('/hotwords');
  await page.waitForLoadState('networkidle');
});

test.describe('çƒ­è¯ç®¡ç†åŠŸèƒ½æµ‹è¯•', () => {
  
  test('é¡µé¢åŠ è½½å’ŒåŸºæœ¬å…ƒç´ æ˜¾ç¤º', async ({ page }) => {
    // æ£€æŸ¥é¡µé¢æ ‡é¢˜
    await expect(page.locator('h1')).toContainText('çƒ­è¯ç®¡ç†');
    
    // æ£€æŸ¥ä¸»è¦æŒ‰é’®æ˜¯å¦å­˜åœ¨
    await expect(page.locator('button:has-text("æ·»åŠ çƒ­è¯")')).toBeVisible();
    await expect(page.locator('button:has-text("æ‰¹é‡å¯¼å…¥")')).toBeVisible();
    await expect(page.locator('button:has-text("æ‰¹é‡åˆ é™¤")')).toBeVisible();
    
    // æ£€æŸ¥æœç´¢æ¡†
    await expect(page.locator('input[placeholder="æœç´¢çƒ­è¯..."]')).toBeVisible();
    
    // æ£€æŸ¥çƒ­è¯åˆ—è¡¨è¡¨æ ¼
    await expect(page.locator('.el-table')).toBeVisible();
  });
  
  test('æ·»åŠ çƒ­è¯åŠŸèƒ½', async ({ page }) => {
    // ç‚¹å‡»æ·»åŠ çƒ­è¯æŒ‰é’®
    await page.click('button:has-text("æ·»åŠ çƒ­è¯")');
    
    // ç­‰å¾…å¯¹è¯æ¡†å‡ºç°
    await expect(page.locator('.el-dialog')).toBeVisible();
    await expect(page.locator('.el-dialog__title')).toContainText('æ·»åŠ çƒ­è¯');
    
    // å¡«å†™çƒ­è¯ä¿¡æ¯
    await page.fill('.el-dialog input[placeholder="è¯·è¾“å…¥çƒ­è¯"]', 'æµ‹è¯•çƒ­è¯');
    
    // è®¾ç½®æƒé‡æ»‘å— - ç‚¹å‡»æ»‘å—çš„ç‰¹å®šä½ç½®æ¥è®¾ç½®æƒé‡
    const slider = page.locator('.el-slider__runway');
    const sliderBox = await slider.boundingBox();
    // ç‚¹å‡»æ»‘å—çš„80%ä½ç½®ï¼ˆå¯¹åº”æƒé‡8ï¼‰
    await slider.click({ 
      position: { 
        x: sliderBox.width * 0.8, 
        y: sliderBox.height / 2 
      } 
    });
    
    // ä¿å­˜çƒ­è¯
    await page.click('.el-dialog button:has-text("ä¿å­˜")');
    
    // ç­‰å¾…å¯¹è¯æ¡†å…³é—­
    await expect(page.locator('.el-dialog')).toBeHidden();
    
    // éªŒè¯çƒ­è¯å·²æ·»åŠ åˆ°åˆ—è¡¨ä¸­
    await expect(page.locator('.el-table').locator('td').filter({ hasText: 'æµ‹è¯•çƒ­è¯' })).toBeVisible();
    
    // éªŒè¯æˆåŠŸæ¶ˆæ¯
    await expect(page.locator('.el-message--success')).toBeVisible();
  });
  
  test('æœç´¢çƒ­è¯åŠŸèƒ½', async ({ page }) => {
    // å…ˆæ·»åŠ å‡ ä¸ªçƒ­è¯
    const testWords = ['æœç´¢æµ‹è¯•1', 'æœç´¢æµ‹è¯•2', 'å…¶ä»–çƒ­è¯'];
    
    for (const word of testWords) {
      await page.click('button:has-text("æ·»åŠ çƒ­è¯")');
      await page.fill('.el-dialog input[placeholder="è¯·è¾“å…¥çƒ­è¯"]', word);
      await page.click('.el-dialog button:has-text("ä¿å­˜")');
      await page.waitForTimeout(500); // ç­‰å¾…æ·»åŠ å®Œæˆ
    }
    
    // ä½¿ç”¨æœç´¢åŠŸèƒ½
    await page.fill('input[placeholder="æœç´¢çƒ­è¯..."]', 'æœç´¢æµ‹è¯•');
    
    // ç­‰å¾…æœç´¢ç»“æœ
    await page.waitForTimeout(1000);
    
    // éªŒè¯æœç´¢ç»“æœ
    await expect(page.locator('.el-table').locator('td').filter({ hasText: 'æœç´¢æµ‹è¯•1' })).toBeVisible();
    await expect(page.locator('.el-table').locator('td').filter({ hasText: 'æœç´¢æµ‹è¯•2' })).toBeVisible();
    await expect(page.locator('.el-table').locator('td').filter({ hasText: 'å…¶ä»–çƒ­è¯' })).toBeHidden();
    
    // æ¸…ç©ºæœç´¢
    await page.fill('input[placeholder="æœç´¢çƒ­è¯..."]', '');
    await page.waitForTimeout(1000);
    
    // éªŒè¯æ‰€æœ‰çƒ­è¯éƒ½æ˜¾ç¤º
    await expect(page.locator('.el-table').locator('td').filter({ hasText: 'å…¶ä»–çƒ­è¯' })).toBeVisible();
  });
  
  test('ç¼–è¾‘çƒ­è¯åŠŸèƒ½', async ({ page }) => {
    // å…ˆæ·»åŠ ä¸€ä¸ªçƒ­è¯
    await page.click('button:has-text("æ·»åŠ çƒ­è¯")');
    await page.fill('.el-dialog input[placeholder="è¯·è¾“å…¥çƒ­è¯"]', 'å¾…ç¼–è¾‘çƒ­è¯');
    await page.click('.el-dialog button:has-text("ä¿å­˜")');
    await page.waitForTimeout(500);
    
    // æ‰¾åˆ°ç¼–è¾‘æŒ‰é’®å¹¶ç‚¹å‡»
    const editButton = page.locator('.el-table').locator('tr').filter({ hasText: 'å¾…ç¼–è¾‘çƒ­è¯' }).locator('button').filter({ hasText: 'ç¼–è¾‘' });
    await editButton.click();
    
    // ç­‰å¾…ç¼–è¾‘å¯¹è¯æ¡†å‡ºç°
    await expect(page.locator('.el-dialog')).toBeVisible();
    await expect(page.locator('.el-dialog__title')).toContainText('ç¼–è¾‘çƒ­è¯');
    
    // ä¿®æ”¹çƒ­è¯å†…å®¹
    await page.fill('.el-dialog input[placeholder="è¯·è¾“å…¥çƒ­è¯"]', 'å·²ç¼–è¾‘çƒ­è¯');
    
    // ä¿å­˜ä¿®æ”¹
    await page.click('.el-dialog button:has-text("ä¿å­˜")');
    
    // ç­‰å¾…å¯¹è¯æ¡†å…³é—­
    await expect(page.locator('.el-dialog')).toBeHidden();
    
    // éªŒè¯ä¿®æ”¹æˆåŠŸ
    await expect(page.locator('.el-table').locator('td').filter({ hasText: 'å·²ç¼–è¾‘çƒ­è¯' })).toBeVisible();
    await expect(page.locator('.el-table').locator('td').filter({ hasText: 'å¾…ç¼–è¾‘çƒ­è¯' })).toBeHidden();
    
    // éªŒè¯æˆåŠŸæ¶ˆæ¯
    await expect(page.locator('.el-message--success')).toBeVisible();
  });
  
  test('åˆ é™¤çƒ­è¯åŠŸèƒ½', async ({ page }) => {
    // å…ˆæ·»åŠ ä¸€ä¸ªçƒ­è¯
    await page.click('button:has-text("æ·»åŠ çƒ­è¯")');
    await page.fill('.el-dialog input[placeholder="è¯·è¾“å…¥çƒ­è¯"]', 'å¾…åˆ é™¤çƒ­è¯');
    await page.click('.el-dialog button:has-text("ä¿å­˜")');
    await page.waitForTimeout(500);
    
    // æ‰¾åˆ°åˆ é™¤æŒ‰é’®å¹¶ç‚¹å‡»
    const deleteButton = page.locator('.el-table').locator('tr').filter({ hasText: 'å¾…åˆ é™¤çƒ­è¯' }).locator('button').filter({ hasText: 'åˆ é™¤' });
    await deleteButton.click();
    
    // ç­‰å¾…ç¡®è®¤å¯¹è¯æ¡†å‡ºç°
    await expect(page.locator('.el-message-box')).toBeVisible();
    await expect(page.locator('.el-message-box__content')).toContainText('ç¡®å®šè¦åˆ é™¤çƒ­è¯');
    
    // ç¡®è®¤åˆ é™¤
    await page.click('.el-message-box button:has-text("ç¡®å®š")');
    
    // éªŒè¯çƒ­è¯å·²è¢«åˆ é™¤
    await expect(page.locator('.el-table').locator('td').filter({ hasText: 'å¾…åˆ é™¤çƒ­è¯' })).toBeHidden();
    
    // éªŒè¯æˆåŠŸæ¶ˆæ¯
    await expect(page.locator('.el-message--success')).toBeVisible();
  });
  
  test('æ‰¹é‡åˆ é™¤åŠŸèƒ½', async ({ page }) => {
    // å…ˆæ·»åŠ å‡ ä¸ªçƒ­è¯
    const testWords = ['æ‰¹é‡åˆ é™¤1', 'æ‰¹é‡åˆ é™¤2', 'ä¿ç•™çƒ­è¯'];
    
    for (const word of testWords) {
      await page.click('button:has-text("æ·»åŠ çƒ­è¯")');
      await page.fill('.el-dialog input[placeholder="è¯·è¾“å…¥çƒ­è¯"]', word);
      await page.click('.el-dialog button:has-text("ä¿å­˜")');
      await page.waitForTimeout(500);
    }
    
    // é€‰ä¸­è¦åˆ é™¤çš„çƒ­è¯
    await page.check('.el-table').locator('tr').filter({ hasText: 'æ‰¹é‡åˆ é™¤1' }).locator('.el-checkbox__input');
    await page.check('.el-table').locator('tr').filter({ hasText: 'æ‰¹é‡åˆ é™¤2' }).locator('.el-checkbox__input');
    
    // ç‚¹å‡»æ‰¹é‡åˆ é™¤æŒ‰é’®
    await page.click('button:has-text("æ‰¹é‡åˆ é™¤")');
    
    // ç­‰å¾…ç¡®è®¤å¯¹è¯æ¡†
    await expect(page.locator('.el-message-box')).toBeVisible();
    await expect(page.locator('.el-message-box__content')).toContainText('ç¡®å®šè¦åˆ é™¤é€‰ä¸­çš„');
    
    // ç¡®è®¤åˆ é™¤
    await page.click('.el-message-box button:has-text("ç¡®å®š")');
    
    // éªŒè¯çƒ­è¯å·²è¢«åˆ é™¤
    await expect(page.locator('.el-table').locator('td').filter({ hasText: 'æ‰¹é‡åˆ é™¤1' })).toBeHidden();
    await expect(page.locator('.el-table').locator('td').filter({ hasText: 'æ‰¹é‡åˆ é™¤2' })).toBeHidden();
    await expect(page.locator('.el-table').locator('td').filter({ hasText: 'ä¿ç•™çƒ­è¯' })).toBeVisible();
  });
  
  test('æ‰¹é‡å¯¼å…¥åŠŸèƒ½', async ({ page }) => {
    // ç‚¹å‡»æ‰¹é‡å¯¼å…¥æŒ‰é’®
    await page.click('button:has-text("æ‰¹é‡å¯¼å…¥")');
    
    // ç­‰å¾…å¯¼å…¥å¯¹è¯æ¡†å‡ºç°
    await expect(page.locator('.el-dialog')).toBeVisible();
    await expect(page.locator('.el-dialog__title')).toContainText('æ‰¹é‡å¯¼å…¥çƒ­è¯');
    
    // åˆ›å»ºæµ‹è¯•æ–‡ä»¶å†…å®¹
    const csvContent = `å¯¼å…¥çƒ­è¯1,5
å¯¼å…¥çƒ­è¯2,8
å¯¼å…¥çƒ­è¯3,3`;
    
    // ä½¿ç”¨æ–‡ä»¶ä¸Šä¼ 
    const fileInput = page.locator('.el-dialog input[type="file"]');
    
    // åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„æ–‡ä»¶
    await fileInput.setInputFiles({
      name: 'test_hotwords.csv',
      mimeType: 'text/csv',
      buffer: Buffer.from(csvContent)
    });
    
    // ç‚¹å‡»å¯¼å…¥æŒ‰é’®
    await page.click('.el-dialog button:has-text("å¯¼å…¥")');
    
    // ç­‰å¾…å¯¼å…¥å®Œæˆ
    await page.waitForTimeout(2000);
    
    // éªŒè¯å¯¼å…¥æˆåŠŸæ¶ˆæ¯
    await expect(page.locator('.el-message--success')).toBeVisible();
    
    // éªŒè¯å¯¼å…¥çš„çƒ­è¯å‡ºç°åœ¨åˆ—è¡¨ä¸­
    await expect(page.locator('.el-table').locator('td').filter({ hasText: 'å¯¼å…¥çƒ­è¯1' })).toBeVisible();
    await expect(page.locator('.el-table').locator('td').filter({ hasText: 'å¯¼å…¥çƒ­è¯2' })).toBeVisible();
    await expect(page.locator('.el-table').locator('td').filter({ hasText: 'å¯¼å…¥çƒ­è¯3' })).toBeVisible();
  });
  
  test('çƒ­è¯æƒé‡æ˜¾ç¤ºå’Œæ’åº', async ({ page }) => {
    // æ·»åŠ ä¸åŒæƒé‡çš„çƒ­è¯
    const testWords = [
      { word: 'é«˜æƒé‡çƒ­è¯', weight: 90 },
      { word: 'ä½æƒé‡çƒ­è¯', weight: 10 },
      { word: 'ä¸­ç­‰æƒé‡çƒ­è¯', weight: 50 }
    ];
    
    for (const { word, weight } of testWords) {
      await page.click('button:has-text("æ·»åŠ çƒ­è¯")');
      await page.fill('.el-dialog input[placeholder="è¯·è¾“å…¥çƒ­è¯"]', word);
      
      // è®¾ç½®æƒé‡
      const slider = page.locator('.el-slider__runway');
      const sliderBox = await slider.boundingBox();
      await slider.click({ 
        position: { 
          x: sliderBox.width * (weight / 100), 
          y: sliderBox.height / 2 
        } 
      });
      
      await page.click('.el-dialog button:has-text("ä¿å­˜")');
      await page.waitForTimeout(500);
    }
    
    // éªŒè¯æƒé‡æ˜¾ç¤º
    await expect(page.locator('.el-table').locator('tr').filter({ hasText: 'é«˜æƒé‡çƒ­è¯' })).toBeVisible();
    await expect(page.locator('.el-table').locator('tr').filter({ hasText: 'ä½æƒé‡çƒ­è¯' })).toBeVisible();
    await expect(page.locator('.el-table').locator('tr').filter({ hasText: 'ä¸­ç­‰æƒé‡çƒ­è¯' })).toBeVisible();
    
    // æ£€æŸ¥æƒé‡æ ‡ç­¾æ˜¯å¦æ­£ç¡®æ˜¾ç¤º
    const highWeightRow = page.locator('.el-table').locator('tr').filter({ hasText: 'é«˜æƒé‡çƒ­è¯' });
    await expect(highWeightRow.locator('.el-tag')).toBeVisible();
  });
  
  test('è¡¨å•éªŒè¯åŠŸèƒ½', async ({ page }) => {
    // ç‚¹å‡»æ·»åŠ çƒ­è¯æŒ‰é’®
    await page.click('button:has-text("æ·»åŠ çƒ­è¯")');
    
    // ä¸è¾“å…¥ä»»ä½•å†…å®¹ç›´æ¥ä¿å­˜
    await page.click('.el-dialog button:has-text("ä¿å­˜")');
    
    // éªŒè¯è¡¨å•éªŒè¯ä¿¡æ¯æ˜¾ç¤º
    await expect(page.locator('.el-form-item__error')).toBeVisible();
    
    // è¾“å…¥ç©ºçš„çƒ­è¯
    await page.fill('.el-dialog input[placeholder="è¯·è¾“å…¥çƒ­è¯"]', '   ');
    await page.click('.el-dialog button:has-text("ä¿å­˜")');
    
    // éªŒè¯ä»ç„¶æœ‰é”™è¯¯ä¿¡æ¯
    await expect(page.locator('.el-form-item__error')).toBeVisible();
    
    // è¾“å…¥æ­£ç¡®çš„çƒ­è¯
    await page.fill('.el-dialog input[placeholder="è¯·è¾“å…¥çƒ­è¯"]', 'æœ‰æ•ˆçƒ­è¯');
    await page.click('.el-dialog button:has-text("ä¿å­˜")');
    
    // éªŒè¯ä¿å­˜æˆåŠŸ
    await expect(page.locator('.el-dialog')).toBeHidden();
    await expect(page.locator('.el-message--success')).toBeVisible();
  });
  
  test('å“åº”å¼è®¾è®¡æµ‹è¯•', async ({ page }) => {
    // æµ‹è¯•ç§»åŠ¨ç«¯è§†å›¾
    await page.setViewportSize({ width: 375, height: 667 });
    
    // éªŒè¯é¡µé¢åœ¨ç§»åŠ¨ç«¯ä»ç„¶å¯ç”¨
    await expect(page.locator('h1')).toContainText('çƒ­è¯ç®¡ç†');
    await expect(page.locator('button:has-text("æ·»åŠ çƒ­è¯")')).toBeVisible();
    
    // æµ‹è¯•æ·»åŠ çƒ­è¯åœ¨ç§»åŠ¨ç«¯çš„è¡¨ç°
    await page.click('button:has-text("æ·»åŠ çƒ­è¯")');
    await expect(page.locator('.el-dialog')).toBeVisible();
    
    // æ¢å¤æ¡Œé¢è§†å›¾
    await page.setViewportSize({ width: 1280, height: 720 });
  });
  
  test('é”™è¯¯å¤„ç†æµ‹è¯•', async ({ page }) => {
    // æ¨¡æ‹Ÿç½‘ç»œé”™è¯¯æƒ…å†µ
    await page.route('**/hotwords', (route) => {
      if (route.request().method() === 'POST') {
        route.fulfill({
          status: 500,
          body: JSON.stringify({ detail: 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯' })
        });
      } else {
        route.continue();
      }
    });
    
    // å°è¯•æ·»åŠ çƒ­è¯
    await page.click('button:has-text("æ·»åŠ çƒ­è¯")');
    await page.fill('.el-dialog input[placeholder="è¯·è¾“å…¥çƒ­è¯"]', 'é”™è¯¯æµ‹è¯•çƒ­è¯');
    await page.click('.el-dialog button:has-text("ä¿å­˜")');
    
    // éªŒè¯é”™è¯¯æ¶ˆæ¯æ˜¾ç¤º
    await expect(page.locator('.el-message--error')).toBeVisible();
    
    // éªŒè¯å¯¹è¯æ¡†ä»ç„¶æ‰“å¼€ï¼ˆç”¨æˆ·å¯ä»¥é‡è¯•ï¼‰
    await expect(page.locator('.el-dialog')).toBeVisible();
  });
  
});

test.describe('çƒ­è¯ç®¡ç†æƒé™æµ‹è¯•', () => {
  
  test('æœªç™»å½•ç”¨æˆ·æ— æ³•è®¿é—®çƒ­è¯ç®¡ç†', async ({ page }) => {
    // æ¸…é™¤ç™»å½•çŠ¶æ€
    await page.evaluate(() => localStorage.removeItem('token'));
    
    // å°è¯•è®¿é—®çƒ­è¯ç®¡ç†é¡µé¢
    await page.goto('/hotwords');
    
    // éªŒè¯è¢«é‡å®šå‘åˆ°ç™»å½•é¡µé¢
    await expect(page).toHaveURL('/login');
  });
  
});
```

--------------------------------------------------------------------------------

File: asr_system_frontend/tests/e2e/smoke.spec.ts
```typescript
import { test, expect } from '@playwright/test';

test.describe('åº”ç”¨å†’çƒŸæµ‹è¯•', () => {
  test('åº”ç”¨æ­£å¸¸åŠ è½½', async ({ page }) => {
    await page.goto('/');
    
    // éªŒè¯é¡µé¢æ ‡é¢˜
    await expect(page).toHaveTitle(/è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ/);
    
    // éªŒè¯é¡µé¢åŒ…å«å…³é”®å…ƒç´ 
    await expect(page.locator('text=ç™»å½•')).toBeVisible();
  });

  test('ç™»å½•é¡µé¢æ­£å¸¸åŠ è½½', async ({ page }) => {
    await page.goto('/login');
    
    // éªŒè¯ç™»å½•è¡¨å•å­˜åœ¨
    await expect(page.locator('input[type="text"]')).toBeVisible();
    await expect(page.locator('input[type="password"]')).toBeVisible();
    await expect(page.locator('button:has-text("ç™»å½•")')).toBeVisible();
  });

  test('æ³¨å†Œé¡µé¢æ­£å¸¸åŠ è½½', async ({ page }) => {
    await page.goto('/register');
    
    // éªŒè¯æ³¨å†Œè¡¨å•å­˜åœ¨
    await expect(page.locator('input[type="text"]')).toBeVisible();
    await expect(page.locator('input[type="password"]')).toBeVisible();
    await expect(page.locator('button:has-text("æ³¨å†Œ")')).toBeVisible();
  });
});
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/main.js
```javascript
import { createApp } from 'vue';
import App from './App.vue';
import router from './router';
import ElementPlus from 'element-plus';
import 'element-plus/dist/index.css';
import './assets/css/main.css';
import axios from 'axios';

// ç§»é™¤ç¡¬ç¼–ç çš„baseURLé…ç½®
// axios.defaults.baseURL = 'http://localhost:8000';
axios.defaults.headers.common['Content-Type'] = 'application/json';

// æ·»åŠ è¯·æ±‚æ‹¦æˆªå™¨ï¼Œè‡ªåŠ¨æ·»åŠ token
axios.interceptors.request.use(
  config => {
    const token = localStorage.getItem('token');
    if (token) {
      config.headers['Authorization'] = `Bearer ${token}`;
    }
    return config;
  },
  error => {
    return Promise.reject(error);
  }
);

const app = createApp(App);
app.use(router);
app.use(ElementPlus);
app.mount('#app');
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/App.vue
```text
<template>
  <router-view />
</template>

<script setup>
// æ ¹ç»„ä»¶æ— éœ€é€»è¾‘
</script>

<style>
html, body, #app {
  height: 100%;
  margin: 0;
  padding: 0;
}
</style>
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/assets/css/main.css
```css
@tailwind base;
@tailwind components;
@tailwind utilities;
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/views/RealtimeTranscription.vue
```text
<template>
  <div class="min-h-screen bg-gray-900 text-gray-200">
    <header class="bg-gray-800 py-4 shadow-md">
      <div class="container mx-auto px-4 flex justify-between items-center">
        <h1 class="text-xl font-bold text-blue-400">å½•éŸ³è½¬å†™</h1>
        <el-button type="primary" @click="$router.push('/')">è¿”å›é¦–é¡µ</el-button>
      </div>
    </header>
    
    <main class="container mx-auto py-8 px-4 max-w-6xl">
      <div class="grid grid-cols-1 lg:grid-cols-3 gap-6">
        <!-- å·¦ä¾§ï¼šæ§åˆ¶é¢æ¿ (UIä¿æŒåŸæ ·) -->
        <div class="lg:col-span-1">
          <el-card class="bg-gray-800 border-none shadow-lg">
            <template #header>
              <div class="flex items-center">
                <el-icon class="mr-2"><microphone /></el-icon>
                <span>å½•éŸ³æ§åˆ¶</span>
              </div>
            </template>
            
            <div class="space-y-4 p-2">
              <!-- å½•éŸ³æ§åˆ¶æŒ‰é’® -->
              <div class="flex flex-col gap-3">
                <el-button 
                  :type="isRecording ? 'danger' : 'primary'"
                  :disabled="isLoading"
                  :loading="isLoading"
                  @click="toggleRecording"
                  size="large"
                  class="w-full"
                >
                  <el-icon class="mr-2">
                    <component :is="isRecording ? 'VideoPause' : 'VideoPlay'" />
                  </el-icon>
                  {{ buttonText }}
                </el-button>
              </div>

              <!-- çŠ¶æ€å’Œæ—¶é•¿æ˜¾ç¤º -->
              <div class="bg-gray-700 p-3 rounded text-center">
                <div class="text-sm text-gray-400">å½“å‰çŠ¶æ€</div>
                <div class="text-lg font-semibold mt-1" :class="statusClass">
                  {{ statusText }}
                </div>
                <div v-if="isRecording" class="text-sm text-gray-400 mt-2">
                  å½•éŸ³æ—¶é•¿: <span class="font-mono">{{ formatTime(recordingDuration) }}</span>
                </div>
              </div>

            </div>
          </el-card>
        </div>
        
        <!-- å³ä¾§ï¼šè½¬å†™ç»“æœ (UIä¿æŒåŸæ ·) -->
        <div class="lg:col-span-2">
          <el-card class="bg-gray-800 border-none shadow-lg">
            <template #header>
              <div class="flex items-center justify-between">
                <div class="flex items-center">
                  <el-icon class="mr-2"><document /></el-icon>
                  <span>è½¬å†™ç»“æœ</span>
                </div>
                <div class="flex gap-2">
                  <el-button size="small" @click="clearResult" :disabled="isLoading">æ¸…ç©ºç»“æœ</el-button>
                  <el-button size="small" @click="exportResult" :disabled="!transcriptionResult || isLoading">å¯¼å‡ºæ–‡æœ¬</el-button>
                </div>
              </div>
            </template>
            
            <div 
              class="bg-gray-700 p-4 rounded min-h-[400px] max-h-[500px] overflow-y-auto"
            >
              <!-- åŠ è½½çŠ¶æ€ -->
              <div v-if="isLoading" class="flex flex-col items-center justify-center h-full text-center text-gray-400">
                <el-icon class="is-loading text-4xl mb-4 text-blue-400"><loading /></el-icon>
                <p>æ­£åœ¨åŠªåŠ›è½¬å†™ä¸­ï¼Œè¯·ç¨å€™...</p>
              </div>
              <!-- ç©ºçŠ¶æ€ -->
              <div v-else-if="!transcriptionResult" class="flex flex-col items-center justify-center h-full text-center text-gray-400">
                <el-icon class="text-5xl mb-2"><files /></el-icon>
                <p>ç‚¹å‡»â€œå¼€å§‹å½•éŸ³â€ï¼Œç»“æŸåç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œ</p>
              </div>
              <!-- æ˜¾ç¤ºç»“æœ -->
              <div v-else class="text-white text-lg leading-relaxed whitespace-pre-wrap">
                {{ transcriptionResult }}
              </div>
            </div>
          </el-card>
        </div>
      </div>
    </main>
  </div>
</template>

<script setup>
import { ref, computed, onUnmounted } from 'vue';
import { ElMessage } from 'element-plus';
import { Microphone, Document, VideoPlay, VideoPause, Loading, Files } from '@element-plus/icons-vue';

// --- çŠ¶æ€ç®¡ç† ---
const isRecording = ref(false);
const isLoading = ref(false);
const mediaRecorder = ref(null);
const audioChunks = ref([]);
const transcriptionResult = ref('');
const recordingDuration = ref(0);
let recordingTimer = null;

// --- UI è®¡ç®—å±æ€§ ---
const buttonText = computed(() => {
  if (isLoading.value) return 'æ­£åœ¨è½¬å†™...';
  return isRecording.value ? 'åœæ­¢å½•éŸ³' : 'å¼€å§‹å½•éŸ³';
});

const statusText = computed(() => {
  if (isLoading.value) return 'æ­£åœ¨å¤„ç†';
  if (isRecording.value) return 'æ­£åœ¨å½•éŸ³';
  return 'ç©ºé—²';
});

const statusClass = computed(() => {
  if (isLoading.value) return 'text-blue-400';
  if (isRecording.value) return 'text-red-400';
  return 'text-green-400';
});

// --- ç”Ÿå‘½å‘¨æœŸé’©å­ ---
onUnmounted(() => {
  if (mediaRecorder.value && mediaRecorder.value.state !== 'inactive') {
    mediaRecorder.value.stop();
  }
  if (recordingTimer) {
    clearInterval(recordingTimer);
  }
});

// --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° (ä¸ä¸Šä¸€ç‰ˆç›¸åŒï¼Œä½†ç°åœ¨ä¼šé©±åŠ¨è¿™ä¸ªUI) ---

const toggleRecording = () => {
  if (!isRecording.value) {
    startRecording();
  } else {
    stopRecording();
  }
};

const startRecording = async () => {
  if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
    ElMessage.error('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒå½•éŸ³åŠŸèƒ½ã€‚');
    return;
  }
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    
    audioChunks.value = [];
    transcriptionResult.value = '';
    
    mediaRecorder.value = new MediaRecorder(stream, { mimeType: 'audio/webm' });

    mediaRecorder.value.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunks.value.push(event.data);
      }
    };

    mediaRecorder.value.onstop = () => {
      transcribeAudio();
      stream.getTracks().forEach(track => track.stop());
    };

    mediaRecorder.value.start();
    isRecording.value = true;

    recordingDuration.value = 0;
    recordingTimer = setInterval(() => {
      recordingDuration.value++;
    }, 1000);

  } catch (error) {
    console.error('æ— æ³•å¼€å§‹å½•éŸ³:', error);
    ElMessage.error('æ— æ³•å¯åŠ¨å½•éŸ³åŠŸèƒ½ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æƒé™ã€‚');
  }
};

const stopRecording = () => {
  if (mediaRecorder.value && mediaRecorder.value.state === 'recording') {
    mediaRecorder.value.stop();
    isRecording.value = false;
    clearInterval(recordingTimer);
  }
};

const transcribeAudio = async () => {
  if (audioChunks.value.length === 0) {
    ElMessage.warning('å½•éŸ³å†…å®¹è¿‡çŸ­ï¼Œæœªè¿›è¡Œè½¬å†™ã€‚');
    return;
  }

  isLoading.value = true;
  transcriptionResult.value = '';

  const audioBlob = new Blob(audioChunks.value, { type: 'audio/webm' });
  const formData = new FormData();
  formData.append('file', audioBlob, `recording-${Date.now()}.webm`);

  try {
    const response = await fetch('/api/asr/transcribe/file', {
      method: 'POST',
      body: formData,
    });

    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(errorData.detail || 'è½¬å†™è¯·æ±‚å¤±è´¥');
    }

    const data = await response.json();
    transcriptionResult.value = data.result || 'æœªèƒ½è¯†åˆ«å‡ºä»»ä½•å†…å®¹ã€‚';
    ElMessage.success('è½¬å†™å®Œæˆï¼');

  } catch (error) {
    console.error('è½¬å†™å¤±è´¥:', error);
    ElMessage.error('è½¬å†™å¤±è´¥: ' + error.message);
    transcriptionResult.value = `é”™è¯¯: ${error.message}`;
  } finally {
    isLoading.value = false;
  }
};

// --- è¾…åŠ©UIå‡½æ•° ---

const formatTime = (seconds) => {
  const m = String(Math.floor(seconds / 60)).padStart(2, '0');
  const s = String(seconds % 60).padStart(2, '0');
  return `${m}:${s}`;
};

const clearResult = () => {
  transcriptionResult.value = '';
};

const exportResult = () => {
  if (!transcriptionResult.value) {
    ElMessage.warning('æ²¡æœ‰å¯å¯¼å‡ºçš„ç»“æœ');
    return;
  }
  const blob = new Blob([transcriptionResult.value], { type: 'text/plain;charset=utf-8' });
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = `å½•éŸ³è½¬å†™ç»“æœ.txt`;
  document.body.appendChild(a);
  a.click();
  document.body.removeChild(a);
  URL.revokeObjectURL(url);
};
</script>

<style scoped>
:deep(.el-card) {
  background-color: #374151;
  border: none;
}
:deep(.el-card__header) {
  background-color: rgba(17, 24, 39, 0.4);
  padding: 12px 16px;
}
</style>
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/views/FileTranscription.vue
```text
<template>
  <div class="min-h-screen bg-gray-900 text-gray-200">
    <header class="bg-gray-800 py-4 shadow-md">
      <div class="container mx-auto px-4">
        <div class="flex items-center justify-between">
          <h1 class="text-xl font-bold text-blue-400">éŸ³é¢‘è½¬å†™</h1>
          <el-button type="primary" plain @click="goBack">è¿”å›</el-button>
        </div>
      </div>
    </header>
    
    <main class="container mx-auto py-8 px-4 max-w-4xl">
      <el-card class="bg-gray-800 border-none shadow-lg">
        <template #header>
          <div class="flex items-center">
            <span>ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶</span>
          </div>
        </template>
        
        <div class="space-y-6">
          <!-- æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ -->
          <div>
            <el-upload
              ref="uploadRef"
              class="upload-demo"
              drag
              :auto-upload="false"
              :on-change="handleFileChange"
              accept=".mp3,.wav,.m4a,.flac"
              :limit="1"
            >
              <el-icon class="el-icon--upload"><upload-filled /></el-icon>
              <div class="el-upload__text">
                å°†éŸ³é¢‘æ–‡ä»¶æ‹–åˆ°æ­¤å¤„ï¼Œæˆ–<em>ç‚¹å‡»ä¸Šä¼ </em>
              </div>
              <template #tip>
                <div class="el-upload__tip text-gray-400">
                  æ”¯æŒ MP3ã€WAVã€M4Aã€FLAC æ ¼å¼
                </div>
              </template>
            </el-upload>
          </div>
          
          <!-- æäº¤æŒ‰é’® -->
          <div class="flex justify-center">
            <el-button
              type="primary"
              :loading="uploading"
              @click="submitTranscription"
            >
              å¼€å§‹è½¬å†™
            </el-button>
          </div>
        </div>
      </el-card>
      
      <!-- è½¬å†™ç»“æœ -->
      <el-card v-if="result" class="bg-gray-800 border-none shadow-lg mt-6">
        <template #header>
          <span>è½¬å†™ç»“æœ</span>
        </template>
        <div class="terminal-output">
          <pre class="whitespace-pre-wrap text-green-400 font-mono text-sm">{{ result }}</pre>
        </div>
      </el-card>

      <!-- ç»ˆç«¯è¾“å‡º -->
      <el-card v-if="terminalOutput" class="bg-gray-800 border-none shadow-lg mt-6">
        <template #header>
          <span>ç»ˆç«¯è¾“å‡º</span>
        </template>
        <div class="terminal-output">
          <pre class="whitespace-pre-wrap text-green-400 font-mono text-sm">{{ terminalOutput }}</pre>
        </div>
      </el-card>
    </main>
  </div>
</template>

<script setup>
import { ref } from 'vue';
import { ElMessage } from 'element-plus';
import { UploadFilled } from '@element-plus/icons-vue';
import { useRouter } from 'vue-router';

const router = useRouter();
const uploadRef = ref();
const selectedFile = ref(null);
const uploading = ref(false);
const result = ref('');
const terminalOutput = ref('');

function goBack() {
  router.back();
}

function handleFileChange(file) {
  selectedFile.value = file.raw;
}

async function submitTranscription() {
  if (!selectedFile.value) {
    ElMessage.error('è¯·å…ˆé€‰æ‹©è¦è½¬å†™çš„éŸ³é¢‘æ–‡ä»¶');
    return;
  }
  
  try {
    uploading.value = true;
    
    const formData = new FormData();
    formData.append('file', selectedFile.value);
    
    const response = await fetch('/api/asr/transcribe/file', {
      method: 'POST',
      body: formData
    });
    
    if (!response.ok) {
      throw new Error('è½¬å†™å¤±è´¥');
    }
    
    const data = await response.json();
    result.value = data.result;
    terminalOutput.value = data.terminal_output;
    ElMessage.success('è½¬å†™å®Œæˆ');
    
  } catch (error) {
    console.error('è½¬å†™å¤±è´¥:', error);
    ElMessage.error('è½¬å†™å¤±è´¥: ' + error.message);
  } finally {
    uploading.value = false;
  }
}
</script>

<style scoped>
:deep(.el-card) {
  background-color: #374151;
  border: none;
  box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
}

:deep(.el-card__header) {
  background-color: rgba(17, 24, 39, 0.4);
  padding: 12px 16px;
  border-bottom: 1px solid rgba(75, 85, 99, 0.4);
}

:deep(.el-upload) {
  border: 2px dashed #4b5563;
  border-radius: 8px;
  cursor: pointer;
  position: relative;
  overflow: hidden;
  transition: all 0.3s ease;
  background-color: rgba(17, 24, 39, 0.2);
}

:deep(.el-upload:hover) {
  border-color: #3b82f6;
  transform: translateY(-1px);
}

:deep(.el-upload-dragger) {
  background-color: transparent;
  border: none;
  padding: 40px 20px;
}

:deep(.el-upload-dragger:hover) {
  background-color: rgba(107, 114, 128, 0.1);
}

:deep(.el-upload__text) {
  color: #9ca3af;
  margin-top: 16px;
}

:deep(.el-upload__text em) {
  color: #3b82f6;
  font-style: normal;
  font-weight: 500;
}

:deep(.el-button) {
  transition: all 0.3s ease;
}

:deep(.el-button:hover) {
  transform: translateY(-1px);
  box-shadow: 0 4px 6px -1px rgba(59, 130, 246, 0.1);
}

.terminal-output {
  background-color: rgba(17, 24, 39, 0.6);
  border-radius: 6px;
  padding: 16px;
  margin-top: 8px;
}

.terminal-output pre {
  margin: 0;
  line-height: 1.5;
}
</style>
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/views/HotwordManagement.vue
```text
<template>
  <div class="min-h-screen bg-gray-900 text-gray-200">
    <header class="bg-gray-800 py-4 shadow-md">
      <div class="container mx-auto px-4 flex justify-between items-center">
        <h1 class="text-xl font-bold text-blue-400">çƒ­è¯ç®¡ç†</h1>
        <el-button type="primary" @click="$router.push('/')">è¿”å›é¦–é¡µ</el-button>
      </div>
    </header>
    
    <main class="container mx-auto py-8 px-4 max-w-6xl">
      <!-- æ“ä½œå·¥å…·æ  -->
      <el-card class="bg-gray-800 border-none shadow-lg mb-6">
        <div class="flex flex-col sm:flex-row gap-4 items-start sm:items-center justify-between">
          <div class="flex flex-col sm:flex-row gap-4 items-start sm:items-center">
            <el-button type="primary" @click="showAddDialog = true">
              <el-icon><plus /></el-icon>
              æ·»åŠ çƒ­è¯
            </el-button>
            <el-button type="success" @click="showImportDialog = true">
              <el-icon><upload /></el-icon>
              æ‰¹é‡å¯¼å…¥
            </el-button>
            <el-button type="danger" :disabled="selectedRows.length === 0" @click="batchDelete">
              <el-icon><delete /></el-icon>
              æ‰¹é‡åˆ é™¤ ({{ selectedRows.length }})
            </el-button>
          </div>
          <div class="flex gap-4 items-center">
            <span class="text-sm text-gray-400">å…± {{ total }} ä¸ªçƒ­è¯</span>
            <el-input
              v-model="searchKeyword"
              placeholder="æœç´¢çƒ­è¯..."
              prefix-icon="Search"
              clearable
              @input="handleSearch"
              class="w-64"
            />
          </div>
        </div>
      </el-card>
      
      <!-- çƒ­è¯åˆ—è¡¨ -->
      <el-card class="bg-gray-800 border-none shadow-lg">
        <el-table
          v-loading="loading"
          :data="filteredHotwords"
          style="width: 100%"
          @selection-change="handleSelectionChange"
          :empty-text="hotwords.length === 0 ? 'æš‚æ— çƒ­è¯ï¼Œç‚¹å‡»æ·»åŠ æŒ‰é’®åˆ›å»º' : 'æ²¡æœ‰åŒ¹é…çš„çƒ­è¯'"
        >
          <el-table-column type="selection" width="55" />
          <el-table-column prop="word" label="çƒ­è¯" min-width="200">
            <template #default="scope">
              <span class="font-medium">{{ scope.row.word }}</span>
            </template>
          </el-table-column>
          <el-table-column prop="weight" label="æƒé‡" width="120">
            <template #default="scope">
              <el-tag :type="getWeightType(scope.row.weight)" size="small">
                {{ scope.row.weight }}
              </el-tag>
            </template>
          </el-table-column>
          <el-table-column prop="created_at" label="åˆ›å»ºæ—¶é—´" width="180">
            <template #default="scope">
              {{ formatDate(scope.row.created_at) }}
            </template>
          </el-table-column>
          <el-table-column label="æ“ä½œ" width="160">
            <template #default="scope">
              <div class="flex gap-2">
                <el-button type="primary" size="small" @click="editHotword(scope.row)">
                  ç¼–è¾‘
                </el-button>
                <el-button type="danger" size="small" @click="deleteHotword(scope.row)">
                  åˆ é™¤
                </el-button>
              </div>
            </template>
          </el-table-column>
        </el-table>
      </el-card>
      
      <!-- æ·»åŠ /ç¼–è¾‘çƒ­è¯å¯¹è¯æ¡† -->
      <el-dialog
        v-model="showAddDialog"
        :title="editingHotword ? 'ç¼–è¾‘çƒ­è¯' : 'æ·»åŠ çƒ­è¯'"
        width="500px"
        :close-on-click-modal="false"
      >
        <el-form
          ref="hotwordFormRef"
          :model="hotwordForm"
          :rules="hotwordRules"
          label-width="80px"
        >
          <el-form-item label="çƒ­è¯" prop="word">
            <el-input
              v-model="hotwordForm.word"
              placeholder="è¯·è¾“å…¥çƒ­è¯"
              maxlength="255"
              show-word-limit
            />
          </el-form-item>
          <el-form-item label="æƒé‡" prop="weight">
            <el-slider
              v-model="hotwordForm.weight"
              :min="1"
              :max="10"
              :marks="weightMarks"
              show-tooltip
            />
            <div class="text-sm text-gray-400 mt-2">
              æƒé‡è¶Šé«˜ï¼Œè¯†åˆ«ä¼˜å…ˆçº§è¶Šé«˜ï¼ˆå»ºè®®ï¼šå¸¸ç”¨è¯1-5ï¼Œä¸“ä¸šæœ¯è¯­6-10ï¼‰
            </div>
          </el-form-item>
        </el-form>
        
        <template #footer>
          <div class="dialog-footer">
            <el-button @click="showAddDialog = false">å–æ¶ˆ</el-button>
            <el-button type="primary" @click="saveHotword" :loading="saving">
              {{ editingHotword ? 'æ›´æ–°' : 'æ·»åŠ ' }}
            </el-button>
          </div>
        </template>
      </el-dialog>
      
      <!-- æ‰¹é‡å¯¼å…¥å¯¹è¯æ¡† -->
      <el-dialog
        v-model="showImportDialog"
        title="æ‰¹é‡å¯¼å…¥çƒ­è¯"
        width="600px"
        :close-on-click-modal="false"
      >
        <div class="space-y-4">
          <div class="bg-blue-900 p-4 rounded-lg">
            <h4 class="font-semibold mb-2">å¯¼å…¥æ ¼å¼è¯´æ˜ï¼š</h4>
            <ul class="text-sm space-y-1">
              <li>â€¢ æ”¯æŒ CSV å’Œ TXT æ ¼å¼æ–‡ä»¶</li>
              <li>â€¢ CSV æ ¼å¼ï¼šæ¯è¡Œä¸€ä¸ªçƒ­è¯ï¼Œæ ¼å¼ä¸º "çƒ­è¯,æƒé‡"ï¼ˆæƒé‡å¯é€‰ï¼Œé»˜è®¤ä¸º5ï¼‰</li>
              <li>â€¢ TXT æ ¼å¼ï¼šæ¯è¡Œä¸€ä¸ªçƒ­è¯</li>
              <li>â€¢ ç¤ºä¾‹ï¼šæœºå™¨å­¦ä¹ ,8</li>
              <li>â€¢ æœ€å¤šå¯å¯¼å…¥100ä¸ªçƒ­è¯ï¼ˆåŒ…å«ç°æœ‰çƒ­è¯ï¼‰</li>
            </ul>
          </div>
          
          <el-upload
            ref="importUploadRef"
            :auto-upload="false"
            :on-change="handleImportFileChange"
            :before-remove="handleImportFileRemove"
            accept=".csv,.txt"
            :limit="1"
            drag
          >
            <el-icon class="el-icon--upload"><upload-filled /></el-icon>
            <div class="el-upload__text">
              å°†æ–‡ä»¶æ‹–åˆ°æ­¤å¤„ï¼Œæˆ–<em>ç‚¹å‡»ä¸Šä¼ </em>
            </div>
            <template #tip>
              <div class="el-upload__tip">
                åªèƒ½ä¸Šä¼  CSV/TXT æ–‡ä»¶ï¼Œä¸”ä¸è¶…è¿‡ 1MB
              </div>
            </template>
          </el-upload>
          
          <div v-if="importPreview.length > 0" class="bg-gray-700 p-4 rounded-lg">
            <h4 class="font-semibold mb-2">é¢„è§ˆï¼ˆå‰10æ¡ï¼‰ï¼š</h4>
            <div class="space-y-1 text-sm">
              <div v-for="(item, index) in importPreview.slice(0, 10)" :key="index" class="flex justify-between">
                <span>{{ item.word }}</span>
                <span class="text-gray-400">æƒé‡: {{ item.weight }}</span>
              </div>
              <div v-if="importPreview.length > 10" class="text-gray-400">
                ...è¿˜æœ‰ {{ importPreview.length - 10 }} æ¡
              </div>
            </div>
          </div>
        </div>
        
        <template #footer>
          <div class="dialog-footer">
            <el-button @click="showImportDialog = false">å–æ¶ˆ</el-button>
            <el-button 
              type="primary" 
              @click="submitImport" 
              :disabled="importPreview.length === 0"
              :loading="importing"
            >
              å¯¼å…¥ {{ importPreview.length }} ä¸ªçƒ­è¯
            </el-button>
          </div>
        </template>
      </el-dialog>
    </main>
  </div>
</template>

<script setup>
import { ref, reactive, computed, onMounted } from 'vue';
import { useRouter } from 'vue-router';
import { ElMessage, ElMessageBox } from 'element-plus';
import { Plus, Upload, Delete, UploadFilled } from '@element-plus/icons-vue';
import { hotwordAPI } from '../services/api';

const router = useRouter();

// æ•°æ®çŠ¶æ€
const hotwords = ref([]);
const loading = ref(false);
const saving = ref(false);
const importing = ref(false);
const total = ref(0);
const selectedRows = ref([]);
const searchKeyword = ref('');

// å¯¹è¯æ¡†çŠ¶æ€
const showAddDialog = ref(false);
const showImportDialog = ref(false);
const editingHotword = ref(null);

// è¡¨å•æ•°æ®
const hotwordForm = reactive({
  word: '',
  weight: 5
});

const importPreview = ref([]);
const importFile = ref(null);

// è¡¨å•éªŒè¯è§„åˆ™
const hotwordRules = {
  word: [
    { required: true, message: 'è¯·è¾“å…¥çƒ­è¯', trigger: 'blur' },
    { min: 1, max: 255, message: 'çƒ­è¯é•¿åº¦åº”åœ¨1-255å­—ç¬¦ä¹‹é—´', trigger: 'blur' }
  ],
  weight: [
    { required: true, message: 'è¯·é€‰æ‹©æƒé‡', trigger: 'change' },
    { type: 'number', min: 1, max: 10, message: 'æƒé‡å¿…é¡»åœ¨1-10ä¹‹é—´', trigger: 'change' }
  ]
};

// æƒé‡æ»‘å—æ ‡è®°
const weightMarks = {
  1: 'ä½',
  5: 'ä¸­',
  10: 'é«˜'
};

// è®¡ç®—å±æ€§
const filteredHotwords = computed(() => {
  if (!searchKeyword.value) return hotwords.value;
  const keyword = searchKeyword.value.toLowerCase();
  return hotwords.value.filter(item => 
    item.word.toLowerCase().includes(keyword)
  );
});

onMounted(() => {
  loadHotwords();
});

// åŠ è½½çƒ­è¯åˆ—è¡¨
async function loadHotwords() {
  try {
    loading.value = true;
    const result = await hotwordAPI.getUserHotwords(0, 100);
    hotwords.value = result;
    total.value = result.length;
  } catch (error) {
    console.error('åŠ è½½çƒ­è¯å¤±è´¥:', error);
    ElMessage.error('åŠ è½½çƒ­è¯å¤±è´¥: ' + (error.response?.data?.detail || error.message));
  } finally {
    loading.value = false;
  }
}

// è¡¨æ ¼é€‰æ‹©å˜åŒ–
function handleSelectionChange(selection) {
  selectedRows.value = selection;
}

// æœç´¢å¤„ç†
function handleSearch() {
  // æœç´¢æ˜¯å“åº”å¼çš„ï¼Œç”±computedè‡ªåŠ¨å¤„ç†
}

// ç¼–è¾‘çƒ­è¯
function editHotword(hotword) {
  editingHotword.value = hotword;
  hotwordForm.word = hotword.word;
  hotwordForm.weight = hotword.weight;
  showAddDialog.value = true;
}

// ä¿å­˜çƒ­è¯
async function saveHotword() {
  const hotwordFormRef = ref();
  if (!hotwordFormRef.value) return;
  
  try {
    await hotwordFormRef.value.validate();
    saving.value = true;
    
    if (editingHotword.value) {
      // æ›´æ–°çƒ­è¯
      await hotwordAPI.updateHotword(editingHotword.value.id, {
        word: hotwordForm.word,
        weight: hotwordForm.weight
      });
      ElMessage.success('çƒ­è¯æ›´æ–°æˆåŠŸ');
    } else {
      // æ·»åŠ çƒ­è¯
      await hotwordAPI.createHotword(hotwordForm.word, hotwordForm.weight);
      ElMessage.success('çƒ­è¯æ·»åŠ æˆåŠŸ');
    }
    
    showAddDialog.value = false;
    resetForm();
    loadHotwords();
  } catch (error) {
    console.error('ä¿å­˜çƒ­è¯å¤±è´¥:', error);
    ElMessage.error('ä¿å­˜å¤±è´¥: ' + (error.response?.data?.detail || error.message));
  } finally {
    saving.value = false;
  }
}

// åˆ é™¤çƒ­è¯
async function deleteHotword(hotword) {
  try {
    await ElMessageBox.confirm(
      `ç¡®å®šè¦åˆ é™¤çƒ­è¯ "${hotword.word}" å—ï¼Ÿ`,
      'ç¡®è®¤åˆ é™¤',
      {
        confirmButtonText: 'ç¡®å®š',
        cancelButtonText: 'å–æ¶ˆ',
        type: 'warning'
      }
    );
    
    await hotwordAPI.deleteHotword(hotword.id);
    ElMessage.success('çƒ­è¯åˆ é™¤æˆåŠŸ');
    loadHotwords();
  } catch (error) {
    if (error !== 'cancel') {
      console.error('åˆ é™¤çƒ­è¯å¤±è´¥:', error);
      ElMessage.error('åˆ é™¤å¤±è´¥: ' + (error.response?.data?.detail || error.message));
    }
  }
}

// æ‰¹é‡åˆ é™¤
async function batchDelete() {
  if (selectedRows.value.length === 0) return;
  
  try {
    await ElMessageBox.confirm(
      `ç¡®å®šè¦åˆ é™¤é€‰ä¸­çš„ ${selectedRows.value.length} ä¸ªçƒ­è¯å—ï¼Ÿ`,
      'ç¡®è®¤æ‰¹é‡åˆ é™¤',
      {
        confirmButtonText: 'ç¡®å®š',
        cancelButtonText: 'å–æ¶ˆ',
        type: 'warning'
      }
    );
    
    // å¹¶è¡Œåˆ é™¤æ‰€æœ‰é€‰ä¸­çš„çƒ­è¯
    await Promise.all(
      selectedRows.value.map(hotword => hotwordAPI.deleteHotword(hotword.id))
    );
    
    ElMessage.success(`æˆåŠŸåˆ é™¤ ${selectedRows.value.length} ä¸ªçƒ­è¯`);
    selectedRows.value = [];
    loadHotwords();
  } catch (error) {
    if (error !== 'cancel') {
      console.error('æ‰¹é‡åˆ é™¤å¤±è´¥:', error);
      ElMessage.error('æ‰¹é‡åˆ é™¤å¤±è´¥: ' + (error.response?.data?.detail || error.message));
    }
  }
}

// å¤„ç†å¯¼å…¥æ–‡ä»¶å˜åŒ–
function handleImportFileChange(file) {
  importFile.value = file.raw;
  parseImportFile(file.raw);
}

function handleImportFileRemove() {
  importFile.value = null;
  importPreview.value = [];
}

// è§£æå¯¼å…¥æ–‡ä»¶
async function parseImportFile(file) {
  try {
    const text = await file.text();
    const lines = text.split('\n').filter(line => line.trim());
    const preview = [];
    
    for (const line of lines) {
      const trimmed = line.trim();
      if (!trimmed) continue;
      
      let word, weight = 5;
      
      // å°è¯•è§£æCSVæ ¼å¼
      if (trimmed.includes(',')) {
        const parts = trimmed.split(',');
        word = parts[0].trim();
        if (parts[1]) {
          const w = parseInt(parts[1].trim());
          if (w >= 1 && w <= 10) {
            weight = w;
          }
        }
      } else {
        word = trimmed;
      }
      
      if (word) {
        preview.push({ word, weight });
      }
    }
    
    importPreview.value = preview;
  } catch (error) {
    console.error('è§£ææ–‡ä»¶å¤±è´¥:', error);
    ElMessage.error('æ–‡ä»¶è§£æå¤±è´¥');
    importPreview.value = [];
  }
}

// æäº¤å¯¼å…¥
async function submitImport() {
  if (!importFile.value) {
    ElMessage.error('è¯·é€‰æ‹©è¦å¯¼å…¥çš„æ–‡ä»¶');
    return;
  }
  
  try {
    importing.value = true;
    const result = await hotwordAPI.importHotwords(importFile.value);
    
    ElMessage.success(
      `å¯¼å…¥å®Œæˆï¼šæˆåŠŸæ·»åŠ  ${result.added_count} ä¸ªçƒ­è¯ï¼Œè·³è¿‡ ${result.skipped_count} ä¸ªé‡å¤çƒ­è¯`
    );
    
    showImportDialog.value = false;
    importFile.value = null;
    importPreview.value = [];
    loadHotwords();
  } catch (error) {
    console.error('å¯¼å…¥å¤±è´¥:', error);
    ElMessage.error('å¯¼å…¥å¤±è´¥: ' + (error.response?.data?.detail || error.message));
  } finally {
    importing.value = false;
  }
}

// é‡ç½®è¡¨å•
function resetForm() {
  editingHotword.value = null;
  hotwordForm.word = '';
  hotwordForm.weight = 5;
}

// å·¥å…·å‡½æ•°
function getWeightType(weight) {
  if (weight <= 3) return 'info';
  if (weight <= 6) return 'warning';
  return 'success';
}

function formatDate(dateString) {
  const date = new Date(dateString);
  return date.toLocaleString('zh-CN');
}
</script>

<style scoped>
:deep(.el-card) {
  background-color: #374151;
  border: none;
}

:deep(.el-card__header) {
  background-color: rgba(17, 24, 39, 0.4);
  padding: 12px 16px;
}

:deep(.el-table) {
  background-color: transparent !important;
}

:deep(.el-table th.el-table__cell) {
  background-color: #1f2937 !important;
}

:deep(.el-table tr) {
  background-color: #374151 !important;
}

:deep(.el-table--striped .el-table__body tr.el-table__row--striped td.el-table__cell) {
  background-color: #4b5563 !important;
}

:deep(.el-table__body tr:hover > td.el-table__cell) {
  background-color: #6b7280 !important;
}

:deep(.el-dialog) {
  background-color: #374151;
}

:deep(.el-dialog__header) {
  background-color: #1f2937;
  margin: 0;
  padding: 16px 20px;
}

:deep(.el-dialog__body) {
  padding: 20px;
}

:deep(.el-upload) {
  border: 2px dashed #4b5563;
  border-radius: 6px;
}

:deep(.el-upload:hover) {
  border-color: #3b82f6;
}

:deep(.el-upload-dragger) {
  background-color: #4b5563;
  border: none;
}

:deep(.el-upload-dragger:hover) {
  background-color: #6b7280;
}

:deep(.el-slider__runway) {
  background-color: #4b5563;
}

:deep(.el-slider__button) {
  border-color: #3b82f6;
}

:deep(.el-form-item__label) {
  color: #d1d5db;
}
</style>
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/views/Dashboard.vue
```text
<template>
  <div class="min-h-screen bg-gray-900 text-gray-200">
    <header class="bg-gray-800 py-4 shadow-md">
      <div class="container mx-auto px-4 flex justify-between items-center">
        <h1 class="text-xl font-bold text-blue-400">æ”¯æŒçƒ­è¯é¢„æµ‹çš„è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ</h1>
        <div class="flex items-center gap-4">
          <span>{{ username }}</span>
          <el-button type="danger" size="small" @click="logout">é€€å‡ºç™»å½•</el-button>
        </div>
      </div>
    </header>
    
    <main class="container mx-auto py-8 px-4">
      <h2 class="text-2xl font-bold mb-6">æ¬¢è¿ä½¿ç”¨è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ</h2>
      
      <div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-10">
        <el-card class="bg-gray-800 border-none shadow-lg hover:shadow-xl transition-all">
          <template #header>
            <div class="flex items-center">
              <i class="el-icon-microphone mr-2"></i>
              <span>ç¦»çº¿æ–‡ä»¶è½¬å†™</span>
            </div>
          </template>
          <div class="text-gray-400">
            ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¿›è¡Œè½¬å†™å¹¶è¿”å›æ–‡æœ¬ç»“æœã€‚
          </div>
          <el-button type="primary" class="mt-4 w-full" @click="$router.push('/transcribe')">å¼€å§‹è½¬å†™</el-button>
        </el-card>
        
        <el-card class="bg-gray-800 border-none shadow-lg hover:shadow-xl transition-all">
          <template #header>
            <div class="flex items-center">
              <i class="el-icon-video-play mr-2"></i>
              <span>å®æ—¶è¯­éŸ³è½¬å†™</span>
            </div>
          </template>
          <div class="text-gray-400">
            ä½¿ç”¨éº¦å…‹é£è¿›è¡Œå®æ—¶å½•éŸ³ï¼Œç³»ç»Ÿä¼šå³æ—¶è½¬å†™æ‚¨çš„è¯­éŸ³å†…å®¹ã€‚
          </div>
          <el-button type="success" class="mt-4 w-full" @click="$router.push('/realtime')">å¼€å§‹å®æ—¶è½¬å†™</el-button>
        </el-card>
        
        <el-card class="bg-gray-800 border-none shadow-lg hover:shadow-xl transition-all">
          <template #header>
            <div class="flex items-center">
              <i class="el-icon-s-order mr-2"></i>
              <span>çƒ­è¯ç®¡ç†</span>
            </div>
          </template>
          <div class="text-gray-400">
            æ·»åŠ å’Œç®¡ç†æ‚¨çš„ä¸“ä¸šé¢†åŸŸè¯æ±‡ï¼Œæé«˜è¯­éŸ³è¯†åˆ«å‡†ç¡®ç‡ã€‚
          </div>
          <el-button type="warning" class="mt-4 w-full" @click="$router.push('/hotwords')">ç®¡ç†çƒ­è¯</el-button>
        </el-card>
      </div>
    </main>
  </div>
</template>

<script setup>
import { ref, onMounted } from 'vue';
import { useRouter } from 'vue-router';
import { authAPI } from '../services/api';
import { ElMessage } from 'element-plus';

const router = useRouter();
const username = ref('ç”¨æˆ·');

onMounted(async () => {
  try {
    // è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
    const userData = await authAPI.getCurrentUser();
    username.value = userData.username;
  } catch (err) {
    console.error('åŠ è½½æ•°æ®å¤±è´¥', err);
    if (err.response?.status === 401) {
      ElMessage.error('ç™»å½•å·²è¿‡æœŸï¼Œè¯·é‡æ–°ç™»å½•');
      logout();
    }
  }
});

function logout() {
  localStorage.removeItem('token');
  router.push('/login');
}
</script>

<style scoped>
:deep(.el-card) {
  background-color: #374151;
  border: none;
}

:deep(.el-card__header) {
  background-color: rgba(17, 24, 39, 0.4);
  padding: 12px 16px;
}
</style>
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/views/Auth/RegisterPage.vue
```text
<template>
  <div class="min-h-screen flex items-center justify-center bg-gray-900">
    <div class="w-full max-w-md p-8 bg-gray-800 rounded-lg shadow-lg border border-gray-700">
      <h1 class="text-3xl font-bold text-center text-blue-400 mb-8">ç”¨æˆ·æ³¨å†Œ</h1>
      <el-form :model="form" ref="registerForm" class="space-y-4">
        <el-form-item prop="username">
          <el-input v-model="form.username" placeholder="è¯·è¾“å…¥ç”¨æˆ·å" prefix-icon="el-icon-user" size="large" clearable />
        </el-form-item>
        <el-form-item prop="password">
          <el-input v-model="form.password" type="password" placeholder="è¯·è¾“å…¥å¯†ç " prefix-icon="el-icon-lock" size="large" show-password clearable />
        </el-form-item>
        <el-form-item prop="confirmPassword">
          <el-input v-model="form.confirmPassword" type="password" placeholder="è¯·å†æ¬¡è¾“å…¥å¯†ç " size="large" show-password clearable />
        </el-form-item>
        <div v-if="errorMsg" class="text-red-500 text-sm text-center mb-2">{{ errorMsg }}</div>
        <el-form-item>
          <el-button type="primary" size="large" class="w-full" @click="onSubmit" :loading="loading">æ³¨å†Œ</el-button>
        </el-form-item>
        <div class="text-sm text-center mt-4">
          å·²æœ‰è´¦å·ï¼Ÿ<router-link to="/login" class="text-blue-400 hover:underline">ç«‹å³ç™»å½•</router-link>
        </div>
      </el-form>
    </div>
  </div>
</template>

<script setup>
import { ref } from 'vue';
import { useRouter } from 'vue-router';
import { authAPI } from '../../services/api';
import { ElMessage } from 'element-plus';

const router = useRouter();
const form = ref({ username: '', password: '', confirmPassword: '' });
const errorMsg = ref('');
const loading = ref(false);

async function onSubmit() {
  if (!form.value.username || !form.value.password || !form.value.confirmPassword) {
    errorMsg.value = 'æ‰€æœ‰å­—æ®µå‡ä¸ºå¿…å¡«é¡¹ã€‚';
    return;
  }
  if (form.value.password !== form.value.confirmPassword) {
    errorMsg.value = 'ä¸¤æ¬¡è¾“å…¥çš„å¯†ç ä¸ä¸€è‡´ã€‚';
    return;
  }
  
  loading.value = true;
  errorMsg.value = '';
  
  try {
    await authAPI.register(form.value.username, form.value.password);
    ElMessage({
      message: 'æ³¨å†ŒæˆåŠŸï¼å°†è¿”å›ç™»å½•é¡µé¢ã€‚',
      type: 'success'
    });
    router.push('/login');
  } catch (err) {
    errorMsg.value = err.response?.data?.detail || 'æ³¨å†Œå¤±è´¥';
  } finally {
    loading.value = false;
  }
}
</script>

<style scoped>
</style>
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/views/Auth/LoginPage.vue
```text
<template>
  <div class="min-h-screen flex items-center justify-center bg-gray-900">
    <div class="w-full max-w-md p-8 bg-gray-800 rounded-lg shadow-lg border border-gray-700">
      <h1 class="text-3xl font-bold text-center text-blue-400 mb-8">ç³»ç»Ÿç™»å½•</h1>
      <el-form :model="form" ref="loginForm" class="space-y-4">
        <el-form-item prop="username">
          <el-input v-model="form.username" placeholder="è¯·è¾“å…¥ç”¨æˆ·å/é‚®ç®±" prefix-icon="el-icon-user" size="large" clearable />
        </el-form-item>
        <el-form-item prop="password">
          <el-input v-model="form.password" type="password" placeholder="è¯·è¾“å…¥å¯†ç " prefix-icon="el-icon-lock" size="large" show-password clearable />
        </el-form-item>
        <el-form-item>
          <div class="flex items-center gap-2">
            <el-input v-model="form.captcha" placeholder="è¾“å…¥éªŒè¯ç " maxlength="4" class="w-1/2" />
            <div class="captcha-box flex-1 h-12 flex items-center justify-center rounded bg-gray-900 border border-yellow-400 text-yellow-400 text-lg font-mono tracking-widest cursor-pointer select-none" @click="generateCaptcha" :title="'ç‚¹å‡»åˆ·æ–°'">{{ captcha }}</div>
          </div>
        </el-form-item>
        <div v-if="errorMsg" class="text-red-500 text-sm text-center mb-2">{{ errorMsg }}</div>
        <el-form-item>
          <el-button type="primary" size="large" class="w-full" @click="onSubmit" :loading="loading">ç™»å½•</el-button>
        </el-form-item>
        <div class="text-sm text-center mt-4">
          è¿˜æ²¡æœ‰è´¦å·ï¼Ÿ<router-link to="/register" class="text-blue-400 hover:underline">ç«‹å³æ³¨å†Œ</router-link>
        </div>
      </el-form>
    </div>
  </div>
</template>

<script setup>
import { ref } from 'vue';
import { useRouter } from 'vue-router';
import { authAPI } from '../../services/api';

const router = useRouter();
const form = ref({ username: '', password: '', captcha: '' });
const errorMsg = ref('');
const captcha = ref('');
const loading = ref(false);

function generateCaptcha() {
  const chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789';
  let result = '';
  for (let i = 0; i < 4; i++) {
    result += chars.charAt(Math.floor(Math.random() * chars.length));
  }
  captcha.value = result;
}

async function onSubmit() {
  if (!form.value.username || !form.value.password || !form.value.captcha) {
    errorMsg.value = 'æ‰€æœ‰å­—æ®µå‡ä¸ºå¿…å¡«é¡¹ã€‚';
    return;
  }
  if (form.value.captcha.toUpperCase() !== captcha.value) {
    errorMsg.value = 'éªŒè¯ç ä¸æ­£ç¡®ã€‚';
    generateCaptcha();
    return;
  }

  loading.value = true;
  errorMsg.value = '';

  try {
    const res = await authAPI.login(form.value.username, form.value.password);
    localStorage.setItem('token', res.access_token);
    router.push('/');
  } catch (err) {
    errorMsg.value = err.response?.data?.detail || 'ç™»å½•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç”¨æˆ·åå’Œå¯†ç ';
    generateCaptcha();
  } finally {
    loading.value = false;
  }
}

generateCaptcha();
</script>

<style scoped>
.captcha-box {
  min-width: 80px;
  height: 48px;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 1.5rem;
  font-family: 'Courier New', Courier, monospace;
  letter-spacing: 5px;
  user-select: none;
  cursor: pointer;
  background-color: #18181b;
  border: 1px solid #facc15;
  color: #facc15;
}
</style>
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/services/api.js
```javascript
import axios from 'axios';

// é…ç½®axiosåŸºç¡€URL - ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œä¾èµ–viteçš„ä»£ç†é…ç½®
axios.defaults.withCredentials = true;  // å…è®¸è·¨åŸŸè¯·æ±‚æºå¸¦å‡­è¯

// WebSocket URLé…ç½® - ä½¿ç”¨ç›¸å¯¹è·¯å¾„
const WS_BASE_URL = '';  // ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºä½¿ç”¨ç›¸å¯¹è·¯å¾„

// è¯·æ±‚æ‹¦æˆªå™¨ï¼šæ·»åŠ è®¤è¯token
// ç¡®ä¿æ‹¦æˆªå™¨æ­£å¸¸å·¥ä½œ
axios.interceptors.request.use(config => {
  const token = localStorage.getItem('token');
  config.headers.Authorization = `Bearer ${token}`; // éœ€è¦ç¡®è®¤tokenå­˜åœ¨
  return config;
});

// å“åº”æ‹¦æˆªå™¨ï¼šå¤„ç†401é”™è¯¯
axios.interceptors.response.use(
  (response) => {
    return response;
  },
  (error) => {
    if (error.response && error.response.status === 401) {
      // Tokenè¿‡æœŸæˆ–æ— æ•ˆï¼Œæ¸…é™¤æœ¬åœ°å­˜å‚¨å¹¶è·³è½¬åˆ°ç™»å½•é¡µ
      localStorage.removeItem('token');
      localStorage.removeItem('user');
      window.location.href = '/login';
    }
    return Promise.reject(error);
  }
);

// Auth API
export const authAPI = {
  login: async (username, password) => {
    const formData = new FormData();
    formData.append('username', username);
    formData.append('password', password);
    const response = await axios.post('/auth/token', formData, {
      headers: {
        'Content-Type': 'multipart/form-data'
      }
    });
    return response.data;
  },
  
  register: async (username, password) => {
    const formData = new FormData();
    formData.append('username', username);
    formData.append('password', password);
    const response = await axios.post('/auth/register', formData, {
      headers: {
        'Content-Type': 'multipart/form-data'
      }
    });
    return response.data;
  },
  
  getCurrentUser: async () => {
    const response = await axios.get('/auth/me');
    return response.data;
  }
};

// Transcription API
export const transcriptionAPI = {
  submitTask: async (file, hotwordListId = null) => {
    const formData = new FormData();
    formData.append('file', file);
    if (hotwordListId) {
      formData.append('hotword_list_id', hotwordListId);
    }
    
    const response = await axios.post('/asr/transcribe/file', formData, {
      headers: {
        'Content-Type': 'multipart/form-data'
      }
    });
    
    return response.data;
  }
};

// Hotwords API
export const hotwordAPI = {
  createHotword: async (word, weight) => {
    const response = await axios.post('/hotwords', { word, weight });
    return response.data;
  },
  
  getUserHotwords: async (skip = 0, limit = 100) => {
    const response = await axios.get(`/hotwords?skip=${skip}&limit=${limit}`);
    return response.data;
  },
  
  updateHotword: async (hotwordId, data) => {
    const response = await axios.put(`/hotwords/${hotwordId}`, data);
    return response.data;
  },
  
  deleteHotword: async (hotwordId) => {
    const response = await axios.delete(`/hotwords/${hotwordId}`);
    return response.data;
  },
  
  importHotwords: async (file) => {
    const formData = new FormData();
    formData.append('file', file);
    
    const response = await axios.post('/hotwords/import', formData, {
      headers: {
        'Content-Type': 'multipart/form-data'
      }
    });
    
    return response.data;
  }
};

// Realtime API (WebSocket ç›¸å…³å·¥å…·å‡½æ•°)
export const realtimeAPI = {
  getWebSocketUrl: () => {
    const token = localStorage.getItem('token');
    return `${WS_BASE_URL}/ws/asr/transcribe/realtime?token=${token}`;
  },
  
  // å¿ƒè·³æ£€æµ‹
  sendHeartbeat: (websocket) => {
    if (websocket && websocket.readyState === WebSocket.OPEN) {
      websocket.send(JSON.stringify({
        type: 'ping',
        timestamp: Date.now()
      }));
    }
  },
  
  // å‘é€å‘½ä»¤
  sendCommand: (websocket, command) => {
    if (websocket && websocket.readyState === WebSocket.OPEN) {
      websocket.send(JSON.stringify(command));
    }
  }
};
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/router/index.js
```javascript
import { createRouter, createWebHistory } from 'vue-router';
import LoginPage from '../views/Auth/LoginPage.vue';
import RegisterPage from '../views/Auth/RegisterPage.vue';
import Dashboard from '../views/Dashboard.vue';
import FileTranscription from '../views/FileTranscription.vue';
import RealtimeTranscription from '../views/RealtimeTranscription.vue';
import HotwordManagement from '../views/HotwordManagement.vue';

const routes = [
  { path: '/login', component: LoginPage },
  { path: '/register', component: RegisterPage },
  { path: '/', component: Dashboard },
  { path: '/transcribe', component: FileTranscription },
  { path: '/realtime', component: RealtimeTranscription },
  { path: '/hotwords', component: HotwordManagement },
];

const router = createRouter({
  history: createWebHistory(),
  routes,
});

router.beforeEach((to, from, next) => {
  const publicPages = ['/login', '/register'];
  const authRequired = !publicPages.includes(to.path);
  const token = localStorage.getItem('token');
  if (authRequired && !token) {
    return next('/login');
  }
  next();
});

export default router;
```

--------------------------------------------------------------------------------

File: test/test_hotwords.py
```python
import pytest
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from asr_system_backend.app.main import app
from asr_system_backend.app.database import Base, get_db
from asr_system_backend.app.models import User, Hotword
from asr_system_backend.app.auth_service import get_password_hash
import tempfile

# åˆ›å»ºæµ‹è¯•æ•°æ®åº“
SQLALCHEMY_DATABASE_URL = "sqlite:///./test.db"
engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False})
TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# åˆ›å»ºæ•°æ®åº“è¡¨
Base.metadata.create_all(bind=engine)

def override_get_db():
    try:
        db = TestingSessionLocal()
        yield db
    finally:
        db.close()

# è¦†ç›–ä¾èµ–
app.dependency_overrides[get_db] = override_get_db

client = TestClient(app)

@pytest.fixture
def test_user():
    """åˆ›å»ºæµ‹è¯•ç”¨æˆ·"""
    db = TestingSessionLocal()
    try:
        # æ¸…ç†ç°æœ‰æµ‹è¯•æ•°æ®
        db.query(Hotword).delete()
        db.query(User).delete()
        db.commit()
        
        # åˆ›å»ºæµ‹è¯•ç”¨æˆ·
        user = User(
            username="testuser",
            hashed_password=get_password_hash("testpass123")
        )
        db.add(user)
        db.commit()
        db.refresh(user)
        
        return user
    finally:
        db.close()

@pytest.fixture
def auth_headers(test_user):
    """è·å–è®¤è¯å¤´"""
    response = client.post("/auth/login", json={
        "username": "testuser",
        "password": "testpass123"
    })
    assert response.status_code == 200
    token = response.json()["access_token"]
    return {"Authorization": f"Bearer {token}"}

class TestHotwordAPI:
    """çƒ­è¯ç®¡ç†APIæµ‹è¯•"""
    
    def test_create_hotword(self, auth_headers):
        """æµ‹è¯•åˆ›å»ºçƒ­è¯"""
        response = client.post("/hotwords", json={
            "word": "æµ‹è¯•çƒ­è¯",
            "weight": 8
        }, headers=auth_headers)
        
        assert response.status_code == 200
        data = response.json()
        assert data["word"] == "æµ‹è¯•çƒ­è¯"
        assert data["weight"] == 8
        assert "id" in data
        assert "created_at" in data
    
    def test_create_hotword_invalid_weight(self, auth_headers):
        """æµ‹è¯•åˆ›å»ºçƒ­è¯ - æ— æ•ˆæƒé‡"""
        response = client.post("/hotwords", json={
            "word": "æµ‹è¯•çƒ­è¯",
            "weight": 15  # è¶…å‡ºèŒƒå›´
        }, headers=auth_headers)
        
        assert response.status_code == 422
    
    def test_create_duplicate_hotword(self, auth_headers):
        """æµ‹è¯•åˆ›å»ºé‡å¤çƒ­è¯"""
        # åˆ›å»ºç¬¬ä¸€ä¸ªçƒ­è¯
        client.post("/hotwords", json={
            "word": "é‡å¤çƒ­è¯",
            "weight": 5
        }, headers=auth_headers)
        
        # å°è¯•åˆ›å»ºç›¸åŒçš„çƒ­è¯
        response = client.post("/hotwords", json={
            "word": "é‡å¤çƒ­è¯",
            "weight": 6
        }, headers=auth_headers)
        
        assert response.status_code == 409
        assert "çƒ­è¯å·²å­˜åœ¨" in response.json()["detail"]
    
    def test_get_user_hotwords(self, auth_headers):
        """æµ‹è¯•è·å–ç”¨æˆ·çƒ­è¯åˆ—è¡¨"""
        # åˆ›å»ºå‡ ä¸ªçƒ­è¯
        for i in range(3):
            client.post("/hotwords", json={
                "word": f"çƒ­è¯{i}",
                "weight": 5
            }, headers=auth_headers)
        
        response = client.get("/hotwords", headers=auth_headers)
        
        assert response.status_code == 200
        data = response.json()
        assert len(data) == 3
        assert all("word" in item for item in data)
    
    def test_get_user_hotwords_pagination(self, auth_headers):
        """æµ‹è¯•çƒ­è¯åˆ—è¡¨åˆ†é¡µ"""
        # åˆ›å»º5ä¸ªçƒ­è¯
        for i in range(5):
            client.post("/hotwords", json={
                "word": f"åˆ†é¡µçƒ­è¯{i}",
                "weight": 5
            }, headers=auth_headers)
        
        # æµ‹è¯•åˆ†é¡µ
        response = client.get("/hotwords?skip=0&limit=2", headers=auth_headers)
        assert response.status_code == 200
        data = response.json()
        assert len(data) == 2
        
        response = client.get("/hotwords?skip=2&limit=2", headers=auth_headers)
        assert response.status_code == 200
        data = response.json()
        assert len(data) == 2
    
    def test_update_hotword(self, auth_headers):
        """æµ‹è¯•æ›´æ–°çƒ­è¯"""
        # åˆ›å»ºçƒ­è¯
        response = client.post("/hotwords", json={
            "word": "åŸå§‹çƒ­è¯",
            "weight": 5
        }, headers=auth_headers)
        hotword_id = response.json()["id"]
        
        # æ›´æ–°çƒ­è¯
        response = client.put(f"/hotwords/{hotword_id}", json={
            "word": "æ›´æ–°çƒ­è¯",
            "weight": 8
        }, headers=auth_headers)
        
        assert response.status_code == 200
        data = response.json()
        assert data["word"] == "æ›´æ–°çƒ­è¯"
        assert data["weight"] == 8
    
    def test_update_nonexistent_hotword(self, auth_headers):
        """æµ‹è¯•æ›´æ–°ä¸å­˜åœ¨çš„çƒ­è¯"""
        response = client.put("/hotwords/nonexistent", json={
            "word": "æ›´æ–°çƒ­è¯",
            "weight": 8
        }, headers=auth_headers)
        
        assert response.status_code == 404
    
    def test_delete_hotword(self, auth_headers):
        """æµ‹è¯•åˆ é™¤çƒ­è¯"""
        # åˆ›å»ºçƒ­è¯
        response = client.post("/hotwords", json={
            "word": "å¾…åˆ é™¤çƒ­è¯",
            "weight": 5
        }, headers=auth_headers)
        hotword_id = response.json()["id"]
        
        # åˆ é™¤çƒ­è¯
        response = client.delete(f"/hotwords/{hotword_id}", headers=auth_headers)
        assert response.status_code == 200
        
        # éªŒè¯çƒ­è¯å·²è¢«åˆ é™¤
        response = client.get("/hotwords", headers=auth_headers)
        data = response.json()
        assert not any(hw["id"] == hotword_id for hw in data)
    
    def test_delete_nonexistent_hotword(self, auth_headers):
        """æµ‹è¯•åˆ é™¤ä¸å­˜åœ¨çš„çƒ­è¯"""
        response = client.delete("/hotwords/nonexistent", headers=auth_headers)
        assert response.status_code == 404
    
    def test_bulk_import_hotwords_csv(self, auth_headers):
        """æµ‹è¯•æ‰¹é‡å¯¼å…¥çƒ­è¯ - CSVæ ¼å¼"""
        # åˆ›å»ºä¸´æ—¶CSVæ–‡ä»¶
        csv_content = """çƒ­è¯1,5
çƒ­è¯2,8
çƒ­è¯3,3
"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            f.write(csv_content)
            temp_file = f.name
        
        try:
            # ä¸Šä¼ CSVæ–‡ä»¶
            with open(temp_file, 'rb') as f:
                response = client.post("/hotwords/import", 
                    files={"file": ("hotwords.csv", f, "text/csv")},
                    headers=auth_headers
                )
            
            assert response.status_code == 200
            data = response.json()
            assert data["added_count"] == 3
            assert data["skipped_count"] == 0
            
            # éªŒè¯çƒ­è¯å·²å¯¼å…¥
            response = client.get("/hotwords", headers=auth_headers)
            hotwords = response.json()
            assert len(hotwords) == 3
            
        finally:
            os.unlink(temp_file)
    
    def test_bulk_import_hotwords_with_duplicates(self, auth_headers):
        """æµ‹è¯•æ‰¹é‡å¯¼å…¥çƒ­è¯ - åŒ…å«é‡å¤é¡¹"""
        # å…ˆåˆ›å»ºä¸€ä¸ªçƒ­è¯
        client.post("/hotwords", json={
            "word": "å·²å­˜åœ¨çƒ­è¯",
            "weight": 5
        }, headers=auth_headers)
        
        # åˆ›å»ºåŒ…å«é‡å¤çƒ­è¯çš„CSVæ–‡ä»¶
        csv_content = """å·²å­˜åœ¨çƒ­è¯,8
æ–°çƒ­è¯1,6
æ–°çƒ­è¯2,7
"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            f.write(csv_content)
            temp_file = f.name
        
        try:
            # ä¸Šä¼ CSVæ–‡ä»¶
            with open(temp_file, 'rb') as f:
                response = client.post("/hotwords/import", 
                    files={"file": ("hotwords.csv", f, "text/csv")},
                    headers=auth_headers
                )
            
            assert response.status_code == 200
            data = response.json()
            assert data["added_count"] == 2  # åªæ·»åŠ äº†ä¸¤ä¸ªæ–°çƒ­è¯
            assert data["skipped_count"] == 1  # è·³è¿‡äº†ä¸€ä¸ªé‡å¤çƒ­è¯
            
        finally:
            os.unlink(temp_file)
    
    def test_bulk_import_invalid_file_format(self, auth_headers):
        """æµ‹è¯•æ‰¹é‡å¯¼å…¥ - æ— æ•ˆæ–‡ä»¶æ ¼å¼"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            f.write("invalid content")
            temp_file = f.name
        
        try:
            # ä¸Šä¼ æ— æ•ˆæ ¼å¼æ–‡ä»¶
            with open(temp_file, 'rb') as f:
                response = client.post("/hotwords/import", 
                    files={"file": ("hotwords.pdf", f, "application/pdf")},
                    headers=auth_headers
                )
            
            assert response.status_code == 422
            
        finally:
            os.unlink(temp_file)
    
    def test_hotword_access_control(self, auth_headers):
        """æµ‹è¯•çƒ­è¯è®¿é—®æ§åˆ¶"""
        # åˆ›å»ºå¦ä¸€ä¸ªç”¨æˆ·
        db = TestingSessionLocal()
        try:
            user2 = User(
                username="testuser2",
                hashed_password=get_password_hash("testpass123")
            )
            db.add(user2)
            db.commit()
        finally:
            db.close()
        
        # è·å–ç¬¬äºŒä¸ªç”¨æˆ·çš„token
        response = client.post("/auth/login", json={
            "username": "testuser2",
            "password": "testpass123"
        })
        user2_token = response.json()["access_token"]
        user2_headers = {"Authorization": f"Bearer {user2_token}"}
        
        # ç”¨æˆ·1åˆ›å»ºçƒ­è¯
        response = client.post("/hotwords", json={
            "word": "ç”¨æˆ·1çƒ­è¯",
            "weight": 5
        }, headers=auth_headers)
        hotword_id = response.json()["id"]
        
        # ç”¨æˆ·2å°è¯•è®¿é—®ç”¨æˆ·1çš„çƒ­è¯
        response = client.put(f"/hotwords/{hotword_id}", json={
            "word": "æ¶æ„ä¿®æ”¹",
            "weight": 10
        }, headers=user2_headers)
        
        assert response.status_code == 403
        
        # ç”¨æˆ·2å°è¯•åˆ é™¤ç”¨æˆ·1çš„çƒ­è¯
        response = client.delete(f"/hotwords/{hotword_id}", headers=user2_headers)
        assert response.status_code == 403
    
    def test_hotword_limit(self, auth_headers):
        """æµ‹è¯•çƒ­è¯æ•°é‡é™åˆ¶"""
        # åˆ›å»º100ä¸ªçƒ­è¯ï¼ˆè¾¾åˆ°é™åˆ¶ï¼‰
        for i in range(100):
            response = client.post("/hotwords", json={
                "word": f"é™åˆ¶æµ‹è¯•çƒ­è¯{i}",
                "weight": 5
            }, headers=auth_headers)
            
            # å‰100ä¸ªåº”è¯¥æˆåŠŸ
            if i < 100:
                assert response.status_code == 200
        
        # å°è¯•åˆ›å»ºç¬¬101ä¸ªçƒ­è¯
        response = client.post("/hotwords", json={
            "word": "è¶…é™çƒ­è¯",
            "weight": 5
        }, headers=auth_headers)
        
        assert response.status_code == 400
        assert "çƒ­è¯æ•°é‡å·²è¾¾ä¸Šé™" in response.json()["detail"]

class TestHotwordAuthentication:
    """çƒ­è¯APIè®¤è¯æµ‹è¯•"""
    
    def test_access_without_auth(self):
        """æµ‹è¯•æœªè®¤è¯è®¿é—®"""
        response = client.get("/hotwords")
        assert response.status_code == 401
        
        response = client.post("/hotwords", json={
            "word": "æµ‹è¯•çƒ­è¯",
            "weight": 5
        })
        assert response.status_code == 401
    
    def test_access_with_invalid_token(self):
        """æµ‹è¯•æ— æ•ˆtokenè®¿é—®"""
        headers = {"Authorization": "Bearer invalid_token"}
        
        response = client.get("/hotwords", headers=headers)
        assert response.status_code == 401
        
        response = client.post("/hotwords", json={
            "word": "æµ‹è¯•çƒ­è¯",
            "weight": 5
        }, headers=headers)
        assert response.status_code == 401

# æ¸…ç†æµ‹è¯•æ•°æ®
def teardown_module():
    """æµ‹è¯•æ¨¡å—æ¸…ç†"""
    if os.path.exists("test.db"):
        os.remove("test.db")
```

--------------------------------------------------------------------------------

File: test/test_rag.py
```python
import pytest
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from asr_system_backend.app.main import app
from asr_system_backend.app.database import Base, get_db
from asr_system_backend.app.models import User, Hotword
from asr_system_backend.app.auth_service import get_password_hash
import tempfile
import time

# åˆ›å»ºæµ‹è¯•æ•°æ®åº“
SQLALCHEMY_DATABASE_URL = "sqlite:///./test_rag.db"
engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False})
TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# åˆ›å»ºæ•°æ®åº“è¡¨
Base.metadata.create_all(bind=engine)

def override_get_db():
    try:
        db = TestingSessionLocal()
        yield db
    finally:
        db.close()

# è¦†ç›–ä¾èµ–
app.dependency_overrides[get_db] = override_get_db

client = TestClient(app)

@pytest.fixture
def test_user():
    """åˆ›å»ºæµ‹è¯•ç”¨æˆ·"""
    db = TestingSessionLocal()
    try:
        # æ¸…ç†ç°æœ‰æµ‹è¯•æ•°æ®
        db.query(Hotword).delete()
        db.query(User).delete()
        db.commit()
        
        # åˆ›å»ºæµ‹è¯•ç”¨æˆ·
        user = User(
            username="raguser",
            hashed_password=get_password_hash("ragpass123")
        )
        db.add(user)
        db.commit()
        db.refresh(user)
        
        return user
    finally:
        db.close()

@pytest.fixture
def auth_headers(test_user):
    """è·å–è®¤è¯å¤´"""
    response = client.post("/auth/login", json={
        "username": "raguser",
        "password": "ragpass123"
    })
    assert response.status_code == 200
    token = response.json()["access_token"]
    return {"Authorization": f"Bearer {token}"}

@pytest.fixture
def sample_hotwords(auth_headers):
    """åˆ›å»ºç¤ºä¾‹çƒ­è¯æ•°æ®"""
    hotwords = [
        {"word": "æœºå™¨å­¦ä¹ ", "weight": 8},
        {"word": "æ·±åº¦å­¦ä¹ ", "weight": 9},
        {"word": "äººå·¥æ™ºèƒ½", "weight": 7},
        {"word": "ç¥ç»ç½‘ç»œ", "weight": 6},
        {"word": "è‡ªç„¶è¯­è¨€å¤„ç†", "weight": 8},
        {"word": "è®¡ç®—æœºè§†è§‰", "weight": 7},
        {"word": "è¯­éŸ³è¯†åˆ«", "weight": 9},
        {"word": "æ•°æ®æŒ–æ˜", "weight": 5},
        {"word": "ç®—æ³•ä¼˜åŒ–", "weight": 6},
        {"word": "æ¨¡å¼è¯†åˆ«", "weight": 7}
    ]
    
    created_hotwords = []
    for hotword_data in hotwords:
        response = client.post("/hotwords", json=hotword_data, headers=auth_headers)
        if response.status_code == 200:
            created_hotwords.append(response.json())
    
    # ç­‰å¾…ç´¢å¼•æ„å»ºå®Œæˆ
    time.sleep(2)
    
    return created_hotwords

class TestRAGHealthCheck:
    """RAGæœåŠ¡å¥åº·æ£€æŸ¥æµ‹è¯•"""
    
    def test_health_check(self):
        """æµ‹è¯•RAGæœåŠ¡å¥åº·æ£€æŸ¥"""
        response = client.get("/rag/health")
        assert response.status_code == 200
        
        data = response.json()
        assert "status" in data
        assert "service" in data
        assert "version" in data
        assert "initialized" in data
        assert data["service"] == "RAG Vector Search Engine"

class TestRAGIndexManagement:
    """RAGç´¢å¼•ç®¡ç†æµ‹è¯•"""
    
    def test_get_index_stats_empty(self, auth_headers):
        """æµ‹è¯•è·å–ç©ºç´¢å¼•ç»Ÿè®¡ä¿¡æ¯"""
        response = client.get("/rag/index/stats", headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert "user_id" in data
        assert "total_hotwords" in data
        assert "index_dimension" in data
        assert "is_initialized" in data
        assert data["total_hotwords"] == 0
    
    def test_get_index_stats_with_data(self, auth_headers, sample_hotwords):
        """æµ‹è¯•è·å–æœ‰æ•°æ®çš„ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯"""
        response = client.get("/rag/index/stats", headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert data["total_hotwords"] == len(sample_hotwords)
        assert data["index_dimension"] == 384
        assert data["is_initialized"] == True
    
    def test_rebuild_index(self, auth_headers, sample_hotwords):
        """æµ‹è¯•é‡å»ºç´¢å¼•"""
        response = client.post("/rag/index/rebuild", headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert data["success"] == True
        assert "ç´¢å¼•é‡å»ºæˆåŠŸ" in data["message"]
        assert "details" in data
        assert data["details"]["hotword_count"] == len(sample_hotwords)

class TestRAGVectorSearch:
    """RAGå‘é‡æœç´¢æµ‹è¯•"""
    
    def test_vector_search_basic(self, auth_headers, sample_hotwords):
        """æµ‹è¯•åŸºç¡€å‘é‡æœç´¢"""
        search_request = {
            "query": "æœºå™¨å­¦ä¹ ç®—æ³•",
            "top_k": 5,
            "threshold": 0.3
        }
        
        response = client.post("/rag/search", json=search_request, headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert "query" in data
        assert "results" in data
        assert "total_found" in data
        assert "processing_time_ms" in data
        assert data["query"] == search_request["query"]
        assert isinstance(data["results"], list)
        assert data["processing_time_ms"] > 0
    
    def test_vector_search_with_results(self, auth_headers, sample_hotwords):
        """æµ‹è¯•å‘é‡æœç´¢è¿”å›ç»“æœ"""
        search_request = {
            "query": "æ·±åº¦å­¦ä¹ ",
            "top_k": 3,
            "threshold": 0.1
        }
        
        response = client.post("/rag/search", json=search_request, headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert len(data["results"]) > 0
        
        # éªŒè¯ç»“æœç»“æ„
        for result in data["results"]:
            assert "word" in result
            assert "weight" in result
            assert "similarity" in result
            assert "rank" in result
            assert 0 <= result["similarity"] <= 1
            assert 1 <= result["weight"] <= 10
    
    def test_vector_search_high_threshold(self, auth_headers, sample_hotwords):
        """æµ‹è¯•é«˜é˜ˆå€¼æœç´¢"""
        search_request = {
            "query": "å®Œå…¨ä¸ç›¸å…³çš„æŸ¥è¯¢å†…å®¹xyz123",
            "top_k": 5,
            "threshold": 0.9
        }
        
        response = client.post("/rag/search", json=search_request, headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        # é«˜é˜ˆå€¼åº”è¯¥è¿”å›å¾ˆå°‘æˆ–æ²¡æœ‰ç»“æœ
        assert data["total_found"] >= 0
    
    def test_vector_search_parameter_validation(self, auth_headers):
        """æµ‹è¯•æœç´¢å‚æ•°éªŒè¯"""
        # æµ‹è¯•æ— æ•ˆçš„top_k
        invalid_request = {
            "query": "æµ‹è¯•",
            "top_k": 100,  # è¶…è¿‡æœ€å¤§å€¼
            "threshold": 0.5
        }
        
        response = client.post("/rag/search", json=invalid_request, headers=auth_headers)
        assert response.status_code == 422
        
        # æµ‹è¯•æ— æ•ˆçš„threshold
        invalid_request = {
            "query": "æµ‹è¯•",
            "top_k": 5,
            "threshold": 1.5  # è¶…è¿‡æœ€å¤§å€¼
        }
        
        response = client.post("/rag/search", json=invalid_request, headers=auth_headers)
        assert response.status_code == 422

class TestRAGSuggestions:
    """RAGçƒ­è¯å»ºè®®æµ‹è¯•"""
    
    def test_get_suggestions_basic(self, auth_headers, sample_hotwords):
        """æµ‹è¯•åŸºç¡€çƒ­è¯å»ºè®®"""
        response = client.get("/rag/suggestions?partial_text=æœºå™¨&max_suggestions=5", headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert "partial_text" in data
        assert "suggestions" in data
        assert "count" in data
        assert data["partial_text"] == "æœºå™¨"
        assert isinstance(data["suggestions"], list)
        assert data["count"] == len(data["suggestions"])
    
    def test_get_suggestions_prefix_match(self, auth_headers, sample_hotwords):
        """æµ‹è¯•å‰ç¼€åŒ¹é…å»ºè®®"""
        response = client.get("/rag/suggestions?partial_text=æ·±åº¦&max_suggestions=3", headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        # åº”è¯¥åŒ…å«"æ·±åº¦å­¦ä¹ "
        assert any("æ·±åº¦" in suggestion for suggestion in data["suggestions"])
    
    def test_get_suggestions_empty_input(self, auth_headers, sample_hotwords):
        """æµ‹è¯•ç©ºè¾“å…¥çš„å»ºè®®"""
        response = client.get("/rag/suggestions?partial_text=&max_suggestions=5", headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert data["count"] == 0
        assert len(data["suggestions"]) == 0
    
    def test_get_suggestions_no_match(self, auth_headers, sample_hotwords):
        """æµ‹è¯•æ— åŒ¹é…çš„å»ºè®®"""
        response = client.get("/rag/suggestions?partial_text=xyz123&max_suggestions=5", headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        # å¯èƒ½è¿”å›0ä¸ªå»ºè®®æˆ–åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„å»ºè®®
        assert data["count"] >= 0

class TestRAGBulkOperations:
    """RAGæ‰¹é‡æ“ä½œæµ‹è¯•"""
    
    def test_bulk_add_hotwords(self, auth_headers):
        """æµ‹è¯•æ‰¹é‡æ·»åŠ çƒ­è¯"""
        bulk_request = {
            "words": [
                {"word": "åŒºå—é“¾æŠ€æœ¯", "weight": 7},
                {"word": "é‡å­è®¡ç®—", "weight": 8},
                {"word": "è¾¹ç¼˜è®¡ç®—", "weight": 6}
            ]
        }
        
        response = client.post("/rag/index/bulk-add", json=bulk_request, headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert data["success"] == True
        assert "details" in data
        assert data["details"]["added"] == 3
        assert data["details"]["skipped"] == 0
    
    def test_bulk_add_with_duplicates(self, auth_headers, sample_hotwords):
        """æµ‹è¯•æ‰¹é‡æ·»åŠ åŒ…å«é‡å¤é¡¹çš„çƒ­è¯"""
        bulk_request = {
            "words": [
                {"word": "æœºå™¨å­¦ä¹ ", "weight": 7},  # é‡å¤é¡¹
                {"word": "æ–°æŠ€æœ¯", "weight": 8},    # æ–°é¡¹
                {"word": "æ·±åº¦å­¦ä¹ ", "weight": 9}   # é‡å¤é¡¹
            ]
        }
        
        response = client.post("/rag/index/bulk-add", json=bulk_request, headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert data["success"] == True
        assert data["details"]["added"] == 1  # åªæœ‰"æ–°æŠ€æœ¯"è¢«æ·»åŠ 
        assert data["details"]["skipped"] == 2  # ä¸¤ä¸ªé‡å¤é¡¹è¢«è·³è¿‡
    
    def test_bulk_add_empty_words(self, auth_headers):
        """æµ‹è¯•æ‰¹é‡æ·»åŠ ç©ºè¯æ±‡"""
        bulk_request = {
            "words": [
                {"word": "", "weight": 7},
                {"word": "   ", "weight": 8},
                {"word": "æœ‰æ•ˆè¯æ±‡", "weight": 6}
            ]
        }
        
        response = client.post("/rag/index/bulk-add", json=bulk_request, headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert data["success"] == True
        assert data["details"]["added"] == 1  # åªæœ‰"æœ‰æ•ˆè¯æ±‡"è¢«æ·»åŠ 
        assert data["details"]["skipped"] == 2  # ä¸¤ä¸ªç©ºè¯æ±‡è¢«è·³è¿‡

class TestRAGModelInfo:
    """RAGæ¨¡å‹ä¿¡æ¯æµ‹è¯•"""
    
    def test_get_model_info(self):
        """æµ‹è¯•è·å–æ¨¡å‹ä¿¡æ¯"""
        response = client.get("/rag/model/info")
        assert response.status_code == 200
        
        data = response.json()
        
        if "status" in data and data["status"] == "not_initialized":
            # å¦‚æœæœåŠ¡æœªåˆå§‹åŒ–ï¼Œè¿™æ˜¯æ­£å¸¸çš„
            assert "message" in data
        else:
            # å¦‚æœæœåŠ¡å·²åˆå§‹åŒ–ï¼ŒéªŒè¯æ¨¡å‹ä¿¡æ¯
            assert "model_name" in data
            assert "dimension" in data
            assert "languages" in data
            assert "description" in data
            assert "performance" in data
            assert data["model_name"] == "sentence-transformers/all-MiniLM-L6-v2"
            assert data["dimension"] == 384

class TestRAGAuthentication:
    """RAGè®¤è¯æµ‹è¯•"""
    
    def test_search_without_auth(self):
        """æµ‹è¯•æœªè®¤è¯çš„æœç´¢è¯·æ±‚"""
        search_request = {
            "query": "æµ‹è¯•æŸ¥è¯¢",
            "top_k": 5,
            "threshold": 0.5
        }
        
        response = client.post("/rag/search", json=search_request)
        assert response.status_code == 401
    
    def test_index_stats_without_auth(self):
        """æµ‹è¯•æœªè®¤è¯çš„ç´¢å¼•ç»Ÿè®¡è¯·æ±‚"""
        response = client.get("/rag/index/stats")
        assert response.status_code == 401
    
    def test_suggestions_without_auth(self):
        """æµ‹è¯•æœªè®¤è¯çš„å»ºè®®è¯·æ±‚"""
        response = client.get("/rag/suggestions?partial_text=æµ‹è¯•")
        assert response.status_code == 401
    
    def test_with_invalid_token(self):
        """æµ‹è¯•æ— æ•ˆtoken"""
        headers = {"Authorization": "Bearer invalid_token"}
        
        response = client.get("/rag/index/stats", headers=headers)
        assert response.status_code == 401

class TestRAGPerformance:
    """RAGæ€§èƒ½æµ‹è¯•"""
    
    def test_search_performance(self, auth_headers, sample_hotwords):
        """æµ‹è¯•æœç´¢æ€§èƒ½"""
        search_request = {
            "query": "æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½",
            "top_k": 5,
            "threshold": 0.3
        }
        
        start_time = time.time()
        response = client.post("/rag/search", json=search_request, headers=auth_headers)
        end_time = time.time()
        
        assert response.status_code == 200
        
        data = response.json()
        # éªŒè¯å“åº”æ—¶é—´åˆç†ï¼ˆåº”è¯¥åœ¨å‡ ç™¾æ¯«ç§’å†…ï¼‰
        response_time_ms = (end_time - start_time) * 1000
        assert response_time_ms < 5000  # 5ç§’å†…å®Œæˆ
        
        # éªŒè¯APIè¿”å›çš„å¤„ç†æ—¶é—´
        assert data["processing_time_ms"] > 0
        assert data["processing_time_ms"] < 5000
    
    def test_multiple_searches(self, auth_headers, sample_hotwords):
        """æµ‹è¯•å¤šæ¬¡æœç´¢çš„ç¨³å®šæ€§"""
        queries = [
            "æœºå™¨å­¦ä¹ ",
            "æ·±åº¦å­¦ä¹ ",
            "äººå·¥æ™ºèƒ½",
            "ç¥ç»ç½‘ç»œ",
            "ç®—æ³•"
        ]
        
        for query in queries:
            search_request = {
                "query": query,
                "top_k": 3,
                "threshold": 0.3
            }
            
            response = client.post("/rag/search", json=search_request, headers=auth_headers)
            assert response.status_code == 200
            
            data = response.json()
            assert "results" in data
            assert "processing_time_ms" in data

# æ¸…ç†æµ‹è¯•æ•°æ®
def teardown_module():
    """æµ‹è¯•æ¨¡å—æ¸…ç†"""
    if os.path.exists("test_rag.db"):
        os.remove("test_rag.db")
```

--------------------------------------------------------------------------------

File: test/test_auth.py
```python
# File: test/test_auth.py

import pytest
from fastapi.testclient import TestClient
from asr_system_backend.app.main import app

client = TestClient(app)

@pytest.fixture(scope="module")
def test_user():
    return {
        "username": "testuser",
        "password": "testpassword123"
    }

def test_register_success(test_user):
    resp = client.post("/auth/register", json=test_user)
    assert resp.status_code == 200 or resp.status_code == 409  # å·²æ³¨å†Œä¹Ÿç®—é€šè¿‡
    data = resp.json()
    if resp.status_code == 200:
        assert data["username"] == test_user["username"]
        assert "user_id" in data
        assert "created_at" in data

def test_register_duplicate(test_user):
    resp = client.post("/auth/register", json=test_user)
    assert resp.status_code == 409
    assert resp.json()["detail"] == "ç”¨æˆ·åå·²å­˜åœ¨"

def test_login_success(test_user):
    resp = client.post("/auth/login", json=test_user)
    assert resp.status_code == 200
    data = resp.json()
    assert "access_token" in data
    assert data["token_type"] == "bearer"

def test_login_wrong_password(test_user):
    resp = client.post("/auth/login", json={"username": test_user["username"], "password": "wrongpass"})
    assert resp.status_code == 401
    assert resp.json()["detail"] == "ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯"

def test_login_nonexistent_user():
    resp = client.post("/auth/login", json={"username": "nouser", "password": "any"})
    assert resp.status_code == 401
    assert resp.json()["detail"] == "ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯"

def test_login_and_get_token(test_user):
    resp = client.post("/auth/login", json=test_user)
    assert resp.status_code == 200
    data = resp.json()
    assert "access_token" in data
    token = data["access_token"]
    # ç”¨tokenè®¿é—®/me
    me_resp = client.get("/auth/me", headers={"Authorization": f"Bearer {token}"})
    assert me_resp.status_code == 200
    me_data = me_resp.json()
    assert me_data["username"] == test_user["username"]
    assert "user_id" in me_data
    assert "created_at" in me_data

def test_me_with_invalid_token():
    resp = client.get("/auth/me", headers={"Authorization": "Bearer invalidtoken"})
    assert resp.status_code == 401
    assert resp.json()["detail"] == "æ— æ•ˆçš„è®¤è¯å‡­æ®"

def test_me_without_token():
    resp = client.get("/auth/me")
    assert resp.status_code == 401
```

--------------------------------------------------------------------------------

File: .github/workflows/ci.yml
```yaml
name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  backend:
    runs-on: ubuntu-latest
    # è®¾ç½®æ­¤ Job ä¸­æ‰€æœ‰ run å‘½ä»¤çš„é»˜è®¤å·¥ä½œç›®å½•
    defaults:
      run:
        working-directory: ./asr_system_backend

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies and run checks
        run: |
          pip install -r requirements.txt
          # å»ºè®®ç§»é™¤ || trueï¼Œè®© lint å¤±è´¥æ—¶æ„å»ºä¹Ÿå¤±è´¥
          flake8 app
          alembic upgrade head
          pytest

  # frontend job ä¿æŒä¸å˜ï¼Œä¹Ÿå¯ä»¥ç”¨ç±»ä¼¼çš„æ–¹æ³•ä¼˜åŒ–
  frontend:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./asr_system_frontend
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          # ç¼“å­˜ npm åŒ…ï¼ŒåŠ å¿«åç»­æ„å»ºé€Ÿåº¦
          cache: 'npm'
          cache-dependency-path: 'asr_system_frontend/package-lock.json'

      - name: Install, Lint, and Build
        run: |
          npm install
          # åŒæ ·å»ºè®®ç§»é™¤ || true
          npm run lint
          npm run build
```

--------------------------------------------------------------------------------

File: models/iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/.mv
```text
Revision:v2.0.4,CreatedAt:1705996149
```

--------------------------------------------------------------------------------

File: models/iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/am.mvn
```text
<Nnet> 
<Splice> 560 560
[ 0 ]
<AddShift> 560 560 
<LearnRateCoef> 0 [ -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 ]
<Rescale> 560 560
<LearnRateCoef> 0 [ 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 ]
</Nnet>
```

--------------------------------------------------------------------------------

File: models/iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/seg_dict  (Skipped, size > 200KB)

--------------------------------------------------------------------------------

File: models/iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/config.yaml
```yaml
# This is an example that demonstrates how to configure a model file.
# You can modify the configuration according to your own requirements.

# to print the register_table:
# from funasr.utils.register import registry_tables
# registry_tables.print()

# network architecture
model: SeacoParaformer
model_conf:
    ctc_weight: 0.0
    lsm_weight: 0.1
    length_normalized_loss: true
    predictor_weight: 1.0
    predictor_bias: 1
    sampling_ratio: 0.75
    inner_dim: 512
    bias_encoder_type: lstm
    bias_encoder_bid: false
    seaco_lsm_weight: 0.1
    seaco_length_normal: true
    train_decoder: false
    NO_BIAS: 8377

# encoder
encoder: SANMEncoder
encoder_conf:
    output_size: 512
    attention_heads: 4
    linear_units: 2048
    num_blocks: 50
    dropout_rate: 0.1
    positional_dropout_rate: 0.1
    attention_dropout_rate: 0.1
    input_layer: pe
    pos_enc_class: SinusoidalPositionEncoder
    normalize_before: true
    kernel_size: 11
    sanm_shfit: 0
    selfattention_layer_type: sanm

# decoder
decoder: ParaformerSANMDecoder
decoder_conf:
    attention_heads: 4
    linear_units: 2048
    num_blocks: 16
    dropout_rate: 0.1
    positional_dropout_rate: 0.1
    self_attention_dropout_rate: 0.1
    src_attention_dropout_rate: 0.1
    att_layer_num: 16
    kernel_size: 11
    sanm_shfit: 0

# seaco decoder
seaco_decoder: ParaformerSANMDecoder
seaco_decoder_conf:
    attention_heads: 4
    linear_units: 1024
    num_blocks: 4
    dropout_rate: 0.1
    positional_dropout_rate: 0.1
    self_attention_dropout_rate: 0.1
    src_attention_dropout_rate: 0.1
    kernel_size: 21
    sanm_shfit: 0
    use_output_layer: false
    wo_input_layer: true

predictor: CifPredictorV3
predictor_conf:
    idim: 512
    threshold: 1.0
    l_order: 1
    r_order: 1
    tail_threshold: 0.45
    smooth_factor2: 0.25
    noise_threshold2: 0.01
    upsample_times: 3
    use_cif1_cnn: false
    upsample_type: cnn_blstm

# frontend related
frontend: WavFrontend
frontend_conf:
    fs: 16000
    window: hamming
    n_mels: 80
    frame_length: 25
    frame_shift: 10
    lfr_m: 7
    lfr_n: 6
    dither: 0.0

specaug: SpecAugLFR
specaug_conf:
    apply_time_warp: false
    time_warp_window: 5
    time_warp_mode: bicubic
    apply_freq_mask: true
    freq_mask_width_range:
    - 0
    - 30
    lfr_rate: 6
    num_freq_mask: 1
    apply_time_mask: true
    time_mask_width_range:
    - 0
    - 12
    num_time_mask: 1

train_conf:
  accum_grad: 1
  grad_clip: 5
  max_epoch: 150
  val_scheduler_criterion:
      - valid
      - acc
  best_model_criterion:
  -   - valid
      - acc
      - max
  keep_nbest_models: 10
  log_interval: 50

optim: adam
optim_conf:
   lr: 0.0005
scheduler: warmuplr
scheduler_conf:
   warmup_steps: 30000

dataset: AudioDataset
dataset_conf:
    index_ds: IndexDSJsonl
    batch_sampler: DynamicBatchLocalShuffleSampler
    batch_type: example # example or length
    batch_size: 1 # if batch_type is example, batch_size is the numbers of samples; if length, batch_size is source_token_len+target_token_len;
    max_token_length: 2048 # filter samples if source_token_len+target_token_len > max_token_length,
    buffer_size: 500
    shuffle: True
    num_workers: 0

tokenizer: CharTokenizer
tokenizer_conf:
  unk_symbol: <unk>
  split_with_space: true


ctc_conf:
    dropout_rate: 0.0
    ctc_type: builtin
    reduce: true
    ignore_nan_grad: true
normalize: null
```

--------------------------------------------------------------------------------

File: models/iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/README.md
```markdown
---
tasks:
- auto-speech-recognition
domain:
- audio
model-type:
- Non-autoregressive
frameworks:
- pytorch
backbone:
- transformer/conformer
metrics:
- CER
license: Apache License 2.0
language: 
- cn
tags:
- FunASR
- Paraformer
- Alibaba
- ICASSP2024
- Hotword
datasets:
  train:
  - 50,000 hour industrial Mandarin task
  test:
  - AISHELL-1-hotword dev/test
indexing:
   results:
   - task:
       name: Automatic Speech Recognition
     dataset:
       name: 50,000 hour industrial Mandarin task
       type: audio    # optional
       args: 16k sampling rate, 8404 characters  # optional
     metrics:
       - type: CER
         value: 8.53%  # float
         description: greedy search, withou lm, avg.
         args: default
       - type: RTF
         value: 0.0251  # float
         description: GPU inference on V100
         args: batch_size=1
widgets:
  - task: auto-speech-recognition
    inputs:
      - type: audio
        name: input
        title: éŸ³é¢‘
    parameters:
      - name: hotword
        title: çƒ­è¯
        type: string
    examples:
      - name: 1
        title: ç¤ºä¾‹1
        inputs:
          - name: input
            data: git://example/asr_example.wav
        parameters:
          - name: hotword
            value: é­”æ­
    inferencespec:
      cpu: 8 #CPUæ•°é‡
      memory: 4096
---

# Paraformer-largeæ¨¡å‹ä»‹ç»

## Highlights
Paraformer-largeçƒ­è¯ç‰ˆæ¨¡å‹æ”¯æŒçƒ­è¯å®šåˆ¶åŠŸèƒ½ï¼šå®ç°çƒ­è¯å®šåˆ¶åŒ–åŠŸèƒ½ï¼ŒåŸºäºæä¾›çš„çƒ­è¯åˆ—è¡¨è¿›è¡Œæ¿€åŠ±å¢å¼ºï¼Œæå‡çƒ­è¯çš„å¬å›ç‡å’Œå‡†ç¡®ç‡ã€‚


## <strong>[FunASRå¼€æºé¡¹ç›®ä»‹ç»](https://github.com/alibaba-damo-academy/FunASR)</strong>
<strong>[FunASR](https://github.com/alibaba-damo-academy/FunASR)</strong>å¸Œæœ›åœ¨è¯­éŸ³è¯†åˆ«çš„å­¦æœ¯ç ”ç©¶å’Œå·¥ä¸šåº”ç”¨ä¹‹é—´æ¶èµ·ä¸€åº§æ¡¥æ¢ã€‚é€šè¿‡å‘å¸ƒå·¥ä¸šçº§è¯­éŸ³è¯†åˆ«æ¨¡å‹çš„è®­ç»ƒå’Œå¾®è°ƒï¼Œç ”ç©¶äººå‘˜å’Œå¼€å‘äººå‘˜å¯ä»¥æ›´æ–¹ä¾¿åœ°è¿›è¡Œè¯­éŸ³è¯†åˆ«æ¨¡å‹çš„ç ”ç©¶å’Œç”Ÿäº§ï¼Œå¹¶æ¨åŠ¨è¯­éŸ³è¯†åˆ«ç”Ÿæ€çš„å‘å±•ã€‚è®©è¯­éŸ³è¯†åˆ«æ›´æœ‰è¶£ï¼

[**githubä»“åº“**](https://github.com/alibaba-damo-academy/FunASR) 
|  [**æœ€æ–°åŠ¨æ€**](https://github.com/alibaba-damo-academy/FunASR#whats-new) 
| [**ç¯å¢ƒå®‰è£…**](https://github.com/alibaba-damo-academy/FunASR#installation)
| [**æœåŠ¡éƒ¨ç½²**](https://www.funasr.com)
| [**æ¨¡å‹åº“**](https://github.com/alibaba-damo-academy/FunASR/tree/main/model_zoo)
| [**è”ç³»æˆ‘ä»¬**](https://github.com/alibaba-damo-academy/FunASR#contact)


## æ¨¡å‹åŸç†ä»‹ç»

SeACoParaformeræ˜¯é˜¿é‡Œå·´å·´è¯­éŸ³å®éªŒå®¤æå‡ºçš„æ–°ä¸€ä»£çƒ­è¯å®šåˆ¶åŒ–éè‡ªå›å½’è¯­éŸ³è¯†åˆ«æ¨¡å‹ã€‚ç›¸æ¯”äºä¸Šä¸€ä»£åŸºäºCLASçš„çƒ­è¯å®šåˆ¶åŒ–æ–¹æ¡ˆï¼ŒSeACoParaformerè§£è€¦äº†çƒ­è¯æ¨¡å—ä¸ASRæ¨¡å‹ï¼Œé€šè¿‡åéªŒæ¦‚ç‡èåˆçš„æ–¹å¼è¿›è¡Œçƒ­è¯æ¿€åŠ±ï¼Œä½¿æ¿€åŠ±è¿‡ç¨‹å¯è§å¯æ§ï¼Œå¹¶ä¸”çƒ­è¯å¬å›ç‡æ˜¾è‘—æå‡ã€‚

<p align="center">
<img src="fig/seaco.png" alt="SeACoParaformeræ¨¡å‹ç»“æ„"  width="380" />


SeACoParaformerçš„æ¨¡å‹ç»“æ„ä¸è®­ç»ƒæµç¨‹å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œé€šè¿‡å¼•å…¥bias encoderè¿›è¡Œçƒ­è¯embeddingæå–ï¼Œbias decoderè¿›è¡Œæ³¨æ„åŠ›å»ºæ¨¡ï¼ŒSeACoParaformerèƒ½å¤Ÿæ•æ‰åˆ°Predictorè¾“å‡ºå’ŒDecoderè¾“å‡ºçš„ä¿¡æ¯ä¸çƒ­è¯çš„ç›¸å…³æ€§ï¼Œå¹¶ä¸”é¢„æµ‹ä¸ASRç»“æœåŒæ­¥çš„çƒ­è¯è¾“å‡ºã€‚é€šè¿‡åéªŒæ¦‚ç‡çš„èåˆï¼Œå®ç°çƒ­è¯æ¿€åŠ±ã€‚ä¸ContextualParaformerç›¸æ¯”ï¼ŒSeACoParaformeræœ‰æ˜æ˜¾çš„æ•ˆæœæå‡ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

<p align="center">
<img src="fig/res.png" alt="SeACoParaformeræ¨¡å‹ç»“æ„"  width="700" />

æ›´è¯¦ç»†çš„ç»†èŠ‚è§ï¼š
- è®ºæ–‡ï¼š [SeACo-Paraformer: A Non-Autoregressive ASR System with Flexible and Effective Hotword Customization Ability](https://arxiv.org/abs/2308.03266)


## åŸºäºModelScopeè¿›è¡Œæ¨ç†

- æ¨ç†æ”¯æŒéŸ³é¢‘æ ¼å¼å¦‚ä¸‹ï¼š
  - wavæ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ï¼šdata/test/audios/asr_example.wav
  - pcmæ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ï¼šdata/test/audios/asr_example.pcm
  - wavæ–‡ä»¶urlï¼Œä¾‹å¦‚ï¼šhttps://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav
  - waväºŒè¿›åˆ¶æ•°æ®ï¼Œæ ¼å¼bytesï¼Œä¾‹å¦‚ï¼šç”¨æˆ·ç›´æ¥ä»æ–‡ä»¶é‡Œè¯»å‡ºbytesæ•°æ®æˆ–è€…æ˜¯éº¦å…‹é£å½•å‡ºbytesæ•°æ®ã€‚
  - å·²è§£æçš„audioéŸ³é¢‘ï¼Œä¾‹å¦‚ï¼šaudio, rate = soundfile.read("asr_example_zh.wav")ï¼Œç±»å‹ä¸ºnumpy.ndarrayæˆ–è€…torch.Tensorã€‚
  - wav.scpæ–‡ä»¶ï¼Œéœ€ç¬¦åˆå¦‚ä¸‹è¦æ±‚ï¼š

```sh
cat wav.scp
asr_example1  data/test/audios/asr_example1.wav
asr_example2  data/test/audios/asr_example2.wav
...
```

- è‹¥è¾“å…¥æ ¼å¼wavæ–‡ä»¶urlï¼Œapiè°ƒç”¨æ–¹å¼å¯å‚è€ƒå¦‚ä¸‹èŒƒä¾‹ï¼š

```python
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks

inference_pipeline = pipeline(
    task=Tasks.auto_speech_recognition,
    model='iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch', model_revision="v2.0.4")

rec_result = inference_pipeline('https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav', hotword='è¾¾æ‘©é™¢ é­”æ­')
print(rec_result)
```

- è¾“å…¥éŸ³é¢‘ä¸ºpcmæ ¼å¼ï¼Œè°ƒç”¨apiæ—¶éœ€è¦ä¼ å…¥éŸ³é¢‘é‡‡æ ·ç‡å‚æ•°audio_fsï¼Œä¾‹å¦‚ï¼š

```python
rec_result = inference_pipeline('https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.pcm', fs=16000, hotword='è¾¾æ‘©é™¢ é­”æ­')
```

- è¾“å…¥éŸ³é¢‘ä¸ºwavæ ¼å¼ï¼Œapiè°ƒç”¨æ–¹å¼å¯å‚è€ƒå¦‚ä¸‹èŒƒä¾‹:

```python
rec_result = inference_pipeline('asr_example_zh.wav', hotword='è¾¾æ‘©é™¢ é­”æ­')
```

- è‹¥è¾“å…¥æ ¼å¼ä¸ºæ–‡ä»¶wav.scp(æ³¨ï¼šæ–‡ä»¶åéœ€è¦ä»¥.scpç»“å°¾)ï¼Œå¯æ·»åŠ  output_dir å‚æ•°å°†è¯†åˆ«ç»“æœå†™å…¥æ–‡ä»¶ä¸­ï¼Œapiè°ƒç”¨æ–¹å¼å¯å‚è€ƒå¦‚ä¸‹èŒƒä¾‹:

```python
inference_pipeline("wav.scp", output_dir='./output_dir', hotword='è¾¾æ‘©é™¢ é­”æ­')
```
è¯†åˆ«ç»“æœè¾“å‡ºè·¯å¾„ç»“æ„å¦‚ä¸‹ï¼š

```sh
tree output_dir/
output_dir/
â””â”€â”€ 1best_recog
    â”œâ”€â”€ score
    â””â”€â”€ text

1 directory, 3 files
```

scoreï¼šè¯†åˆ«è·¯å¾„å¾—åˆ†

textï¼šè¯­éŸ³è¯†åˆ«ç»“æœæ–‡ä»¶


- è‹¥è¾“å…¥éŸ³é¢‘ä¸ºå·²è§£æçš„audioéŸ³é¢‘ï¼Œapiè°ƒç”¨æ–¹å¼å¯å‚è€ƒå¦‚ä¸‹èŒƒä¾‹ï¼š

```python
import soundfile

waveform, sample_rate = soundfile.read("asr_example_zh.wav")
rec_result = inference_pipeline(waveform, hotword='è¾¾æ‘©é™¢ é­”æ­')
```

- ASRã€VADã€PUNCæ¨¡å‹è‡ªç”±ç»„åˆ

å¯æ ¹æ®ä½¿ç”¨éœ€æ±‚å¯¹VADå’ŒPUNCæ ‡ç‚¹æ¨¡å‹è¿›è¡Œè‡ªç”±ç»„åˆï¼Œä½¿ç”¨æ–¹å¼å¦‚ä¸‹ï¼š
```python
inference_pipeline = pipeline(
    task=Tasks.auto_speech_recognition,
    model='iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch', model_revision="v2.0.4",
    vad_model='iic/speech_fsmn_vad_zh-cn-16k-common-pytorch', vad_model_revision="v2.0.4",
    punc_model='iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch', punc_model_revision="v2.0.3",
    # spk_model="iic/speech_campplus_sv_zh-cn_16k-common",
    # spk_model_revision="v2.0.2",
)
```
è‹¥ä¸ä½¿ç”¨PUNCæ¨¡å‹ï¼Œå¯é…ç½®punc_model=Noneï¼Œæˆ–ä¸ä¼ å…¥punc_modelå‚æ•°ï¼Œå¦‚éœ€åŠ å…¥LMæ¨¡å‹ï¼Œå¯å¢åŠ é…ç½®lm_model='iic/speech_transformer_lm_zh-cn-common-vocab8404-pytorch'ï¼Œå¹¶è®¾ç½®lm_weightå’Œbeam_sizeå‚æ•°ã€‚

## åŸºäºFunASRè¿›è¡Œæ¨ç†

ä¸‹é¢ä¸ºå¿«é€Ÿä¸Šæ‰‹æ•™ç¨‹ï¼Œæµ‹è¯•éŸ³é¢‘ï¼ˆ[ä¸­æ–‡](https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/vad_example.wav)ï¼Œ[è‹±æ–‡](https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_en.wav)ï¼‰

### å¯æ‰§è¡Œå‘½ä»¤è¡Œ
åœ¨å‘½ä»¤è¡Œç»ˆç«¯æ‰§è¡Œï¼š

```shell
funasr +model=paraformer-zh +vad_model="fsmn-vad" +punc_model="ct-punc" +input=vad_example.wav
```

æ³¨ï¼šæ”¯æŒå•æ¡éŸ³é¢‘æ–‡ä»¶è¯†åˆ«ï¼Œä¹Ÿæ”¯æŒæ–‡ä»¶åˆ—è¡¨ï¼Œåˆ—è¡¨ä¸ºkaldié£æ ¼wav.scpï¼š`wav_id   wav_path`

### pythonç¤ºä¾‹
#### éå®æ—¶è¯­éŸ³è¯†åˆ«
```python
from funasr import AutoModel
# paraformer-zh is a multi-functional asr model
# use vad, punc, spk or not as you need
model = AutoModel(model="paraformer-zh", model_revision="v2.0.4",
                  vad_model="fsmn-vad", vad_model_revision="v2.0.4",
                  punc_model="ct-punc-c", punc_model_revision="v2.0.4",
                  # spk_model="cam++", spk_model_revision="v2.0.2",
                  )
res = model.generate(input=f"{model.model_path}/example/asr_example.wav", 
            batch_size_s=300, 
            hotword='é­”æ­')
print(res)
```
æ³¨ï¼š`model_hub`ï¼šè¡¨ç¤ºæ¨¡å‹ä»“åº“ï¼Œ`ms`ä¸ºé€‰æ‹©modelscopeä¸‹è½½ï¼Œ`hf`ä¸ºé€‰æ‹©huggingfaceä¸‹è½½ã€‚

#### å®æ—¶è¯­éŸ³è¯†åˆ«

```python
from funasr import AutoModel

chunk_size = [0, 10, 5] #[0, 10, 5] 600ms, [0, 8, 4] 480ms
encoder_chunk_look_back = 4 #number of chunks to lookback for encoder self-attention
decoder_chunk_look_back = 1 #number of encoder chunks to lookback for decoder cross-attention

model = AutoModel(model="paraformer-zh-streaming", model_revision="v2.0.4")

import soundfile
import os

wav_file = os.path.join(model.model_path, "example/asr_example.wav")
speech, sample_rate = soundfile.read(wav_file)
chunk_stride = chunk_size[1] * 960 # 600ms

cache = {}
total_chunk_num = int(len((speech)-1)/chunk_stride+1)
for i in range(total_chunk_num):
    speech_chunk = speech[i*chunk_stride:(i+1)*chunk_stride]
    is_final = i == total_chunk_num - 1
    res = model.generate(input=speech_chunk, cache=cache, is_final=is_final, chunk_size=chunk_size, encoder_chunk_look_back=encoder_chunk_look_back, decoder_chunk_look_back=decoder_chunk_look_back)
    print(res)
```

æ³¨ï¼š`chunk_size`ä¸ºæµå¼å»¶æ—¶é…ç½®ï¼Œ`[0,10,5]`è¡¨ç¤ºä¸Šå±å®æ—¶å‡ºå­—ç²’åº¦ä¸º`10*60=600ms`ï¼Œæœªæ¥ä¿¡æ¯ä¸º`5*60=300ms`ã€‚æ¯æ¬¡æ¨ç†è¾“å…¥ä¸º`600ms`ï¼ˆé‡‡æ ·ç‚¹æ•°ä¸º`16000*0.6=960`ï¼‰ï¼Œè¾“å‡ºä¸ºå¯¹åº”æ–‡å­—ï¼Œæœ€åä¸€ä¸ªè¯­éŸ³ç‰‡æ®µè¾“å…¥éœ€è¦è®¾ç½®`is_final=True`æ¥å¼ºåˆ¶è¾“å‡ºæœ€åä¸€ä¸ªå­—ã€‚

#### è¯­éŸ³ç«¯ç‚¹æ£€æµ‹ï¼ˆéå®æ—¶ï¼‰
```python
from funasr import AutoModel

model = AutoModel(model="fsmn-vad", model_revision="v2.0.4")

wav_file = f"{model.model_path}/example/asr_example.wav"
res = model.generate(input=wav_file)
print(res)
```

#### è¯­éŸ³ç«¯ç‚¹æ£€æµ‹ï¼ˆå®æ—¶ï¼‰
```python
from funasr import AutoModel

chunk_size = 200 # ms
model = AutoModel(model="fsmn-vad", model_revision="v2.0.4")

import soundfile

wav_file = f"{model.model_path}/example/vad_example.wav"
speech, sample_rate = soundfile.read(wav_file)
chunk_stride = int(chunk_size * sample_rate / 1000)

cache = {}
total_chunk_num = int(len((speech)-1)/chunk_stride+1)
for i in range(total_chunk_num):
    speech_chunk = speech[i*chunk_stride:(i+1)*chunk_stride]
    is_final = i == total_chunk_num - 1
    res = model.generate(input=speech_chunk, cache=cache, is_final=is_final, chunk_size=chunk_size)
    if len(res[0]["value"]):
        print(res)
```

#### æ ‡ç‚¹æ¢å¤
```python
from funasr import AutoModel

model = AutoModel(model="ct-punc", model_revision="v2.0.4")

res = model.generate(input="é‚£ä»Šå¤©çš„ä¼šå°±åˆ°è¿™é‡Œå§ happy new year æ˜å¹´è§")
print(res)
```

#### æ—¶é—´æˆ³é¢„æµ‹
```python
from funasr import AutoModel

model = AutoModel(model="fa-zh", model_revision="v2.0.4")

wav_file = f"{model.model_path}/example/asr_example.wav"
text_file = f"{model.model_path}/example/text.txt"
res = model.generate(input=(wav_file, text_file), data_type=("sound", "text"))
print(res)
```

æ›´å¤šè¯¦ç»†ç”¨æ³•ï¼ˆ[ç¤ºä¾‹](https://github.com/alibaba-damo-academy/FunASR/tree/main/examples/industrial_data_pretraining)ï¼‰


## å¾®è°ƒ

è¯¦ç»†ç”¨æ³•ï¼ˆ[ç¤ºä¾‹](https://github.com/alibaba-damo-academy/FunASR/tree/main/examples/industrial_data_pretraining)ï¼‰


## ç›¸å…³è®ºæ–‡ä»¥åŠå¼•ç”¨ä¿¡æ¯

```BibTeX
@article{shi2023seaco,
  title={SeACo-Paraformer: A Non-Autoregressive ASR System with Flexible and Effective Hotword Customization Ability},
  author={Shi, Xian and Yang, Yexin and Li, Zerui and Zhang, Shiliang},
  journal={arXiv preprint arXiv:2308.03266 (accepted by ICASSP2024)},
  year={2023}
}
```
```

--------------------------------------------------------------------------------

File: models/damo/speech_fsmn_vad_zh-cn-16k-common-onnx/.mv
```text
Revision:v2.0.4,CreatedAt:1714031199
```

--------------------------------------------------------------------------------

File: models/damo/speech_fsmn_vad_zh-cn-16k-common-onnx/am.mvn
```text
<Nnet>
<Splice> 400 400
[ 0 ]
<AddShift> 400 400
<LearnRateCoef> 0 [ -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 ]
<Rescale> 400 400
<LearnRateCoef> 0 [ 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 ]
</Nnet>
```

--------------------------------------------------------------------------------

File: models/damo/speech_fsmn_vad_zh-cn-16k-common-onnx/model_quant.onnx  (Skipped, size > 200KB)

--------------------------------------------------------------------------------

File: models/damo/speech_fsmn_vad_zh-cn-16k-common-onnx/config.yaml
```yaml
frontend: WavFrontendOnline
frontend_conf:
    fs: 16000
    window: hamming
    n_mels: 80
    frame_length: 25
    frame_shift: 10
    dither: 0.0
    lfr_m: 5
    lfr_n: 1

model: FsmnVADStreaming
model_conf:
    sample_rate: 16000
    detect_mode: 1 
    snr_mode: 0
    max_end_silence_time: 800
    max_start_silence_time: 3000
    do_start_point_detection: True
    do_end_point_detection: True
    window_size_ms: 200
    sil_to_speech_time_thres: 150
    speech_to_sil_time_thres: 150
    speech_2_noise_ratio: 1.0
    do_extend: 1
    lookback_time_start_point: 200
    lookahead_time_end_point: 100
    max_single_segment_time: 60000
    snr_thres: -100.0
    noise_frame_num_used_for_snr: 100
    decibel_thres: -100.0
    speech_noise_thres: 0.6
    fe_prior_thres: 0.0001
    silence_pdf_num: 1
    sil_pdf_ids: [0]
    speech_noise_thresh_low: -0.1
    speech_noise_thresh_high: 0.3
    output_frame_probs: False
    frame_in_ms: 10
    frame_length_ms: 25
    
encoder: FSMN
encoder_conf:
    input_dim: 400
    input_affine_dim: 140
    fsmn_layers: 4
    linear_dim: 250
    proj_dim: 128
    lorder: 20
    rorder: 0
    lstride: 1
    rstride: 0
    output_affine_dim: 140
    output_dim: 248
```

--------------------------------------------------------------------------------

File: models/damo/speech_fsmn_vad_zh-cn-16k-common-onnx/README.md
```markdown
---
tasks:
- voice-activity-detection
domain:
- audio
model-type:
- VAD model
frameworks:
- onnx
backbone:
- fsmn
metrics:
- f1_score
license: Apache License 2.0
language: 
- cn
tags:
- FunASR
- FSMN
- Alibaba
- Online
datasets:
  train:
  - 20,000 hour industrial Mandarin task
  test:
  - 20,000 hour industrial Mandarin task
widgets:
  - task: voice-activity-detection
    inputs:
      - type: audio
        name: input
        title: éŸ³é¢‘
    examples:
      - name: 1
        title: ç¤ºä¾‹1
        inputs:
          - name: input
            data: git://example/vad_example.wav 
    inferencespec:
      cpu: 1 #CPUæ•°é‡
      memory: 4096
---

# FSMN-Monophone VAD æ¨¡å‹ä»‹ç»

[//]: # (FSMN-Monophone VAD æ¨¡å‹)

## Highlights
æ¨¡å‹ä¸º[FSMN-Monophone VAD](https://www.modelscope.cn/models/damo/speech_fsmn_vad_zh-cn-16k-common-pytorch/summary)çš„onnxé‡åŒ–å¯¼å‡ºç‰ˆæœ¬ï¼Œå¯ä»¥ç›´æ¥ç”¨æ¥åšç”Ÿäº§éƒ¨ç½²ï¼Œä¸€é”®éƒ¨ç½²æ•™ç¨‹ï¼ˆ[ç‚¹å‡»æ­¤å¤„](https://github.com/alibaba-damo-academy/FunASR/blob/main/runtime/readme_cn.md)ï¼‰



## <strong>[ModelScope-FunASR](https://github.com/alibaba-damo-academy/FunASR)</strong>
<strong>[FunASR](https://github.com/alibaba-damo-academy/FunASR)</strong>æä¾›å¯ä¾¿æ·æœ¬åœ°æˆ–è€…äº‘ç«¯æœåŠ¡å™¨éƒ¨ç½²çš„ç¦»çº¿æ–‡ä»¶è½¬å†™æœåŠ¡ï¼Œå†…æ ¸ä¸ºFunASRå·²å¼€æºruntime-SDKã€‚ é›†æˆäº†è¾¾æ‘©é™¢è¯­éŸ³å®éªŒå®¤åœ¨Modelscopeç¤¾åŒºå¼€æºçš„è¯­éŸ³ç«¯ç‚¹æ£€æµ‹(VAD)ã€Paraformer-largeè¯­éŸ³è¯†åˆ«(ASR)ã€æ ‡ç‚¹æ¢å¤(PUNC) ç­‰ç›¸å…³èƒ½åŠ›ï¼Œæ‹¥æœ‰å®Œæ•´çš„è¯­éŸ³è¯†åˆ«é“¾è·¯ï¼Œå¯ä»¥å°†å‡ åä¸ªå°æ—¶çš„éŸ³é¢‘æˆ–è§†é¢‘è¯†åˆ«æˆå¸¦æ ‡ç‚¹çš„æ–‡å­—ï¼Œè€Œä¸”æ”¯æŒä¸Šç™¾è·¯è¯·æ±‚åŒæ—¶è¿›è¡Œè½¬å†™ã€‚

[**æœ€æ–°åŠ¨æ€**](https://github.com/alibaba-damo-academy/FunASR#whats-new) 
| [**ç¯å¢ƒå®‰è£…**](https://github.com/alibaba-damo-academy/FunASR#installation)
| [**ä»‹ç»æ–‡æ¡£**](https://alibaba-damo-academy.github.io/FunASR/en/index.html)
| [**æœåŠ¡éƒ¨ç½²**](https://github.com/alibaba-damo-academy/FunASR/blob/main/runtime/readme_cn.md)
| [**æ¨¡å‹åº“**](https://github.com/alibaba-damo-academy/FunASR/blob/main/docs/model_zoo/modelscope_models.md)
| [**è”ç³»æˆ‘ä»¬**](https://github.com/alibaba-damo-academy/FunASR#contact)

## å¿«é€Ÿä¸Šæ‰‹
### dockerå®‰è£…
å¦‚æœæ‚¨å·²å®‰è£…dockerï¼Œå¿½ç•¥æœ¬æ­¥éª¤ï¼!
é€šè¿‡ä¸‹è¿°å‘½ä»¤åœ¨æœåŠ¡å™¨ä¸Šå®‰è£…dockerï¼š
```shell
curl -O https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/shell/install_docker.shï¼›
sudo bash install_docker.sh
```
dockerå®‰è£…å¤±è´¥è¯·å‚è€ƒ [Docker Installation](https://alibaba-damo-academy.github.io/FunASR/en/installation/docker.html)

### é•œåƒå¯åŠ¨
é€šè¿‡ä¸‹è¿°å‘½ä»¤æ‹‰å–å¹¶å¯åŠ¨FunASR runtimeçš„dockeré•œåƒï¼ˆ[è·å–æœ€æ–°é•œåƒç‰ˆæœ¬](https://github.com/alibaba-damo-academy/FunASR/blob/main/runtime/docs/SDK_advanced_guide_offline_zh.md)ï¼‰ï¼š

```shell
sudo docker pull \
  registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-cpu-0.3.0
mkdir -p ./funasr-runtime-resources/models
sudo docker run -p 10095:10095 -it --privileged=true \
  -v $PWD/funasr-runtime-resources/models:/workspace/models \
  registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-cpu-0.3.0
```

### æœåŠ¡ç«¯å¯åŠ¨

dockerå¯åŠ¨ä¹‹åï¼Œå¯åŠ¨ funasr-wss-serveræœåŠ¡ç¨‹åºï¼š
```shell
cd FunASR/runtime
nohup bash run_server.sh \
  --download-model-dir /workspace/models \
  --vad-dir damo/speech_fsmn_vad_zh-cn-16k-common-onnx \
  --model-dir damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-onnx  \
  --punc-dir damo/punc_ct-transformer_cn-en-common-vocab471067-large-onnx \
  --lm-dir damo/speech_ngram_lm_zh-cn-ai-wesp-fst \
  --itn-dir thuduj12/fst_itn_zh \
  --hotword /workspace/models/hotwords.txt > log.out 2>&1 &
```

### å®¢æˆ·ç«¯æµ‹è¯•ä¸ä½¿ç”¨

è¿è¡Œä¸Šé¢å®‰è£…æŒ‡ä»¤åï¼Œä¼šåœ¨./funasr-runtime-resourcesï¼ˆé»˜è®¤å®‰è£…ç›®å½•ï¼‰ä¸­ä¸‹è½½å®¢æˆ·ç«¯æµ‹è¯•å·¥å…·ç›®å½•samplesï¼ˆ[ä¸‹è½½ç‚¹å‡»æ­¤å¤„](https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/sample/funasr_samples.tar.gz)ï¼‰ï¼Œ
æˆ‘ä»¬ä»¥Pythonè¯­è¨€å®¢æˆ·ç«¯ä¸ºä¾‹ï¼Œè¿›è¡Œè¯´æ˜ï¼Œæ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼è¾“å…¥ï¼ˆ.wav, .pcm, .mp3ç­‰ï¼‰ï¼Œä¹Ÿæ”¯æŒè§†é¢‘è¾“å…¥(.mp4ç­‰)ï¼Œä»¥åŠå¤šæ–‡ä»¶åˆ—è¡¨wav.scpè¾“å…¥ï¼Œå…¶ä»–ç‰ˆæœ¬å®¢æˆ·ç«¯è¯·å‚è€ƒæ–‡æ¡£ï¼ˆ[ç‚¹å‡»æ­¤å¤„](https://alibaba-damo-academy.github.io/FunASR/en/runtime/docs/SDK_tutorial_zh.html#id5)ï¼‰

```shell
python3 wss_client_asr.py --host "127.0.0.1" --port 10095 --mode offline --audio_in "../audio/asr_example.wav"
```

æ›´è¯¦ç»†ç”¨æ³•ä»‹ç»ï¼ˆ[ç‚¹å‡»æ­¤å¤„](https://github.com/alibaba-damo-academy/FunASR/blob/main/runtime/docs/SDK_tutorial_zh.md)ï¼‰


## ç›¸å…³è®ºæ–‡ä»¥åŠå¼•ç”¨ä¿¡æ¯

```BibTeX
@inproceedings{zhang2018deep,
  title={Deep-FSMN for large vocabulary continuous speech recognition},
  author={Zhang, Shiliang and Lei, Ming and Yan, Zhijie and Dai, Lirong},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5869--5873},
  year={2018},
  organization={IEEE}
}
```
```

--------------------------------------------------------------------------------

File: models/damo/speech_fsmn_vad_zh-cn-16k-common-onnx/quickstart.md
```markdown
---
<!-- è¯¥éƒ¨åˆ†ä¸ºå‚æ•°é…ç½®éƒ¨åˆ† -->

---
<!-- å…¬å…±å†…å®¹éƒ¨åˆ†  -->

ç”¨æ³•è¯·å‚è€ƒæ–‡æ¡£ï¼ˆ[ä¸€é”®éƒ¨ç½²](https://github.com/alibaba-damo-academy/FunASR/blob/main/funasr/runtime/readme_cn.md)ï¼‰

---
<!-- åœ¨çº¿ä½¿ç”¨ç‹¬æœ‰å†…å®¹éƒ¨åˆ† -->

---
<!-- æœ¬åœ°ä½¿ç”¨ç‹¬æœ‰å†…å®¹éƒ¨åˆ† -->
```

--------------------------------------------------------------------------------

File: client/funasr_realtime_chunk_client.py
```python
# File: client/funasr_realtime_chunk_client.py
# è¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºå¤„ç†å®æ—¶éŸ³é¢‘ç‰‡æ®µçš„æ–°è„šæœ¬

import asyncio
import argparse
import json
import logging
import os
import websockets
import wave

# åªæŠ¥å‘Šä¸¥é‡é”™è¯¯ï¼Œä¿æŒè¾“å‡ºå¹²å‡€
logging.basicConfig(level=logging.CRITICAL)

# å®šä¹‰å…¨å±€å˜é‡æ¥å­˜å‚¨æœ€ç»ˆç»“æœ
final_result = ""
# ä½¿ç”¨ asyncio.Event æ¥åŒæ­¥ä»»åŠ¡ï¼Œç¡®ä¿åœ¨è·å–ç»“æœå‰ä»»åŠ¡å·²å®Œæˆ
is_done = asyncio.Event()

async def process_audio_chunk(websocket, audio_path):
    """è¯»å–WAVæ–‡ä»¶ï¼Œå¹¶å°†å…¶å‘é€åˆ°FunASRè¿›è¡Œè¯†åˆ«"""
    try:
        with wave.open(audio_path, "rb") as wav_file:
            sample_rate = wav_file.getframerate()
            audio_bytes = wav_file.readframes(wav_file.getnframes())
    except Exception as e:
        logging.error(f"æ— æ³•è¯»å–ä¸´æ—¶WAVæ–‡ä»¶: {e}")
        is_done.set()
        return

    # FunASRçš„WebSocketè¿æ¥é…ç½®
    config = {
        "mode": "offline",
        "chunk_size": [5, 10, 5],
        "wav_name": "realtime_chunk",
        "is_speaking": True,
        "hotwords": "",
        "itn": True,
        "audio_fs": sample_rate,
    }

    try:
        # å‘é€é…ç½®
        await websocket.send(json.dumps(config))
        # å‘é€éŸ³é¢‘æ•°æ®
        await websocket.send(audio_bytes)
        # å‘é€ç»“æŸæ ‡è®°
        await websocket.send(json.dumps({"is_speaking": False}))

        # ç­‰å¾…å¹¶æ¥æ”¶ç»“æœ
        while not is_done.is_set():
            response = await asyncio.wait_for(websocket.recv(), timeout=10.0)
            response_data = json.loads(response)
            
            # æˆ‘ä»¬åªå…³å¿ƒåŒ…å«æœ€ç»ˆæ–‡æœ¬çš„'offline'æ¨¡å¼ç»“æœ
            if response_data.get("mode") == "offline" and "text" in response_data:
                global final_result
                final_result = response_data["text"]
                break # æ”¶åˆ°ç»“æœåå³å¯é€€å‡ºå¾ªç¯
    except Exception as e:
        logging.error(f"ä¸FunASRé€šä¿¡æ—¶å‡ºé”™: {e}")
    finally:
        # ç¡®ä¿is_doneäº‹ä»¶è¢«è®¾ç½®ï¼Œä»¥å…è®¸ä¸»ç¨‹åºé€€å‡º
        is_done.set()

async def main(host, port, audio_path):
    """ä¸»å‡½æ•°ï¼Œå»ºç«‹è¿æ¥å¹¶å¤„ç†éŸ³é¢‘"""
    uri = f"ws://{host}:{port}"
    try:
        # è¿æ¥åˆ°FunASRçš„WebSocketæœåŠ¡
        async with websockets.connect(uri, subprotocols=["binary"], ping_interval=None) as websocket:
            await process_audio_chunk(websocket, audio_path)
    except Exception as e:
        logging.error(f"æ— æ³•è¿æ¥åˆ°FunASR WebSocketæœåŠ¡äº {uri}: {e}")
        is_done.set()


if __name__ == "__main__":
    # ä»å‘½ä»¤è¡Œæ¥æ”¶å¿…è¦çš„å‚æ•°
    parser = argparse.ArgumentParser(description="FunASRå®æ—¶éŸ³é¢‘å—è¯†åˆ«å®¢æˆ·ç«¯")
    parser.add_argument("--host", default="127.0.0.1", help="FunASRæœåŠ¡åœ°å€")
    parser.add_argument("--port", type=int, default=10095, help="FunASRæœåŠ¡ç«¯å£")
    parser.add_argument("--audio_in", required=True, help="è¾“å…¥çš„WAVéŸ³é¢‘æ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()

    # è¿è¡Œä¸»å¼‚æ­¥å‡½æ•°
    asyncio.run(main(args.host, args.port, args.audio_in))
    
    # ç¡®ä¿åªæ‰“å°æœ€ç»ˆçš„ã€çº¯å‡€çš„æ–‡æœ¬ç»“æœ
    print(final_result, end='')
```

--------------------------------------------------------------------------------

File: client/test_demo.ps1
```powershell
python ./client/funasr_wss_client.py       --host "127.0.0.1"       --port 10095       --mode offline       --audio_in "./client/BAC009S0764W0179.wav"
```

--------------------------------------------------------------------------------

File: client/funasr_wss_client.py
```python
# -*- encoding: utf-8 -*-
import os
import time
import websockets, ssl
import asyncio

# import threading
import argparse
import json
import traceback
from multiprocessing import Process

# from funasr.fileio.datadir_writer import DatadirWriter

import logging

logging.basicConfig(level=logging.ERROR)

parser = argparse.ArgumentParser()
parser.add_argument(
    "--host", type=str, default="localhost", required=False, help="host ip, localhost, 0.0.0.0"
)
parser.add_argument("--port", type=int, default=10095, required=False, help="grpc server port")
parser.add_argument("--chunk_size", type=str, default="5, 10, 5", help="chunk")
parser.add_argument("--encoder_chunk_look_back", type=int, default=4, help="chunk")
parser.add_argument("--decoder_chunk_look_back", type=int, default=0, help="chunk")
parser.add_argument("--chunk_interval", type=int, default=10, help="chunk")
parser.add_argument(
    "--hotword",
    type=str,
    default="",
    help="hotword file path, one hotword perline (e.g.:é˜¿é‡Œå·´å·´ 20)",
)
parser.add_argument("--audio_in", type=str, default=None, help="audio_in")
parser.add_argument("--audio_fs", type=int, default=16000, help="audio_fs")
parser.add_argument(
    "--send_without_sleep",
    action="store_true",
    default=True,
    help="if audio_in is set, send_without_sleep",
)
parser.add_argument("--thread_num", type=int, default=1, help="thread_num")
parser.add_argument("--words_max_print", type=int, default=10000, help="chunk")
parser.add_argument("--output_dir", type=str, default=None, help="output_dir")
parser.add_argument("--ssl", type=int, default=1, help="1 for ssl connect, 0 for no ssl")
parser.add_argument("--use_itn", type=int, default=1, help="1 for using itn, 0 for not itn")
parser.add_argument("--mode", type=str, default="2pass", help="offline, online, 2pass")

args = parser.parse_args()
args.chunk_size = [int(x) for x in args.chunk_size.split(",")]
print(args)
# voices = asyncio.Queue()
from queue import Queue

voices = Queue()
offline_msg_done = False

if args.output_dir is not None:
    # if os.path.exists(args.output_dir):
    #     os.remove(args.output_dir)

    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir)


async def record_microphone():
    is_finished = False
    import pyaudio

    # print("2")
    global voices
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    chunk_size = 60 * args.chunk_size[1] / args.chunk_interval
    CHUNK = int(RATE / 1000 * chunk_size)

    p = pyaudio.PyAudio()

    stream = p.open(
        format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK
    )
    # hotwords
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        if os.path.exists(args.hotword):
            f_scp = open(args.hotword)
            hot_lines = f_scp.readlines()
            for line in hot_lines:
                words = line.strip().split(" ")
                if len(words) < 2:
                    print("Please checkout format of hotwords")
                    continue
                try:
                    fst_dict[" ".join(words[:-1])] = int(words[-1])
                except ValueError:
                    print("Please checkout format of hotwords")
            hotword_msg = json.dumps(fst_dict)
        else:
            hotword_msg = args.hotword

    use_itn = True
    if args.use_itn == 0:
        use_itn = False

    message = json.dumps(
        {
            "mode": args.mode,
            "chunk_size": args.chunk_size,
            "chunk_interval": args.chunk_interval,
            "encoder_chunk_look_back": args.encoder_chunk_look_back,
            "decoder_chunk_look_back": args.decoder_chunk_look_back,
            "wav_name": "microphone",
            "is_speaking": True,
            "hotwords": hotword_msg,
            "itn": use_itn,
        }
    )
    # voices.put(message)
    await websocket.send(message)
    while True:
        data = stream.read(CHUNK)
        message = data
        # voices.put(message)
        await websocket.send(message)
        await asyncio.sleep(0.005)


async def record_from_scp(chunk_begin, chunk_size):
    global voices
    is_finished = False
    if args.audio_in.endswith(".scp"):
        f_scp = open(args.audio_in)
        wavs = f_scp.readlines()
    else:
        wavs = [args.audio_in]

    # hotwords
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        if os.path.exists(args.hotword):
            f_scp = open(args.hotword)
            hot_lines = f_scp.readlines()
            for line in hot_lines:
                words = line.strip().split(" ")
                if len(words) < 2:
                    print("Please checkout format of hotwords")
                    continue
                try:
                    fst_dict[" ".join(words[:-1])] = int(words[-1])
                except ValueError:
                    print("Please checkout format of hotwords")
            hotword_msg = json.dumps(fst_dict)
        else:
            hotword_msg = args.hotword
        print(hotword_msg)

    sample_rate = args.audio_fs
    wav_format = "pcm"
    use_itn = True
    if args.use_itn == 0:
        use_itn = False

    if chunk_size > 0:
        wavs = wavs[chunk_begin : chunk_begin + chunk_size]
    for wav in wavs:
        wav_splits = wav.strip().split()

        wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
        wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
        if not len(wav_path.strip()) > 0:
            continue
        if wav_path.endswith(".pcm"):
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()
        elif wav_path.endswith(".wav"):
            import wave

            with wave.open(wav_path, "rb") as wav_file:
                params = wav_file.getparams()
                sample_rate = wav_file.getframerate()
                frames = wav_file.readframes(wav_file.getnframes())
                audio_bytes = bytes(frames)
        else:
            wav_format = "others"
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()

        stride = int(60 * args.chunk_size[1] / args.chunk_interval / 1000 * sample_rate * 2)
        chunk_num = (len(audio_bytes) - 1) // stride + 1
        # print(stride)

        # send first time
        message = json.dumps(
            {
                "mode": args.mode,
                "chunk_size": args.chunk_size,
                "chunk_interval": args.chunk_interval,
                "encoder_chunk_look_back": args.encoder_chunk_look_back,
                "decoder_chunk_look_back": args.decoder_chunk_look_back,
                "audio_fs": sample_rate,
                "wav_name": wav_name,
                "wav_format": wav_format,
                "is_speaking": True,
                "hotwords": hotword_msg,
                "itn": use_itn,
            }
        )

        # voices.put(message)
        await websocket.send(message)
        is_speaking = True
        for i in range(chunk_num):

            beg = i * stride
            data = audio_bytes[beg : beg + stride]
            message = data
            # voices.put(message)
            await websocket.send(message)
            if i == chunk_num - 1:
                is_speaking = False
                message = json.dumps({"is_speaking": is_speaking})
                # voices.put(message)
                await websocket.send(message)

            sleep_duration = (
                0.001
                if args.mode == "offline"
                else 60 * args.chunk_size[1] / args.chunk_interval / 1000
            )

            await asyncio.sleep(sleep_duration)

    if not args.mode == "offline":
        await asyncio.sleep(2)
    # offline model need to wait for message recved

    if args.mode == "offline":
        global offline_msg_done
        while not offline_msg_done:
            await asyncio.sleep(1)

    await websocket.close()


async def message(id):
    global websocket, voices, offline_msg_done
    text_print = ""
    text_print_2pass_online = ""
    text_print_2pass_offline = ""
    if args.output_dir is not None:
        ibest_writer = open(
            os.path.join(args.output_dir, "text.{}".format(id)), "a", encoding="utf-8"
        )
    else:
        ibest_writer = None
    try:
        while True:

            meg = await websocket.recv()
            meg = json.loads(meg)
            wav_name = meg.get("wav_name", "demo")
            text = meg["text"]
            timestamp = ""
            offline_msg_done = meg.get("is_final", False)
            if "timestamp" in meg:
                timestamp = meg["timestamp"]

            if ibest_writer is not None:
                if timestamp != "":
                    text_write_line = "{}\t{}\t{}\n".format(wav_name, text, timestamp)
                else:
                    text_write_line = "{}\t{}\n".format(wav_name, text)
                ibest_writer.write(text_write_line)

            if "mode" not in meg:
                continue
            if meg["mode"] == "online":
                text_print += "{}".format(text)
                text_print = text_print[-args.words_max_print :]
                os.system("clear")
                print("\rpid" + str(id) + ": " + text_print)
            elif meg["mode"] == "offline":
                if timestamp != "":
                    text_print += "{} timestamp: {}".format(text, timestamp)
                else:
                    text_print += "{}".format(text)

                # text_print = text_print[-args.words_max_print:]
                # os.system('clear')
                print("\rpid" + str(id) + ": " + wav_name + ": " + text_print)
                offline_msg_done = True
            else:
                if meg["mode"] == "2pass-online":
                    text_print_2pass_online += "{}".format(text)
                    text_print = text_print_2pass_offline + text_print_2pass_online
                else:
                    text_print_2pass_online = ""
                    text_print = text_print_2pass_offline + "{}".format(text)
                    text_print_2pass_offline += "{}".format(text)
                text_print = text_print[-args.words_max_print :]
                os.system("clear")
                print("\rpid" + str(id) + ": " + text_print)
                # offline_msg_done=True

    except Exception as e:
        print("Exception:", e)
        # traceback.print_exc()
        # await websocket.close()


async def ws_client(id, chunk_begin, chunk_size):
    if args.audio_in is None:
        chunk_begin = 0
        chunk_size = 1
    global websocket, voices, offline_msg_done

    for i in range(chunk_begin, chunk_begin + chunk_size):
        offline_msg_done = False
        voices = Queue()
        if args.ssl == 1:
            ssl_context = ssl.SSLContext()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE
            uri = "wss://{}:{}".format(args.host, args.port)
        else:
            uri = "ws://{}:{}".format(args.host, args.port)
            ssl_context = None
        print("connect to", uri)
        async with websockets.connect(
            uri, subprotocols=["binary"], ping_interval=None, ssl=ssl_context
        ) as websocket:
            if args.audio_in is not None:
                task = asyncio.create_task(record_from_scp(i, 1))
            else:
                task = asyncio.create_task(record_microphone())
            task3 = asyncio.create_task(message(str(id) + "_" + str(i)))  # processid+fileid
            await asyncio.gather(task, task3)
    exit(0)


def one_thread(id, chunk_begin, chunk_size):
    asyncio.get_event_loop().run_until_complete(ws_client(id, chunk_begin, chunk_size))
    asyncio.get_event_loop().run_forever()


if __name__ == "__main__":
    # for microphone
    if args.audio_in is None:
        p = Process(target=one_thread, args=(0, 0, 0))
        p.start()
        p.join()
        print("end")
    else:
        # calculate the number of wavs for each preocess
        if args.audio_in.endswith(".scp"):
            f_scp = open(args.audio_in)
            wavs = f_scp.readlines()
        else:
            wavs = [args.audio_in]
        for wav in wavs:
            wav_splits = wav.strip().split()
            wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
            wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
            audio_type = os.path.splitext(wav_path)[-1].lower()

        total_len = len(wavs)
        if total_len >= args.thread_num:
            chunk_size = int(total_len / args.thread_num)
            remain_wavs = total_len - chunk_size * args.thread_num
        else:
            chunk_size = 1
            remain_wavs = 0

        process_list = []
        chunk_begin = 0
        for i in range(args.thread_num):
            now_chunk_size = chunk_size
            if remain_wavs > 0:
                now_chunk_size = chunk_size + 1
                remain_wavs = remain_wavs - 1
            # process i handle wavs at chunk_begin and size of now_chunk_size
            p = Process(target=one_thread, args=(i, chunk_begin, now_chunk_size))
            chunk_begin = chunk_begin + now_chunk_size
            p.start()
            process_list.append(p)

        for i in process_list:
            p.join()

        print("end")
```

--------------------------------------------------------------------------------

File: client/test_demo.sh
```shell
python ./client/funasr_wss_client.py       --host "127.0.0.1"       --port 10095       --mode offline       --audio_in "./client/BAC009S0764W0179.wav"
```

--------------------------------------------------------------------------------

File: client/asr_system_backend/client/funasr_wss_client.py
```python
# -*- encoding: utf-8 -*-
import os
import time
import websockets, ssl
import asyncio

# import threading
import argparse
import json
import traceback
from multiprocessing import Process

# from funasr.fileio.datadir_writer import DatadirWriter

import logging

logging.basicConfig(level=logging.ERROR)

parser = argparse.ArgumentParser()
parser.add_argument(
    "--host", type=str, default="localhost", required=False, help="host ip, localhost, 0.0.0.0"
)
parser.add_argument("--port", type=int, default=10095, required=False, help="grpc server port")
parser.add_argument("--chunk_size", type=str, default="5, 10, 5", help="chunk")
parser.add_argument("--encoder_chunk_look_back", type=int, default=4, help="chunk")
parser.add_argument("--decoder_chunk_look_back", type=int, default=0, help="chunk")
parser.add_argument("--chunk_interval", type=int, default=10, help="chunk")
parser.add_argument(
    "--hotword",
    type=str,
    default="",
    help="hotword file path, one hotword perline (e.g.:é˜¿é‡Œå·´å·´ 20)",
)
parser.add_argument("--audio_in", type=str, default=None, help="audio_in")
parser.add_argument("--audio_fs", type=int, default=16000, help="audio_fs")
parser.add_argument(
    "--send_without_sleep",
    action="store_true",
    default=True,
    help="if audio_in is set, send_without_sleep",
)
parser.add_argument("--thread_num", type=int, default=1, help="thread_num")
parser.add_argument("--words_max_print", type=int, default=10000, help="chunk")
parser.add_argument("--output_dir", type=str, default=None, help="output_dir")
parser.add_argument("--ssl", type=int, default=1, help="1 for ssl connect, 0 for no ssl")
parser.add_argument("--use_itn", type=int, default=1, help="1 for using itn, 0 for not itn")
parser.add_argument("--mode", type=str, default="2pass", help="offline, online, 2pass")

args = parser.parse_args()
args.chunk_size = [int(x) for x in args.chunk_size.split(",")]
print(args)
# voices = asyncio.Queue()
from queue import Queue

voices = Queue()
offline_msg_done = False

if args.output_dir is not None:
    # if os.path.exists(args.output_dir):
    #     os.remove(args.output_dir)

    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir)


async def record_microphone():
    is_finished = False
    import pyaudio

    # print("2")
    global voices
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    chunk_size = 60 * args.chunk_size[1] / args.chunk_interval
    CHUNK = int(RATE / 1000 * chunk_size)

    p = pyaudio.PyAudio()

    stream = p.open(
        format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK
    )
    # hotwords
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        if os.path.exists(args.hotword):
            f_scp = open(args.hotword)
            hot_lines = f_scp.readlines()
            for line in hot_lines:
                words = line.strip().split(" ")
                if len(words) < 2:
                    print("Please checkout format of hotwords")
                    continue
                try:
                    fst_dict[" ".join(words[:-1])] = int(words[-1])
                except ValueError:
                    print("Please checkout format of hotwords")
            hotword_msg = json.dumps(fst_dict)
        else:
            hotword_msg = args.hotword

    use_itn = True
    if args.use_itn == 0:
        use_itn = False

    message = json.dumps(
        {
            "mode": args.mode,
            "chunk_size": args.chunk_size,
            "chunk_interval": args.chunk_interval,
            "encoder_chunk_look_back": args.encoder_chunk_look_back,
            "decoder_chunk_look_back": args.decoder_chunk_look_back,
            "wav_name": "microphone",
            "is_speaking": True,
            "hotwords": hotword_msg,
            "itn": use_itn,
        }
    )
    # voices.put(message)
    await websocket.send(message)
    while True:
        data = stream.read(CHUNK)
        message = data
        # voices.put(message)
        await websocket.send(message)
        await asyncio.sleep(0.005)


async def record_from_scp(chunk_begin, chunk_size):
    global voices
    is_finished = False
    if args.audio_in.endswith(".scp"):
        f_scp = open(args.audio_in)
        wavs = f_scp.readlines()
    else:
        wavs = [args.audio_in]

    # hotwords
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        if os.path.exists(args.hotword):
            f_scp = open(args.hotword)
            hot_lines = f_scp.readlines()
            for line in hot_lines:
                words = line.strip().split(" ")
                if len(words) < 2:
                    print("Please checkout format of hotwords")
                    continue
                try:
                    fst_dict[" ".join(words[:-1])] = int(words[-1])
                except ValueError:
                    print("Please checkout format of hotwords")
            hotword_msg = json.dumps(fst_dict)
        else:
            hotword_msg = args.hotword
        print(hotword_msg)

    sample_rate = args.audio_fs
    wav_format = "pcm"
    use_itn = True
    if args.use_itn == 0:
        use_itn = False

    if chunk_size > 0:
        wavs = wavs[chunk_begin : chunk_begin + chunk_size]
    for wav in wavs:
        wav_splits = wav.strip().split()

        wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
        wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
        if not len(wav_path.strip()) > 0:
            continue
        if wav_path.endswith(".pcm"):
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()
        elif wav_path.endswith(".wav"):
            import wave

            with wave.open(wav_path, "rb") as wav_file:
                params = wav_file.getparams()
                sample_rate = wav_file.getframerate()
                frames = wav_file.readframes(wav_file.getnframes())
                audio_bytes = bytes(frames)
        else:
            wav_format = "others"
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()

        stride = int(60 * args.chunk_size[1] / args.chunk_interval / 1000 * sample_rate * 2)
        chunk_num = (len(audio_bytes) - 1) // stride + 1
        # print(stride)

        # send first time
        message = json.dumps(
            {
                "mode": args.mode,
                "chunk_size": args.chunk_size,
                "chunk_interval": args.chunk_interval,
                "encoder_chunk_look_back": args.encoder_chunk_look_back,
                "decoder_chunk_look_back": args.decoder_chunk_look_back,
                "audio_fs": sample_rate,
                "wav_name": wav_name,
                "wav_format": wav_format,
                "is_speaking": True,
                "hotwords": hotword_msg,
                "itn": use_itn,
            }
        )

        # voices.put(message)
        await websocket.send(message)
        is_speaking = True
        for i in range(chunk_num):

            beg = i * stride
            data = audio_bytes[beg : beg + stride]
            message = data
            # voices.put(message)
            await websocket.send(message)
            if i == chunk_num - 1:
                is_speaking = False
                message = json.dumps({"is_speaking": is_speaking})
                # voices.put(message)
                await websocket.send(message)

            sleep_duration = (
                0.001
                if args.mode == "offline"
                else 60 * args.chunk_size[1] / args.chunk_interval / 1000
            )

            await asyncio.sleep(sleep_duration)

    if not args.mode == "offline":
        await asyncio.sleep(2)
    # offline model need to wait for message recved

    if args.mode == "offline":
        global offline_msg_done
        while not offline_msg_done:
            await asyncio.sleep(1)

    await websocket.close()


async def message(id):
    global websocket, voices, offline_msg_done
    text_print = ""
    text_print_2pass_online = ""
    text_print_2pass_offline = ""
    if args.output_dir is not None:
        ibest_writer = open(
            os.path.join(args.output_dir, "text.{}".format(id)), "a", encoding="utf-8"
        )
    else:
        ibest_writer = None
    try:
        while True:

            meg = await websocket.recv()
            meg = json.loads(meg)
            wav_name = meg.get("wav_name", "demo")
            text = meg["text"]
            timestamp = ""
            offline_msg_done = meg.get("is_final", False)
            if "timestamp" in meg:
                timestamp = meg["timestamp"]

            if ibest_writer is not None:
                if timestamp != "":
                    text_write_line = "{}\t{}\t{}\n".format(wav_name, text, timestamp)
                else:
                    text_write_line = "{}\t{}\n".format(wav_name, text)
                ibest_writer.write(text_write_line)

            if "mode" not in meg:
                continue
            if meg["mode"] == "online":
                text_print += "{}".format(text)
                text_print = text_print[-args.words_max_print :]
                os.system("clear")
                print("\rpid" + str(id) + ": " + text_print)
            elif meg["mode"] == "offline":
                if timestamp != "":
                    text_print += "{} timestamp: {}".format(text, timestamp)
                else:
                    text_print += "{}".format(text)

                # text_print = text_print[-args.words_max_print:]
                # os.system('clear')
                print("\rpid" + str(id) + ": " + wav_name + ": " + text_print)
                offline_msg_done = True
            else:
                if meg["mode"] == "2pass-online":
                    text_print_2pass_online += "{}".format(text)
                    text_print = text_print_2pass_offline + text_print_2pass_online
                else:
                    text_print_2pass_online = ""
                    text_print = text_print_2pass_offline + "{}".format(text)
                    text_print_2pass_offline += "{}".format(text)
                text_print = text_print[-args.words_max_print :]
                os.system("clear")
                print("\rpid" + str(id) + ": " + text_print)
                # offline_msg_done=True

    except Exception as e:
        print("Exception:", e)
        # traceback.print_exc()
        # await websocket.close()


async def ws_client(id, chunk_begin, chunk_size):
    if args.audio_in is None:
        chunk_begin = 0
        chunk_size = 1
    global websocket, voices, offline_msg_done

    for i in range(chunk_begin, chunk_begin + chunk_size):
        offline_msg_done = False
        voices = Queue()
        if args.ssl == 1:
            ssl_context = ssl.SSLContext()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE
            uri = "wss://{}:{}".format(args.host, args.port)
        else:
            uri = "ws://{}:{}".format(args.host, args.port)
            ssl_context = None
        print("connect to", uri)
        async with websockets.connect(
            uri, subprotocols=["binary"], ping_interval=None, ssl=ssl_context
        ) as websocket:
            if args.audio_in is not None:
                task = asyncio.create_task(record_from_scp(i, 1))
            else:
                task = asyncio.create_task(record_microphone())
            task3 = asyncio.create_task(message(str(id) + "_" + str(i)))  # processid+fileid
            await asyncio.gather(task, task3)
    exit(0)


def one_thread(id, chunk_begin, chunk_size):
    asyncio.get_event_loop().run_until_complete(ws_client(id, chunk_begin, chunk_size))
    asyncio.get_event_loop().run_forever()


if __name__ == "__main__":
    # for microphone
    if args.audio_in is None:
        p = Process(target=one_thread, args=(0, 0, 0))
        p.start()
        p.join()
        print("end")
    else:
        # calculate the number of wavs for each preocess
        if args.audio_in.endswith(".scp"):
            f_scp = open(args.audio_in)
            wavs = f_scp.readlines()
        else:
            wavs = [args.audio_in]
        for wav in wavs:
            wav_splits = wav.strip().split()
            wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
            wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
            audio_type = os.path.splitext(wav_path)[-1].lower()

        total_len = len(wavs)
        if total_len >= args.thread_num:
            chunk_size = int(total_len / args.thread_num)
            remain_wavs = total_len - chunk_size * args.thread_num
        else:
            chunk_size = 1
            remain_wavs = 0

        process_list = []
        chunk_begin = 0
        for i in range(args.thread_num):
            now_chunk_size = chunk_size
            if remain_wavs > 0:
                now_chunk_size = chunk_size + 1
                remain_wavs = remain_wavs - 1
            # process i handle wavs at chunk_begin and size of now_chunk_size
            p = Process(target=one_thread, args=(i, chunk_begin, now_chunk_size))
            chunk_begin = chunk_begin + now_chunk_size
            p.start()
            process_list.append(p)

        for i in process_list:
            p.join()

        print("end")
```

--------------------------------------------------------------------------------

File: asr_system_backend/env.example
```text
# ASRç³»ç»Ÿç¯å¢ƒå˜é‡é…ç½®æ¨¡æ¿
# è¯·å¤åˆ¶æ­¤æ–‡ä»¶ä¸º.envå¹¶å¡«å…¥çœŸå®å€¼

# æ•°æ®åº“é…ç½®
DATABASE_URL=sqlite:///./asr_system.db

# JWTå®‰å…¨é…ç½®
JWT_SECRET_KEY=your_jwt_secret_key_here_please_change_this
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=60

# ASRå¼•æ“é…ç½®
ASR_MODEL_SIZE=base
ASR_LANGUAGE=zh
ASR_ENABLE_GPU=true
ASR_MAX_FILE_SIZE_MB=100
ASR_PROCESSING_TIMEOUT=300

# æ–‡ä»¶å­˜å‚¨é…ç½®
UPLOAD_DIR=uploads
TEMP_DIR=temp

# RAGæœåŠ¡é…ç½®
RAG_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
RAG_SIMILARITY_THRESHOLD=0.5

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
LOG_FILE=app.log

# æ€§èƒ½é…ç½®
BACKGROUND_TASK_WORKERS=2

# OpenAI APIé…ç½®ï¼ˆå¦‚æœä½¿ç”¨OpenAI Whisper APIï¼‰
# OPENAI_API_KEY=your_openai_api_key_here

# é˜¿é‡Œäº‘é…ç½®ï¼ˆå¦‚æœä½¿ç”¨é˜¿é‡Œäº‘æœåŠ¡ï¼‰
# ALIYUN_ACCESS_KEY_ID=your_access_key_id
# ALIYUN_ACCESS_KEY_SECRET=your_access_key_secret

# ç™¾åº¦AIé…ç½®ï¼ˆå¦‚æœä½¿ç”¨ç™¾åº¦è¯­éŸ³è¯†åˆ«ï¼‰
# BAIDU_APP_ID=your_baidu_app_id
# BAIDU_API_KEY=your_baidu_api_key
# BAIDU_SECRET_KEY=your_baidu_secret_key

# å¼€å‘æ¨¡å¼é…ç½®
DEBUG=true
DEVELOPMENT=true
```

--------------------------------------------------------------------------------

File: asr_system_backend/setup.py
```python
# File: asr_system_backend/setup.py
from setuptools import setup, find_packages

setup(
    name="asr_system_backend",  # <-- æŠŠè¿™é‡Œçš„è¿å­—ç¬¦æ”¹æˆä¸‹åˆ’çº¿ï¼
    version="0.1.0",
    packages=find_packages(),
)
```

--------------------------------------------------------------------------------

File: asr_system_backend/alembic.ini
```ini
# A generic, single database configuration.

[alembic]
# path to migration scripts.
# this is typically a path given in POSIX (e.g. forward slashes)
# format, relative to the token %(here)s which refers to the location of this
# ini file
script_location = %(here)s/alembic

# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s
# Uncomment the line below if you want the files to be prepended with date and time
# see https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file
# for all available tokens
# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.  for multiple paths, the path separator
# is defined by "path_separator" below.
prepend_sys_path = .


# timezone to use when rendering the date within the migration file
# as well as the filename.
# If specified, requires the python>=3.9 or backports.zoneinfo library and tzdata library.
# Any required deps can installed by adding `alembic[tz]` to the pip requirements
# string value is passed to ZoneInfo()
# leave blank for localtime
# timezone =

# max length of characters to apply to the "slug" field
# truncate_slug_length = 40

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; This defaults
# to <script_location>/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path.
# The path separator used here should be the separator specified by "path_separator"
# below.
# version_locations = %(here)s/bar:%(here)s/bat:%(here)s/alembic/versions

# path_separator; This indicates what character is used to split lists of file
# paths, including version_locations and prepend_sys_path within configparser
# files such as alembic.ini.
# The default rendered in new alembic.ini files is "os", which uses os.pathsep
# to provide os-dependent path splitting.
#
# Note that in order to support legacy alembic.ini files, this default does NOT
# take place if path_separator is not present in alembic.ini.  If this
# option is omitted entirely, fallback logic is as follows:
#
# 1. Parsing of the version_locations option falls back to using the legacy
#    "version_path_separator" key, which if absent then falls back to the legacy
#    behavior of splitting on spaces and/or commas.
# 2. Parsing of the prepend_sys_path option falls back to the legacy
#    behavior of splitting on spaces, commas, or colons.
#
# Valid values for path_separator are:
#
# path_separator = :
# path_separator = ;
# path_separator = space
# path_separator = newline
#
# Use os.pathsep. Default configuration used for new projects.
path_separator = os

# set to 'true' to search source files recursively
# in each "version_locations" directory
# new in Alembic version 1.10
# recursive_version_locations = false

# the output encoding used when revision files
# are written from script.py.mako
# output_encoding = utf-8

# database URL.  This is consumed by the user-maintained env.py script only.
# other means of configuring database URLs may be customized within the env.py
# file.
sqlalchemy.url = sqlite:///./test_ci.db


[post_write_hooks]
# post_write_hooks defines scripts or Python functions that are run
# on newly generated revision scripts.  See the documentation for further
# detail and examples

# format using "black" - use the console_scripts runner, against the "black" entrypoint
# hooks = black
# black.type = console_scripts
# black.entrypoint = black
# black.options = -l 79 REVISION_SCRIPT_FILENAME

# lint with attempts to fix using "ruff" - use the exec runner, execute a binary
# hooks = ruff
# ruff.type = exec
# ruff.executable = %(here)s/.venv/bin/ruff
# ruff.options = check --fix REVISION_SCRIPT_FILENAME

# Logging configuration.  This is also consumed by the user-maintained
# env.py script only.
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARNING
handlers = console
qualname =

[logger_sqlalchemy]
level = WARNING
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S
```

--------------------------------------------------------------------------------

File: asr_system_backend/.gitignore
```text
# Python
__pycache__/
*.py[cod]
*.pyo
*.pyd

# Virtualenv
venv/
.venv/
ENV/

# SQLite database
*.db
*.sqlite3

# Alembic
alembic/versions/

# VSCode
.vscode/

# OS files
.DS_Store
Thumbs.db
```

--------------------------------------------------------------------------------

File: asr_system_backend/init_db.py
```python
#!/usr/bin/env python3
"""
æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
ç”¨äºåˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„å’Œåˆå§‹æ•°æ®
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from app.database import Base, engine, SessionLocal
from app.models import User, Hotword, TranscriptionTask, TranscriptionSegment
from app.config import get_settings
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_tables():
    """åˆ›å»ºæ‰€æœ‰æ•°æ®è¡¨"""
    try:
        logger.info("æ­£åœ¨åˆ›å»ºæ•°æ®åº“è¡¨...")
        Base.metadata.create_all(bind=engine)
        logger.info("âœ… æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ")
        return True
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¡¨åˆ›å»ºå¤±è´¥: {e}")
        return False

def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®ï¼ˆå¯é€‰ï¼‰"""
    try:
        db = SessionLocal()
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
        user_count = db.query(User).count()
        if user_count > 0:
            logger.info("æ•°æ®åº“ä¸­å·²æœ‰ç”¨æˆ·æ•°æ®ï¼Œè·³è¿‡ç¤ºä¾‹æ•°æ®åˆ›å»º")
            return True
        
        logger.info("åˆ›å»ºç¤ºä¾‹æ•°æ®...")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ ç¤ºä¾‹æ•°æ®åˆ›å»ºé€»è¾‘
        # ä½†ä¸ºäº†å®‰å…¨ï¼Œæˆ‘ä»¬æš‚æ—¶ä¸åˆ›å»ºä»»ä½•ç¤ºä¾‹æ•°æ®
        
        logger.info("âœ… ç¤ºä¾‹æ•°æ®åˆ›å»ºå®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ç¤ºä¾‹æ•°æ®åˆ›å»ºå¤±è´¥: {e}")
        return False
    finally:
        db.close()

def verify_database():
    """éªŒè¯æ•°æ®åº“è¿æ¥å’Œè¡¨ç»“æ„"""
    try:
        db = SessionLocal()
        
        # æµ‹è¯•æ¯ä¸ªè¡¨
        tables = [User, Hotword, TranscriptionTask, TranscriptionSegment]
        for table in tables:
            count = db.query(table).count()
            logger.info(f"è¡¨ {table.__tablename__}: {count} æ¡è®°å½•")
        
        logger.info("âœ… æ•°æ®åº“éªŒè¯æˆåŠŸ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“éªŒè¯å¤±è´¥: {e}")
        return False
    finally:
        db.close()

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 50)
    logger.info("ASRç³»ç»Ÿæ•°æ®åº“åˆå§‹åŒ–")
    logger.info("=" * 50)
    
    settings = get_settings()
    logger.info(f"æ•°æ®åº“URL: {settings.DATABASE_URL}")
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    upload_dir = Path(settings.UPLOAD_DIR)
    temp_dir = Path(settings.TEMP_DIR)
    
    upload_dir.mkdir(exist_ok=True)
    temp_dir.mkdir(exist_ok=True)
    
    logger.info(f"ä¸Šä¼ ç›®å½•: {upload_dir.absolute()}")
    logger.info(f"ä¸´æ—¶ç›®å½•: {temp_dir.absolute()}")
    
    # åˆå§‹åŒ–æ•°æ®åº“
    success = True
    success &= create_tables()
    success &= create_sample_data()
    success &= verify_database()
    
    if success:
        logger.info("ğŸ‰ æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼")
        logger.info("ç°åœ¨å¯ä»¥å¯åŠ¨åº”ç”¨ç¨‹åºäº†:")
        logger.info("uvicorn app.main:app --reload --host 0.0.0.0 --port 8000")
    else:
        logger.error("âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥")
        sys.exit(1)

if __name__ == "__main__":
    main()
```

--------------------------------------------------------------------------------

File: asr_system_backend/README.md
```markdown
## ç”¨æˆ·è®¤è¯APIè¯´æ˜

### æ³¨å†Œ
POST /auth/register
- å‚æ•°ï¼šusername, password
- è¿”å›ï¼šç”¨æˆ·ä¿¡æ¯

### ç™»å½•
POST /auth/login
- å‚æ•°ï¼šusername, password
- è¿”å›ï¼šaccess_tokenï¼ˆJWTä»¤ç‰Œï¼‰

### è·å–å½“å‰ç”¨æˆ·
GET /auth/me
- Header: Authorization: Bearer <access_token>
- è¿”å›ï¼šå½“å‰ç”¨æˆ·ä¿¡æ¯

## æœ¬åœ°è¿è¡Œ
1. å®‰è£…ä¾èµ–ï¼špip install -r requirements.txt
2. å¯åŠ¨æœåŠ¡ï¼šuvicorn app.main:app --reload
3. è®¿é—®APIæ–‡æ¡£ï¼šhttp://localhost:8000/docs 

### æ•°æ®åº“è¿ç§»æ“ä½œ

1. ç”Ÿæˆè¿ç§»è„šæœ¬ï¼ˆå¦‚æœ‰æ¨¡å‹å˜æ›´ï¼‰ï¼š
   ```
   alembic revision --autogenerate -m "æè¿°"
   ```
2. åº”ç”¨è¿ç§»åˆ°æ•°æ®åº“ï¼š
   ```
   alembic upgrade head
   ```
3. å›æ»šè¿ç§»ï¼ˆå¦‚éœ€ï¼‰ï¼š
   ```
   alembic downgrade -1
   ```

### CI/CD è¯´æ˜

- æœ¬é¡¹ç›®å·²é›†æˆ GitHub Actions è‡ªåŠ¨åŒ–æµç¨‹ï¼ŒåŒ…å«åç«¯ä¾èµ–å®‰è£…ã€ä»£ç é£æ ¼æ£€æŸ¥ã€æ•°æ®åº“è¿ç§»ã€è‡ªåŠ¨åŒ–æµ‹è¯•ï¼Œå‰ç«¯ä¾èµ–å®‰è£…ã€ä»£ç é£æ ¼æ£€æŸ¥ã€æ„å»ºç­‰ç¯èŠ‚ã€‚
- æ¯æ¬¡ push æˆ– PR åˆ° main åˆ†æ”¯æ—¶è‡ªåŠ¨è§¦å‘ã€‚
- è¯¦è§ `.github/workflows/ci.yml`.
```

--------------------------------------------------------------------------------

File: asr_system_backend/alembic/README
```text
Generic single-database configuration.
```

--------------------------------------------------------------------------------

File: asr_system_backend/alembic/env.py
```python
from logging.config import fileConfig

from sqlalchemy import engine_from_config
from sqlalchemy import pool

from alembic import context

from app.database import Base  # æ–°å¢

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# add your model's MetaData object here
# for 'autogenerate' support
# from myapp import mymodel
# target_metadata = mymodel.Base.metadata
target_metadata = Base.metadata  # ä¿®æ”¹æ­¤è¡Œ

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.


def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    """
    connectable = engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection, target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
```

--------------------------------------------------------------------------------

File: asr_system_backend/alembic/script.py.mako
```text
"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
${imports if imports else ""}

# revision identifiers, used by Alembic.
revision: str = ${repr(up_revision)}
down_revision: Union[str, Sequence[str], None] = ${repr(down_revision)}
branch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}
depends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}


def upgrade() -> None:
    """Upgrade schema."""
    ${upgrades if upgrades else "pass"}


def downgrade() -> None:
    """Downgrade schema."""
    ${downgrades if downgrades else "pass"}
```

--------------------------------------------------------------------------------

File: asr_system_backend/alembic/versions/928c19ceeb23_add_terminal_output_field.py
```python
"""add terminal output field

Revision ID: 928c19ceeb23
Revises: 
Create Date: 2025-07-17 00:01:07.710107

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '928c19ceeb23'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/services.py
```python
import os
import subprocess
from datetime import datetime
from sqlalchemy.orm import Session
from . import models
from .config import get_settings

settings = get_settings()

class TranscriptionService:
    @staticmethod
    def process_transcription_task(db: Session, task_id: str, file_path: str, hotword_list_id: str = None):
        """å¤„ç†è½¬å†™ä»»åŠ¡"""
        try:
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            task = db.query(models.TranscriptionTask).filter(models.TranscriptionTask.id == task_id).first()
            if not task:
                return
            
            task.status = "processing"
            db.commit()
            
            # è°ƒç”¨æœ¬åœ°å®¢æˆ·ç«¯è¿›è¡Œè½¬å†™
            client_path = os.path.join(os.path.dirname(__file__), "client", "funasr_wss_client.py")
            cmd = ["python", client_path, "--host", "localhost", "--port", "10095", "--mode", "offline", "--audio_in", file_path]
            
            # æ‰§è¡Œå‘½ä»¤å¹¶æ•è·è¾“å‡º
            process = subprocess.run(cmd, capture_output=True, text=True)
            terminal_output = process.stdout + process.stderr
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€å’Œè¾“å‡º
            task.status = "completed" if process.returncode == 0 else "failed"
            task.terminal_output = terminal_output
            task.completed_at = datetime.utcnow()
            db.commit()
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(file_path)
            except:
                pass
                
        except Exception as e:
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            task = db.query(models.TranscriptionTask).filter(models.TranscriptionTask.id == task_id).first()
            if task:
                task.status = "failed"
                task.terminal_output = str(e)
                task.completed_at = datetime.utcnow()
                db.commit()
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(file_path)
            except:
                pass
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/config.py
```python
import os
from typing import Optional
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class Settings:
    """åº”ç”¨é…ç½®è®¾ç½®"""
    
    # æ•°æ®åº“é…ç½®
    DATABASE_URL: str = os.getenv("DATABASE_URL", "sqlite:///./asr_system.db")
    
    # JWTé…ç½®
    JWT_SECRET_KEY: str = os.getenv("JWT_SECRET_KEY", "!!!secret_key!!!")
    JWT_ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = int(os.getenv("ACCESS_TOKEN_EXPIRE_MINUTES", "60"))
    
    # ASRå¼•æ“é…ç½®
    ASR_MODEL_SIZE: str = os.getenv("ASR_MODEL_SIZE", "base")  # tiny, base, small, medium, large
    ASR_LANGUAGE: str = os.getenv("ASR_LANGUAGE", "zh")  # é»˜è®¤è¯­è¨€
    ASR_ENABLE_GPU: bool = os.getenv("ASR_ENABLE_GPU", "true").lower() == "true"
    ASR_MAX_FILE_SIZE_MB: int = int(os.getenv("ASR_MAX_FILE_SIZE_MB", "100"))
    ASR_SUPPORTED_FORMATS: list = [".wav", ".mp3", ".m4a", ".flac", ".aac", ".ogg"]
    
    # æ–‡ä»¶å­˜å‚¨é…ç½®
    UPLOAD_DIR: str = os.getenv("UPLOAD_DIR", "uploads")
    TEMP_DIR: str = os.getenv("TEMP_DIR", "temp")
    MAX_UPLOAD_SIZE: int = ASR_MAX_FILE_SIZE_MB * 1024 * 1024  # è½¬æ¢ä¸ºå­—èŠ‚
    
    # RAGæœåŠ¡é…ç½®
    RAG_MODEL_NAME: str = os.getenv("RAG_MODEL_NAME", "sentence-transformers/all-MiniLM-L6-v2")
    RAG_VECTOR_DIMENSION: int = 384
    RAG_SIMILARITY_THRESHOLD: float = float(os.getenv("RAG_SIMILARITY_THRESHOLD", "0.5"))
    
    # æ—¥å¿—é…ç½®
    LOG_LEVEL: str = os.getenv("LOG_LEVEL", "INFO")
    LOG_FILE: Optional[str] = os.getenv("LOG_FILE", None)
    
    # CORSé…ç½®
    CORS_ORIGINS = [
        origin.strip()
        for origin in os.getenv(
            "CORS_ORIGINS",
            "http://localhost:2956,http://127.0.0.1:2956,http://0.0.0.0:2956"
        ).split(",")
    ]
    
    # æ€§èƒ½é…ç½®
    BACKGROUND_TASK_WORKERS: int = int(os.getenv("BACKGROUND_TASK_WORKERS", "2"))
    ASR_PROCESSING_TIMEOUT: int = int(os.getenv("ASR_PROCESSING_TIMEOUT", "300"))  # 5åˆ†é’Ÿ
    
    def __init__(self):
        # ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
        os.makedirs(self.UPLOAD_DIR, exist_ok=True)
        os.makedirs(self.TEMP_DIR, exist_ok=True)
    
    @property
    def asr_model_config(self) -> dict:
        """è·å–ASRæ¨¡å‹é…ç½®"""
        return {
            "model_size": self.ASR_MODEL_SIZE,
            "language": self.ASR_LANGUAGE,
            "enable_gpu": self.ASR_ENABLE_GPU,
            "max_file_size_mb": self.ASR_MAX_FILE_SIZE_MB,
            "supported_formats": self.ASR_SUPPORTED_FORMATS,
            "processing_timeout": self.ASR_PROCESSING_TIMEOUT
        }
    
    @property
    def rag_config(self) -> dict:
        """è·å–RAGæœåŠ¡é…ç½®"""
        return {
            "model_name": self.RAG_MODEL_NAME,
            "vector_dimension": self.RAG_VECTOR_DIMENSION,
            "similarity_threshold": self.RAG_SIMILARITY_THRESHOLD
        }

# å…¨å±€é…ç½®å®ä¾‹
settings = Settings()

def get_settings() -> Settings:
    """è·å–åº”ç”¨é…ç½®"""
    return settings
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/asr_engine.py
```python
import os
import logging
import asyncio
import websockets
import json
import wave
from typing import List, Dict, Optional
from datetime import datetime
from .config import get_settings

logger = logging.getLogger(__name__)
settings = get_settings()

class ASREngine:
    def __init__(self):
        """åˆå§‹åŒ–ASRå¼•æ“"""
        self.host = "127.0.0.1"  # FunASRæœåŠ¡åœ°å€
        self.port = 10095       # FunASRæœåŠ¡ç«¯å£
        self.initialized = True  # FunASRæœåŠ¡æ˜¯ç‹¬ç«‹çš„Dockerå®¹å™¨ï¼Œä¸éœ€è¦åˆå§‹åŒ–
    
    def initialize(self):
        """FunASRæœåŠ¡æ˜¯ç‹¬ç«‹çš„Dockerå®¹å™¨ï¼Œä¸éœ€è¦åˆå§‹åŒ–"""
        pass
    
    async def _transcribe_with_funasr(self, audio_file_path: str) -> Dict:
        """ä½¿ç”¨FunASR WebSocketå®¢æˆ·ç«¯è¿›è¡Œè½¬å†™"""
        try:
            # è¯»å–éŸ³é¢‘æ–‡ä»¶
            with wave.open(audio_file_path, 'rb') as wav_file:
                audio_bytes = wav_file.readframes(wav_file.getnframes())
                sample_rate = wav_file.getframerate()
            
            # è¿æ¥WebSocketæœåŠ¡å™¨
            uri = f"ws://{self.host}:{self.port}"
            logger.info(f"æ­£åœ¨è¿æ¥FunASRæœåŠ¡: {uri}")
            
            async with websockets.connect(uri, ping_interval=None) as websocket:
                # å‘é€åˆå§‹é…ç½®
                config = {
                    "mode": "offline",
                    "chunk_size": [5, 10, 5],
                    "chunk_interval": 10,
                    "wav_name": os.path.basename(audio_file_path),
                    "is_speaking": True,
                    "audio_fs": sample_rate,
                    "wav_format": "wav",
                    "hotwords": "",
                    "itn": True
                }
                await websocket.send(json.dumps(config))
                logger.info("å·²å‘é€é…ç½®ä¿¡æ¯")
                
                # å‘é€éŸ³é¢‘æ•°æ®
                await websocket.send(audio_bytes)
                logger.info("å·²å‘é€éŸ³é¢‘æ•°æ®")
                
                # å‘é€ç»“æŸæ ‡è®°
                await websocket.send(json.dumps({"is_speaking": False}))
                logger.info("å·²å‘é€ç»“æŸæ ‡è®°")
                
                # æ¥æ”¶è½¬å†™ç»“æœ
                while True:
                    try:
                        result = await websocket.recv()
                        logger.info(f"æ”¶åˆ°ç»“æœ: {result}")
                        
                        if isinstance(result, str):
                            try:
                                # å°è¯•è§£æJSONç»“æœ
                                json_result = json.loads(result)
                                if "text" in json_result:
                                    text = json_result["text"]
                                else:
                                    # å¦‚æœä¸æ˜¯JSONæˆ–æ²¡æœ‰textå­—æ®µï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬
                                    text = result.split(": ")[-1].strip()
                                
                                # æ„å»ºæ ‡å‡†æ ¼å¼çš„ç»“æœ
                                formatted_result = {
                                    "text": text,
                                    "language": "zh",
                                    "segments": [{
                                        "segment_id": 0,
                                        "start_time": 0,
                                        "end_time": 0,  # FunASRç¦»çº¿æ¨¡å¼ä¸æä¾›æ—¶é—´æˆ³
                                        "text": text,
                                        "confidence": 1.0  # FunASRç¦»çº¿æ¨¡å¼ä¸æä¾›ç½®ä¿¡åº¦
                                    }],
                                    "duration": 0,  # FunASRç¦»çº¿æ¨¡å¼ä¸æä¾›æ—¶é•¿
                                    "processing_time": datetime.now().isoformat()
                                }
                                return formatted_result
                            except json.JSONDecodeError:
                                continue
                    except websockets.exceptions.ConnectionClosed:
                        break
                
                raise ValueError("æœªæ”¶åˆ°æœ‰æ•ˆçš„è½¬å†™ç»“æœ")
                    
        except Exception as e:
            logger.error(f"FunASRè½¬å†™å¤±è´¥: {str(e)}")
            raise
    
    async def _transcribe_with_funasr(self, audio_stream):
        uri = f"ws://{self.host}:{self.port}"
        async with websockets.connect(uri) as ws:
            # å‘é€å®æ—¶éŸ³é¢‘æµ
            while True:
                chunk = await audio_stream.read(640)  # 40msçš„16kHz 16bitéŸ³é¢‘
                if not chunk:
                    break
                await ws.send(chunk)
                # æ¥æ”¶è½¬å†™ç»“æœ
                result = await ws.recv()
                yield json.loads(result)
    
    def transcribe_audio(self, audio_file_path: str, language: str = "zh") -> Dict:
        """è½¬å†™éŸ³é¢‘æ–‡ä»¶"""
        if not os.path.exists(audio_file_path):
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file_path}")
            
        # åˆ›å»ºäº‹ä»¶å¾ªç¯å¹¶è¿è¡ŒWebSocketå®¢æˆ·ç«¯
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            result = loop.run_until_complete(self._transcribe_with_funasr(audio_file_path))
            return result
        finally:
            loop.close()
    
    def get_supported_formats(self) -> List[str]:
        """è·å–æ”¯æŒçš„éŸ³é¢‘æ ¼å¼"""
        return [".wav"]  # ç›®å‰åªæ”¯æŒWAVæ ¼å¼
    
    def validate_audio_file(self, file_path: str) -> bool:
        """éªŒè¯éŸ³é¢‘æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            _, ext = os.path.splitext(file_path.lower())
            if ext not in self.get_supported_formats():
                return False
            
            # å°è¯•æ‰“å¼€WAVæ–‡ä»¶
            with wave.open(file_path, 'rb') as wav_file:
                return wav_file.getnframes() > 0
                
        except Exception:
            return False

# å…¨å±€ASRå¼•æ“å®ä¾‹
asr_engine = ASREngine()

def get_asr_engine() -> ASREngine:
    """è·å–ASRå¼•æ“å®ä¾‹"""
    return asr_engine
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/auth_service.py
```python
from datetime import datetime, timedelta
from typing import Optional
from jose import JWTError, jwt
from passlib.context import CryptContext
from fastapi import HTTPException, status
from .config import get_settings

settings = get_settings()

# å¯†ç å“ˆå¸Œä¸Šä¸‹æ–‡
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

def verify_password(plain_password: str, hashed_password: str) -> bool:
    """éªŒè¯å¯†ç """
    return pwd_context.verify(plain_password, hashed_password)

def get_password_hash(password: str) -> str:
    """ç”Ÿæˆå¯†ç å“ˆå¸Œ"""
    return pwd_context.hash(password)

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None) -> str:
    """åˆ›å»ºJWTè®¿é—®ä»¤ç‰Œ"""
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, settings.JWT_SECRET_KEY, algorithm=settings.JWT_ALGORITHM)
    return encoded_jwt

def decode_access_token(token: str) -> dict:
    """è§£ç JWTè®¿é—®ä»¤ç‰Œ"""
    try:
        payload = jwt.decode(token, settings.JWT_SECRET_KEY, algorithms=[settings.JWT_ALGORITHM])
        return payload
    except JWTError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="æ— æ•ˆçš„ä»¤ç‰Œ",
            headers={"WWW-Authenticate": "Bearer"},
        ) 

async def get_current_user_from_token(token: str):
    """ä»ä»¤ç‰Œä¸­è·å–å½“å‰ç”¨æˆ·"""
    from .models import User
    from .database import get_db
    from sqlalchemy.orm import Session
    from fastapi import Depends

    payload = decode_access_token(token)
    username: str = payload.get("sub")
    if username is None:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="æ— æ•ˆçš„è®¤è¯å‡­æ®",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    db = next(get_db())
    user = db.query(User).filter(User.username == username).first()
    if user is None:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="ç”¨æˆ·ä¸å­˜åœ¨",
            headers={"WWW-Authenticate": "Bearer"},
        )
    return user
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/__init__.py
```python

```

--------------------------------------------------------------------------------

File: asr_system_backend/app/models.py
```python
from sqlalchemy import Column, Integer, String, DateTime, create_engine
from datetime import datetime
from app.database import DATABASE_URL  # ç°åœ¨å¯ä»¥æ­£ç¡®å¯¼å…¥
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

Base = declarative_base()
DATABASE_URL = "sqlite:///asr_system.db"

engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

class User(Base):
    __tablename__ = "users"
    id = Column(Integer, primary_key=True, index=True)
    username = Column(String, unique=True)
    hashed_password = Column(String)
    created_at = Column(DateTime, default=datetime.now)  # ç¡®ä¿è¿™é‡Œä½¿ç”¨æ­£ç¡®
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/schemas.py
```python
from pydantic import BaseModel, Field, field_validator, ConfigDict
from typing import Optional, List
from datetime import datetime

# ç”¨æˆ·ç›¸å…³æ¨¡å‹
class UserBase(BaseModel):
    username: str = Field(..., min_length=3, max_length=50)

class UserCreate(UserBase):
    password: str = Field(..., min_length=6)

class UserLogin(BaseModel):
    username: str
    password: str

class UserOut(BaseModel):
    id: str
    username: str
    created_at: datetime

    class Config:
        from_attributes = True

# ä»¤ç‰Œç›¸å…³æ¨¡å‹
class Token(BaseModel):
    access_token: str
    token_type: str

class TokenData(BaseModel):
    username: Optional[str] = None

# çƒ­è¯ç›¸å…³æ¨¡å‹
class HotwordBase(BaseModel):
    word: str = Field(..., min_length=1, max_length=255)
    weight: int = Field(5, ge=1, le=10)

class HotwordCreate(HotwordBase):
    pass

class HotwordUpdate(HotwordBase):
    word: Optional[str] = None
    weight: Optional[int] = None

    @field_validator('word')
    def word_not_empty(cls, v):
        if v is not None and len(v.strip()) == 0:
            raise ValueError('è¯æ±‡ä¸èƒ½ä¸ºç©º')
        return v
    
    @field_validator('weight')
    def weight_in_range(cls, v):
        if v is not None and (v < 1 or v > 10):
            raise ValueError('æƒé‡å¿…é¡»åœ¨1-10ä¹‹é—´')
        return v

class HotwordOut(BaseModel):
    id: str
    word: str
    weight: int
    created_at: datetime

    class Config:
        from_attributes = True

# è½¬å†™ç›¸å…³æ¨¡å‹
class TranscriptionTaskBase(BaseModel):
    filename: str

class TranscriptionTaskCreate(TranscriptionTaskBase):
    pass

class TranscriptionTaskOut(BaseModel):
    id: str
    filename: str
    status: str
    created_at: datetime
    completed_at: Optional[datetime] = None
    error_message: Optional[str] = None

    class Config:
        from_attributes = True

class TranscriptionSegmentOut(BaseModel):
    id: str
    segment_id: int
    start_time: float
    end_time: float
    text: str
    confidence: float

    class Config:
        from_attributes = True

class TranscriptionTaskWithSegments(TranscriptionTaskOut):
    segments: List[TranscriptionSegmentOut] = []
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/rag_service.py
```python
import os
import json
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from typing import List, Dict, Optional, Tuple
from sqlalchemy.orm import Session
from . import models
import logging
import pickle
from datetime import datetime
from .config import get_settings

logger = logging.getLogger(__name__)
settings = get_settings()

class RAGService:
    def __init__(self):
        self.model = None
        self.index = None
        self.hotword_embeddings = {}
        self.hotword_metadata = {}
        self.dimension = 384  # sentence-transformers/all-MiniLM-L6-v2 çš„ç»´åº¦
        self.initialized = False
        self.index_dir = os.path.join(settings.TEMP_DIR, "rag_indices")
        
        # ç¡®ä¿ç´¢å¼•ç›®å½•å­˜åœ¨
        os.makedirs(self.index_dir, exist_ok=True)
        
    def initialize(self):
        """åˆå§‹åŒ–RAGæœåŠ¡ï¼ŒåŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
        try:
            # åŠ è½½è½»é‡çº§çš„å¤šè¯­è¨€æ¨¡å‹
            logger.info("æ­£åœ¨åŠ è½½å¥å­åµŒå…¥æ¨¡å‹...")
            self.model = SentenceTransformer(settings.RAG_MODEL_NAME)
            self.dimension = self.model.get_sentence_embedding_dimension()
            
            # åˆ›å»ºFAISSç´¢å¼• (ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦)
            self.index = faiss.IndexFlatIP(self.dimension)
            
            self.initialized = True
            logger.info(f"RAGæœåŠ¡åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {settings.RAG_MODEL_NAME}, ç»´åº¦: {self.dimension})")
        except Exception as e:
            logger.error(f"RAGæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.initialized = False
    
    def save_user_index(self, user_id: str) -> bool:
        """ä¿å­˜ç”¨æˆ·ç´¢å¼•åˆ°æ–‡ä»¶"""
        try:
            if user_id not in self.hotword_metadata:
                logger.warning(f"ç”¨æˆ· {user_id} çš„ç´¢å¼•ä¸å­˜åœ¨ï¼Œæ— æ³•ä¿å­˜")
                return False
                
            index_file = os.path.join(self.index_dir, f"user_{user_id}.index")
            metadata_file = os.path.join(self.index_dir, f"user_{user_id}.metadata")
            
            # ä¿å­˜FAISSç´¢å¼•
            user_embeddings = self.hotword_embeddings.get(user_id)
            if user_embeddings is not None:
                # åˆ›å»ºä¸´æ—¶ç´¢å¼•åªåŒ…å«è¯¥ç”¨æˆ·çš„å‘é‡
                temp_index = faiss.IndexFlatIP(self.dimension)
                temp_index.add(user_embeddings)
                faiss.write_index(temp_index, index_file)
                
            # ä¿å­˜å…ƒæ•°æ®
            metadata = self.hotword_metadata[user_id].copy()
            metadata['last_updated'] = datetime.now().isoformat()
            metadata['dimension'] = self.dimension
            
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
                
            logger.info(f"ç”¨æˆ· {user_id} çš„ç´¢å¼•å·²ä¿å­˜åˆ°æ–‡ä»¶")
            return True
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç”¨æˆ·ç´¢å¼•å¤±è´¥: {str(e)}")
            return False
    
    def load_user_index(self, user_id: str) -> bool:
        """ä»æ–‡ä»¶åŠ è½½ç”¨æˆ·ç´¢å¼•"""
        try:
            index_file = os.path.join(self.index_dir, f"user_{user_id}.index")
            metadata_file = os.path.join(self.index_dir, f"user_{user_id}.metadata")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(index_file) or not os.path.exists(metadata_file):
                logger.info(f"ç”¨æˆ· {user_id} çš„ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨")
                return False
                
            # åŠ è½½å…ƒæ•°æ®
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
                
            # éªŒè¯ç»´åº¦å…¼å®¹æ€§
            if metadata.get('dimension', 0) != self.dimension:
                logger.warning(f"ç”¨æˆ· {user_id} çš„ç´¢å¼•ç»´åº¦ä¸åŒ¹é…ï¼Œéœ€è¦é‡å»º")
                return False
                
            # åŠ è½½FAISSç´¢å¼•
            temp_index = faiss.read_index(index_file)
            embeddings = np.zeros((temp_index.ntotal, self.dimension), dtype=np.float32)
            temp_index.reconstruct_n(0, temp_index.ntotal, embeddings)
            
            # æ¢å¤åˆ°æœåŠ¡ä¸­
            self.hotword_embeddings[user_id] = embeddings
            self.hotword_metadata[user_id] = metadata
            
            # é‡å»ºå…¨å±€ç´¢å¼•
            self._rebuild_global_index()
            
            logger.info(f"ç”¨æˆ· {user_id} çš„ç´¢å¼•å·²ä»æ–‡ä»¶åŠ è½½ï¼ŒåŒ…å« {len(metadata.get('words', []))} ä¸ªçƒ­è¯")
            return True
            
        except Exception as e:
            logger.error(f"åŠ è½½ç”¨æˆ·ç´¢å¼•å¤±è´¥: {str(e)}")
            return False
    
    def _rebuild_global_index(self):
        """é‡å»ºå…¨å±€FAISSç´¢å¼•"""
        try:
            self.index.reset()
            
            for user_id, embeddings in self.hotword_embeddings.items():
                if embeddings is not None and len(embeddings) > 0:
                    self.index.add(embeddings)
                    
            logger.debug("å…¨å±€ç´¢å¼•é‡å»ºå®Œæˆ")
            
        except Exception as e:
            logger.error(f"é‡å»ºå…¨å±€ç´¢å¼•å¤±è´¥: {str(e)}")
    
    def build_user_hotword_index(self, db: Session, user_id: str) -> bool:
        """ä¸ºç‰¹å®šç”¨æˆ·æ„å»ºçƒ­è¯ç´¢å¼•"""
        if not self.initialized:
            self.initialize()
            
        if not self.initialized:
            return False
            
        try:
            # å°è¯•ä»æ–‡ä»¶åŠ è½½ç°æœ‰ç´¢å¼•
            if self.load_user_index(user_id):
                # æ£€æŸ¥æ•°æ®åº“ä¸­çš„çƒ­è¯æ˜¯å¦æœ‰æ›´æ–°
                db_hotwords = db.query(models.Hotword).filter(
                    models.Hotword.user_id == user_id
                ).all()
                
                db_words = {hw.word: hw.weight for hw in db_hotwords}
                cached_words = {word: weight for word, weight in zip(
                    self.hotword_metadata[user_id]['words'],
                    self.hotword_metadata[user_id]['weights']
                )}
                
                # å¦‚æœæ•°æ®ä¸€è‡´ï¼Œç›´æ¥ä½¿ç”¨ç¼“å­˜çš„ç´¢å¼•
                if db_words == cached_words:
                    logger.info(f"ç”¨æˆ· {user_id} çš„ç´¢å¼•å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€é‡å»º")
                    return True
            
            # è·å–ç”¨æˆ·çš„æ‰€æœ‰çƒ­è¯
            hotwords = db.query(models.Hotword).filter(
                models.Hotword.user_id == user_id
            ).all()
            
            if not hotwords:
                logger.info(f"ç”¨æˆ· {user_id} æ²¡æœ‰çƒ­è¯ï¼Œè·³è¿‡ç´¢å¼•æ„å»º")
                # æ¸…ç†å¯èƒ½å­˜åœ¨çš„æ—§ç´¢å¼•
                if user_id in self.hotword_embeddings:
                    del self.hotword_embeddings[user_id]
                if user_id in self.hotword_metadata:
                    del self.hotword_metadata[user_id]
                return True
            
            # æå–çƒ­è¯æ–‡æœ¬å’Œæƒé‡
            hotword_texts = [hw.word for hw in hotwords]
            hotword_weights = [hw.weight for hw in hotwords]
            
            # ç”ŸæˆåµŒå…¥å‘é‡
            logger.info(f"æ­£åœ¨ä¸ºç”¨æˆ· {user_id} ç”Ÿæˆ {len(hotword_texts)} ä¸ªçƒ­è¯çš„å‘é‡åµŒå…¥...")
            embeddings = self.model.encode(hotword_texts, normalize_embeddings=True)
            
            # æ›´æ–°å†…å­˜ä¸­çš„æ•°æ®
            self.hotword_embeddings[user_id] = embeddings
            self.hotword_metadata[user_id] = {
                'words': hotword_texts,
                'weights': hotword_weights,
                'ids': [hw.id for hw in hotwords]
            }
            
            # é‡å»ºå…¨å±€ç´¢å¼•
            self._rebuild_global_index()
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            self.save_user_index(user_id)
            
            logger.info(f"ä¸ºç”¨æˆ· {user_id} æ„å»ºäº†åŒ…å« {len(hotwords)} ä¸ªçƒ­è¯çš„ç´¢å¼•")
            return True
            
        except Exception as e:
            logger.error(f"æ„å»ºç”¨æˆ·çƒ­è¯ç´¢å¼•å¤±è´¥: {str(e)}")
            return False
    
    def predict_hotwords(self, text: str, user_id: str, top_k: int = 5, threshold: float = 0.5) -> List[Dict]:
        """æ ¹æ®è¾“å…¥æ–‡æœ¬é¢„æµ‹ç›¸å…³çƒ­è¯"""
        if not self.initialized:
            logger.warning("RAGæœåŠ¡æœªåˆå§‹åŒ–")
            return []
            
        if user_id not in self.hotword_metadata:
            logger.warning(f"ç”¨æˆ· {user_id} çš„çƒ­è¯ç´¢å¼•ä¸å­˜åœ¨")
            return []
            
        try:
            # å¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œç¼–ç 
            query_embedding = self.model.encode([text], normalize_embeddings=True)
            
            # åœ¨FAISSç´¢å¼•ä¸­æœç´¢
            similarities, indices = self.index.search(query_embedding, min(top_k, len(self.hotword_metadata[user_id]['words'])))
            
            # æ„å»ºç»“æœ
            predictions = []
            metadata = self.hotword_metadata[user_id]
            
            for i, (similarity, idx) in enumerate(zip(similarities[0], indices[0])):
                if similarity >= threshold:  # åªè¿”å›ç›¸ä¼¼åº¦è¶…è¿‡é˜ˆå€¼çš„ç»“æœ
                    predictions.append({
                        'word': metadata['words'][idx],
                        'weight': metadata['weights'][idx],
                        'similarity': float(similarity),
                        'rank': i + 1
                    })
            
            # æŒ‰æƒé‡å’Œç›¸ä¼¼åº¦æ’åº
            predictions.sort(key=lambda x: (x['weight'] * x['similarity']), reverse=True)
            
            return predictions[:top_k]
            
        except Exception as e:
            logger.error(f"çƒ­è¯é¢„æµ‹å¤±è´¥: {str(e)}")
            return []
    
    def enhance_transcription_with_hotwords(self, transcription_text: str, user_id: str) -> Dict:
        """ä½¿ç”¨çƒ­è¯å¢å¼ºè½¬å†™ç»“æœ"""
        if not transcription_text:
            return {
                'enhanced_text': transcription_text,
                'hotwords_detected': [],
                'confidence_boost': 1.0
            }
        
        try:
            # é¢„æµ‹ç›¸å…³çƒ­è¯
            predicted_hotwords = self.predict_hotwords(transcription_text, user_id, top_k=10, threshold=0.3)
            
            enhanced_text = transcription_text
            detected_hotwords = []
            confidence_boost = 1.0
            
            # æ£€æŸ¥æ˜¯å¦æœ‰çƒ­è¯åœ¨è½¬å†™æ–‡æœ¬ä¸­
            for hotword_info in predicted_hotwords:
                word = hotword_info['word']
                if word.lower() in transcription_text.lower():
                    detected_hotwords.append(hotword_info)
                    # æ ¹æ®çƒ­è¯æƒé‡æå‡ç½®ä¿¡åº¦
                    confidence_boost += (hotword_info['weight'] / 10) * 0.1
            
            # åº”ç”¨ç®€å•çš„çƒ­è¯æ›¿æ¢å¢å¼ºï¼ˆåœ¨å®é™…åº”ç”¨ä¸­å¯èƒ½æ›´å¤æ‚ï¼‰
            for hotword_info in detected_hotwords:
                word = hotword_info['word']
                # ç¡®ä¿æ­£ç¡®çš„å¤§å°å†™
                enhanced_text = enhanced_text.replace(word.lower(), word)
                enhanced_text = enhanced_text.replace(word.upper(), word)
            
            return {
                'enhanced_text': enhanced_text,
                'hotwords_detected': detected_hotwords,
                'confidence_boost': min(confidence_boost, 2.0),  # æœ€å¤§æå‡2å€
                'predicted_hotwords': predicted_hotwords[:5]  # è¿”å›å‰5ä¸ªé¢„æµ‹çƒ­è¯
            }
            
        except Exception as e:
            logger.error(f"è½¬å†™å¢å¼ºå¤±è´¥: {str(e)}")
            return {
                'enhanced_text': transcription_text,
                'hotwords_detected': [],
                'confidence_boost': 1.0
            }
    
    def get_hotword_suggestions(self, partial_text: str, user_id: str, max_suggestions: int = 5) -> List[str]:
        """æ ¹æ®éƒ¨åˆ†è¾“å…¥æ–‡æœ¬è·å–çƒ­è¯å»ºè®®"""
        if not partial_text or len(partial_text) < 2:
            return []
            
        if user_id not in self.hotword_metadata:
            return []
            
        try:
            # é¢„æµ‹ç›¸å…³çƒ­è¯
            predictions = self.predict_hotwords(partial_text, user_id, top_k=max_suggestions * 2, threshold=0.2)
            
            # è¿‡æ»¤å‡ºä»¥éƒ¨åˆ†æ–‡æœ¬å¼€å¤´çš„çƒ­è¯æˆ–ç›¸ä¼¼çš„çƒ­è¯
            suggestions = []
            metadata = self.hotword_metadata[user_id]
            
            # é¦–å…ˆæ·»åŠ å‰ç¼€åŒ¹é…çš„çƒ­è¯
            for word in metadata['words']:
                if word.lower().startswith(partial_text.lower()) and len(suggestions) < max_suggestions:
                    suggestions.append(word)
            
            # ç„¶åæ·»åŠ è¯­ä¹‰ç›¸ä¼¼çš„çƒ­è¯
            for pred in predictions:
                if pred['word'] not in suggestions and len(suggestions) < max_suggestions:
                    suggestions.append(pred['word'])
            
            return suggestions[:max_suggestions]
            
        except Exception as e:
            logger.error(f"è·å–çƒ­è¯å»ºè®®å¤±è´¥: {str(e)}")
            return []
    
    def clear_user_index(self, user_id: str) -> bool:
        """æ¸…é™¤ç”¨æˆ·ç´¢å¼•"""
        try:
            # ä»å†…å­˜ä¸­åˆ é™¤
            if user_id in self.hotword_embeddings:
                del self.hotword_embeddings[user_id]
            if user_id in self.hotword_metadata:
                del self.hotword_metadata[user_id]
                
            # åˆ é™¤æ–‡ä»¶
            index_file = os.path.join(self.index_dir, f"user_{user_id}.index")
            metadata_file = os.path.join(self.index_dir, f"user_{user_id}.metadata")
            
            for file_path in [index_file, metadata_file]:
                if os.path.exists(file_path):
                    os.remove(file_path)
                    
            # é‡å»ºå…¨å±€ç´¢å¼•
            self._rebuild_global_index()
            
            logger.info(f"ç”¨æˆ· {user_id} çš„ç´¢å¼•å·²æ¸…é™¤")
            return True
            
        except Exception as e:
            logger.error(f"æ¸…é™¤ç”¨æˆ·ç´¢å¼•å¤±è´¥: {str(e)}")
            return False
    
    def get_service_stats(self) -> Dict:
        """è·å–RAGæœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        try:
            total_users = len(self.hotword_metadata)
            total_hotwords = sum(len(meta.get('words', [])) for meta in self.hotword_metadata.values())
            
            return {
                'initialized': self.initialized,
                'model_name': settings.RAG_MODEL_NAME if self.initialized else None,
                'dimension': self.dimension if self.initialized else 0,
                'total_users_indexed': total_users,
                'total_hotwords': total_hotwords,
                'index_dir': self.index_dir,
                'memory_usage_mb': self._estimate_memory_usage()
            }
            
        except Exception as e:
            logger.error(f"è·å–æœåŠ¡ç»Ÿè®¡å¤±è´¥: {str(e)}")
            return {'error': str(e)}
    
    def _estimate_memory_usage(self) -> float:
        """ä¼°ç®—å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
        try:
            total_size = 0
            
            # ä¼°ç®—åµŒå…¥å‘é‡çš„å¤§å°
            for embeddings in self.hotword_embeddings.values():
                if embeddings is not None:
                    total_size += embeddings.nbytes
                    
            # ä¼°ç®—å…ƒæ•°æ®çš„å¤§å°
            for metadata in self.hotword_metadata.values():
                total_size += len(str(metadata).encode('utf-8'))
                
            return total_size / (1024 * 1024)  # è½¬æ¢ä¸ºMB
            
        except Exception as e:
            logger.error(f"ä¼°ç®—å†…å­˜ä½¿ç”¨é‡å¤±è´¥: {str(e)}")
            return 0.0

# å…¨å±€RAGæœåŠ¡å®ä¾‹
rag_service = RAGService()

def get_rag_service() -> RAGService:
    """è·å–RAGæœåŠ¡å®ä¾‹"""
    return rag_service
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/main.py
```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
# 1. å¯¼å…¥æˆ‘ä»¬æ‰€æœ‰éœ€è¦çš„è·¯ç”±æ¨¡å—
from .routers import transcription, auth, realtime_websocket, polling_ws_realtime
from .models import Base, engine
from .config import get_settings

# åˆå§‹åŒ–æ•°æ®åº“
Base.metadata.create_all(bind=engine)

app = FastAPI(title="è¯­éŸ³è¯†åˆ«ç³»ç»ŸAPI")
settings = get_settings()

# CORSä¸­é—´ä»¶é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æºï¼Œç”¨äºå¼€å‘ç¯å¢ƒ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# æ–‡ä»¶è·¯å¾„: asr_system_backend/app/main.py
# ...
# åŒ…å«è·¯ç”±
app.include_router(auth.router, tags=["è®¤è¯"])
app.include_router(transcription.router, tags=["è½¬å†™"]) 
# ç¡®ä¿è¿™ä¸€è¡Œæ˜¯å­˜åœ¨çš„
app.include_router(realtime_websocket.router, tags=["å®æ—¶è½¬å†™"])
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/database.py
```python
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, declarative_base

# å°†å˜é‡åæ”¹ä¸ºDATABASE_URL
DATABASE_URL = "sqlite:///./asr_system.db"

engine = create_engine(
    DATABASE_URL,  # ä½¿ç”¨æ–°å˜é‡å
    connect_args={"check_same_thread": False}
)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

Base = declarative_base()

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/transcription.py
```python
from fastapi import APIRouter, UploadFile, File, HTTPException
import os
import subprocess
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

router = APIRouter(
    prefix="/api/asr",
    tags=["transcription"]
)

@router.post("/transcribe/file")
async def transcribe_file(file: UploadFile = File(...)):
    """
    ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶å¹¶è¿”å›è½¬å†™ç»“æœ
    """
    try:
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        current_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        root_dir = os.path.dirname(current_dir)  # å›åˆ°asr-systemç›®å½•
        
        logger.info(f"Processing file: {file.filename}")
        
        # ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        file_path = os.path.join(root_dir, "client", f"temp_{file.filename}")
        temp_script = os.path.join(root_dir, "client", "temp_test.sh")
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        logger.info(f"Saved file to: {file_path}")
        
        # ä¿®æ”¹test_demo.shä¸­çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        demo_script = os.path.join(root_dir, "client", "test_demo.sh")
        with open(demo_script, "r") as f:
            script_content = f.read()
        
        # æ›¿æ¢éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        script_content = script_content.replace("BAC009S0764W0179.wav", f"temp_{file.filename}")
        
        # ä¿å­˜ä¸´æ—¶è„šæœ¬
        with open(temp_script, "w") as f:
            f.write(script_content)
        
        # è®¾ç½®è„šæœ¬å¯æ‰§è¡Œæƒé™
        os.chmod(temp_script, 0o755)
        logger.info("Created and configured temporary script")
        
        # æ‰§è¡Œè„šæœ¬
        os.chdir(root_dir)  # åˆ‡æ¢åˆ°é¡¹ç›®æ ¹ç›®å½•
        logger.info(f"Executing script from directory: {root_dir}")
        result = subprocess.run([f"./client/temp_test.sh"], shell=True, capture_output=True, text=True)
        output = result.stdout + result.stderr
        logger.info("Script execution completed")
        
        # è§£æç»“æœ
        transcription = ""
        for line in output.split("\n"):
            if "pid0_0: demo:" in line:
                transcription = line.split("pid0_0: demo:")[-1].strip()
                logger.info(f"Found transcription: {transcription}")
                break
        
        if not transcription:
            logger.warning("No transcription found in output")
            logger.debug(f"Full output: {output}")
            
        return {
            "result": transcription
        }
        
    except Exception as e:
        logger.error(f"Error processing file: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(file_path):
            os.remove(file_path)
        if os.path.exists(temp_script):
            os.remove(temp_script)
        logger.info("Cleaned up temporary files")
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/chat.py
```python
# æ–‡ä»¶: asr_system_backend/app/routers/chat.py

import logging
from fastapi import APIRouter, HTTPException, status, Depends
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import dashscope
from ..config import get_settings

# é…ç½®æ—¥å¿—å’Œè·¯ç”±
logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/chat", tags=["Chat"])
settings = get_settings()

# å®šä¹‰è¯·æ±‚ä½“æ¨¡å‹
class ChatRequest(BaseModel):
    prompt: str

# å®šä¹‰ä¸€ä¸ªå¼‚æ­¥ç”Ÿæˆå™¨ï¼Œç”¨äºæµå¼ä¼ è¾“æ•°æ®
async def stream_generator(prompt: str):
    """
    è°ƒç”¨DeepSeek APIå¹¶ä»¥æµå¼æ–¹å¼è¿”å›ç»“æœ
    """
    # ä»é…ç½®ä¸­è·å–API Key
    api_key = settings.DASHSCOPE_API_KEY
    if not api_key:
        logger.error("DashScope API Key æœªé…ç½®")
        # ç›´æ¥åœ¨æµä¸­è¿”å›é”™è¯¯ä¿¡æ¯
        yield "Error: Server's API Key is not configured."
        return

    dashscope.api_key = api_key

    try:
        # è°ƒç”¨DeepSeekæ¨¡å‹çš„æµå¼ç”Ÿæˆæ¥å£
        responses = dashscope.Generation.call(
            model='deepseek-v2-chat',
            prompt=prompt,
            stream=True,
            incremental_output=True # å¢é‡è¾“å‡ºï¼Œå®ç°æ‰“å­—æœºæ•ˆæœ
        )

        for resp in responses:
            if resp.status_code == 200:
                content = resp.output.choices[0]['message']['content']
                yield content # å°†æ¯ä¸ªå¢é‡å†…å®¹å—å‘é€ç»™å‰ç«¯
            else:
                error_msg = f"Error: code: {resp.status_code}, message: {resp.message}"
                logger.error(error_msg)
                yield error_msg
                break
    except Exception as e:
        logger.error(f"è°ƒç”¨DashScope APIæ—¶å‡ºé”™: {e}")
        yield f"Error: An exception occurred while calling the AI service."

# å®šä¹‰æµå¼APIç«¯ç‚¹
@router.post("/stream")
async def stream_chat(request: ChatRequest):
    """
    æ¥æ”¶å‰ç«¯çš„Promptï¼Œå¹¶ä»¥æµå¼æ–¹å¼è¿”å›DeepSeekæ¨¡å‹çš„å“åº”
    """
    if not request.prompt:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Promptä¸èƒ½ä¸ºç©º"
        )
    
    return StreamingResponse(stream_generator(request.prompt), media_type="text/event-stream")
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/hotword.py
```python
from fastapi import APIRouter, Depends, HTTPException, status, UploadFile, File, Form
from sqlalchemy.orm import Session
from typing import List
from .. import schemas, models
from ..database import get_db
from .auth import get_current_user
from ..rag_service import get_rag_service
import csv
from io import StringIO

router = APIRouter(
    prefix="/hotwords",
    tags=["hotwords"]
)

@router.post("", response_model=schemas.HotwordOut)
def create_hotword(
    hotword_in: schemas.HotwordCreate,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    åˆ›å»ºæ–°çš„çƒ­è¯
    """
    # æŸ¥è¯¢ç”¨æˆ·å½“å‰çš„çƒ­è¯æ•°é‡ï¼Œæ£€æŸ¥æ˜¯å¦è¾¾åˆ°ä¸Šé™ï¼ˆå‡è®¾ä¸Šé™ä¸º100ï¼‰
    count = db.query(models.Hotword).filter(models.Hotword.user_id == current_user.id).count()
    if count >= 100:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="çƒ­è¯æ•°é‡å·²è¾¾ä¸Šé™ï¼ˆ100ä¸ªï¼‰"
        )
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„çƒ­è¯
    existing = db.query(models.Hotword).filter(
        models.Hotword.user_id == current_user.id,
        models.Hotword.word == hotword_in.word
    ).first()
    
    if existing:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail="çƒ­è¯å·²å­˜åœ¨"
        )
    
    # åˆ›å»ºæ–°çƒ­è¯
    db_hotword = models.Hotword(
        user_id=current_user.id,
        word=hotword_in.word,
        weight=hotword_in.weight
    )
    db.add(db_hotword)
    db.commit()
    db.refresh(db_hotword)
    
    # é‡å»ºç”¨æˆ·çš„RAGç´¢å¼•
    try:
        rag_service = get_rag_service()
        if rag_service.initialized:
            rag_service.build_user_hotword_index(db, current_user.id)
    except Exception as e:
        print(f"é‡å»ºRAGç´¢å¼•å¤±è´¥: {str(e)}")
    
    return db_hotword

@router.get("", response_model=List[schemas.HotwordOut])
def get_user_hotwords(
    skip: int = 0,
    limit: int = 100,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    è·å–ç”¨æˆ·çš„çƒ­è¯åˆ—è¡¨
    """
    hotwords = db.query(models.Hotword).filter(
        models.Hotword.user_id == current_user.id
    ).offset(skip).limit(limit).all()
    
    return hotwords

@router.put("/{hotword_id}", response_model=schemas.HotwordOut)
def update_hotword(
    hotword_id: str,
    hotword_in: schemas.HotwordUpdate,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    æ›´æ–°çƒ­è¯
    """
    # æŸ¥æ‰¾çƒ­è¯
    hotword = db.query(models.Hotword).filter(models.Hotword.id == hotword_id).first()
    
    # å¤„ç†é”™è¯¯æƒ…å†µ
    if not hotword:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="çƒ­è¯ä¸å­˜åœ¨"
        )
    
    # ç¡®è®¤æƒé™
    if hotword.user_id != current_user.id:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="æ— æƒä¿®æ”¹æ­¤çƒ­è¯"
        )
    
    # å¦‚æœè¦æ›´æ”¹è¯æœ¬èº«ï¼Œæ£€æŸ¥æ˜¯å¦ä¼šå¯¼è‡´é‡å¤
    if hotword_in.word is not None and hotword_in.word != hotword.word:
        existing = db.query(models.Hotword).filter(
            models.Hotword.user_id == current_user.id,
            models.Hotword.word == hotword_in.word
        ).first()
        if existing:
            raise HTTPException(
                status_code=status.HTTP_409_CONFLICT,
                detail="çƒ­è¯å·²å­˜åœ¨"
            )
        hotword.word = hotword_in.word
    
    # æ›´æ–°æƒé‡
    if hotword_in.weight is not None:
        hotword.weight = hotword_in.weight
    
    db.commit()
    db.refresh(hotword)
    
    # é‡å»ºç”¨æˆ·çš„RAGç´¢å¼•
    try:
        rag_service = get_rag_service()
        if rag_service.initialized:
            rag_service.build_user_hotword_index(db, current_user.id)
    except Exception as e:
        print(f"é‡å»ºRAGç´¢å¼•å¤±è´¥: {str(e)}")
    
    return hotword

@router.delete("/{hotword_id}")
def delete_hotword(
    hotword_id: str,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    åˆ é™¤çƒ­è¯
    """
    # æŸ¥æ‰¾çƒ­è¯
    hotword = db.query(models.Hotword).filter(models.Hotword.id == hotword_id).first()
    
    # å¤„ç†é”™è¯¯æƒ…å†µ
    if not hotword:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="çƒ­è¯ä¸å­˜åœ¨"
        )
    
    # ç¡®è®¤æƒé™
    if hotword.user_id != current_user.id:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="æ— æƒåˆ é™¤æ­¤çƒ­è¯"
        )
    
    # åˆ é™¤çƒ­è¯
    db.delete(hotword)
    db.commit()
    
    # é‡å»ºç”¨æˆ·çš„RAGç´¢å¼•
    try:
        rag_service = get_rag_service()
        if rag_service.initialized:
            rag_service.build_user_hotword_index(db, current_user.id)
    except Exception as e:
        print(f"é‡å»ºRAGç´¢å¼•å¤±è´¥: {str(e)}")
    
    return {"message": "çƒ­è¯å·²æˆåŠŸåˆ é™¤"}

@router.post("/import", response_model=dict)
async def bulk_import_hotwords(
    file: UploadFile = File(...),
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    æ‰¹é‡å¯¼å…¥çƒ­è¯
    """
    # æ–‡ä»¶ç±»å‹éªŒè¯
    if not file.filename.endswith(('.csv', '.txt')):
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail="åªæ”¯æŒCSVæˆ–TXTæ ¼å¼æ–‡ä»¶"
        )
    
    # è¯»å–å¹¶è§£ææ–‡ä»¶
    content = await file.read()
    
    # å°è¯•è§£æCSV
    added_count = 0
    skipped_count = 0
    
    try:
        text = content.decode('utf-8')
        csv_reader = csv.reader(StringIO(text))
        
        # æŸ¥è¯¢ç”¨æˆ·å½“å‰çƒ­è¯æ•°é‡
        current_count = db.query(models.Hotword).filter(models.Hotword.user_id == current_user.id).count()
        max_allowed = 100
        remaining = max_allowed - current_count
        
        if remaining <= 0:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="çƒ­è¯æ•°é‡å·²è¾¾ä¸Šé™ï¼ˆ100ä¸ªï¼‰"
            )
        
        # å¼€å§‹å¯¼å…¥
        for row in csv_reader:
            # æ£€æŸ¥æ˜¯å¦å·²è¾¾åˆ°ä¸Šé™
            if added_count >= remaining:
                break
                
            # è·³è¿‡ç©ºè¡Œæˆ–æ ¼å¼é”™è¯¯è¡Œ
            if not row:
                continue
            
            word = row[0].strip()
            if not word:
                continue
                
            # å°è¯•è·å–æƒé‡
            weight = 5  # é»˜è®¤æƒé‡
            if len(row) > 1:
                try:
                    w = int(row[1].strip())
                    if 1 <= w <= 10:
                        weight = w
                except ValueError:
                    pass
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing = db.query(models.Hotword).filter(
                models.Hotword.user_id == current_user.id,
                models.Hotword.word == word
            ).first()
            
            if existing:
                skipped_count += 1
                continue
            
            # åˆ›å»ºæ–°çƒ­è¯
            db_hotword = models.Hotword(
                user_id=current_user.id,
                word=word,
                weight=weight
            )
            db.add(db_hotword)
            added_count += 1
        
        # æäº¤äº‹åŠ¡
        db.commit()
        
        # é‡å»ºç”¨æˆ·çš„RAGç´¢å¼•
        try:
            rag_service = get_rag_service()
            if rag_service.initialized:
                rag_service.build_user_hotword_index(db, current_user.id)
        except Exception as e:
            print(f"é‡å»ºRAGç´¢å¼•å¤±è´¥: {str(e)}")
        
        return {
            "added_count": added_count,
            "skipped_count": skipped_count
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail=f"æ–‡ä»¶è§£æé”™è¯¯: {str(e)}"
        )
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/polling_ws_realtime.py
```python
# æ–‡ä»¶è·¯å¾„: asr_system_backend/app/routers/polling_ws_realtime.py
# åŠŸèƒ½: ä¸ºæ–°çš„â€œè½®è¯¢å¼WebSocketâ€å®æ—¶è½¬å†™åŠŸèƒ½æä¾›åç«¯æœåŠ¡ã€‚

import asyncio
import logging
import os
import subprocess
import uuid
from fastapi import APIRouter, WebSocket, WebSocketDisconnect, Depends, Query
from sqlalchemy.orm import Session

from ..database import get_db
from ..models import User
from ..auth_service import decode_access_token

# --- æ—¥å¿—å’Œè·¯ç”±é…ç½® ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
# åˆ›å»ºä¸€ä¸ªå…¨æ–°çš„è·¯ç”±å™¨å®ä¾‹
router = APIRouter()

# --- æ–°çš„ã€ç‹¬ç«‹çš„è¿æ¥ç®¡ç†å™¨ ---
class PollingConnectionManager:
    """ä¸ºæ–°åŠŸèƒ½åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„è¿æ¥ç®¡ç†å™¨ï¼Œé¿å…ä¸ç°æœ‰åŠŸèƒ½æ··æ·†ã€‚"""
    def __init__(self):
        self.active_connections: dict[str, WebSocket] = {}

    async def connect(self, websocket: WebSocket, client_id: str):
        await websocket.accept()
        self.active_connections[client_id] = websocket
        logger.info(f"[Polling WS] å®¢æˆ·ç«¯ {client_id} å·²è¿æ¥ã€‚")

    def disconnect(self, client_id: str):
        if client_id in self.active_connections:
            del self.active_connections[client_id]
            logger.info(f"[Polling WS] å®¢æˆ·ç«¯ {client_id} å·²æ–­å¼€ã€‚")

    async def send_json(self, client_id: str, data: dict):
        if client_id in self.active_connections:
            await self.active_connections[client_id].send_json(data)

polling_manager = PollingConnectionManager()


# --- WebSocketè®¤è¯ (å¯å¤ç”¨ï¼Œä½†ä¸ºæ¸…æ™°èµ·è§ï¼Œæˆ‘ä»¬æ”¾åœ¨è¿™é‡Œ) ---
async def get_current_user_from_polling_ws(token: str = Query(...), db: Session = Depends(get_db)):
    try:
        payload = decode_access_token(token)
        username: str = payload.get("sub")
        if not username: return None
        user = db.query(User).filter(User.username == username).first()
        return user
    except Exception:
        return None


# --- éŸ³é¢‘å¤„ç†æ ¸å¿ƒå‡½æ•° (ä¸ä¸Šæ¬¡æä¾›çš„é€»è¾‘ç›¸åŒ) ---
async def process_polling_chunk(client_id: str, audio_data: bytes):
    temp_id = str(uuid.uuid4())
    webm_path = f"/tmp/{temp_id}.webm"
    wav_path = f"/tmp/{temp_id}.wav"
    
    try:
        with open(webm_path, "wb") as f:
            f.write(audio_data)

        command = f"ffmpeg -i {webm_path} -ar 16000 -ac 1 -y {wav_path}"
        process = await asyncio.create_subprocess_shell(command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
        _, stderr = await process.communicate()

        if process.returncode != 0:
            logger.error(f"[Polling WS] FFmpegè½¬æ¢å¤±è´¥: {stderr.decode()}")
            await polling_manager.send_json(client_id, {"type": "error", "message": "éŸ³é¢‘æ ¼å¼å¤„ç†å¤±è´¥"})
            return

        root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..'))
        client_script_path = os.path.join(root_dir, "client", "funasr_wss_client.py")
        
        transcribe_command = ["python", client_script_path, "--host", "127.0.0.1", "--port", "10095", "--mode", "offline", "--audio_in", wav_path]
        
        transcribe_process = await asyncio.create_subprocess_exec(*transcribe_command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
        transcribe_stdout, transcribe_stderr = await transcribe_process.communicate()
        output = transcribe_stdout.decode() + transcribe_stderr.decode()
        
        transcription = ""
        for line in output.split("\n"):
            if "pid0_0: demo:" in line:
                transcription = line.split("pid0_0: demo:")[-1].strip()
                break
        
        logger.info(f"[Polling WS] å®¢æˆ·ç«¯ {client_id} çš„è½¬å†™ç»“æœ: '{transcription}'")

        if transcription:
            await polling_manager.send_json(client_id, {
                "type": "polling_transcription_result", # ä½¿ç”¨æ–°çš„ç±»å‹ä»¥åŒºåˆ†
                "text": transcription
            })

    except Exception as e:
        logger.error(f"[Polling WS] å¤„ç†éŸ³é¢‘å—æ—¶å‡ºé”™: {e}")
        await polling_manager.send_json(client_id, {"type": "error", "message": "æœåŠ¡å™¨å¤„ç†éŸ³é¢‘æ—¶å‡ºé”™"})
    finally:
        if os.path.exists(webm_path): os.remove(webm_path)
        if os.path.exists(wav_path): os.remove(wav_path)


# --- æ–°çš„WebSocketç«¯ç‚¹å®šä¹‰ ---
@router.websocket("/ws/asr/transcribe/polling_realtime") # <--- æ³¨æ„ï¼Œè¿™æ˜¯å…¨æ–°çš„URL
async def websocket_polling_endpoint(
    websocket: WebSocket,
    token: str = Query(...),
    db: Session = Depends(get_db)
):
    user = await get_current_user_from_polling_ws(token, db)
    if not user:
        await websocket.close(code=1008, reason="è®¤è¯å¤±è´¥")
        return

    client_id = str(uuid.uuid4())
    await polling_manager.connect(websocket, client_id)
    
    try:
        await polling_manager.send_json(client_id, {"type": "polling_connection_established"})
        
        while True:
            audio_data = await websocket.receive_bytes()
            asyncio.create_task(process_polling_chunk(client_id, audio_data))

    except WebSocketDisconnect:
        polling_manager.disconnect(client_id)
    except Exception as e:
        logger.error(f"[Polling WS] è¿æ¥ ({client_id}) å‡ºç°æ„å¤–é”™è¯¯: {e}")
        polling_manager.disconnect(client_id)
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/auth.py
```python
from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm
from sqlalchemy.orm import Session
from ..models import SessionLocal, User
from ..auth_service import verify_password, get_password_hash, create_access_token, decode_access_token
from ..config import get_settings

router = APIRouter(prefix="/auth", tags=["è®¤è¯"])
settings = get_settings()

oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/auth/token")

# ä¾èµ–é¡¹ï¼šè·å–æ•°æ®åº“ä¼šè¯
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

@router.post("/register")
def register(form_data: OAuth2PasswordRequestForm = Depends(), db: Session = Depends(get_db)):
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²å­˜åœ¨
    db_user = db.query(User).filter(User.username == form_data.username).first()
    if db_user:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="ç”¨æˆ·åå·²å­˜åœ¨"
        )
    
    # åˆ›å»ºæ–°ç”¨æˆ·
    hashed_password = get_password_hash(form_data.password)
    db_user = User(username=form_data.username, hashed_password=hashed_password)
    db.add(db_user)
    db.commit()
    db.refresh(db_user)
    
    # ç”Ÿæˆè®¿é—®ä»¤ç‰Œ
    access_token = create_access_token(
        data={"sub": db_user.username}
    )
    return {"access_token": access_token, "token_type": "bearer"}

@router.post("/token")
def login(form_data: OAuth2PasswordRequestForm = Depends(), db: Session = Depends(get_db)):
    # éªŒè¯ç”¨æˆ·
    user = db.query(User).filter(User.username == form_data.username).first()
    if not user or not verify_password(form_data.password, user.hashed_password):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    # ç”Ÿæˆè®¿é—®ä»¤ç‰Œ
    access_token = create_access_token(
        data={"sub": user.username}
    )
    return {"access_token": access_token, "token_type": "bearer"}

# è·å–å½“å‰ç”¨æˆ·
async def get_current_user(token: str = Depends(oauth2_scheme), db: Session = Depends(get_db)):
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="æ— æ•ˆçš„è®¤è¯å‡­è¯",
        headers={"WWW-Authenticate": "Bearer"},
    )
    try:
        payload = decode_access_token(token)
        username: str = payload.get("sub")
        if username is None:
            raise credentials_exception
    except:
        raise credentials_exception
    
    user = db.query(User).filter(User.username == username).first()
    if user is None:
        raise credentials_exception
    return user

@router.get("/me")
async def read_users_me(current_user: User = Depends(get_current_user)):
    return {
        "username": current_user.username,
        "created_at": current_user.created_at.isoformat()
    }
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/rag.py
```python
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List, Dict, Optional, Any
from pydantic import BaseModel, Field
from .. import models
from ..database import get_db
from .auth import get_current_user
from ..rag_service import get_rag_service
import logging
import json
import os

logger = logging.getLogger(__name__)
router = APIRouter(
    prefix="/rag",
    tags=["rag"]
)

# Pydanticæ¨¡å‹å®šä¹‰
class VectorSearchRequest(BaseModel):
    query: str = Field(..., description="æœç´¢æŸ¥è¯¢æ–‡æœ¬")
    top_k: int = Field(5, ge=1, le=50, description="è¿”å›ç»“æœæ•°é‡")
    threshold: float = Field(0.3, ge=0.0, le=1.0, description="ç›¸ä¼¼åº¦é˜ˆå€¼")

class VectorSearchResult(BaseModel):
    word: str
    weight: int
    similarity: float
    rank: int

class VectorSearchResponse(BaseModel):
    query: str
    results: List[VectorSearchResult]
    total_found: int
    processing_time_ms: float

class IndexStatsResponse(BaseModel):
    user_id: str
    total_hotwords: int
    index_dimension: int
    is_initialized: bool
    last_updated: Optional[str] = None

class BulkAddRequest(BaseModel):
    words: List[Dict[str, Any]] = Field(..., description="çƒ­è¯åˆ—è¡¨ï¼Œæ ¼å¼ï¼š[{'word': 'xxx', 'weight': 5}]")

class IndexManagementResponse(BaseModel):
    success: bool
    message: str
    details: Optional[Dict] = None

@router.get("/health", summary="RAGæœåŠ¡å¥åº·æ£€æŸ¥")
def health_check():
    """RAGæœåŠ¡å¥åº·æ£€æŸ¥"""
    rag_service = get_rag_service()
    return {
        "status": "healthy" if rag_service.initialized else "initializing",
        "service": "RAG Vector Search Engine",
        "version": "1.0.0",
        "initialized": rag_service.initialized
    }

@router.post("/search", response_model=VectorSearchResponse, summary="å‘é‡ç›¸ä¼¼åº¦æœç´¢")
def vector_search(
    request: VectorSearchRequest,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    åŸºäºå‘é‡ç›¸ä¼¼åº¦çš„çƒ­è¯æœç´¢
    
    ä½¿ç”¨FAISSè¿›è¡Œé«˜æ•ˆçš„å‘é‡æ£€ç´¢ï¼Œæ”¯æŒè¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…
    """
    import time
    start_time = time.time()
    
    try:
        rag_service = get_rag_service()
        
        # ç¡®ä¿RAGæœåŠ¡å·²åˆå§‹åŒ–
        if not rag_service.initialized:
            rag_service.initialize()
            
        # ç¡®ä¿ç”¨æˆ·ç´¢å¼•å·²æ„å»º
        if current_user.id not in rag_service.hotword_metadata:
            rag_service.build_user_hotword_index(db, current_user.id)
        
        # æ‰§è¡Œå‘é‡æœç´¢
        predictions = rag_service.predict_hotwords(
            request.query, 
            current_user.id, 
            top_k=request.top_k, 
            threshold=request.threshold
        )
        
        # æ„å»ºå“åº”
        results = [
            VectorSearchResult(
                word=pred["word"],
                weight=pred["weight"],
                similarity=pred["similarity"],
                rank=pred["rank"]
            )
            for pred in predictions
        ]
        
        processing_time = (time.time() - start_time) * 1000
        
        return VectorSearchResponse(
            query=request.query,
            results=results,
            total_found=len(results),
            processing_time_ms=round(processing_time, 2)
        )
        
    except Exception as e:
        logger.error(f"å‘é‡æœç´¢å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æœç´¢å¤±è´¥: {str(e)}"
        )

@router.get("/index/stats", response_model=IndexStatsResponse, summary="è·å–ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯")
def get_index_stats(
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """è·å–ç”¨æˆ·çƒ­è¯ç´¢å¼•çš„ç»Ÿè®¡ä¿¡æ¯"""
    try:
        rag_service = get_rag_service()
        
        # è·å–ç”¨æˆ·çƒ­è¯æ•°é‡
        hotword_count = db.query(models.Hotword).filter(
            models.Hotword.user_id == current_user.id
        ).count()
        
        # æ£€æŸ¥ç´¢å¼•çŠ¶æ€
        has_index = current_user.id in rag_service.hotword_metadata
        
        return IndexStatsResponse(
            user_id=current_user.id,
            total_hotwords=hotword_count,
            index_dimension=rag_service.dimension if rag_service.initialized else 0,
            is_initialized=rag_service.initialized and has_index,
            last_updated=None  # TODO: å¯ä»¥æ·»åŠ æ—¶é—´æˆ³è·Ÿè¸ª
        )
        
    except Exception as e:
        logger.error(f"è·å–ç´¢å¼•ç»Ÿè®¡å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"
        )

@router.post("/index/rebuild", response_model=IndexManagementResponse, summary="é‡å»ºç”¨æˆ·ç´¢å¼•")
def rebuild_index(
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """é‡å»ºç”¨æˆ·çš„çƒ­è¯å‘é‡ç´¢å¼•"""
    try:
        rag_service = get_rag_service()
        
        # ç¡®ä¿RAGæœåŠ¡å·²åˆå§‹åŒ–
        if not rag_service.initialized:
            rag_service.initialize()
            
        # é‡å»ºç´¢å¼•
        success = rag_service.build_user_hotword_index(db, current_user.id)
        
        if success:
            hotword_count = len(rag_service.hotword_metadata.get(current_user.id, {}).get('words', []))
            return IndexManagementResponse(
                success=True,
                message=f"ç´¢å¼•é‡å»ºæˆåŠŸï¼ŒåŒ…å« {hotword_count} ä¸ªçƒ­è¯",
                details={
                    "user_id": current_user.id,
                    "hotword_count": hotword_count,
                    "dimension": rag_service.dimension
                }
            )
        else:
            return IndexManagementResponse(
                success=False,
                message="ç´¢å¼•é‡å»ºå¤±è´¥"
            )
            
    except Exception as e:
        logger.error(f"é‡å»ºç´¢å¼•å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"é‡å»ºç´¢å¼•å¤±è´¥: {str(e)}"
        )

@router.post("/index/bulk-add", response_model=IndexManagementResponse, summary="æ‰¹é‡æ·»åŠ çƒ­è¯åˆ°ç´¢å¼•")
def bulk_add_to_index(
    request: BulkAddRequest,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    æ‰¹é‡æ·»åŠ çƒ­è¯åˆ°å‘é‡ç´¢å¼•
    
    è¿™æ˜¯ä¸€ä¸ªé«˜çº§åŠŸèƒ½ï¼Œå…è®¸ç›´æ¥å‘ç´¢å¼•æ·»åŠ è¯æ¡è€Œä¸é€šè¿‡å¸¸è§„çš„çƒ­è¯ç®¡ç†API
    """
    try:
        rag_service = get_rag_service()
        
        # ç¡®ä¿RAGæœåŠ¡å·²åˆå§‹åŒ–
        if not rag_service.initialized:
            rag_service.initialize()
            
        added_count = 0
        skipped_count = 0
        
        for word_data in request.words:
            word = word_data.get("word", "").strip()
            weight = word_data.get("weight", 5)
            
            if not word:
                skipped_count += 1
                continue
                
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing = db.query(models.Hotword).filter(
                models.Hotword.user_id == current_user.id,
                models.Hotword.word == word
            ).first()
            
            if existing:
                skipped_count += 1
                continue
                
            # æ·»åŠ åˆ°æ•°æ®åº“
            db_hotword = models.Hotword(
                user_id=current_user.id,
                word=word,
                weight=weight
            )
            db.add(db_hotword)
            added_count += 1
            
        # æäº¤æ•°æ®åº“æ›´æ”¹
        db.commit()
        
        # é‡å»ºç´¢å¼•
        if added_count > 0:
            rag_service.build_user_hotword_index(db, current_user.id)
            
        return IndexManagementResponse(
            success=True,
            message=f"æ‰¹é‡æ·»åŠ å®Œæˆï¼šæ–°å¢ {added_count} ä¸ªï¼Œè·³è¿‡ {skipped_count} ä¸ª",
            details={
                "added": added_count,
                "skipped": skipped_count,
                "total_processed": len(request.words)
            }
        )
        
    except Exception as e:
        logger.error(f"æ‰¹é‡æ·»åŠ å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ‰¹é‡æ·»åŠ å¤±è´¥: {str(e)}"
        )

@router.get("/suggestions", summary="è·å–çƒ­è¯å»ºè®®")
def get_suggestions(
    partial_text: str,
    max_suggestions: int = 5,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    æ ¹æ®éƒ¨åˆ†è¾“å…¥æ–‡æœ¬è·å–çƒ­è¯å»ºè®®
    
    ç»“åˆå‰ç¼€åŒ¹é…å’Œè¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œæä¾›æ™ºèƒ½çš„çƒ­è¯è¡¥å…¨å»ºè®®
    """
    try:
        rag_service = get_rag_service()
        
        # ç¡®ä¿RAGæœåŠ¡å·²åˆå§‹åŒ–
        if not rag_service.initialized:
            rag_service.initialize()
            
        # ç¡®ä¿ç”¨æˆ·ç´¢å¼•å·²æ„å»º
        if current_user.id not in rag_service.hotword_metadata:
            rag_service.build_user_hotword_index(db, current_user.id)
            
        # è·å–å»ºè®®
        suggestions = rag_service.get_hotword_suggestions(
            partial_text, 
            current_user.id, 
            max_suggestions
        )
        
        return {
            "partial_text": partial_text,
            "suggestions": suggestions,
            "count": len(suggestions)
        }
        
    except Exception as e:
        logger.error(f"è·å–å»ºè®®å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–å»ºè®®å¤±è´¥: {str(e)}"
        )

@router.get("/model/info", summary="è·å–æ¨¡å‹ä¿¡æ¯")
def get_model_info():
    """è·å–å½“å‰ä½¿ç”¨çš„å‘é‡åŒ–æ¨¡å‹ä¿¡æ¯"""
    try:
        rag_service = get_rag_service()
        
        if not rag_service.initialized:
            return {
                "status": "not_initialized",
                "message": "RAGæœåŠ¡æœªåˆå§‹åŒ–"
            }
            
        model_info = {
            "model_name": "sentence-transformers/all-MiniLM-L6-v2",
            "dimension": rag_service.dimension,
            "max_sequence_length": 256,  # æ¨¡å‹çš„æœ€å¤§åºåˆ—é•¿åº¦
            "languages": ["zh", "en", "multilingual"],
            "description": "è½»é‡çº§å¤šè¯­è¨€å¥å­åµŒå…¥æ¨¡å‹ï¼Œé€‚åˆä¸­è‹±æ–‡æ··åˆåœºæ™¯",
            "performance": {
                "embedding_speed": "~1000 sentences/sec (CPU)",
                "model_size": "~90MB",
                "accuracy": "é€‚ä¸­ï¼Œå¹³è¡¡é€Ÿåº¦ä¸å‡†ç¡®æ€§"
            }
        }
        
        return model_info
        
    except Exception as e:
        logger.error(f"è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {str(e)}"
        )
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/realtime_websocket.py
```python
# æ–‡ä»¶è·¯å¾„: asr_system_backend/app/routers/realtime_websocket.py
# åŠŸèƒ½: æ¥æ”¶å‰ç«¯é€šè¿‡WebSocketå‘é€çš„å®æ—¶éŸ³é¢‘æµï¼Œæ‹¼æ¥å¤„ç†åè¿”å›è½¬å†™ç»“æœã€‚

import asyncio
import logging
import os
import subprocess
import uuid
from datetime import datetime, timedelta
from fastapi import APIRouter, WebSocket, WebSocketDisconnect, Depends, Query
from sqlalchemy.orm import Session

from ..database import get_db
from ..models import User
from ..auth_service import decode_access_token

# --- æ—¥å¿—å’Œè·¯ç”±é…ç½® ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
router = APIRouter()

# --- å­˜å‚¨æ¯ä¸ªè¿æ¥çš„éŸ³é¢‘ç¼“å†²åŒºå’ŒçŠ¶æ€ ---
# ä½¿ç”¨å­—å…¸æ¥ç®¡ç†å¤šä¸ªå¹¶å‘è¿æ¥ï¼Œkeyæ˜¯å”¯ä¸€çš„client_id
client_buffers: dict[str, bytearray] = {}
client_last_processed_time: dict[str, datetime] = {}
PROCESSING_INTERVAL_SECONDS = 5 # æ¯éš”5ç§’å¤„ç†ä¸€æ¬¡ç´¯ç§¯çš„éŸ³é¢‘

# --- WebSocketè¿æ¥ç®¡ç†å™¨ ---
class ConnectionManager:
    def __init__(self):
        self.active_connections: dict[str, WebSocket] = {}

    async def connect(self, websocket: WebSocket, client_id: str):
        await websocket.accept()
        self.active_connections[client_id] = websocket
        # åˆå§‹åŒ–è¯¥è¿æ¥çš„ç¼“å†²åŒºå’Œæ—¶é—´æˆ³
        client_buffers[client_id] = bytearray()
        client_last_processed_time[client_id] = datetime.now()
        logger.info(f"å®¢æˆ·ç«¯ {client_id} å·²è¿æ¥ï¼Œå¹¶å·²åˆ›å»ºéŸ³é¢‘ç¼“å†²åŒºã€‚")

    def disconnect(self, client_id: str):
        # æ¸…ç†èµ„æº
        if client_id in self.active_connections:
            del self.active_connections[client_id]
        if client_id in client_buffers:
            del client_buffers[client_id]
        if client_id in client_last_processed_time:
            del client_last_processed_time[client_id]
        logger.info(f"å®¢æˆ·ç«¯ {client_id} å·²æ–­å¼€ï¼Œç›¸å…³èµ„æºå·²æ¸…ç†ã€‚")

    async def send_json(self, client_id: str, data: dict):
        if client_id in self.active_connections:
            await self.active_connections[client_id].send_json(data)

manager = ConnectionManager()

# --- WebSocketè®¤è¯ ---
async def get_current_user_from_ws_token(token: str, db: Session):
    try:
        payload = decode_access_token(token)
        username: str = payload.get("sub")
        if not username: return None
        return db.query(User).filter(User.username == username).first()
    except Exception:
        return None

# --- éŸ³é¢‘å¤„ç†æ ¸å¿ƒå‡½æ•° ---
async def process_accumulated_audio(client_id: str):
    """
    å¤„ç†æŒ‡å®šå®¢æˆ·ç«¯ç´¯ç§¯çš„éŸ³é¢‘æ•°æ®ã€‚
    è¿™ä¸ªå‡½æ•°ä¼šè¢«å®šæ—¶è°ƒç”¨æˆ–è€…åœ¨æ¥æ”¶åˆ°æ–°æ•°æ®æ—¶è§¦å‘æ£€æŸ¥ã€‚
    """
    # æ£€æŸ¥ç¼“å†²åŒºä¸­æ˜¯å¦æœ‰æ•°æ®
    if client_id not in client_buffers or len(client_buffers[client_id]) == 0:
        return

    # å¤åˆ¶ç¼“å†²åŒºå†…å®¹è¿›è¡Œå¤„ç†ï¼Œå¹¶æ¸…ç©ºåŸç¼“å†²åŒº
    audio_data_to_process = client_buffers[client_id]
    client_buffers[client_id] = bytearray()
    
    # æ›´æ–°å¤„ç†æ—¶é—´æˆ³
    client_last_processed_time[client_id] = datetime.now()
    
    logger.info(f"å¼€å§‹å¤„ç†å®¢æˆ·ç«¯ {client_id} çš„ {len(audio_data_to_process)} å­—èŠ‚éŸ³é¢‘æ•°æ®ã€‚")

    # åç»­é€»è¾‘ä¸ä¹‹å‰çš„å®ç°å®Œå…¨ä¸€è‡´ï¼šä¿å­˜ã€è½¬æ¢ã€è°ƒç”¨è„šæœ¬ã€è¿”å›ç»“æœã€æ¸…ç†
    temp_id = str(uuid.uuid4())
    webm_path = f"/tmp/{temp_id}.webm"
    wav_path = f"/tmp/{temp_id}.wav"
    
    try:
        with open(webm_path, "wb") as f:
            f.write(audio_data_to_process)

        command = f"ffmpeg -i {webm_path} -ar 16000 -ac 1 -y {wav_path}"
        process = await asyncio.create_subprocess_shell(command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
        _, stderr = await process.communicate()

        if process.returncode != 0:
            error_message = f"FFmpegè½¬æ¢å¤±è´¥: {stderr.decode()}"
            logger.error(error_message)
            await manager.send_json(client_id, {"type": "error", "message": "éŸ³é¢‘æ ¼å¼å¤„ç†å¤±è´¥"})
            return

        root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..'))
        client_script_path = os.path.join(root_dir, "client", "funasr_wss_client.py")
        
        transcribe_command = ["python", client_script_path, "--host", "127.0.0.1", "--port", "10095", "--mode", "offline", "--audio_in", wav_path]
        
        transcribe_process = await asyncio.create_subprocess_exec(*transcribe_command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
        transcribe_stdout, _ = await transcribe_process.communicate()
        output = transcribe_stdout.decode()
        
        transcription = ""
        for line in output.split("\n"):
            if "pid0_0: demo:" in line:
                transcription = line.split("pid0_0: demo:")[-1].strip()
                break
        
        logger.info(f"å®¢æˆ·ç«¯ {client_id} çš„è½¬å†™ç»“æœ: '{transcription}'")

        if transcription:
            await manager.send_json(client_id, {
                "type": "transcription_result",
                "data": {
                    "text": transcription,
                    "confidence": 0.95,
                    "hotwords_detected": [],
                    "confidence_boost": 1.0,
                    "timestamp": datetime.now().isoformat()
                }
            })

    except Exception as e:
        logger.error(f"å¤„ç†ç´¯ç§¯éŸ³é¢‘æ—¶å‡ºé”™: {e}")
        await manager.send_json(client_id, {"type": "error", "message": "æœåŠ¡å™¨å¤„ç†éŸ³é¢‘æ—¶å‡ºé”™"})
    finally:
        if os.path.exists(webm_path): os.remove(webm_path)
        if os.path.exists(wav_path): os.remove(wav_path)

# --- WebSocketç«¯ç‚¹å®šä¹‰ ---
@router.websocket("/ws/asr/transcribe/realtime")
async def websocket_endpoint(
    websocket: WebSocket,
    token: str = Query(...),
    db: Session = Depends(get_db)
):
    """
    å¤„ç†å®æ—¶è¯­éŸ³è½¬å†™çš„WebSocketç«¯ç‚¹ã€‚
    è¿™ä¸ªç‰ˆæœ¬ä¼šç´¯ç§¯éŸ³é¢‘æ•°æ®ï¼Œå¹¶æŒ‰å›ºå®šæ—¶é—´é—´éš”è¿›è¡Œå¤„ç†ã€‚
    """
    user = await get_current_user_from_ws_token(token, db)
    if not user:
        await websocket.close(code=1008, reason="è®¤è¯å¤±è´¥")
        return

    client_id = str(uuid.uuid4())
    await manager.connect(websocket, client_id)
    
    try:
        await manager.send_json(client_id, {"type": "connection_established", "user_id": user.username})
        await manager.send_json(client_id, {"type": "ready"})
        
        while True:
            # 1. æ¥æ”¶å‰ç«¯å‘é€çš„ä¸€å°å—éŸ³é¢‘æ•°æ®
            audio_data = await websocket.receive_bytes()
            
            # 2. å°†æ¥æ”¶åˆ°çš„æ•°æ®è¿½åŠ åˆ°è¯¥å®¢æˆ·ç«¯çš„ç¼“å†²åŒº
            if client_id in client_buffers:
                client_buffers[client_id].extend(audio_data)

            # 3. æ£€æŸ¥æ˜¯å¦è¾¾åˆ°äº†å¤„ç†æ—¶é—´
            now = datetime.now()
            last_processed = client_last_processed_time.get(client_id, now)
            
            if now - last_processed >= timedelta(seconds=PROCESSING_INTERVAL_SECONDS):
                # å¦‚æœè·ç¦»ä¸Šæ¬¡å¤„ç†å·²è¶…è¿‡5ç§’ï¼Œåˆ™ç«‹å³å¤„ç†ç´¯ç§¯çš„éŸ³é¢‘
                # ä½¿ç”¨create_taskä½¿å…¶åœ¨åå°è¿è¡Œï¼Œä¸é˜»å¡æ¥æ”¶ä¸‹ä¸€å—æ•°æ®
                asyncio.create_task(process_accumulated_audio(client_id))

    except WebSocketDisconnect:
        # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥æ—¶ï¼Œå¤„ç†æœ€åå‰©ä½™çš„éŸ³é¢‘æ•°æ®
        logger.info(f"å®¢æˆ·ç«¯ {client_id} æ­£åœ¨æ–­å¼€è¿æ¥ï¼Œå¤„ç†å‰©ä½™éŸ³é¢‘...")
        await process_accumulated_audio(client_id)
        manager.disconnect(client_id)
    except Exception as e:
        logger.error(f"WebSocketè¿æ¥å‡ºç°æ„å¤–é”™è¯¯ ({client_id}): {e}")
        manager.disconnect(client_id)
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/__init__.py
```python

```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/realtime.py
```python
import asyncio
import json
import logging
from typing import Dict, List
from fastapi import APIRouter, WebSocket, WebSocketDisconnect, Depends, HTTPException, Query
from fastapi.security import HTTPAuthorizationCredentials, HTTPBearer
from sqlalchemy.orm import Session
from .. import models
from ..database import get_db
from ..asr_engine import get_asr_engine
from ..rag_service import get_rag_service
from ..auth_service import decode_access_token
import numpy as np
import wave
import io
import tempfile
import os

logger = logging.getLogger(__name__)
router = APIRouter()

# å­˜å‚¨æ´»åŠ¨çš„WebSocketè¿æ¥
active_connections: Dict[str, WebSocket] = {}

class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
        self.user_connections: Dict[str, str] = {}  # user_id -> connection_id
        
    async def connect(self, websocket: WebSocket, user_id: str, connection_id: str):
        """æ¥å—WebSocketè¿æ¥"""
        await websocket.accept()
        self.active_connections[connection_id] = websocket
        self.user_connections[user_id] = connection_id
        logger.info(f"ç”¨æˆ· {user_id} å»ºç«‹WebSocketè¿æ¥ {connection_id}")
        
    def disconnect(self, connection_id: str):
        """æ–­å¼€WebSocketè¿æ¥"""
        if connection_id in self.active_connections:
            websocket = self.active_connections[connection_id]
            del self.active_connections[connection_id]
            
            # ç§»é™¤ç”¨æˆ·è¿æ¥æ˜ å°„
            for user_id, conn_id in list(self.user_connections.items()):
                if conn_id == connection_id:
                    del self.user_connections[user_id]
                    break
                    
            logger.info(f"WebSocketè¿æ¥ {connection_id} å·²æ–­å¼€")
            
    async def send_message(self, connection_id: str, message: dict):
        """å‘é€æ¶ˆæ¯åˆ°æŒ‡å®šè¿æ¥"""
        if connection_id in self.active_connections:
            websocket = self.active_connections[connection_id]
            try:
                await websocket.send_text(json.dumps(message))
            except Exception as e:
                logger.error(f"å‘é€æ¶ˆæ¯å¤±è´¥: {str(e)}")
                self.disconnect(connection_id)

manager = ConnectionManager()

async def get_current_user_ws(token: str, db: Session = Depends(get_db)):
    """WebSocketè®¤è¯ä¸­é—´ä»¶"""
    try:
        # è§£ç JWT token
        payload = decode_access_token(token)
        user_id = payload.get("sub")
        
        if not user_id:
            raise HTTPException(status_code=401, detail="æ— æ•ˆçš„token")
            
        # ä»æ•°æ®åº“è·å–ç”¨æˆ·ä¿¡æ¯
        user = db.query(models.User).filter(models.User.id == user_id).first()
        if not user:
            raise HTTPException(status_code=401, detail="ç”¨æˆ·ä¸å­˜åœ¨")
            
        return user
    except Exception as e:
        logger.error(f"WebSocketè®¤è¯å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=401, detail="è®¤è¯å¤±è´¥")

@router.websocket("/ws/asr/transcribe/realtime")
async def websocket_realtime_transcribe(
    websocket: WebSocket,
    token: str = Query(...),
    db: Session = Depends(get_db)
):
    """å®æ—¶è¯­éŸ³è½¬å†™WebSocketç«¯ç‚¹"""
    connection_id = f"conn_{hash(websocket)}"
    
    try:
        # è®¤è¯ç”¨æˆ·
        user = await get_current_user_ws(token, db)
        
        # å»ºç«‹è¿æ¥
        await manager.connect(websocket, user.id, connection_id)
        
        # å‘é€è¿æ¥æˆåŠŸæ¶ˆæ¯
        await manager.send_message(connection_id, {
            "type": "connection_established",
            "message": "WebSocketè¿æ¥å·²å»ºç«‹",
            "user_id": user.id
        })
        
        # åˆå§‹åŒ–ASRå¼•æ“
        asr_engine = get_asr_engine()
        if not asr_engine.initialized:
            asr_engine.initialize()
            
        # åˆå§‹åŒ–RAGæœåŠ¡
        rag_service = get_rag_service()
        if not rag_service.initialized:
            rag_service.initialize()
            
        # ä¸ºç”¨æˆ·æ„å»ºçƒ­è¯ç´¢å¼•
        rag_service.build_user_hotword_index(db, user.id)
        
        # éŸ³é¢‘æ•°æ®ç¼“å†²åŒº
        audio_buffer = bytearray()
        sample_rate = 16000  # é»˜è®¤é‡‡æ ·ç‡
        chunk_duration = 2.0  # 2ç§’ä¸€ä¸ªå¤„ç†å—
        chunk_size = int(sample_rate * chunk_duration * 2)  # 16-bit PCM
        
        await manager.send_message(connection_id, {
            "type": "ready",
            "message": "å®æ—¶è½¬å†™æœåŠ¡å·²å‡†å¤‡å°±ç»ª",
            "config": {
                "sample_rate": sample_rate,
                "chunk_duration": chunk_duration,
                "supported_formats": ["PCM", "WAV"]
            }
        })
        
        while True:
            # æ¥æ”¶éŸ³é¢‘æ•°æ®
            data = await websocket.receive()
            
            if data["type"] == "websocket.receive":
                if "bytes" in data:
                    # å¤„ç†äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®
                    audio_data = data["bytes"]
                    audio_buffer.extend(audio_data)
                    
                    # å½“ç¼“å†²åŒºç§¯ç´¯è¶³å¤Ÿæ•°æ®æ—¶è¿›è¡Œè½¬å†™
                    if len(audio_buffer) >= chunk_size:
                        # æå–éŸ³é¢‘å—
                        chunk_data = bytes(audio_buffer[:chunk_size])
                        audio_buffer = audio_buffer[chunk_size:]
                        
                        # å¼‚æ­¥å¤„ç†éŸ³é¢‘è½¬å†™
                        asyncio.create_task(
                            process_audio_chunk(
                                chunk_data,
                                connection_id,
                                user.id,
                                asr_engine,
                                rag_service,
                                db,
                                sample_rate
                            )
                        )
                        
                elif "text" in data:
                    # å¤„ç†æ–‡æœ¬å‘½ä»¤
                    try:
                        command = json.loads(data["text"])
                        await handle_command(command, connection_id, user.id, db)
                    except json.JSONDecodeError:
                        await manager.send_message(connection_id, {
                            "type": "error",
                            "message": "æ— æ•ˆçš„JSONæ ¼å¼"
                        })
                        
    except WebSocketDisconnect:
        logger.info(f"WebSocketè¿æ¥ {connection_id} ä¸»åŠ¨æ–­å¼€")
        manager.disconnect(connection_id)
    except Exception as e:
        logger.error(f"WebSocketé”™è¯¯: {str(e)}")
        await manager.send_message(connection_id, {
            "type": "error",
            "message": f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}"
        })
        manager.disconnect(connection_id)

async def process_audio_chunk(
    audio_data: bytes,
    connection_id: str,
    user_id: str,
    asr_engine,
    rag_service,
    db: Session,
    sample_rate: int
):
    """å¤„ç†éŸ³é¢‘å—çš„å¼‚æ­¥ä»»åŠ¡"""
    try:
        # å°†éŸ³é¢‘æ•°æ®å†™å…¥ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
            # åˆ›å»ºWAVæ–‡ä»¶å¤´
            wav_buffer = io.BytesIO()
            with wave.open(wav_buffer, 'wb') as wav_file:
                wav_file.setnchannels(1)  # å•å£°é“
                wav_file.setsampwidth(2)  # 16-bit
                wav_file.setframerate(sample_rate)
                wav_file.writeframes(audio_data)
            
            # å†™å…¥ä¸´æ—¶æ–‡ä»¶
            temp_file.write(wav_buffer.getvalue())
            temp_file_path = temp_file.name
            
        try:
            # ä½¿ç”¨ASRå¼•æ“è½¬å†™éŸ³é¢‘
            transcription_result = asr_engine.transcribe_audio(temp_file_path)
            
            # æå–è½¬å†™æ–‡æœ¬
            transcription_text = transcription_result.get("text", "").strip()
            
            if transcription_text:
                # ä½¿ç”¨RAGæœåŠ¡å¢å¼ºè½¬å†™ç»“æœ
                enhanced_result = rag_service.enhance_transcription_with_hotwords(
                    transcription_text, user_id
                )
                
                # å‘é€è½¬å†™ç»“æœ
                await manager.send_message(connection_id, {
                    "type": "transcription_result",
                    "data": {
                        "text": enhanced_result["enhanced_text"],
                        "original_text": transcription_text,
                        "confidence_boost": enhanced_result["confidence_boost"],
                        "hotwords_detected": enhanced_result["hotwords_detected"],
                        "predicted_hotwords": enhanced_result.get("predicted_hotwords", []),
                        "segments": transcription_result.get("segments", []),
                        "timestamp": transcription_result.get("processing_time")
                    }
                })
            else:
                # å‘é€é™éŸ³æ£€æµ‹ç»“æœ
                await manager.send_message(connection_id, {
                    "type": "silence_detected",
                    "message": "æ£€æµ‹åˆ°é™éŸ³"
                })
                
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_file_path):
                os.remove(temp_file_path)
                
    except Exception as e:
        logger.error(f"éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}")
        await manager.send_message(connection_id, {
            "type": "error",
            "message": f"éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}"
        })

async def handle_command(command: dict, connection_id: str, user_id: str, db: Session):
    """å¤„ç†WebSocketå‘½ä»¤"""
    try:
        command_type = command.get("type")
        
        if command_type == "ping":
            await manager.send_message(connection_id, {
                "type": "pong",
                "timestamp": command.get("timestamp")
            })
            
        elif command_type == "get_hotwords":
            # è·å–ç”¨æˆ·çƒ­è¯åˆ—è¡¨
            hotwords = db.query(models.Hotword).filter(
                models.Hotword.user_id == user_id
            ).all()
            
            await manager.send_message(connection_id, {
                "type": "hotwords_list",
                "data": [
                    {
                        "id": hw.id,
                        "word": hw.word,
                        "weight": hw.weight
                    }
                    for hw in hotwords
                ]
            })
            
        elif command_type == "update_config":
            # æ›´æ–°å®æ—¶è½¬å†™é…ç½®
            config = command.get("config", {})
            await manager.send_message(connection_id, {
                "type": "config_updated",
                "message": "é…ç½®å·²æ›´æ–°",
                "config": config
            })
            
        else:
            await manager.send_message(connection_id, {
                "type": "error",
                "message": f"æœªçŸ¥å‘½ä»¤ç±»å‹: {command_type}"
            })
            
    except Exception as e:
        logger.error(f"å‘½ä»¤å¤„ç†å¤±è´¥: {str(e)}")
        await manager.send_message(connection_id, {
            "type": "error",
            "message": f"å‘½ä»¤å¤„ç†å¤±è´¥: {str(e)}"
        })
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/realtime_asr/funasr_client.py
```python
"""
FunASR å®æ—¶å®¢æˆ·ç«¯
è´Ÿè´£ä¸ FunASR æœåŠ¡å™¨å»ºç«‹ WebSocket è¿æ¥å¹¶è¿›è¡Œå®æ—¶éŸ³é¢‘è½¬å†™
"""

import json
import asyncio
import websockets
import logging
from typing import Optional, Dict, Any

logger = logging.getLogger(__name__)

class FunASRRealtimeClient:
    """FunASR å®æ—¶è½¬å†™å®¢æˆ·ç«¯"""
    
    def __init__(self, host: str = "127.0.0.1", port: int = 10095):
        """
        åˆå§‹åŒ– FunASR å®æ—¶å®¢æˆ·ç«¯
        
        Args:
            host: FunASR æœåŠ¡å™¨åœ°å€
            port: FunASR æœåŠ¡å™¨ç«¯å£
        """
        self.host = host
        self.port = port
        self.ws: Optional[websockets.WebSocketClientProtocol] = None
        self.is_connected = False
        self.task_id: Optional[str] = None
        
    async def connect(self) -> bool:
        """
        è¿æ¥åˆ° FunASR æœåŠ¡å™¨
        
        Returns:
            bool: è¿æ¥æ˜¯å¦æˆåŠŸ
        """
        try:
            ws_url = f"ws://{self.host}:{self.port}/ws/decode"
            self.ws = await websockets.connect(ws_url)
            self.is_connected = True
            
            # å‘é€å¯åŠ¨å‘½ä»¤
            start_command = {
                "mode": "online",
                "chunk_size": 3200,  # 200ms @ 16kHz
                "chunk_interval": 200,  # æ¯200mså‘é€ä¸€æ¬¡
                "wav_format": True,  # ä½¿ç”¨ WAV æ ¼å¼
                "audio_fs": 16000,  # é‡‡æ ·ç‡
                "audio_channels": 1,  # å•å£°é“
                "audio_bits": 16,  # 16ä½
            }
            
            await self.ws.send(json.dumps(start_command))
            response = await self.ws.recv()
            response_data = json.loads(response)
            
            if response_data.get("status") == 0:
                self.task_id = response_data.get("task_id")
                logger.info(f"Connected to FunASR server, task_id: {self.task_id}")
                return True
            else:
                logger.error(f"Failed to start streaming: {response_data}")
                return False
                
        except Exception as e:
            logger.error(f"Failed to connect to FunASR server: {e}")
            self.is_connected = False
            return False
            
    async def send_audio(self, audio_chunk: bytes) -> Dict[str, Any]:
        """
        å‘é€éŸ³é¢‘æ•°æ®åˆ° FunASR æœåŠ¡å™¨
        
        Args:
            audio_chunk: éŸ³é¢‘æ•°æ®å—
            
        Returns:
            Dict[str, Any]: è¯†åˆ«ç»“æœ
        """
        if not self.is_connected or not self.ws:
            raise ConnectionError("Not connected to FunASR server")
            
        try:
            # å‘é€éŸ³é¢‘æ•°æ®
            await self.ws.send(audio_chunk)
            
            # æ¥æ”¶è¯†åˆ«ç»“æœ
            response = await self.ws.recv()
            result = json.loads(response)
            
            return {
                "text": result.get("text", ""),
                "is_final": result.get("is_final", False),
                "confidence": result.get("confidence", 0.0),
                "segments": result.get("segments", []),
                "status": result.get("status", -1)
            }
            
        except Exception as e:
            logger.error(f"Error while sending audio data: {e}")
            raise
            
    async def stop(self) -> None:
        """åœæ­¢è½¬å†™å¹¶å…³é—­è¿æ¥"""
        if self.ws:
            try:
                # å‘é€ç»“æŸå‘½ä»¤
                end_command = {
                    "end": True,
                    "task_id": self.task_id
                }
                await self.ws.send(json.dumps(end_command))
                
                # ç­‰å¾…æœ€åçš„ç»“æœ
                response = await self.ws.recv()
                logger.info(f"Final response: {response}")
                
            except Exception as e:
                logger.error(f"Error while stopping transcription: {e}")
            
            finally:
                await self.ws.close()
                self.ws = None
                self.is_connected = False
                self.task_id = None
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/realtime_asr/realtime_handler.py
```python
import numpy as np
import torch
from transformers import WhisperProcessor, WhisperForConditionalGeneration
import io
import wave
from typing import Optional
import asyncio
import soundfile as sf
import tempfile
import subprocess
import os

class RealtimeASRHandler:
    def __init__(self):
        # åˆå§‹åŒ–Whisperæ¨¡å‹
        self.processor = WhisperProcessor.from_pretrained("openai/whisper-small")
        self.model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-small")
        if torch.cuda.is_available():
            self.model = self.model.to("cuda")
        
        # éŸ³é¢‘ç¼“å†²è®¾ç½®
        self.sample_rate = 16000  # WhisperæœŸæœ›çš„é‡‡æ ·ç‡
        self.audio_buffer = np.array([], dtype=np.float32)
        self.buffer_size = self.sample_rate * 3  # 3ç§’çš„éŸ³é¢‘ç¼“å†²
        
        # è½¬å†™è®¾ç½®
        self.is_processing = False
        self.last_transcription = ""

    async def process_audio(self, audio_data: bytes) -> Optional[str]:
        try:
            # å°†webméŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºnumpyæ•°ç»„
            audio_array = await self._convert_webm_to_array(audio_data)
            if audio_array is None:
                return None
            
            # æ·»åŠ åˆ°ç¼“å†²åŒº
            self.audio_buffer = np.append(self.audio_buffer, audio_array)
            
            # å¦‚æœç¼“å†²åŒºè¾¾åˆ°æŒ‡å®šå¤§å°ï¼Œè¿›è¡Œå¤„ç†
            if len(self.audio_buffer) >= self.buffer_size and not self.is_processing:
                self.is_processing = True
                try:
                    # å¤„ç†éŸ³é¢‘å¹¶è·å–è½¬å†™ç»“æœ
                    transcription = await self._transcribe_audio()
                    self.last_transcription = transcription
                    
                    # æ¸…é™¤å·²å¤„ç†çš„éŸ³é¢‘æ•°æ®ï¼Œä¿ç•™æœ€å0.5ç§’ä»¥å®ç°å¹³æ»‘è¿‡æ¸¡
                    overlap_samples = int(0.5 * self.sample_rate)
                    self.audio_buffer = self.audio_buffer[-overlap_samples:]
                    
                finally:
                    self.is_processing = False
                
                return self.last_transcription
            
            return None
            
        except Exception as e:
            print(f"å¤„ç†éŸ³é¢‘æ—¶å‡ºé”™: {str(e)}")
            return None

    async def _convert_webm_to_array(self, audio_data: bytes) -> Optional[np.ndarray]:
        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶æ¥å­˜å‚¨éŸ³é¢‘æ•°æ®
            with tempfile.NamedTemporaryFile(suffix='.webm', delete=False) as webm_file:
                webm_file.write(audio_data)
                webm_path = webm_file.name

            # åˆ›å»ºä¸´æ—¶WAVæ–‡ä»¶
            wav_path = webm_path + '.wav'
            
            # ä½¿ç”¨ffmpegå°†webmè½¬æ¢ä¸ºwav
            cmd = [
                'ffmpeg',
                '-i', webm_path,
                '-ar', str(self.sample_rate),
                '-ac', '1',
                '-f', 'wav',
                wav_path,
                '-y'
            ]
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            await process.communicate()
            
            if process.returncode == 0:
                # è¯»å–è½¬æ¢åçš„WAVæ–‡ä»¶
                audio_array, _ = sf.read(wav_path)
                return audio_array.astype(np.float32)
            else:
                print("éŸ³é¢‘è½¬æ¢å¤±è´¥")
                return None
                
        except Exception as e:
            print(f"è½¬æ¢éŸ³é¢‘æ ¼å¼æ—¶å‡ºé”™: {str(e)}")
            return None
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(webm_path)
                os.unlink(wav_path)
            except:
                pass

    async def _transcribe_audio(self) -> str:
        # åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œè½¬å†™ä»»åŠ¡
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, self._run_transcription)

    def _run_transcription(self) -> str:
        try:
            # å‡†å¤‡è¾“å…¥ç‰¹å¾
            input_features = self.processor(
                self.audio_buffer, 
                sampling_rate=self.sample_rate, 
                return_tensors="pt"
            ).input_features
            
            if torch.cuda.is_available():
                input_features = input_features.to("cuda")
            
            # ç”Ÿæˆè½¬å†™
            predicted_ids = self.model.generate(input_features)
            transcription = self.processor.batch_decode(
                predicted_ids, 
                skip_special_tokens=True
            )[0]
            
            return transcription.strip()
        except Exception as e:
            print(f"è½¬å†™è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return ""

    async def cleanup(self):
        # æ¸…ç†èµ„æº
        self.audio_buffer = np.array([], dtype=np.float32)
        self.is_processing = False
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/realtime_asr/__init__.py
```python
"""
å®æ—¶è¯­éŸ³è½¬å†™æ¨¡å—
æä¾›WebSocketæœåŠ¡ï¼Œæ”¯æŒå®æ—¶éŸ³é¢‘æµè½¬å†™åŠŸèƒ½
"""

# from .realtime_handler import RealtimeTranscriptionHandler
# åªå¯¼å…¥å®é™…ç”¨åˆ°çš„å†…å®¹
from .funasr_client import FunASRRealtimeClient

__all__ = ['FunASRRealtimeClient']
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/realtime_asr/routes.py
```python
"""
å®æ—¶è½¬å†™è·¯ç”±
å¤„ç†å®æ—¶è½¬å†™ç›¸å…³çš„ WebSocket è¯·æ±‚
"""

from fastapi import APIRouter, WebSocket, Query
from .realtime_handler import RealtimeTranscriptionHandler

router = APIRouter()
handler = RealtimeTranscriptionHandler()

@router.websocket("/ws/asr/transcribe/realtime")
async def websocket_endpoint(
    websocket: WebSocket,
    token: str = Query(..., description="ç”¨æˆ·è®¤è¯ä»¤ç‰Œ")
):
    """
    å®æ—¶è½¬å†™ WebSocket ç«¯ç‚¹
    
    Args:
        websocket: WebSocket è¿æ¥
        token: ç”¨æˆ·è®¤è¯ä»¤ç‰Œ
    """
    await handler.handle_client(websocket, token)
```

--------------------------------------------------------------------------------

File: asr_system_backend/client/funasr_wss_client.py
```python
# -*- encoding: utf-8 -*-
import os
import time
import websockets, ssl
import asyncio

# import threading
import argparse
import json
import traceback
from multiprocessing import Process

# from funasr.fileio.datadir_writer import DatadirWriter

import logging

logging.basicConfig(level=logging.ERROR)

parser = argparse.ArgumentParser()
parser.add_argument(
    "--host", type=str, default="localhost", required=False, help="host ip, localhost, 0.0.0.0"
)
parser.add_argument("--port", type=int, default=10095, required=False, help="grpc server port")
parser.add_argument("--chunk_size", type=str, default="5, 10, 5", help="chunk")
parser.add_argument("--encoder_chunk_look_back", type=int, default=4, help="chunk")
parser.add_argument("--decoder_chunk_look_back", type=int, default=0, help="chunk")
parser.add_argument("--chunk_interval", type=int, default=10, help="chunk")
parser.add_argument(
    "--hotword",
    type=str,
    default="",
    help="hotword file path, one hotword perline (e.g.:é˜¿é‡Œå·´å·´ 20)",
)
parser.add_argument("--audio_in", type=str, default=None, help="audio_in")
parser.add_argument("--audio_fs", type=int, default=16000, help="audio_fs")
parser.add_argument(
    "--send_without_sleep",
    action="store_true",
    default=True,
    help="if audio_in is set, send_without_sleep",
)
parser.add_argument("--thread_num", type=int, default=1, help="thread_num")
parser.add_argument("--words_max_print", type=int, default=10000, help="chunk")
parser.add_argument("--output_dir", type=str, default=None, help="output_dir")
parser.add_argument("--ssl", type=int, default=1, help="1 for ssl connect, 0 for no ssl")
parser.add_argument("--use_itn", type=int, default=1, help="1 for using itn, 0 for not itn")
parser.add_argument("--mode", type=str, default="2pass", help="offline, online, 2pass")

args = parser.parse_args()
args.chunk_size = [int(x) for x in args.chunk_size.split(",")]
print(args)
# voices = asyncio.Queue()
from queue import Queue

voices = Queue()
offline_msg_done = False

if args.output_dir is not None:
    # if os.path.exists(args.output_dir):
    #     os.remove(args.output_dir)

    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir)


async def record_microphone():
    is_finished = False
    import pyaudio

    # print("2")
    global voices
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    chunk_size = 60 * args.chunk_size[1] / args.chunk_interval
    CHUNK = int(RATE / 1000 * chunk_size)

    p = pyaudio.PyAudio()

    stream = p.open(
        format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK
    )
    # hotwords
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        if os.path.exists(args.hotword):
            f_scp = open(args.hotword)
            hot_lines = f_scp.readlines()
            for line in hot_lines:
                words = line.strip().split(" ")
                if len(words) < 2:
                    print("Please checkout format of hotwords")
                    continue
                try:
                    fst_dict[" ".join(words[:-1])] = int(words[-1])
                except ValueError:
                    print("Please checkout format of hotwords")
            hotword_msg = json.dumps(fst_dict)
        else:
            hotword_msg = args.hotword

    use_itn = True
    if args.use_itn == 0:
        use_itn = False

    message = json.dumps(
        {
            "mode": args.mode,
            "chunk_size": args.chunk_size,
            "chunk_interval": args.chunk_interval,
            "encoder_chunk_look_back": args.encoder_chunk_look_back,
            "decoder_chunk_look_back": args.decoder_chunk_look_back,
            "wav_name": "microphone",
            "is_speaking": True,
            "hotwords": hotword_msg,
            "itn": use_itn,
        }
    )
    # voices.put(message)
    await websocket.send(message)
    while True:
        data = stream.read(CHUNK)
        message = data
        # voices.put(message)
        await websocket.send(message)
        await asyncio.sleep(0.005)


async def record_from_scp(chunk_begin, chunk_size):
    global voices
    is_finished = False
    if args.audio_in.endswith(".scp"):
        f_scp = open(args.audio_in)
        wavs = f_scp.readlines()
    else:
        wavs = [args.audio_in]

    # hotwords
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        if os.path.exists(args.hotword):
            f_scp = open(args.hotword)
            hot_lines = f_scp.readlines()
            for line in hot_lines:
                words = line.strip().split(" ")
                if len(words) < 2:
                    print("Please checkout format of hotwords")
                    continue
                try:
                    fst_dict[" ".join(words[:-1])] = int(words[-1])
                except ValueError:
                    print("Please checkout format of hotwords")
            hotword_msg = json.dumps(fst_dict)
        else:
            hotword_msg = args.hotword
        print(hotword_msg)

    sample_rate = args.audio_fs
    wav_format = "pcm"
    use_itn = True
    if args.use_itn == 0:
        use_itn = False

    if chunk_size > 0:
        wavs = wavs[chunk_begin : chunk_begin + chunk_size]
    for wav in wavs:
        wav_splits = wav.strip().split()

        wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
        wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
        if not len(wav_path.strip()) > 0:
            continue
        if wav_path.endswith(".pcm"):
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()
        elif wav_path.endswith(".wav"):
            import wave

            with wave.open(wav_path, "rb") as wav_file:
                params = wav_file.getparams()
                sample_rate = wav_file.getframerate()
                frames = wav_file.readframes(wav_file.getnframes())
                audio_bytes = bytes(frames)
        else:
            wav_format = "others"
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()

        stride = int(60 * args.chunk_size[1] / args.chunk_interval / 1000 * sample_rate * 2)
        chunk_num = (len(audio_bytes) - 1) // stride + 1
        # print(stride)

        # send first time
        message = json.dumps(
            {
                "mode": args.mode,
                "chunk_size": args.chunk_size,
                "chunk_interval": args.chunk_interval,
                "encoder_chunk_look_back": args.encoder_chunk_look_back,
                "decoder_chunk_look_back": args.decoder_chunk_look_back,
                "audio_fs": sample_rate,
                "wav_name": wav_name,
                "wav_format": wav_format,
                "is_speaking": True,
                "hotwords": hotword_msg,
                "itn": use_itn,
            }
        )

        # voices.put(message)
        await websocket.send(message)
        is_speaking = True
        for i in range(chunk_num):

            beg = i * stride
            data = audio_bytes[beg : beg + stride]
            message = data
            # voices.put(message)
            await websocket.send(message)
            if i == chunk_num - 1:
                is_speaking = False
                message = json.dumps({"is_speaking": is_speaking})
                # voices.put(message)
                await websocket.send(message)

            sleep_duration = (
                0.001
                if args.mode == "offline"
                else 60 * args.chunk_size[1] / args.chunk_interval / 1000
            )

            await asyncio.sleep(sleep_duration)

    if not args.mode == "offline":
        await asyncio.sleep(2)
    # offline model need to wait for message recved

    if args.mode == "offline":
        global offline_msg_done
        while not offline_msg_done:
            await asyncio.sleep(1)

    await websocket.close()


async def message(id):
    global websocket, voices, offline_msg_done
    text_print = ""
    text_print_2pass_online = ""
    text_print_2pass_offline = ""
    if args.output_dir is not None:
        ibest_writer = open(
            os.path.join(args.output_dir, "text.{}".format(id)), "a", encoding="utf-8"
        )
    else:
        ibest_writer = None
    try:
        while True:

            meg = await websocket.recv()
            meg = json.loads(meg)
            wav_name = meg.get("wav_name", "demo")
            text = meg["text"]
            timestamp = ""
            offline_msg_done = meg.get("is_final", False)
            if "timestamp" in meg:
                timestamp = meg["timestamp"]

            if ibest_writer is not None:
                if timestamp != "":
                    text_write_line = "{}\t{}\t{}\n".format(wav_name, text, timestamp)
                else:
                    text_write_line = "{}\t{}\n".format(wav_name, text)
                ibest_writer.write(text_write_line)

            if "mode" not in meg:
                continue
            if meg["mode"] == "online":
                text_print += "{}".format(text)
                text_print = text_print[-args.words_max_print :]
                os.system("clear")
                print("\rpid" + str(id) + ": " + text_print)
            elif meg["mode"] == "offline":
                if timestamp != "":
                    text_print += "{} timestamp: {}".format(text, timestamp)
                else:
                    text_print += "{}".format(text)

                # text_print = text_print[-args.words_max_print:]
                # os.system('clear')
                print("\rpid" + str(id) + ": " + wav_name + ": " + text_print)
                offline_msg_done = True
            else:
                if meg["mode"] == "2pass-online":
                    text_print_2pass_online += "{}".format(text)
                    text_print = text_print_2pass_offline + text_print_2pass_online
                else:
                    text_print_2pass_online = ""
                    text_print = text_print_2pass_offline + "{}".format(text)
                    text_print_2pass_offline += "{}".format(text)
                text_print = text_print[-args.words_max_print :]
                os.system("clear")
                print("\rpid" + str(id) + ": " + text_print)
                # offline_msg_done=True

    except Exception as e:
        print("Exception:", e)
        # traceback.print_exc()
        # await websocket.close()


async def ws_client(id, chunk_begin, chunk_size):
    if args.audio_in is None:
        chunk_begin = 0
        chunk_size = 1
    global websocket, voices, offline_msg_done

    for i in range(chunk_begin, chunk_begin + chunk_size):
        offline_msg_done = False
        voices = Queue()
        if args.ssl == 1:
            ssl_context = ssl.SSLContext()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE
            uri = "wss://{}:{}".format(args.host, args.port)
        else:
            uri = "ws://{}:{}".format(args.host, args.port)
            ssl_context = None
        print("connect to", uri)
        async with websockets.connect(
            uri, subprotocols=["binary"], ping_interval=None, ssl=ssl_context
        ) as websocket:
            if args.audio_in is not None:
                task = asyncio.create_task(record_from_scp(i, 1))
            else:
                task = asyncio.create_task(record_microphone())
            task3 = asyncio.create_task(message(str(id) + "_" + str(i)))  # processid+fileid
            await asyncio.gather(task, task3)
    exit(0)


def one_thread(id, chunk_begin, chunk_size):
    asyncio.get_event_loop().run_until_complete(ws_client(id, chunk_begin, chunk_size))
    asyncio.get_event_loop().run_forever()


if __name__ == "__main__":
    # for microphone
    if args.audio_in is None:
        p = Process(target=one_thread, args=(0, 0, 0))
        p.start()
        p.join()
        print("end")
    else:
        # calculate the number of wavs for each preocess
        if args.audio_in.endswith(".scp"):
            f_scp = open(args.audio_in)
            wavs = f_scp.readlines()
        else:
            wavs = [args.audio_in]
        for wav in wavs:
            wav_splits = wav.strip().split()
            wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
            wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
            audio_type = os.path.splitext(wav_path)[-1].lower()

        total_len = len(wavs)
        if total_len >= args.thread_num:
            chunk_size = int(total_len / args.thread_num)
            remain_wavs = total_len - chunk_size * args.thread_num
        else:
            chunk_size = 1
            remain_wavs = 0

        process_list = []
        chunk_begin = 0
        for i in range(args.thread_num):
            now_chunk_size = chunk_size
            if remain_wavs > 0:
                now_chunk_size = chunk_size + 1
                remain_wavs = remain_wavs - 1
            # process i handle wavs at chunk_begin and size of now_chunk_size
            p = Process(target=one_thread, args=(i, chunk_begin, now_chunk_size))
            chunk_begin = chunk_begin + now_chunk_size
            p.start()
            process_list.append(p)

        for i in process_list:
            p.join()

        print("end")
```

--------------------------------------------------------------------------------

File: asr_system_backend/asr_system_backend/app/client/funasr_wss_client.py
```python
# -*- encoding: utf-8 -*-
import os
import time
import websockets, ssl
import asyncio

# import threading
import argparse
import json
import traceback
from multiprocessing import Process

# from funasr.fileio.datadir_writer import DatadirWriter

import logging

logging.basicConfig(level=logging.ERROR)

parser = argparse.ArgumentParser()
parser.add_argument(
    "--host", type=str, default="localhost", required=False, help="host ip, localhost, 0.0.0.0"
)
parser.add_argument("--port", type=int, default=10095, required=False, help="grpc server port")
parser.add_argument("--chunk_size", type=str, default="5, 10, 5", help="chunk")
parser.add_argument("--encoder_chunk_look_back", type=int, default=4, help="chunk")
parser.add_argument("--decoder_chunk_look_back", type=int, default=0, help="chunk")
parser.add_argument("--chunk_interval", type=int, default=10, help="chunk")
parser.add_argument(
    "--hotword",
    type=str,
    default="",
    help="hotword file path, one hotword perline (e.g.:é˜¿é‡Œå·´å·´ 20)",
)
parser.add_argument("--audio_in", type=str, default=None, help="audio_in")
parser.add_argument("--audio_fs", type=int, default=16000, help="audio_fs")
parser.add_argument(
    "--send_without_sleep",
    action="store_true",
    default=True,
    help="if audio_in is set, send_without_sleep",
)
parser.add_argument("--thread_num", type=int, default=1, help="thread_num")
parser.add_argument("--words_max_print", type=int, default=10000, help="chunk")
parser.add_argument("--output_dir", type=str, default=None, help="output_dir")
parser.add_argument("--ssl", type=int, default=1, help="1 for ssl connect, 0 for no ssl")
parser.add_argument("--use_itn", type=int, default=1, help="1 for using itn, 0 for not itn")
parser.add_argument("--mode", type=str, default="2pass", help="offline, online, 2pass")

args = parser.parse_args()
args.chunk_size = [int(x) for x in args.chunk_size.split(",")]
print(args)
# voices = asyncio.Queue()
from queue import Queue

voices = Queue()
offline_msg_done = False

if args.output_dir is not None:
    # if os.path.exists(args.output_dir):
    #     os.remove(args.output_dir)

    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir)


async def record_microphone():
    is_finished = False
    import pyaudio

    # print("2")
    global voices
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    chunk_size = 60 * args.chunk_size[1] / args.chunk_interval
    CHUNK = int(RATE / 1000 * chunk_size)

    p = pyaudio.PyAudio()

    stream = p.open(
        format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK
    )
    # hotwords
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        if os.path.exists(args.hotword):
            f_scp = open(args.hotword)
            hot_lines = f_scp.readlines()
            for line in hot_lines:
                words = line.strip().split(" ")
                if len(words) < 2:
                    print("Please checkout format of hotwords")
                    continue
                try:
                    fst_dict[" ".join(words[:-1])] = int(words[-1])
                except ValueError:
                    print("Please checkout format of hotwords")
            hotword_msg = json.dumps(fst_dict)
        else:
            hotword_msg = args.hotword

    use_itn = True
    if args.use_itn == 0:
        use_itn = False

    message = json.dumps(
        {
            "mode": args.mode,
            "chunk_size": args.chunk_size,
            "chunk_interval": args.chunk_interval,
            "encoder_chunk_look_back": args.encoder_chunk_look_back,
            "decoder_chunk_look_back": args.decoder_chunk_look_back,
            "wav_name": "microphone",
            "is_speaking": True,
            "hotwords": hotword_msg,
            "itn": use_itn,
        }
    )
    # voices.put(message)
    await websocket.send(message)
    while True:
        data = stream.read(CHUNK)
        message = data
        # voices.put(message)
        await websocket.send(message)
        await asyncio.sleep(0.005)


async def record_from_scp(chunk_begin, chunk_size):
    global voices
    is_finished = False
    if args.audio_in.endswith(".scp"):
        f_scp = open(args.audio_in)
        wavs = f_scp.readlines()
    else:
        wavs = [args.audio_in]

    # hotwords
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        if os.path.exists(args.hotword):
            f_scp = open(args.hotword)
            hot_lines = f_scp.readlines()
            for line in hot_lines:
                words = line.strip().split(" ")
                if len(words) < 2:
                    print("Please checkout format of hotwords")
                    continue
                try:
                    fst_dict[" ".join(words[:-1])] = int(words[-1])
                except ValueError:
                    print("Please checkout format of hotwords")
            hotword_msg = json.dumps(fst_dict)
        else:
            hotword_msg = args.hotword
        print(hotword_msg)

    sample_rate = args.audio_fs
    wav_format = "pcm"
    use_itn = True
    if args.use_itn == 0:
        use_itn = False

    if chunk_size > 0:
        wavs = wavs[chunk_begin : chunk_begin + chunk_size]
    for wav in wavs:
        wav_splits = wav.strip().split()

        wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
        wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
        if not len(wav_path.strip()) > 0:
            continue
        if wav_path.endswith(".pcm"):
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()
        elif wav_path.endswith(".wav"):
            import wave

            with wave.open(wav_path, "rb") as wav_file:
                params = wav_file.getparams()
                sample_rate = wav_file.getframerate()
                frames = wav_file.readframes(wav_file.getnframes())
                audio_bytes = bytes(frames)
        else:
            wav_format = "others"
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()

        stride = int(60 * args.chunk_size[1] / args.chunk_interval / 1000 * sample_rate * 2)
        chunk_num = (len(audio_bytes) - 1) // stride + 1
        # print(stride)

        # send first time
        message = json.dumps(
            {
                "mode": args.mode,
                "chunk_size": args.chunk_size,
                "chunk_interval": args.chunk_interval,
                "encoder_chunk_look_back": args.encoder_chunk_look_back,
                "decoder_chunk_look_back": args.decoder_chunk_look_back,
                "audio_fs": sample_rate,
                "wav_name": wav_name,
                "wav_format": wav_format,
                "is_speaking": True,
                "hotwords": hotword_msg,
                "itn": use_itn,
            }
        )

        # voices.put(message)
        await websocket.send(message)
        is_speaking = True
        for i in range(chunk_num):

            beg = i * stride
            data = audio_bytes[beg : beg + stride]
            message = data
            # voices.put(message)
            await websocket.send(message)
            if i == chunk_num - 1:
                is_speaking = False
                message = json.dumps({"is_speaking": is_speaking})
                # voices.put(message)
                await websocket.send(message)

            sleep_duration = (
                0.001
                if args.mode == "offline"
                else 60 * args.chunk_size[1] / args.chunk_interval / 1000
            )

            await asyncio.sleep(sleep_duration)

    if not args.mode == "offline":
        await asyncio.sleep(2)
    # offline model need to wait for message recved

    if args.mode == "offline":
        global offline_msg_done
        while not offline_msg_done:
            await asyncio.sleep(1)

    await websocket.close()


async def message(id):
    global websocket, voices, offline_msg_done
    text_print = ""
    text_print_2pass_online = ""
    text_print_2pass_offline = ""
    if args.output_dir is not None:
        ibest_writer = open(
            os.path.join(args.output_dir, "text.{}".format(id)), "a", encoding="utf-8"
        )
    else:
        ibest_writer = None
    try:
        while True:

            meg = await websocket.recv()
            meg = json.loads(meg)
            wav_name = meg.get("wav_name", "demo")
            text = meg["text"]
            timestamp = ""
            offline_msg_done = meg.get("is_final", False)
            if "timestamp" in meg:
                timestamp = meg["timestamp"]

            if ibest_writer is not None:
                if timestamp != "":
                    text_write_line = "{}\t{}\t{}\n".format(wav_name, text, timestamp)
                else:
                    text_write_line = "{}\t{}\n".format(wav_name, text)
                ibest_writer.write(text_write_line)

            if "mode" not in meg:
                continue
            if meg["mode"] == "online":
                text_print += "{}".format(text)
                text_print = text_print[-args.words_max_print :]
                os.system("clear")
                print("\rpid" + str(id) + ": " + text_print)
            elif meg["mode"] == "offline":
                if timestamp != "":
                    text_print += "{} timestamp: {}".format(text, timestamp)
                else:
                    text_print += "{}".format(text)

                # text_print = text_print[-args.words_max_print:]
                # os.system('clear')
                print("\rpid" + str(id) + ": " + wav_name + ": " + text_print)
                offline_msg_done = True
            else:
                if meg["mode"] == "2pass-online":
                    text_print_2pass_online += "{}".format(text)
                    text_print = text_print_2pass_offline + text_print_2pass_online
                else:
                    text_print_2pass_online = ""
                    text_print = text_print_2pass_offline + "{}".format(text)
                    text_print_2pass_offline += "{}".format(text)
                text_print = text_print[-args.words_max_print :]
                os.system("clear")
                print("\rpid" + str(id) + ": " + text_print)
                # offline_msg_done=True

    except Exception as e:
        print("Exception:", e)
        # traceback.print_exc()
        # await websocket.close()


async def ws_client(id, chunk_begin, chunk_size):
    if args.audio_in is None:
        chunk_begin = 0
        chunk_size = 1
    global websocket, voices, offline_msg_done

    for i in range(chunk_begin, chunk_begin + chunk_size):
        offline_msg_done = False
        voices = Queue()
        if args.ssl == 1:
            ssl_context = ssl.SSLContext()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE
            uri = "wss://{}:{}".format(args.host, args.port)
        else:
            uri = "ws://{}:{}".format(args.host, args.port)
            ssl_context = None
        print("connect to", uri)
        async with websockets.connect(
            uri, subprotocols=["binary"], ping_interval=None, ssl=ssl_context
        ) as websocket:
            if args.audio_in is not None:
                task = asyncio.create_task(record_from_scp(i, 1))
            else:
                task = asyncio.create_task(record_microphone())
            task3 = asyncio.create_task(message(str(id) + "_" + str(i)))  # processid+fileid
            await asyncio.gather(task, task3)
    exit(0)


def one_thread(id, chunk_begin, chunk_size):
    asyncio.get_event_loop().run_until_complete(ws_client(id, chunk_begin, chunk_size))
    asyncio.get_event_loop().run_forever()


if __name__ == "__main__":
    # for microphone
    if args.audio_in is None:
        p = Process(target=one_thread, args=(0, 0, 0))
        p.start()
        p.join()
        print("end")
    else:
        # calculate the number of wavs for each preocess
        if args.audio_in.endswith(".scp"):
            f_scp = open(args.audio_in)
            wavs = f_scp.readlines()
        else:
            wavs = [args.audio_in]
        for wav in wavs:
            wav_splits = wav.strip().split()
            wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
            wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
            audio_type = os.path.splitext(wav_path)[-1].lower()

        total_len = len(wavs)
        if total_len >= args.thread_num:
            chunk_size = int(total_len / args.thread_num)
            remain_wavs = total_len - chunk_size * args.thread_num
        else:
            chunk_size = 1
            remain_wavs = 0

        process_list = []
        chunk_begin = 0
        for i in range(args.thread_num):
            now_chunk_size = chunk_size
            if remain_wavs > 0:
                now_chunk_size = chunk_size + 1
                remain_wavs = remain_wavs - 1
            # process i handle wavs at chunk_begin and size of now_chunk_size
            p = Process(target=one_thread, args=(i, chunk_begin, now_chunk_size))
            chunk_begin = chunk_begin + now_chunk_size
            p.start()
            process_list.append(p)

        for i in process_list:
            p.join()

        print("end")
```

--------------------------------------------------------------------------------

File: sql/0001_initial_schema.sql
```sql
-- æ–‡ä»¶å: 0001_initial_schema.sql
-- æè¿°: åˆ›å»ºé¡¹ç›®æ‰€éœ€çš„å…¨éƒ¨æ ¸å¿ƒè¡¨ç»“æ„ï¼ˆPostgreSQLç‰ˆï¼‰

-- 1. åˆ›å»ºè‡ªå®šä¹‰ENUMç±»å‹ï¼Œç”¨äºä»»åŠ¡çŠ¶æ€
CREATE TYPE task_status AS ENUM ('pending', 'processing', 'completed', 'failed');

-- 2. åˆ›å»º users è¡¨
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(255) NOT NULL UNIQUE,
    hashed_password VARCHAR(255) NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP
);
COMMENT ON TABLE users IS 'å­˜å‚¨ç³»ç»Ÿç”¨æˆ·ä¿¡æ¯';

-- 3. åˆ›å»º hotwords è¡¨
CREATE TABLE hotwords (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    word VARCHAR(255) NOT NULL,
    weight INTEGER NOT NULL DEFAULT 5 CHECK (weight >= 1 AND weight <= 10),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
    UNIQUE (user_id, word)
);
COMMENT ON TABLE hotwords IS 'å­˜å‚¨ç”¨æˆ·è‡ªå®šä¹‰çš„çƒ­è¯';
CREATE INDEX idx_hotwords_user_id ON hotwords(user_id);

-- 4. åˆ›å»º transcription_tasks è¡¨
CREATE TABLE transcription_tasks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    status task_status NOT NULL DEFAULT 'pending',
    error_message TEXT,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP WITH TIME ZONE
);
COMMENT ON TABLE transcription_tasks IS 'è®°å½•è¯­éŸ³è½¬å†™ä»»åŠ¡';
CREATE INDEX idx_tasks_user_id ON transcription_tasks(user_id);
CREATE INDEX idx_tasks_status ON transcription_tasks(status);

-- 5. åˆ›å»º transcription_segments è¡¨
CREATE TABLE transcription_segments (
    id BIGSERIAL PRIMARY KEY,
    task_id UUID NOT NULL REFERENCES transcription_tasks(id) ON DELETE CASCADE,
    start_time FLOAT NOT NULL,
    end_time FLOAT NOT NULL,
    text TEXT NOT NULL,
    confidence FLOAT
);
COMMENT ON TABLE transcription_segments IS 'å­˜å‚¨ç»“æ„åŒ–çš„è½¬å†™ç»“æœåˆ†æ®µ';
CREATE INDEX idx_segments_task_id ON transcription_segments(task_id);
```

--------------------------------------------------------------------------------

File: .git/config
```text
[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
[remote "origin"]
	url = git@github.com:Miki-Riako/asr-system.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "main"]
	remote = origin
	merge = refs/heads/main
	vscode-merge-base = origin/main
```

--------------------------------------------------------------------------------

File: .git/packed-refs
```text
# pack-refs with: peeled fully-peeled sorted 
e076f06e191466160a18c4129749553ce100258b refs/remotes/origin/main
```

--------------------------------------------------------------------------------

File: .git/ORIG_HEAD
```text
6481a932458e144c6fc11d7cd8c3e1deae2083e9
```

--------------------------------------------------------------------------------

File: .git/COMMIT_EDITMSG
```text
commit
```

--------------------------------------------------------------------------------

File: .git/description
```text
Unnamed repository; edit this file 'description' to name the repository.
```

--------------------------------------------------------------------------------

File: .git/FETCH_HEAD
```text
6724e78d9de92025ea2292ac1af3abb3293c8fd7		branch 'main' of github.com:Miki-Riako/asr-system
```

--------------------------------------------------------------------------------

File: .git/HEAD
```text
ref: refs/heads/main
```

--------------------------------------------------------------------------------

File: .git/logs/HEAD
```text
0000000000000000000000000000000000000000 e076f06e191466160a18c4129749553ce100258b ght <ght0719@qq.com> 1751858378 +0800	clone: from github.com:Miki-Riako/asr-system.git
e076f06e191466160a18c4129749553ce100258b 7b03493583299eb0c1c69523a15e58c293be855a ght <ght0719@qq.com> 1751859594 +0800	pull: Fast-forward
7b03493583299eb0c1c69523a15e58c293be855a 2a0f6dae50abdc215cbaecb360b28950d316672c ght <ght0719@qq.com> 1752461771 +0800	pull: Fast-forward
2a0f6dae50abdc215cbaecb360b28950d316672c 2a0f6dae50abdc215cbaecb360b28950d316672c ght <ght0719@qq.com> 1752590635 +0800	reset: moving to HEAD
2a0f6dae50abdc215cbaecb360b28950d316672c 380f44c7fd1c86822b3fbdf073274421c621e9ee ght <ght0719@qq.com> 1752675833 +0800	reset: moving to HEAD~1
380f44c7fd1c86822b3fbdf073274421c621e9ee 1254ba52a2eda6ca6d949d3583ead8317d7a6e8c ght <ght0719@qq.com> 1752675851 +0800	reset: moving to HEAD~1
1254ba52a2eda6ca6d949d3583ead8317d7a6e8c 2a0f6dae50abdc215cbaecb360b28950d316672c ght <ght0719@qq.com> 1752675914 +0800	pull: Fast-forward
2a0f6dae50abdc215cbaecb360b28950d316672c 471c9e993f5a04345d621245862ef4e06dc969d2 ght <ght0719@qq.com> 1752688313 +0800	commit: è½¬å†™
471c9e993f5a04345d621245862ef4e06dc969d2 3eb26444660cd32b7ada80e490c927676e0725fe ght <ght0719@qq.com> 1752693197 +0800	commit: commit
3eb26444660cd32b7ada80e490c927676e0725fe da063928fee9b5544dfa01ba1647a072f04f7115 ght <ght0719@qq.com> 1752719908 +0800	commit: commit
da063928fee9b5544dfa01ba1647a072f04f7115 3eb26444660cd32b7ada80e490c927676e0725fe ght <ght0719@qq.com> 1752721726 +0800	reset: moving to HEAD~1
3eb26444660cd32b7ada80e490c927676e0725fe 471c9e993f5a04345d621245862ef4e06dc969d2 ght <ght0719@qq.com> 1752721732 +0800	reset: moving to HEAD~1
471c9e993f5a04345d621245862ef4e06dc969d2 2a0f6dae50abdc215cbaecb360b28950d316672c ght <ght0719@qq.com> 1752721736 +0800	reset: moving to HEAD~1
2a0f6dae50abdc215cbaecb360b28950d316672c 32bf3540ec39caf599c7a3d1410d1735e5dd676f ght <ght0719@qq.com> 1752721819 +0800	commit: update
32bf3540ec39caf599c7a3d1410d1735e5dd676f c754c505ee78fb4535c05269acd33ebc2fbf8661 ght <ght0719@qq.com> 1752721829 +0800	commit: update
c754c505ee78fb4535c05269acd33ebc2fbf8661 09894afad25a2ddf6a20c338d7a766b2fa842fec ght <ght0719@qq.com> 1752752300 +0800	pull: Fast-forward
09894afad25a2ddf6a20c338d7a766b2fa842fec a3c308bb7e5d81b3eb68858d3b0a8d14e5178e1d ght <ght0719@qq.com> 1752760723 +0800	commit: ç½‘é¡µæŠ¥é”™æ”¹å¥½
a3c308bb7e5d81b3eb68858d3b0a8d14e5178e1d e106eb2cd515bc83e8e1123ff617a54b481a7b0b ght <ght0719@qq.com> 1752760891 +0800	commit: update
e106eb2cd515bc83e8e1123ff617a54b481a7b0b e106eb2cd515bc83e8e1123ff617a54b481a7b0b ght <ght0719@qq.com> 1752768200 +0800	reset: moving to origin/main
e106eb2cd515bc83e8e1123ff617a54b481a7b0b 6724e78d9de92025ea2292ac1af3abb3293c8fd7 ght <ght0719@qq.com> 1752771217 +0800	commit: commit
6724e78d9de92025ea2292ac1af3abb3293c8fd7 6481a932458e144c6fc11d7cd8c3e1deae2083e9 ght <ght0719@qq.com> 1752771732 +0800	commit: commit
6481a932458e144c6fc11d7cd8c3e1deae2083e9 6481a932458e144c6fc11d7cd8c3e1deae2083e9 ght <ght0719@qq.com> 1752773646 +0800	reset: moving to origin/main
```

--------------------------------------------------------------------------------

File: .git/logs/refs/heads/main
```text
0000000000000000000000000000000000000000 e076f06e191466160a18c4129749553ce100258b ght <ght0719@qq.com> 1751858378 +0800	clone: from github.com:Miki-Riako/asr-system.git
e076f06e191466160a18c4129749553ce100258b 7b03493583299eb0c1c69523a15e58c293be855a ght <ght0719@qq.com> 1751859594 +0800	pull: Fast-forward
7b03493583299eb0c1c69523a15e58c293be855a 2a0f6dae50abdc215cbaecb360b28950d316672c ght <ght0719@qq.com> 1752461771 +0800	pull: Fast-forward
2a0f6dae50abdc215cbaecb360b28950d316672c 380f44c7fd1c86822b3fbdf073274421c621e9ee ght <ght0719@qq.com> 1752675833 +0800	reset: moving to HEAD~1
380f44c7fd1c86822b3fbdf073274421c621e9ee 1254ba52a2eda6ca6d949d3583ead8317d7a6e8c ght <ght0719@qq.com> 1752675851 +0800	reset: moving to HEAD~1
1254ba52a2eda6ca6d949d3583ead8317d7a6e8c 2a0f6dae50abdc215cbaecb360b28950d316672c ght <ght0719@qq.com> 1752675914 +0800	pull: Fast-forward
2a0f6dae50abdc215cbaecb360b28950d316672c 471c9e993f5a04345d621245862ef4e06dc969d2 ght <ght0719@qq.com> 1752688313 +0800	commit: è½¬å†™
471c9e993f5a04345d621245862ef4e06dc969d2 3eb26444660cd32b7ada80e490c927676e0725fe ght <ght0719@qq.com> 1752693197 +0800	commit: commit
3eb26444660cd32b7ada80e490c927676e0725fe da063928fee9b5544dfa01ba1647a072f04f7115 ght <ght0719@qq.com> 1752719908 +0800	commit: commit
da063928fee9b5544dfa01ba1647a072f04f7115 3eb26444660cd32b7ada80e490c927676e0725fe ght <ght0719@qq.com> 1752721726 +0800	reset: moving to HEAD~1
3eb26444660cd32b7ada80e490c927676e0725fe 471c9e993f5a04345d621245862ef4e06dc969d2 ght <ght0719@qq.com> 1752721732 +0800	reset: moving to HEAD~1
471c9e993f5a04345d621245862ef4e06dc969d2 2a0f6dae50abdc215cbaecb360b28950d316672c ght <ght0719@qq.com> 1752721736 +0800	reset: moving to HEAD~1
2a0f6dae50abdc215cbaecb360b28950d316672c 32bf3540ec39caf599c7a3d1410d1735e5dd676f ght <ght0719@qq.com> 1752721819 +0800	commit: update
32bf3540ec39caf599c7a3d1410d1735e5dd676f c754c505ee78fb4535c05269acd33ebc2fbf8661 ght <ght0719@qq.com> 1752721829 +0800	commit: update
c754c505ee78fb4535c05269acd33ebc2fbf8661 09894afad25a2ddf6a20c338d7a766b2fa842fec ght <ght0719@qq.com> 1752752300 +0800	pull: Fast-forward
09894afad25a2ddf6a20c338d7a766b2fa842fec a3c308bb7e5d81b3eb68858d3b0a8d14e5178e1d ght <ght0719@qq.com> 1752760723 +0800	commit: ç½‘é¡µæŠ¥é”™æ”¹å¥½
a3c308bb7e5d81b3eb68858d3b0a8d14e5178e1d e106eb2cd515bc83e8e1123ff617a54b481a7b0b ght <ght0719@qq.com> 1752760891 +0800	commit: update
e106eb2cd515bc83e8e1123ff617a54b481a7b0b 6724e78d9de92025ea2292ac1af3abb3293c8fd7 ght <ght0719@qq.com> 1752771217 +0800	commit: commit
6724e78d9de92025ea2292ac1af3abb3293c8fd7 6481a932458e144c6fc11d7cd8c3e1deae2083e9 ght <ght0719@qq.com> 1752771732 +0800	commit: commit
```

--------------------------------------------------------------------------------

File: .git/logs/refs/remotes/origin/main
```text
e076f06e191466160a18c4129749553ce100258b 7b03493583299eb0c1c69523a15e58c293be855a ght <ght0719@qq.com> 1751859594 +0800	pull: fast-forward
7b03493583299eb0c1c69523a15e58c293be855a 380f44c7fd1c86822b3fbdf073274421c621e9ee ght <ght0719@qq.com> 1752460094 +0800	pull: fast-forward
380f44c7fd1c86822b3fbdf073274421c621e9ee 2a0f6dae50abdc215cbaecb360b28950d316672c ght <ght0719@qq.com> 1752461771 +0800	pull: fast-forward
2a0f6dae50abdc215cbaecb360b28950d316672c c754c505ee78fb4535c05269acd33ebc2fbf8661 ght <ght0719@qq.com> 1752722056 +0800	update by push
c754c505ee78fb4535c05269acd33ebc2fbf8661 09894afad25a2ddf6a20c338d7a766b2fa842fec ght <ght0719@qq.com> 1752752300 +0800	pull: fast-forward
09894afad25a2ddf6a20c338d7a766b2fa842fec e106eb2cd515bc83e8e1123ff617a54b481a7b0b ght <ght0719@qq.com> 1752760916 +0800	update by push
e106eb2cd515bc83e8e1123ff617a54b481a7b0b 6724e78d9de92025ea2292ac1af3abb3293c8fd7 ght <ght0719@qq.com> 1752771352 +0800	update by push
6724e78d9de92025ea2292ac1af3abb3293c8fd7 6481a932458e144c6fc11d7cd8c3e1deae2083e9 ght <ght0719@qq.com> 1752771751 +0800	update by push
```

--------------------------------------------------------------------------------

File: .git/logs/refs/remotes/origin/HEAD
```text
0000000000000000000000000000000000000000 e076f06e191466160a18c4129749553ce100258b ght <ght0719@qq.com> 1751858378 +0800	clone: from github.com:Miki-Riako/asr-system.git
```

--------------------------------------------------------------------------------

File: .git/hooks/pre-merge-commit.sample
```text
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup
test -x "$GIT_DIR/hooks/pre-commit" &&
        exec "$GIT_DIR/hooks/pre-commit"
:
```

--------------------------------------------------------------------------------

File: .git/hooks/commit-msg.sample
```text
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}
```

--------------------------------------------------------------------------------

File: .git/hooks/fsmonitor-watchman.sample
```text
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 2) and last update token
# formatted as a string and outputs to stdout a new update token and
# all files that have been modified since the update token. Paths must
# be relative to the root of the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $last_update_token) = @ARGV;

# Uncomment for debugging
# print STDERR "$0 $version $last_update_token\n";

# Check the hook interface version
if ($version ne 2) {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree = get_working_dir();

my $retry = 1;

my $json_pkg;
eval {
	require JSON::XS;
	$json_pkg = "JSON::XS";
	1;
} or do {
	require JSON::PP;
	$json_pkg = "JSON::PP";
};

launch_watchman();

sub launch_watchman {
	my $o = watchman_query();
	if (is_work_tree_watched($o)) {
		output_result($o->{clock}, @{$o->{files}});
	}
}

sub output_result {
	my ($clockid, @files) = @_;

	# Uncomment for debugging watchman output
	# open (my $fh, ">", ".git/watchman-output.out");
	# binmode $fh, ":utf8";
	# print $fh "$clockid\n@files\n";
	# close $fh;

	binmode STDOUT, ":utf8";
	print $clockid;
	print "\0";
	local $, = "\0";
	print @files;
}

sub watchman_clock {
	my $response = qx/watchman clock "$git_work_tree"/;
	die "Failed to get clock id on '$git_work_tree'.\n" .
		"Falling back to scanning...\n" if $? != 0;

	return $json_pkg->new->utf8->decode($response);
}

sub watchman_query {
	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	or die "open2() failed: $!\n" .
	"Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $last_update_token but not from the .git folder.
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	if (substr($last_update_token, 0, 1) eq "c") {
		$last_update_token = "\"$last_update_token\"";
	}
	my $query = <<"	END";
		["query", "$git_work_tree", {
			"since": $last_update_token,
			"fields": ["name"],
			"expression": ["not", ["dirname", ".git"]]
		}]
	END

	# Uncomment for debugging the watchman query
	# open (my $fh, ">", ".git/watchman-query.json");
	# print $fh $query;
	# close $fh;

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	# Uncomment for debugging the watch response
	# open ($fh, ">", ".git/watchman-response.json");
	# print $fh $response;
	# close $fh;

	die "Watchman: command returned no output.\n" .
	"Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	"Falling back to scanning...\n" unless $response =~ /^\{/;

	return $json_pkg->new->utf8->decode($response);
}

sub is_work_tree_watched {
	my ($output) = @_;
	my $error = $output->{error};
	if ($retry > 0 and $error and $error =~ m/unable to resolve root .* directory (.*) is not watched/) {
		$retry--;
		my $response = qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;
		$output = $json_pkg->new->utf8->decode($response);
		$error = $output->{error};
		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		# Uncomment for debugging watchman output
		# open (my $fh, ">", ".git/watchman-output.out");
		# close $fh;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		my $o = watchman_clock();
		$error = $output->{error};

		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		output_result($o->{clock}, ("/"));
		$last_update_token = $o->{clock};

		eval { launch_watchman() };
		return 0;
	}

	die "Watchman: $error.\n" .
	"Falling back to scanning...\n" if $error;

	return 1;
}

sub get_working_dir {
	my $working_dir;
	if ($^O =~ 'msys' || $^O =~ 'cygwin') {
		$working_dir = Win32::GetCwd();
		$working_dir =~ tr/\\/\//;
	} else {
		require Cwd;
		$working_dir = Cwd::cwd();
	}

	return $working_dir;
}
```

--------------------------------------------------------------------------------

File: .git/hooks/prepare-commit-msg.sample
```text
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi
```

--------------------------------------------------------------------------------

File: .git/hooks/post-update.sample
```text
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info
```

--------------------------------------------------------------------------------

File: .git/hooks/update.sample
```text
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --type=bool hooks.allowunannotated)
allowdeletebranch=$(git config --type=bool hooks.allowdeletebranch)
denycreatebranch=$(git config --type=bool hooks.denycreatebranch)
allowdeletetag=$(git config --type=bool hooks.allowdeletetag)
allowmodifytag=$(git config --type=bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0
```

--------------------------------------------------------------------------------

File: .git/hooks/pre-rebase.sample
```text
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END
```

--------------------------------------------------------------------------------

File: .git/hooks/applypatch-msg.sample
```text
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:
```

--------------------------------------------------------------------------------

File: .git/hooks/pre-receive.sample
```text
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi
```

--------------------------------------------------------------------------------

File: .git/hooks/pre-applypatch.sample
```text
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:
```

--------------------------------------------------------------------------------

File: .git/hooks/push-to-checkout.sample
```text
#!/bin/sh

# An example hook script to update a checked-out tree on a git push.
#
# This hook is invoked by git-receive-pack(1) when it reacts to git
# push and updates reference(s) in its repository, and when the push
# tries to update the branch that is currently checked out and the
# receive.denyCurrentBranch configuration variable is set to
# updateInstead.
#
# By default, such a push is refused if the working tree and the index
# of the remote repository has any difference from the currently
# checked out commit; when both the working tree and the index match
# the current commit, they are updated to match the newly pushed tip
# of the branch. This hook is to be used to override the default
# behaviour; however the code below reimplements the default behaviour
# as a starting point for convenient modification.
#
# The hook receives the commit with which the tip of the current
# branch is going to be updated:
commit=$1

# It can exit with a non-zero status to refuse the push (when it does
# so, it must not modify the index or the working tree).
die () {
	echo >&2 "$*"
	exit 1
}

# Or it can make any necessary changes to the working tree and to the
# index to bring them to the desired state when the tip of the current
# branch is updated to the new commit, and exit with a zero status.
#
# For example, the hook can simply run git read-tree -u -m HEAD "$1"
# in order to emulate git fetch that is run in the reverse direction
# with git push, as the two-tree form of git read-tree -u -m is
# essentially the same as git switch or git checkout that switches
# branches while keeping the local changes in the working tree that do
# not interfere with the difference between the branches.

# The below is a more-or-less exact translation to shell of the C code
# for the default behaviour for git's push-to-checkout hook defined in
# the push_to_deploy() function in builtin/receive-pack.c.
#
# Note that the hook will be executed from the repository directory,
# not from the working tree, so if you want to perform operations on
# the working tree, you will have to adapt your code accordingly, e.g.
# by adding "cd .." or using relative paths.

if ! git update-index -q --ignore-submodules --refresh
then
	die "Up-to-date check failed"
fi

if ! git diff-files --quiet --ignore-submodules --
then
	die "Working directory has unstaged changes"
fi

# This is a rough translation of:
#
#   head_has_history() ? "HEAD" : EMPTY_TREE_SHA1_HEX
if git cat-file -e HEAD 2>/dev/null
then
	head=HEAD
else
	head=$(git hash-object -t tree --stdin </dev/null)
fi

if ! git diff-index --quiet --cached --ignore-submodules $head --
then
	die "Working directory has staged changes"
fi

if ! git read-tree -u -m "$commit"
then
	die "Could not update working tree to new HEAD"
fi
```

--------------------------------------------------------------------------------

File: .git/hooks/pre-commit.sample
```text
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --type=bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --
```

--------------------------------------------------------------------------------

File: .git/hooks/pre-push.sample
```text
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local oid> <remote ref> <remote oid>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')

while read local_ref local_oid remote_ref remote_oid
do
	if test "$local_oid" = "$zero"
	then
		# Handle delete
		:
	else
		if test "$remote_oid" = "$zero"
		then
			# New branch, examine all commits
			range="$local_oid"
		else
			# Update to existing branch, examine new commits
			range="$remote_oid..$local_oid"
		fi

		# Check for WIP commit
		commit=$(git rev-list -n 1 --grep '^WIP' "$range")
		if test -n "$commit"
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0
```

--------------------------------------------------------------------------------

File: .git/info/exclude
```text
# git ls-files --others --exclude-from=.git/info/exclude
# Lines that start with '#' are comments.
# For a project mostly in C, the following would be a good set of
# exclude patterns (uncomment them if you want to use them):
# *.[oa]
# *~
```

--------------------------------------------------------------------------------

File: .git/refs/heads/main
```text
6481a932458e144c6fc11d7cd8c3e1deae2083e9
```

--------------------------------------------------------------------------------

File: .git/refs/remotes/origin/main
```text
6481a932458e144c6fc11d7cd8c3e1deae2083e9
```

--------------------------------------------------------------------------------

File: .git/refs/remotes/origin/HEAD
```text
ref: refs/remotes/origin/main
```

--------------------------------------------------------------------------------

File: .git/objects/pack/pack-c0cb4203b59cbe1ffaf0d18b14609b2efc8cb131.pack  (Skipped, size > 200KB)

--------------------------------------------------------------------------------

File: .git/objects/fb/19e07f2870b09b08226a42d7d5d6d26a3f3a16  (Skipped, size > 200KB)

--------------------------------------------------------------------------------

File: .git/objects/08/c4f60b4d7be7949d5d3e7b8b8fc78455c56e2e  (Skipped, size > 200KB)

--------------------------------------------------------------------------------

