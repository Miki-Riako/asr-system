File: LICENSE
```text
MIT License

Copyright (c) 2025 Kagami's Adjmatrix

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

--------------------------------------------------------------------------------

File: RAG_POC_README.md
```markdown
# RAG检索引擎 (FAISS) POC 使用文档

## 项目概述

本POC（概念验证）项目实现了一个基于FAISS的向量检索引擎，专门用于语音识别系统中的热词预测和增强功能。该服务采用轻量级的微服务架构，提供高效的语义相似度搜索能力。

## 核心特性

### 🔍 **向量检索能力**

- 基于 **sentence-transformers/all-MiniLM-L6-v2** 模型进行文本向量化
- 使用 **FAISS IndexFlatIP** 实现高效的余弦相似度搜索
- 支持多用户隔离的索引管理

### 💾 **索引持久化**

- 自动保存/加载用户向量索引到本地文件
- 智能缓存机制，避免重复计算
- 支持增量更新和索引重建

### 🚀 **高性能设计**

- 内存中索引确保毫秒级查询响应
- 批量向量化处理提升构建效率
- 轻量级模型（~90MB）平衡速度与准确性

### 🔒 **安全与隔离**

- 基于JWT的用户认证
- 用户间数据完全隔离
- RESTful API设计，易于集成

## 技术架构

```
┌─────────────────────────────────────────────────────────────┐
│                    RAG检索引擎架构                           │
├─────────────────────────────────────────────────────────────┤
│  FastAPI Router (/rag/*)                                   │
│  ├── /search          - 向量相似度搜索                      │
│  ├── /suggestions     - 智能热词建议                        │
│  ├── /index/stats     - 索引统计信息                        │
│  ├── /index/rebuild   - 重建用户索引                        │
│  └── /model/info      - 模型信息查询                        │
├─────────────────────────────────────────────────────────────┤
│  RAGService (核心服务层)                                    │
│  ├── SentenceTransformer  - 文本向量化                     │
│  ├── FAISS IndexFlatIP   - 向量索引与搜索                   │
│  ├── 索引持久化管理        - 文件存储与加载                  │
│  └── 用户数据隔离         - 多用户支持                      │
├─────────────────────────────────────────────────────────────┤
│  存储层                                                     │
│  ├── temp/rag_indices/   - 索引文件存储                     │
│  │   ├── user_xxx.index     - FAISS索引文件                 │
│  │   └── user_xxx.metadata  - 元数据JSON文件                │
│  └── SQLite Database     - 热词数据持久化                   │
└─────────────────────────────────────────────────────────────┘
```

## 快速开始

### 1. 环境准备

确保已安装必要的依赖：

```bash
# 进入后端目录
cd asr_system_backend

# 安装依赖
pip install -r requirements.txt
```

### 2. 启动服务

```bash
# 启动FastAPI服务
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 3. 验证服务状态

```bash
# 检查RAG服务健康状态
curl http://localhost:8000/rag/health
```

预期响应：

```json
{
  "status": "healthy",
  "service": "RAG Vector Search Engine", 
  "version": "1.0.0",
  "initialized": true
}
```

## API接口详细说明

### 🔍 向量搜索接口

**POST** `/rag/search`

根据查询文本进行向量相似度搜索，返回最相关的热词。

**请求参数：**

```json
{
  "query": "人工智能技术",
  "top_k": 5,
  "threshold": 0.3
}
```

**响应示例：**

```json
{
  "query": "人工智能技术",
  "results": [
    {
      "word": "机器学习",
      "weight": 8,
      "similarity": 0.85,
      "rank": 1
    },
    {
      "word": "深度学习",
      "weight": 9,
      "similarity": 0.82,
      "rank": 2
    }
  ],
  "total_found": 2,
  "processing_time_ms": 12.5
}
```

### 📊 索引统计接口

**GET** `/rag/index/stats`

获取当前用户的索引统计信息。

**响应示例：**

```json
{
  "user_id": "user123",
  "total_hotwords": 156,
  "index_dimension": 384,
  "is_initialized": true,
  "last_updated": "2025-07-11T15:30:00"
}
```

### 🔄 索引管理接口

**POST** `/rag/index/rebuild`

强制重建用户的向量索引。

**响应示例：**

```json
{
  "success": true,
  "message": "索引重建成功，包含 156 个热词",
  "details": {
    "user_id": "user123",
    "hotword_count": 156,
    "dimension": 384
  }
}
```

### 💡 智能建议接口

**GET** `/rag/suggestions?partial_text=机器&max_suggestions=5`

根据部分输入文本获取热词补全建议。

**响应示例：**

```json
{
  "partial_text": "机器",
  "suggestions": [
    "机器学习",
    "机器人",
    "机器视觉",
    "机器翻译"
  ],
  "count": 4
}
```

### 📋 批量操作接口

**POST** `/rag/index/bulk-add`

批量添加热词到索引中。

**请求参数：**

```json
{
  "words": [
    {"word": "自然语言处理", "weight": 8},
    {"word": "计算机视觉", "weight": 7},
    {"word": "语音识别", "weight": 9}
  ]
}
```

**响应示例：**

```json
{
  "success": true,
  "message": "批量添加完成：新增 3 个，跳过 0 个",
  "details": {
    "added": 3,
    "skipped": 0,
    "total_processed": 3
  }
}
```

### 🔧 模型信息接口

**GET** `/rag/model/info`

获取当前使用的向量化模型详细信息。

**响应示例：**

```json
{
  "model_name": "sentence-transformers/all-MiniLM-L6-v2",
  "dimension": 384,
  "max_sequence_length": 256,
  "languages": ["zh", "en", "multilingual"],
  "description": "轻量级多语言句子嵌入模型，适合中英文混合场景",
  "performance": {
    "embedding_speed": "~1000 sentences/sec (CPU)",
    "model_size": "~90MB",
    "accuracy": "适中，平衡速度与准确性"
  }
}
```

## 使用场景示例

### 场景1：实时转写中的热词预测

```python
import requests

# 用户说话内容
transcription = "今天我们讨论人工智能在医疗领域的应用"

# 搜索相关热词
response = requests.post("http://localhost:8000/rag/search", 
    headers={"Authorization": "Bearer YOUR_JWT_TOKEN"},
    json={
        "query": transcription,
        "top_k": 10,
        "threshold": 0.4
    }
)

results = response.json()
# 根据搜索结果进行转写增强...
```

### 场景2：热词输入自动补全

```python
# 用户输入部分文本
partial_input = "深度"

# 获取补全建议
response = requests.get(
    f"http://localhost:8000/rag/suggestions?partial_text={partial_input}&max_suggestions=5",
    headers={"Authorization": "Bearer YOUR_JWT_TOKEN"}
)

suggestions = response.json()["suggestions"]
# ["深度学习", "深度神经网络", "深度强化学习", ...]
```

### 场景3：系统性能监控

```python
# 获取索引统计信息
stats_response = requests.get("http://localhost:8000/rag/index/stats",
    headers={"Authorization": "Bearer YOUR_JWT_TOKEN"})

stats = stats_response.json()
print(f"用户热词数量: {stats['total_hotwords']}")
print(f"索引维度: {stats['index_dimension']}")
print(f"索引状态: {'已初始化' if stats['is_initialized'] else '未初始化'}")
```

## 性能特性

### 🚀 **查询性能**

- **响应时间**: < 50ms (典型场景)
- **吞吐量**: > 100 QPS (单实例)
- **内存占用**: ~200MB (1000个热词)

### 📈 **扩展性**

- **热词数量**: 支持每用户1000+热词
- **并发用户**: 支持100+并发用户
- **索引大小**: 每1000个热词约1.5MB存储

### 🔧 **配置优化**

在 `asr_system_backend/env.example` 中可调整以下参数：

```bash
# RAG服务配置
RAG_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
RAG_SIMILARITY_THRESHOLD=0.5

# 性能配置  
BACKGROUND_TASK_WORKERS=2
```

## 部署建议

### 生产环境部署

1. **使用更强大的硬件**

   ```bash
   # 推荐配置
   CPU: 4核心以上
   内存: 8GB以上
   存储: SSD存储提升索引I/O性能
   ```
2. **模型缓存优化**

   ```bash
   # 预下载模型到本地
   export TRANSFORMERS_CACHE=/path/to/model/cache
   ```
3. **索引文件备份**

   ```bash
   # 定期备份索引目录
   cp -r temp/rag_indices/ /backup/rag_indices_$(date +%Y%m%d)/
   ```

### 监控与维护

1. **健康检查**

   ```bash
   # 添加到监控系统
   curl -f http://localhost:8000/rag/health || exit 1
   ```
2. **日志监控**

   ```bash
   # 关注关键日志
   grep "RAG服务" app.log
   grep "索引重建" app.log
   ```
3. **性能监控**

   ```python
   # 定期检查服务统计
   GET /rag/index/stats
   ```

## 故障排除

### 常见问题

**Q: 服务启动时提示"模型下载失败"**

```bash
# 解决方案：手动下载模型
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
```

**Q: 搜索结果为空**

```bash
# 检查用户是否有热词数据
GET /rag/index/stats

# 如果热词为0，先添加热词
POST /hotwords
```

**Q: 索引文件损坏**

```bash
# 强制重建索引
POST /rag/index/rebuild
```

## 技术细节

### 向量化模型选择

选择 `all-MiniLM-L6-v2` 的原因：

- **多语言支持**: 支持中英文混合场景
- **模型大小**: 仅90MB，适合部署
- **准确性**: 在句子相似度任务上表现优秀
- **速度**: CPU上可达1000句/秒的处理速度

### FAISS索引策略

使用 `IndexFlatIP` 的考虑：

- **精确搜索**: 保证100%准确的相似度计算
- **简单可靠**: 无需调参，稳定性好
- **内存效率**: 对于中小规模数据集最优

### 数据隔离设计

每个用户的数据完全隔离：

- **索引文件**: `user_{user_id}.index`
- **元数据文件**: `user_{user_id}.metadata`
- **内存结构**: 按用户ID分别存储

## 开发与贡献

### 本地开发

```bash
# 克隆项目
git clone <project-url>

# 安装开发依赖
pip install -r requirements.txt

# 运行测试
pytest test/test_rag.py

# 启动开发服务器
uvicorn app.main:app --reload
```

### 代码结构

```
asr_system_backend/
├── app/
│   ├── routers/
│   │   └── rag.py           # RAG API路由
│   ├── rag_service.py       # 核心RAG服务
│   └── main.py             # 主应用入口
├── temp/
│   └── rag_indices/        # 索引文件存储
└── test/
    └── test_rag.py         # RAG功能测试
```

## 版本历史

- **v1.0.0** (2025-07-11)
  - 初始POC版本发布
  - 基础向量搜索功能
  - 索引持久化支持
  - 多用户隔离机制

## 许可证

本项目采用MIT许可证，详见LICENSE文件。

---

**致谢**
感谢sentence-transformers和FAISS开源项目为本POC提供的技术基础。
```

--------------------------------------------------------------------------------

File: run.sh
```shell
#!/bin/bash

# 颜色定义
GREEN='\033[0;32m'
BLUE='\033[0;34m'
RED='\033[0;31m'
YELLOW='\033[0;33m'
NC='\033[0m' # No Color

# 端口配置
BACKEND_PORT=${BACKEND_PORT:-8080}
FRONTEND_PORT=${FRONTEND_PORT:-2956}
BACKEND_HOST=${BACKEND_HOST:-localhost}

# PID文件
BACKEND_PID_FILE=".backend.pid"
FRONTEND_PID_FILE=".frontend.pid"

# 检查并清理被占用的端口
check_and_clean_port() {
    local port=$1
    local pid=$(lsof -ti:${port})
    if [ ! -z "$pid" ]; then
        echo -e "${YELLOW}端口 ${port} 被进程 ${pid} 占用，正在清理...${NC}"
        kill -9 $pid
        sleep 1
    fi
}

start_services() {
    echo -e "${BLUE}=== 支持热词预测的语音识别系统启动脚本 ===${NC}"
    
    # 检查并清理端口
    check_and_clean_port $BACKEND_PORT
    check_and_clean_port $FRONTEND_PORT
    
    # 检查是否已经运行
    if [ -f "$BACKEND_PID_FILE" ]; then
        echo -e "${RED}后端服务似乎已在运行，请先停止服务。${NC}"
        return 1
    fi
    
    if [ -f "$FRONTEND_PID_FILE" ]; then
        echo -e "${RED}前端服务似乎已在运行，请先停止服务。${NC}"
        return 1
    fi
    
    # 启动后端服务
    echo -e "${GREEN}>>> 启动后端服务...${NC}"
    cd asr_system_backend
    nohup uvicorn app.main:app --reload --host 0.0.0.0 --port $BACKEND_PORT > ../backend.log 2>&1 &
    BACKEND_PID=$!
    echo $BACKEND_PID > ../$BACKEND_PID_FILE
    cd ..
    
    # 启动前端服务
    echo -e "${GREEN}>>> 启动前端服务...${NC}"
    cd asr_system_frontend
    nohup npm run dev -- --port $FRONTEND_PORT --host > ../frontend.log 2>&1 &
    FRONTEND_PID=$!
    echo $FRONTEND_PID > ../$FRONTEND_PID_FILE
    cd ..
    
    echo -e "${BLUE}=== 服务已启动! ===${NC}"
    echo -e "${GREEN}后端服务运行于: ${YELLOW}http://localhost:$BACKEND_PORT${NC}"
    echo -e "${GREEN}前端服务运行于: ${YELLOW}http://localhost:$FRONTEND_PORT${NC}"
    echo -e "${GREEN}API文档: ${YELLOW}http://localhost:$BACKEND_PORT/docs${NC}"
    echo -e "${BLUE}=== 使用 ./run.sh logs 查看日志 ===${NC}"
    echo -e "${BLUE}=== 使用 ./run.sh stop 停止服务 ===${NC}"
}

stop_services() {
    echo -e "${BLUE}=== 停止服务... ===${NC}"
    
    # 停止后端
    if [ -f "$BACKEND_PID_FILE" ]; then
        BACKEND_PID=$(cat $BACKEND_PID_FILE)
        echo -e "${GREEN}>>> 停止后端服务 (PID: $BACKEND_PID)...${NC}"
        kill $BACKEND_PID 2>/dev/null || true
        rm $BACKEND_PID_FILE
    else
        echo -e "${YELLOW}未找到后端服务PID文件，服务可能未运行。${NC}"
    fi
    
    # 停止前端
    if [ -f "$FRONTEND_PID_FILE" ]; then
        FRONTEND_PID=$(cat $FRONTEND_PID_FILE)
        echo -e "${GREEN}>>> 停止前端服务 (PID: $FRONTEND_PID)...${NC}"
        kill $FRONTEND_PID 2>/dev/null || true
        rm $FRONTEND_PID_FILE
    else
        echo -e "${YELLOW}未找到前端服务PID文件，服务可能未运行。${NC}"
    fi
    
    echo -e "${BLUE}=== 服务已停止 ===${NC}"
}

show_logs() {
    case $1 in
        backend)
            echo -e "${BLUE}=== 显示后端日志 (按 Ctrl+C 退出) ===${NC}"
            tail -f backend.log
            ;;
        frontend)
            echo -e "${BLUE}=== 显示前端日志 (按 Ctrl+C 退出) ===${NC}"
            tail -f frontend.log
            ;;
        *)
            echo -e "${BLUE}=== 显示所有日志 (按 Ctrl+C 退出) ===${NC}"
            tail -f backend.log frontend.log
            ;;
    esac
}

# 主命令处理
case $1 in
    stop)
        stop_services
        ;;
    logs)
        show_logs $2
        ;;
    *)
        start_services
        ;;
esac
```

--------------------------------------------------------------------------------

File: setup.py
```python
#!/usr/bin/env python3
"""
支持热词预测的语音识别系统 - 初始化设置脚本
作者：李俊洁 (项目组长)
日期：2025年7月8日

此脚本用于初始化系统环境，包括：
1. 检查并安装Python和Node.js依赖
2. 配置数据库
3. 创建必要的目录结构
4. 生成默认配置文件
"""

import os
import sys
import subprocess
import shutil
import secrets
from pathlib import Path

class ASRSystemSetup:
    def __init__(self):
        self.project_root = Path(__file__).parent.absolute()
        self.backend_dir = self.project_root / "asr_system_backend"
        self.frontend_dir = self.project_root / "asr_system_frontend"
        
    def print_banner(self):
        """显示设置横幅"""
        print("=" * 60)
        print("    支持热词预测的语音识别系统")
        print("    ASR System with Hotword Prediction")
        print("=" * 60)
        print("正在初始化系统环境...\n")
        
    def check_prerequisites(self):
        """检查系统先决条件"""
        print("🔍 检查系统先决条件...")
        
        # 检查Python版本
        python_version = sys.version_info
        if python_version.major < 3 or (python_version.major == 3 and python_version.minor < 8):
            print("❌ 错误：需要Python 3.8或更高版本")
            return False
        print(f"✅ Python版本: {python_version.major}.{python_version.minor}.{python_version.micro}")
        
        # 检查Node.js
        try:
            result = subprocess.run(['node', '--version'], capture_output=True, text=True)
            if result.returncode == 0:
                print(f"✅ Node.js版本: {result.stdout.strip()}")
            else:
                print("❌ 错误：未找到Node.js，请先安装Node.js")
                return False
        except FileNotFoundError:
            print("❌ 错误：未找到Node.js，请先安装Node.js")
            return False
        
        # 检查npm
        try:
            result = subprocess.run(['npm', '--version'], capture_output=True, text=True)
            if result.returncode == 0:
                print(f"✅ npm版本: {result.stdout.strip()}")
            else:
                print("❌ 错误：未找到npm")
                return False
        except FileNotFoundError:
            print("❌ 错误：未找到npm")
            return False
            
        return True

if __name__ == "__main__":
    setup = ASRSystemSetup()
    setup.print_banner()
    if setup.check_prerequisites():
        print("✅ 系统先决条件检查通过")
        print("请运行完整的构建脚本: python -m build 或使用 build.sh")
    else:
        print("❌ 系统先决条件检查失败")
        sys.exit(1)
```

--------------------------------------------------------------------------------

File: docker.md
```markdown
## 本地部署Docker

通过该方法不用调用API，直接在本地部署。
```bash
sudo docker rm -f 055c5f54c1b13cf0f5eea0c23a5a53f650c656cc2a6e159da3620ec1b3de580a
# 或使用容器名
sudo docker rm -f funasr_server
```

### docker build

首先需要有docker

第二步：拉取 FunASR 并且启动离线服务镜像

现在您已经在容器内部了，这里是一个纯净且配置好的环境。请在容器的命令行中执行以下命令来启动后端的识别服务：

```bash
sudo docker pull registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-cpu-0.4.5
```

第三步：启动 FunASR 服务端容器
当镜像下载完成后，我们就可以用它启动一个服务容器了。请在您的 Paraformer-ASR 目录下（或者任何您方便的地方）运行以下命令：

```bash
# 这个命令会先创建一个本地目录，用于存放将来从网上下载的模型
mkdir -p ./funasr-runtime-resources/models

# 启动容器，并将我们刚创建的目录映射到容器内部
sudo docker run --name funasr_server -p 10095:10095 -it --privileged=true \
  -v $PWD/funasr-runtime-resources/models:/workspace/models \
  registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-cpu-0.4.5

```

当您运行这个命令后，您的终端会进入到 Docker 容器的内部，您会看到一个新的命令行提示符，类似 root@xxxxxx:/workspace#。

第四步：在容器内启动识别服务
现在您已经在容器内部了，这里是一个纯净且配置好的环境。请在容器的命令行中执行以下命令来启动后端的识别服务：

```bash
# 进入正确的目录
cd FunASR/runtime

# 启动服务脚本，它会自动下载所需的模型到 /workspace/models 目录
nohup bash run_server.sh \
  --download-model-dir /workspace/models \
  --vad-dir damo/speech_fsmn_vad_zh-cn-16k-common-onnx \
  --model-dir damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-onnx  \
  --punc-dir damo/punc_ct-transformer_cn-en-common-vocab471067-large-onnx \
  --lm-dir damo/speech_ngram_lm_zh-cn-ai-wesp-fst \
  --itn-dir thuduj12/fst_itn_zh \
  --hotword /workspace/models/hotwords.txt > log.txt 2>&1 &
```

服务会在后台启动。您可以运行 tail -f log.txt 来查看模型的下载和加载过程。当您看到类似 "Started server on 0.0.0.0:10095" 的日志时，就代表服务端已经准备就绪了。

下一步：确认服务状态（在当前容器终端）

为了确保服务已经完全准备就绪，您可以在当前这个容器的终端 (root@dca31...) 里，输入下面的命令查看日志：
```bash
tail -f log.txt
```

这个命令会持续显示日志的最新内容。请观察一下，当您看到类似 Started server on 0.0.0.0:10095 或者模型加载完成的日志时，就说明服务端已经准备好接收请求了。
确认完毕后，您可以按 Ctrl + C 退出日志查看，但请不要关闭这个终端窗口，让服务继续在后台运行。

### docker run

之后，再进入docker可以使用：

如果容器正在运行 (Up): 这是最理想的情况！说明您的识别服务还在后台运行。您只需要用 exec 命令在容器里打开一个新的终端窗口即可“进入”：
```bash
sudo docker exec -it funasr_server /bin/bash
```
执行后，您就会立刻回到熟悉的 root@... 命令行界面。
如果容器已经停止 (Exited): 这说明您可能关闭了它。没关系，我们分两步走：先启动它，再进入它。
```bash
# 第一步：重启容器
sudo docker start funasr_server

# 第二步：进入容器
sudo docker exec -it funasr_server /bin/bash
```
```

--------------------------------------------------------------------------------

File: experiments.py
```python
import csv
import matplotlib.pyplot as plt
import numpy as np
from scipy.interpolate import make_interp_spline
from multiprocessing import Queue, Process
import websockets, ssl, asyncio, json, os, argparse

# DEBUG=8
DEBUG = float('inf')

parser = argparse.ArgumentParser()
parser.add_argument("--host", type=str, default="localhost", required=False, help="host ip, localhost, 0.0.0.0")
parser.add_argument("--port", type=int, default=10095, required=False, help="grpc server port")

args = parser.parse_args()
args.chunk_size = [5, 10, 5]
args.chunk_interval = 10
args.audio_fs = 16000
args.thread_num = 1
args.ssl = 1
args.use_itn = 1

voices = Queue()
offline_msg_done=False

async def record_microphone():
    import pyaudio
    global voices
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    chunk_size = 60 * args.chunk_size[1] / args.chunk_interval
    CHUNK = int(RATE / 1000 * chunk_size)

    p = pyaudio.PyAudio()

    stream = p.open(format=FORMAT,
                    channels=CHANNELS,
                    rate=RATE,
                    input=True,
                    frames_per_buffer=CHUNK)
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        f_scp = open(args.hotword)
        hot_lines = f_scp.readlines()
        for line in hot_lines:
            words = line.strip().split(" ")
            if len(words) < 2:
                continue
            try:
                fst_dict[" ".join(words[:-1])] = int(words[-1])
            except ValueError:
                continue
        hotword_msg=json.dumps(fst_dict)

    use_itn=True
    if args.use_itn == 0:
        use_itn=False
    
    message = json.dumps({"mode": "offline", "chunk_size": args.chunk_size, "chunk_interval": args.chunk_interval, "wav_name": "microphone", "is_speaking": True, "hotwords":hotword_msg, "itn": use_itn})
    await websocket.send(message)
    while True:
        data = stream.read(CHUNK)
        message = data
        await websocket.send(message)
        await asyncio.sleep(0.005)

async def record_from_scp(chunk_begin, chunk_size):
    global voices
    if args.audio_in.endswith(".scp"):
        f_scp = open(args.audio_in)
        wavs = f_scp.readlines()
    else:
        wavs = [args.audio_in]

    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        f_scp = open(args.hotword)
        hot_lines = f_scp.readlines()
        for line in hot_lines:
            words = line.strip().split(" ")
            if len(words) < 2:
                continue
            try:
                fst_dict[" ".join(words[:-1])] = int(words[-1])
            except ValueError:
                continue
        hotword_msg=json.dumps(fst_dict)

    sample_rate = args.audio_fs
    wav_format = "pcm"
    use_itn=True
    if args.use_itn == 0:
        use_itn=False
    if chunk_size > 0:
        wavs = wavs[chunk_begin:chunk_begin + chunk_size]
    for wav in wavs:
        wav_splits = wav.strip().split()
        wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
        wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
        if not len(wav_path.strip()) > 0:
            continue
        if wav_path.endswith(".pcm"):
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()
        elif wav_path.endswith(".wav"):
            import wave
            with wave.open(wav_path, "rb") as wav_file:
                sample_rate = wav_file.getframerate()
                frames = wav_file.readframes(wav_file.getnframes())
                audio_bytes = bytes(frames)        
        else:
            wav_format = "others"
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()

        stride = int(60 * args.chunk_size[1] / args.chunk_interval / 1000 * sample_rate * 2)
        chunk_num = (len(audio_bytes) - 1) // stride + 1
        message = json.dumps({"mode": "offline", "chunk_size": args.chunk_size, "chunk_interval": args.chunk_interval, "audio_fs":sample_rate, "wav_name": wav_name, "wav_format": wav_format, "is_speaking": True, "hotwords":hotword_msg, "itn": use_itn})
        await websocket.send(message)
        is_speaking = True
        for i in range(chunk_num):
            beg = i * stride
            data = audio_bytes[beg:beg + stride]
            message = data
            await websocket.send(message)
            if i == chunk_num - 1:
                is_speaking = False
                message = json.dumps({"is_speaking": is_speaking})
                await websocket.send(message)
            
            sleep_duration = 0.001
            await asyncio.sleep(sleep_duration)
    
    global offline_msg_done
    while not offline_msg_done:
        await asyncio.sleep(1)
    
    await websocket.close()

async def message(id, result_queue):
    global websocket, voices, offline_msg_done
    try:
        while True:
            meg = await websocket.recv()
            meg = json.loads(meg)
            text = meg["text"]
            offline_msg_done = meg.get("is_final", False)
            result_queue.put(text)
            if 'mode' not in meg:
                continue
            if meg["mode"] == "offline":
                result_queue.put(text)
                offline_msg_done = True
    except Exception as e:
        print("Exception:", e)

async def ws_client(id, chunk_begin, chunk_size, result_queue):
    global websocket, voices, offline_msg_done
    for i in range(chunk_begin, chunk_begin+chunk_size):
        offline_msg_done=False
        voices = Queue()
        if args.ssl == 1:
            ssl_context = ssl.SSLContext()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE
            uri = "wss://{}:{}".format(args.host, args.port)
        else:
            uri = "ws://{}:{}".format(args.host, args.port)
            ssl_context = None
        async with websockets.connect(uri, subprotocols=["binary"], ping_interval=None, ssl=ssl_context) as websocket:
            if args.audio_in is not None:
                task = asyncio.create_task(record_from_scp(i, 1))
            else:
                task = asyncio.create_task(record_microphone())
            task3 = asyncio.create_task(message(str(id)+"_"+str(i), result_queue))
            await asyncio.gather(task, task3)
    exit(0)
    
def one_thread(id, chunk_begin, chunk_size, result_queue):
    asyncio.get_event_loop().run_until_complete(ws_client(id, chunk_begin, chunk_size, result_queue))
    asyncio.get_event_loop().run_forever()


def run_audio(audio_file, hotwords=""):
    args.audio_in = audio_file
    args.hotword = hotwords
    result_queue = Queue()

    if args.audio_in is None:
        p = Process(target=one_thread, args=(0, 0, 0, result_queue))
        p.start()
        p.join()
    else:
        if args.audio_in.endswith(".scp"):
            with open(args.audio_in) as f_scp:
                wavs = f_scp.readlines()
        else:
            wavs = [args.audio_in]
        total_len = len(wavs)
        
        if total_len >= args.thread_num:
            chunk_size = int(total_len / args.thread_num)
            remain_wavs = total_len - chunk_size * args.thread_num
        else:
            chunk_size = 1
            remain_wavs = 0
        
        process_list = []
        chunk_begin = 0
        for i in range(args.thread_num):
            now_chunk_size = chunk_size
            if remain_wavs > 0:
                now_chunk_size = chunk_size + 1
                remain_wavs -= 1
            p = Process(target=one_thread, args=(i, chunk_begin, now_chunk_size, result_queue))
            chunk_begin += now_chunk_size
            p.start()
            process_list.append(p)
        
        for p in process_list:
            p.join()
    result = []
    while not result_queue.empty():
        result.append(result_queue.get())
    return "\n".join(set(result))

class Experiments:
    def __init__(self):
        self.hotwords_path  = './samples/python/speech_asr_aishell_hotwords_testsets/hotwords.txt'
        self.reference_path = './samples/python/speech_asr_aishell_hotwords_testsets/speech_asr_aishell_hotwords_testsets.csv'
        self.reference = []
        self.results   = []
        self.cnt = 0
        
        self.hotwords = self.load_hotwords(self.hotwords_path)
        self.pre_process()
    
    def load_hotwords(self, path):
        hotwords = set()
        with open(path, 'r', encoding='utf-8') as f:
            for line in f:
                word = line.strip().split()[0]
                hotwords.add(word)
        return hotwords
    
    @staticmethod
    def min_distance(word1: str, word2: str) -> int:
        row = len(word1) + 1
        column = len(word2) + 1
        cache = [ [0]*column for _ in range(row) ]
        for i in range(row):
            for j in range(column):
                if i ==0 and j ==0:
                    cache[i][j] = 0
                elif i == 0 and j!=0:
                    cache[i][j] = j
                elif j == 0 and i!=0:
                    cache[i][j] = i
                else:
                    if word1[i-1] == word2[j-1]:
                        cache[i][j] = cache[i-1][j-1]
                    else:
                        replace = cache[i-1][j-1] + 1
                        insert = cache[i][j-1] + 1
                        remove = cache[i-1][j] + 1
                        cache[i][j] = min(replace, insert, remove)
        return cache[row-1][column-1]

    def pre_process(self):
        ...

    def process_data(self):
        with open(self.reference_path, 'r', encoding='utf-8') as file:
            reader = csv.reader(file)
            next(reader)
            for i, row in enumerate(reader):
                if i >= DEBUG:
                    break
                input_audio, reference = row
                input_audio = input_audio
                reference = reference.replace(' ', '')
                result_no_hotword, result_with_hotword = self.generate(input_audio)
                cer_no_hotword, ref_len_no_hotword = self.calculate_cer(reference, result_no_hotword)
                cer_with_hotword, ref_len_with_hotword = self.calculate_cer(reference, result_with_hotword)
                precision_no_hotword, recall_no_hotword = self.calculate_precision_recall(reference, result_no_hotword)
                precision_with_hotword, recall_with_hotword = self.calculate_precision_recall(reference, result_with_hotword)
                self.results.append({
                    "input_audio": input_audio,
                    "reference": reference,
                    "result_no_hotword": result_no_hotword,
                    "result_with_hotword": result_with_hotword,
                    "cer_no_hotword": cer_no_hotword,
                    "cer_with_hotword": cer_with_hotword,
                    "ref_len_no_hotword": ref_len_no_hotword,
                    "ref_len_with_hotword": ref_len_with_hotword,
                    "precision_no_hotword": precision_no_hotword,
                    "recall_no_hotword": recall_no_hotword,
                    "precision_with_hotword": precision_with_hotword,
                    "recall_with_hotword": recall_with_hotword,
                })

    def generate(self, input_audio: str):
        try:
            print(str(self.cnt)+": "+input_audio)
            self.cnt += 1
            result_no_hotword = run_audio(input_audio).replace('，', '')
            result_with_hotword = run_audio(input_audio, self.hotwords_path).replace('，', '')
            return result_no_hotword.replace(' ', '').split("\n")[0], result_with_hotword.replace(' ', '').split("\n")[0]
        except Exception as e:
            print(f"Error generating ASR results: {e}")
            return "", ""

    def calculate_precision_recall(self, reference: str, hypothesis: str):
        ref_hotwords = set([word for word in self.hotwords if word in reference])
        hyp_hotwords = set([word for word in self.hotwords if word in hypothesis])
        true_positives = len(ref_hotwords & hyp_hotwords)
        precision = true_positives / len(hyp_hotwords) if hyp_hotwords else 0
        recall = true_positives / len(ref_hotwords) if ref_hotwords else 0
        return precision, recall

    def calculate_cer(self, reference: str, hypothesis: str):
        distance = self.min_distance(reference, hypothesis)
        len_ref = len(reference)
        if len_ref == 0:
            return 0, 0
        return (distance / len(reference)) * 100, len(reference)

    def post_process(self):
        # Calculate total CER
        avg_no_hotword = sum(result["ref_len_no_hotword"] for result in self.results)
        avg_with_hotword = sum(result["ref_len_with_hotword"] for result in self.results)
        self.sum_data = len(self.results)
        self.avg_cer_no_hotword = 0.0 if self.sum_data < 1 else sum(result["cer_no_hotword"] for result in self.results) / self.sum_data
        self.avg_cer_with_hotword = 0.0 if self.sum_data < 1 else sum(result["cer_with_hotword"] for result in self.results) / self.sum_data
        self.weighted_cer_no_hotword = 0.0 if avg_no_hotword < 1 else sum(result["cer_no_hotword"] * result["ref_len_no_hotword"] for result in self.results) / avg_no_hotword
        self.weighted_cer_with_hotword = 0.0 if avg_with_hotword < 1 else sum(result["cer_with_hotword"] * result["ref_len_with_hotword"] for result in self.results) / avg_with_hotword

        # Calculate Precision, Recall, and F1-Score
        self.avg_precision_no_hotword = sum(result["precision_no_hotword"] for result in self.results) / self.sum_data
        self.avg_recall_no_hotword = sum(result["recall_no_hotword"] for result in self.results) / self.sum_data
        self.avg_precision_with_hotword = sum(result["precision_with_hotword"] for result in self.results) / self.sum_data
        self.avg_recall_with_hotword = sum(result["recall_with_hotword"] for result in self.results) / self.sum_data
        self.f1_score_no_hotword = 2 * (self.avg_precision_no_hotword * self.avg_recall_no_hotword) / (self.avg_precision_no_hotword + self.avg_recall_no_hotword) if (self.avg_precision_no_hotword + self.avg_recall_no_hotword) > 0 else 0
        self.f1_score_with_hotword = 2 * (self.avg_precision_with_hotword * self.avg_recall_with_hotword) / (self.avg_precision_with_hotword + self.avg_recall_with_hotword) if (self.avg_precision_with_hotword + self.avg_recall_with_hotword) > 0 else 0

        # Plot image
        self.plot('output.png')
        self.plot('output_new.png', True)

    def plot(self, filename, smooth=False):
        cer_no_hotword = [result["cer_no_hotword"] for result in self.results]
        cer_with_hotword = [result["cer_with_hotword"] for result in self.results]
        bins = np.arange(0, max(cer_no_hotword + cer_with_hotword) + 5, 5)
        count_no_hotword, _ = np.histogram(cer_no_hotword, bins=bins)
        count_with_hotword, _ = np.histogram(cer_with_hotword, bins=bins)
        x = bins[:-1] + 2.5
        plt.figure(figsize=(12, 6))

        if smooth:
            x_smooth = np.linspace(x.min(), x.max(), 300)
            spl_no_hotword = make_interp_spline(x, count_no_hotword, k=3)
            spl_with_hotword = make_interp_spline(x, count_with_hotword, k=3)
            count_no_hotword_smooth = spl_no_hotword(x_smooth)
            count_with_hotword_smooth = spl_with_hotword(x_smooth)
            plt.plot(x_smooth, count_no_hotword_smooth, label='No Hotword', color='blue')
            plt.plot(x_smooth, count_with_hotword_smooth, label='With Hotword', color='red')
        else:
            plt.scatter(x, count_no_hotword, label='No Hotword', color='blue')
            plt.scatter(x, count_with_hotword, label='With Hotword', color='red')

        plt.xlabel('CER Range')
        plt.ylabel('Count')
        plt.legend(loc='lower left', title=f'Counts of data: {self.sum_data}')
        plt.title('CER Distribution')
        plt.savefig('./images/' + filename)
        plt.show()

    def show(self):
        print()
        for result in self.results:
            print(f"\nInput Audio: {result['input_audio']}")
            print(f"Reference:         {result['reference']}")
            print(f"No Hotwords:       {result['result_no_hotword']}")
            print(f"With Hotwords:     {result['result_with_hotword']}")
            print(f"CER(%) no hotwords:   {result['cer_no_hotword']:.4f}")
            print(f"CER(%) with hotwords: {result['cer_with_hotword']:.4f}")

        print()
        print(f"Average CER(%) no hotwords:    {self.avg_cer_no_hotword:.4f}")
        print(f"Average CER(%) with hotwords:  {self.avg_cer_with_hotword:.4f}")
        print(f"Weighted CER(%) no hotwords:   {self.weighted_cer_no_hotword:.4f}")
        print(f"Weighted CER(%) with hotwords: {self.weighted_cer_with_hotword:.4f}")
        print(f"Counts of data:                {self.sum_data}")

        print(f"\nHotwords Metrics (No Hotwords):")
        print(f"Precision: {self.avg_precision_no_hotword:.4f}")
        print(f"Recall:    {self.avg_recall_no_hotword:.4f}")
        print(f"F1-Score: {self.f1_score_no_hotword:.4f}")

        print(f"\nHotwords Metrics (With Hotwords):")
        print(f"Precision: {self.avg_precision_with_hotword:.4f}")
        print(f"Recall:    {self.avg_recall_with_hotword:.4f}")
        print(f"F1-Score: {self.f1_score_with_hotword:.4f}")

if __name__ == '__main__':
    e = Experiments()
    e.process_data()
    e.post_process()
    e.show()
```

--------------------------------------------------------------------------------

File: pytest.ini
```ini
[pytest]
pythonpath = .
```

--------------------------------------------------------------------------------

File: build.ps1
```powershell
# ASR System with Hotword Prediction - Build Script (PowerShell)

# Color definitions
$Green = 'Green'
$Blue = 'Cyan'
$Red = 'Red'
$Yellow = 'Yellow'

Write-Host "=== ASR System with Hotword Prediction - Build Script ===" -ForegroundColor $Blue
Write-Host "=== Starting build process... ===" -ForegroundColor $Blue

# Create virtual environment
Write-Host ">>> Creating Python virtual environment..." -ForegroundColor $Green
python -m venv venv
if (-not $?) {
    Write-Host "Failed to create virtual environment! Please make sure Python 3.6+ is installed." -ForegroundColor $Red
    exit 1
}

# Activate virtual environment
Write-Host ">>> Activating Python virtual environment..." -ForegroundColor $Green
.\venv\Scripts\Activate.ps1
if (-not $?) {
    Write-Host "Failed to activate virtual environment!" -ForegroundColor $Red
    exit 1
}

# Create upload directory
Write-Host ">>> Creating necessary directories..." -ForegroundColor $Green
New-Item -ItemType Directory -Force -Path .\asr_system_backend\uploads | Out-Null

# Install backend dependencies
Write-Host ">>> Installing backend dependencies..." -ForegroundColor $Green
Push-Location .\asr_system_backend
pip install -r requirements.txt
if (-not $?) {
    Write-Host "Failed to install backend dependencies!" -ForegroundColor $Red
    Pop-Location
    exit 1
}
Pop-Location

# Install frontend dependencies
Write-Host ">>> Installing frontend dependencies..." -ForegroundColor $Green
Push-Location .\asr_system_frontend

# Copy environment file if it doesn't exist
if (-not (Test-Path ".env")) {
    Write-Host ">>> Creating frontend environment configuration..." -ForegroundColor $Green
    Copy-Item "env.example" ".env"
    Write-Host "⚠️  Please edit asr_system_frontend\.env file to set your configuration parameters" -ForegroundColor $Yellow
}

npm install
if (-not $?) {
    Write-Host "Failed to install frontend dependencies! You may need to install Node.js first." -ForegroundColor $Red
    Pop-Location
    exit 1
}
Pop-Location

# Run database migrations
Write-Host ">>> Initializing database..." -ForegroundColor $Green
Push-Location .\asr_system_backend

# Copy environment file if it doesn't exist
if (-not (Test-Path ".env")) {
    Write-Host ">>> Creating backend environment configuration..." -ForegroundColor $Green
    Copy-Item "env.example" ".env"
    Write-Host "⚠️  Please edit asr_system_backend\.env file to set your configuration parameters" -ForegroundColor $Yellow
}

# Use our initialization script
python init_db.py
if (-not $?) {
    Write-Host "Database initialization failed!" -ForegroundColor $Red
    Pop-Location
    exit 1
}

# Run Alembic migrations
$env:PYTHONPATH = "$($env:PYTHONPATH);$(Get-Location)"
alembic upgrade head
if (-not $?) {
    Write-Host "Database migration failed!" -ForegroundColor $Red
    Pop-Location
    exit 1
}
Pop-Location

Write-Host "=== Build completed successfully! ===" -ForegroundColor $Blue
Write-Host "=== Use .\run.ps1 to start the application ===" -ForegroundColor $Blue
```

--------------------------------------------------------------------------------

File: .gitignore
```text
.markdown
asr_system_frontend/node_modules
asr_system_frontend/package-lock.json
funasr-runtime-resources

asr_system.db
.backend_info.txt
.backend.pid
.frontend_info.txt
.frontend.pid

*.pt

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[codz]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py.cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# UV
#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#uv.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock
#poetry.toml

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#   pdm recommends including project-wide configuration in pdm.toml, but excluding .pdm-python.
#   https://pdm-project.org/en/latest/usage/project/#working-with-version-control
#pdm.lock
#pdm.toml
.pdm-python
.pdm-build/

# pixi
#   Similar to Pipfile.lock, it is generally recommended to include pixi.lock in version control.
#pixi.lock
#   Pixi creates a virtual environment in the .pixi directory, just like venv module creates one
#   in the .venv directory. It is recommended not to include this directory in version control.
.pixi

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.env.local
.env.development
.env.production
.envrc
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# 敏感配置文件
*/config/local.py
*/config/production.py
*/.env
*/.env.local

# 上传文件和临时文件
uploads/
temp/
*/uploads/
*/temp/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

# Abstra
# Abstra is an AI-powered process automation framework.
# Ignore directories containing user credentials, local state, and settings.
# Learn more at https://abstra.io/docs
.abstra/

# Visual Studio Code
#  Visual Studio Code specific template is maintained in a separate VisualStudioCode.gitignore 
#  that can be found at https://github.com/github/gitignore/blob/main/Global/VisualStudioCode.gitignore
#  and can be added to the global gitignore or merged into this file. However, if you prefer, 
#  you could uncomment the following to ignore the entire vscode folder
# .vscode/

# Ruff stuff:
.ruff_cache/

# PyPI configuration file
.pypirc

# Cursor
#  Cursor is an AI-powered code editor. `.cursorignore` specifies files/directories to
#  exclude from AI features like autocomplete and code analysis. Recommended for sensitive data
#  refer to https://docs.cursor.com/context/ignore-files
.cursorignore
.cursorindexingignore

# Marimo
marimo/_static/
marimo/_lsp/
__marimo__/
# 忽略所有 .msc 后缀的文件
**/.msc
```

--------------------------------------------------------------------------------

File: verify_system.py
```python
#!/usr/bin/env python3
"""
系统功能验证脚本
用于快速检查ASR系统的各项功能是否正常工作
"""

import os
import sys
import time
import requests
import json
from pathlib import Path

class SystemVerifier:
    def __init__(self):
        self.base_url = "http://localhost:8080"
        self.frontend_url = "http://localhost:2956"
        self.token = None
        self.test_user = {
            "username": "test_user_" + str(int(time.time())),
            "password": "test123456"
        }
    
    def print_banner(self):
        print("=" * 60)
        print("     ASR系统功能验证")
        print("=" * 60)
        print()
    
    def check_backend_health(self):
        """检查后端服务是否正常运行"""
        print("🔍 检查后端服务健康状态...")
        try:
            response = requests.get(f"{self.base_url}/docs", timeout=5)
            if response.status_code == 200:
                print("✅ 后端服务运行正常")
                return True
            else:
                print("❌ 后端服务响应异常")
                return False
        except requests.exceptions.RequestException as e:
            print(f"❌ 无法连接到后端服务: {e}")
            print("请确保后端服务已启动 (运行 ./run.sh 或 .\run.ps1)")
            return False
    
    def check_frontend_health(self):
        """检查前端服务是否正常运行"""
        print("🔍 检查前端服务健康状态...")
        try:
            response = requests.get(self.frontend_url, timeout=5)
            if response.status_code == 200:
                print("✅ 前端服务运行正常")
                return True
            else:
                print("❌ 前端服务响应异常")
                return False
        except requests.exceptions.RequestException as e:
            print(f"❌ 无法连接到前端服务: {e}")
            print("请确保前端服务已启动")
            return False
    
    def test_user_registration(self):
        """测试用户注册功能"""
        print("🔍 测试用户注册功能...")
        try:
            response = requests.post(
                f"{self.base_url}/auth/register",
                json=self.test_user,
                timeout=10
            )
            if response.status_code == 200:
                print("✅ 用户注册功能正常")
                return True
            else:
                print(f"❌ 用户注册失败: {response.status_code}")
                return False
        except Exception as e:
            print(f"❌ 用户注册测试失败: {e}")
            return False
    
    def test_user_login(self):
        """测试用户登录功能"""
        print("🔍 测试用户登录功能...")
        try:
            # 准备表单数据格式
            login_data = {
                "username": self.test_user["username"],
                "password": self.test_user["password"]
            }
            
            response = requests.post(
                f"{self.base_url}/auth/login",
                data=login_data,
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                if "access_token" in result:
                    self.token = result["access_token"]
                    print("✅ 用户登录功能正常")
                    return True
                else:
                    print("❌ 登录响应中缺少token")
                    return False
            else:
                print(f"❌ 用户登录失败: {response.status_code}")
                print(f"响应内容: {response.text}")
                return False
        except Exception as e:
            print(f"❌ 用户登录测试失败: {e}")
            return False
    
    def test_hotword_management(self):
        """测试热词管理功能"""
        print("🔍 测试热词管理功能...")
        if not self.token:
            print("❌ 需要先登录才能测试热词管理")
            return False
        
        headers = {"Authorization": f"Bearer {self.token}"}
        
        try:
            # 测试创建热词
            hotword_data = {"word": "测试热词", "weight": 8}
            response = requests.post(
                f"{self.base_url}/hotwords",
                json=hotword_data,
                headers=headers,
                timeout=10
            )
            
            if response.status_code == 200:
                hotword = response.json()
                hotword_id = hotword["id"]
                
                # 测试获取热词列表
                response = requests.get(
                    f"{self.base_url}/hotwords",
                    headers=headers,
                    timeout=10
                )
                
                if response.status_code == 200:
                    hotwords = response.json()
                    if len(hotwords) > 0:
                        print("✅ 热词管理功能正常")
                        
                        # 清理测试数据
                        requests.delete(
                            f"{self.base_url}/hotwords/{hotword_id}",
                            headers=headers
                        )
                        return True
                    else:
                        print("❌ 热词列表为空")
                        return False
                else:
                    print("❌ 获取热词列表失败")
                    return False
            else:
                print(f"❌ 创建热词失败: {response.status_code}")
                return False
                
        except Exception as e:
            print(f"❌ 热词管理测试失败: {e}")
            return False
    
    def test_transcription_api(self):
        """测试转写API（不上传真实文件）"""
        print("🔍 测试转写API端点...")
        if not self.token:
            print("❌ 需要先登录才能测试转写API")
            return False
        
        headers = {"Authorization": f"Bearer {self.token}"}
        
        try:
            # 测试获取任务列表API
            response = requests.get(
                f"{self.base_url}/asr/tasks",
                headers=headers,
                timeout=10
            )
            
            if response.status_code == 200:
                print("✅ 转写API端点正常")
                return True
            else:
                print(f"❌ 转写API测试失败: {response.status_code}")
                return False
                
        except Exception as e:
            print(f"❌ 转写API测试失败: {e}")
            return False
    
    def check_database(self):
        """检查数据库连接"""
        print("🔍 检查数据库连接...")
        try:
            # 检查数据库文件是否存在
            db_path = Path("asr_system_backend/asr_system.db")
            if db_path.exists():
                print("✅ 数据库文件存在")
                return True
            else:
                print("❌ 数据库文件不存在")
                print("请运行数据库初始化: cd asr_system_backend && python init_db.py")
                return False
        except Exception as e:
            print(f"❌ 数据库检查失败: {e}")
            return False
    
    def check_required_files(self):
        """检查必要文件是否存在"""
        print("🔍 检查必要文件...")
        
        required_files = [
            "asr_system_backend/app/main.py",
            "asr_system_backend/app/models.py",
            "asr_system_backend/app/asr_engine.py",
            "asr_system_backend/app/rag_service.py",
            "asr_system_frontend/src/main.js",
            "asr_system_frontend/src/App.vue",
        ]
        
        all_exist = True
        for file_path in required_files:
            if Path(file_path).exists():
                print(f"✅ {file_path}")
            else:
                print(f"❌ {file_path} 缺失")
                all_exist = False
        
        return all_exist
    
    def print_summary(self, results):
        """打印测试结果摘要"""
        print("\n" + "=" * 60)
        print("     测试结果摘要")
        print("=" * 60)
        
        passed = sum(results.values())
        total = len(results)
        
        for test_name, result in results.items():
            status = "✅ 通过" if result else "❌ 失败"
            print(f"{test_name:<20} {status}")
        
        print("-" * 60)
        print(f"总计: {passed}/{total} 项测试通过")
        
        if passed == total:
            print("\n🎉 所有测试通过！系统运行正常！")
            print("\n🚀 您现在可以：")
            print("   - 访问前端界面: http://localhost:2956")
            print("   - 查看API文档: http://localhost:8080/docs")
            print("   - 开始使用语音识别功能")
        else:
            print(f"\n⚠️  有 {total - passed} 项测试失败，请检查相关组件")
    
    def run_all_tests(self):
        """运行所有测试"""
        self.print_banner()
        
        results = {}
        
        # 基础环境检查
        results["必要文件检查"] = self.check_required_files()
        results["数据库检查"] = self.check_database()
        results["后端服务"] = self.check_backend_health()
        results["前端服务"] = self.check_frontend_health()
        
        # 功能测试（只有在服务正常时才执行）
        if results["后端服务"]:
            results["用户注册"] = self.test_user_registration()
            results["用户登录"] = self.test_user_login()
            results["热词管理"] = self.test_hotword_management()
            results["转写API"] = self.test_transcription_api()
        
        self.print_summary(results)
        
        return all(results.values())

def main():
    verifier = SystemVerifier()
    success = verifier.run_all_tests()
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
```

--------------------------------------------------------------------------------

File: test_transcription.py
```python
import requests
import json
import os
import time

# 配置
API_BASE = "http://localhost:8080/api"
TEST_AUDIO = "client/BAC009S0764W0179.wav"
TEST_USER = {
    "username": "testuser",
    "password": "testpass123"
}

def register_user():
    """注册测试用户"""
    try:
        response = requests.post(f"{API_BASE}/auth/register", json=TEST_USER)
        print("注册结果:", response.json())
    except:
        print("用户可能已存在,继续登录")

def login():
    """登录并获取token"""
    response = requests.post(f"{API_BASE}/auth/login", data=TEST_USER)
    return response.json()["access_token"]

def upload_and_transcribe(token):
    """上传音频并获取转写结果"""
    headers = {"Authorization": f"Bearer {token}"}
    
    # 上传文件
    print("正在上传音频文件...")
    with open(TEST_AUDIO, "rb") as f:
        files = {"file": (os.path.basename(TEST_AUDIO), f)}
        response = requests.post(
            f"{API_BASE}/asr/transcribe/file",
            headers=headers,
            files=files
        )
        
        if not response.ok:
            print("上传失败:", response.text)
            return
            
        task_id = response.json()["id"]
        print(f"上传成功,任务ID: {task_id}")
    
    # 等待处理完成并获取结果
    print("等待转写完成...")
    time.sleep(2)  # 给一些处理时间
    
    response = requests.get(
        f"{API_BASE}/asr/tasks/{task_id}/output",
        headers=headers
    )
    
    if response.ok:
        result = response.json()
        print("\n转写结果:")
        print("-" * 50)
        print(result["terminal_output"])
        print("-" * 50)
    else:
        print("获取结果失败:", response.text)

def main():
    print("开始测试转写功能...")
    register_user()
    token = login()
    upload_and_transcribe(token)

if __name__ == "__main__":
    main()
```

--------------------------------------------------------------------------------

File: prompt.py
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import argparse
from pathlib import Path
import pathspec
from tqdm import tqdm

# --- 配置部分 (无变化) ---
DEFAULT_EXCLUDE_PATTERNS = [
    "*.pyc", "__pycache__/", "*.o", "*.a", "*.so", "*.lib", "*.dll", "*.exe",
    ".idea/", ".vscode/", ".project", ".classpath", ".settings/", "node_modules/", "venv/", ".venv/",
    "*.log", "*.tmp", "*.bak", "*.swp",
    "*.png", "*.jpg", "*.jpeg", "*.gif", "*.bmp", "*.svg", "*.ico",
    "*.mp4", "*.mov", "*.avi", "*.mkv", "*.mp3", "*.wav", "*.flac",
    "*.zip", "*.tar.gz", "*.rar", "*.7z", "*.gz", "*.bz2",
    "*.pdf", "*.doc", "*.docx", "*.xls", "*.xlsx", "*.ppt", "*.pptx", "*.db", "*.sqlite3",
    "*.txt", "*.json"
]
DEFAULT_MAX_FILE_SIZE = 200 * 1024
LANGUAGE_MAP = {
    ".py": "python", ".pyw": "python", ".js": "javascript", ".jsx": "javascript",
    ".ts": "typescript", ".tsx": "typescript", ".c": "c", ".h": "c", ".cpp": "cpp",
    ".hpp": "cpp", ".cxx": "cpp", ".java": "java", ".go": "go", ".rs": "rust",
    ".rb": "ruby", ".php": "php", ".cs": "csharp", ".swift": "swift", ".kt": "kotlin",
    ".scala": "scala", ".sh": "shell", ".bash": "shell", ".ps1": "powershell",
    ".bat": "batch", ".sql": "sql", ".html": "html", ".htm": "html", ".css": "css",
    ".json": "json", ".xml": "xml", ".yaml": "yaml", ".yml": "yaml", ".toml": "toml",
    ".md": "markdown", ".markdown": "markdown", ".rst": "rst", ".txt": "text",
    "Dockerfile": "dockerfile", ".env": "ini", ".ini": "ini", ".conf": "ini",
}

# --- 辅助函数 ---
def get_language_identifier(filepath: Path) -> str:
    if filepath.name in LANGUAGE_MAP: return LANGUAGE_MAP[filepath.name]
    return LANGUAGE_MAP.get(filepath.suffix.lower(), "text")

def is_likely_binary(filepath: Path, chunk_size=1024) -> bool:
    try:
        with open(filepath, 'rb') as f: return b'\0' in f.read(chunk_size)
    except IOError: return True

def find_git_root(start_path: Path) -> Path:
    current_path = start_path.resolve()
    while current_path != current_path.parent:
        if (current_path / ".git").is_dir(): return current_path
        current_path = current_path.parent
    return start_path.resolve()

# 【【【BUG已彻底修复的函数】】】
def load_gitignore_rules(git_root: Path) -> pathspec.PathSpec:
    """
    只加载项目根目录的.gitignore文件。这避免了子目录中
    的.gitignore文件（如submodule或依赖包）的规则对整个项目造成污染。
    """
    gitignore_path = git_root / '.gitignore'
    rules = []
    if gitignore_path.is_file():
        try:
            with open(gitignore_path, 'r', encoding='utf-8', errors='ignore') as f:
                rules = [line for line in (l.strip() for l in f) if line and not line.startswith('#')]
        except IOError:
            pass # 无法读取则忽略
    return pathspec.PathSpec.from_lines('gitwildmatch', rules)

# --- 主处理函数 (逻辑已验证正确) ---
def process_project(project_root: str, output_file: str, extra_excludes: list, max_size: int,
                    include_exts: set = None, verbose: bool = False):
    root_path = Path(project_root).resolve()
    if not root_path.is_dir():
        print(f"错误: 路径 '{project_root}' 不是一个有效的目录。", file=sys.stderr); sys.exit(1)

    git_root = find_git_root(root_path)
    if verbose:
        print(f"项目根目录: {root_path}", file=sys.stderr)
        print(f"Git根目录: {git_root}", file=sys.stderr)
        print("🔍 正在加载 .gitignore 规则...", file=sys.stderr)
    
    gitignore_spec = load_gitignore_rules(git_root)
    custom_spec = pathspec.PathSpec.from_lines('gitwildmatch', extra_excludes)

    if verbose: print("📂 正在扫描项目文件...", file=sys.stderr)
    
    filtered_files = []
    # 使用os.walk进行遍历，性能和控制力都很好
    for dirpath, dirnames, filenames in os.walk(root_path, topdown=True, followlinks=False):
        current_dir_path = Path(dirpath)
        
        # 过滤目录：原地修改dirnames列表，os.walk就不会再进入这些目录
        dirs_to_keep = []
        for d in dirnames:
            dir_path_for_check = current_dir_path.relative_to(root_path) / d
            dir_path_str = dir_path_for_check.as_posix()
            
            # 检查目录时，在末尾添加斜杠'/'
            if gitignore_spec.match_file(dir_path_str + '/') or custom_spec.match_file(dir_path_str + '/'):
                continue
            else:
                dirs_to_keep.append(d)
        dirnames[:] = dirs_to_keep

        # 过滤文件
        for f in filenames:
            file_path = current_dir_path / f
            file_path_for_check = file_path.relative_to(root_path)
            file_path_str = file_path_for_check.as_posix()
            
            if gitignore_spec.match_file(file_path_str) or custom_spec.match_file(file_path_str):
                continue
            else:
                filtered_files.append(file_path)

    # 准备输出
    output_stream = open(output_file, 'w', encoding='utf-8') if output_file else sys.stdout
    try:
        file_iterator = tqdm(filtered_files, desc="🚀 处理文件中", unit="file", disable=not verbose, bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]")
        
        for filepath in file_iterator:
            if include_exts and filepath.suffix.lower() not in include_exts: continue
            
            relative_path_str = filepath.relative_to(root_path).as_posix()
            
            try:
                file_size = filepath.stat().st_size
                if file_size > max_size:
                    print(f"File: {relative_path_str}  (Skipped, size > {max_size / 1024:.0f}KB)", file=output_stream); print("\n" + "-"*80 + "\n", file=output_stream)
                    continue
                
                content = ""
                if file_size > 0:
                    if is_likely_binary(filepath): continue
                    content = filepath.read_text(encoding='utf-8')

            except (IOError, OSError, UnicodeDecodeError): continue
            
            language = get_language_identifier(filepath)
            print(f"File: {relative_path_str}", file=output_stream)
            print(f"```{language}", file=output_stream); print(content.strip(), file=output_stream); print("```", file=output_stream)
            print("\n" + "-"*80 + "\n", file=output_stream)
    finally:
        if output_file:
            output_stream.close()
            if verbose: print(f"✅ 处理完成，输出已保存到: {output_file}", file=sys.stderr)

def main():
    parser = argparse.ArgumentParser(description="从项目目录中提取可读源代码和文本文件，格式化后输出以供LLM分析。", formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument("project_root", help="要扫描的项目根目录路径。")
    parser.add_argument("-o", "--output", help="输出文件的路径。如果未指定，则输出到标准输出 (stdout)。")
    parser.add_argument("--exclude", nargs='*', default=DEFAULT_EXCLUDE_PATTERNS, help="要额外排除的文件/目录的 glob 模式列表。")
    parser.add_argument("--include-ext", nargs='*', help="仅包含指定扩展名的文件 (白名单模式)。")
    parser.add_argument("--max-size", type=int, default=DEFAULT_MAX_FILE_SIZE, help=f"文件内容的最大大小（字节）。")
    parser.add_argument("-v", "--verbose", action="store_true", help="显示详细处理信息和进度条。")
    
    args = parser.parse_args()
    include_exts_set = {ext if ext.startswith('.') else '.' + ext.lower() for ext in args.include_ext} if args.include_ext else None

    process_project(project_root=args.project_root, output_file=args.output, extra_excludes=args.exclude,
                    max_size=args.max_size, include_exts=include_exts_set, verbose=args.verbose)

if __name__ == "__main__":
    main()
```

--------------------------------------------------------------------------------

File: build.sh
```shell
#!/bin/bash

# 颜色定义
GREEN='\033[0;32m'
BLUE='\033[0;34m'
RED='\033[0;31m'
NC='\033[0m' # No Color

echo -e "${BLUE}=== 支持热词预测的语音识别系统构建脚本 ===${NC}"
echo -e "${BLUE}=== 开始构建项目... ===${NC}"

# 创建虚拟环境
echo -e "${GREEN}>>> 创建Python虚拟环境...${NC}"
python -m venv venv
source venv/bin/activate

# 创建上传目录
echo -e "${GREEN}>>> 创建必要的目录...${NC}"
mkdir -p asr_system_backend/uploads

# 安装后端依赖
echo -e "${GREEN}>>> 安装后端依赖...${NC}"
cd asr_system_backend
pip install -r requirements.txt
cd ..

# 安装前端依赖
echo -e "${GREEN}>>> 安装前端依赖...${NC}"
cd asr_system_frontend

# 复制环境变量文件（如果不存在）
if [ ! -f ".env" ]; then
    echo -e "${GREEN}>>> 创建前端环境配置文件...${NC}"
    cp env.example .env
    echo -e "${YELLOW}⚠️  请编辑 asr_system_frontend/.env 文件，设置您的配置参数${NC}"
fi

npm install
cd ..

# 运行数据库迁移
echo -e "${GREEN}>>> 初始化数据库...${NC}"
cd asr_system_backend

# 复制环境变量文件（如果不存在）
if [ ! -f ".env" ]; then
    echo -e "${GREEN}>>> 创建后端环境配置文件...${NC}"
    cp env.example .env
    echo -e "${YELLOW}⚠️  请编辑 asr_system_backend/.env 文件，设置您的配置参数${NC}"
fi

# 使用我们的初始化脚本
python init_db.py

# 运行Alembic迁移
export PYTHONPATH=$PYTHONPATH:$(pwd)
alembic upgrade head
cd ..

echo -e "${BLUE}=== 构建完成! ===${NC}"
echo -e "${BLUE}=== 使用 run.sh 来启动应用 ===${NC}"
```

--------------------------------------------------------------------------------

File: README.md
```markdown
# 支持热词预测的语音识别系统

一个集成了热词预测和增强功能的智能语音识别系统，专为提升特定领域语音识别准确率而设计。

## 🎯 项目概述

本系统是一个完整的语音识别解决方案，包含以下核心功能：

- **智能语音识别**：基于OpenAI Whisper的高精度语音转写
- **热词预测与增强**：利用RAG技术提升特定领域术语识别率
- **用户管理系统**：完整的注册、登录和权限管理
- **文件批量处理**：支持多种音频格式的批量转写
- **实时交互界面**：现代化的Vue.js前端界面

## 🚀 快速开始

### 系统要求

- **Python**: 3.8+
- **Node.js**: 16+
- **npm**: 7+
- **操作系统**: Windows 10+, macOS 10.14+, Ubuntu 18.04+

### 一键安装

1. **克隆项目**

   ```bash
   git clone <repository-url>
   cd asr-system
   ```
2. **运行设置脚本**

   ```bash
   # 检查系统先决条件
   python setup.py

   # Linux/Mac - 完整构建
   ./build.sh

   # Windows - 完整构建
   .\build.ps1
   ```
3. **启动服务**

   ```bash
   # Linux/Mac
   ./run.sh

   # Windows
   .\run.ps1
   ```
4. **访问应用**

   - 🌐 **前端界面**: http://localhost:5173
   - 🔧 **API服务**: http://localhost:8000
   - 📚 **API文档**: http://localhost:8000/docs

## 📁 项目架构

```
asr-system/
├── 🔥 asr_system_backend/          # FastAPI后端服务
│   ├── app/
│   │   ├── main.py                 # 应用入口
│   │   ├── models.py               # 数据模型
│   │   ├── schemas.py              # API模式
│   │   ├── config.py               # 配置管理
│   │   ├── asr_engine.py           # ASR引擎
│   │   ├── rag_service.py          # RAG热词服务
│   │   └── routers/                # API路由
│   ├── alembic/                    # 数据库迁移
│   ├── requirements.txt            # Python依赖
│   └── env.example                 # 环境变量模板
├── 🎨 asr_system_frontend/         # Vue.js前端应用
│   ├── src/
│   │   ├── views/                  # 页面组件
│   │   ├── router/                 # 路由配置
│   │   └── services/               # API服务
│   ├── tests/e2e/                  # E2E测试
│   ├── package.json                # Node.js依赖
│   └── env.example                 # 前端环境变量
├── 🗄️ sql/                        # 数据库结构
├── 🧪 test/                       # 测试文件
├── 📝 setup.py                    # 系统设置脚本
├── 🚀 build.sh/.ps1               # 构建脚本
├── ▶️ run.sh/.ps1                 # 启动脚本
└── 📖 README.md                   # 项目文档
```

## ✨ 核心功能

### 🎤 语音识别引擎

- **基于Whisper**：采用OpenAI最新Whisper模型
- **多格式支持**：wav, mp3, m4a, flac, aac, ogg
- **批量处理**：支持大批量音频文件处理
- **高精度识别**：针对中文优化的识别算法

### 🔍 热词预测系统

- **智能预测**：基于RAG技术的热词关联
- **权重调节**：1-10级可调权重系统
- **批量导入**：支持CSV/TXT格式批量导入
- **实时增强**：转写结果实时热词增强

### 👤 用户管理

- **安全认证**：JWT Token认证机制
- **权限隔离**：用户数据完全隔离
- **会话管理**：自动登录状态管理

### 🎛️ 管理界面

- **响应式设计**：支持桌面和移动设备
- **实时反馈**：转写进度实时显示
- **数据可视化**：转写结果统计图表

## 🔧 配置指南

### 环境配置

1. **复制环境变量模板**

   ```bash
   # 后端配置
   cp asr_system_backend/env.example asr_system_backend/.env

   # 前端配置  
   cp asr_system_frontend/env.example asr_system_frontend/.env
   ```
2. **编辑配置文件**

   ```bash
   # 编辑后端配置
   nano asr_system_backend/.env

   # 编辑前端配置
   nano asr_system_frontend/.env
   ```

### 重要配置项

**后端配置 (.env)**

```bash
# JWT安全密钥 (请修改为随机字符串)
JWT_SECRET_KEY=your_secret_key_here

# ASR引擎配置
ASR_MODEL_SIZE=base          # tiny/base/small/medium/large
ASR_LANGUAGE=zh              # 识别语言
ASR_ENABLE_GPU=true          # 是否启用GPU加速
```

**前端配置 (.env)**

```bash
# API服务地址
VITE_API_BASE_URL=http://localhost:8000
```

## 🧪 测试

### E2E测试

```bash
cd asr_system_frontend
npm run test:e2e
```

### 后端测试

```bash
cd asr_system_backend
python -m pytest
```

## 📊 性能特点

- **识别准确率**: 95%+ (中文通用场景)
- **热词增强**: 特定领域提升10-20%准确率
- **处理速度**: 实时系数 < 0.3 (GPU加速)
- **并发支持**: 支持多用户同时使用
- **文件支持**: 最大100MB音频文件

## 🐛 常见问题

### Q: 首次启动时模型下载很慢？

A: 系统会自动下载Whisper和sentence-transformers模型，请确保网络连接稳定。

### Q: GPU加速不生效？

A: 请确保安装了CUDA和PyTorch GPU版本。

### Q: 热词预测不准确？

A: 请检查热词权重设置，建议重要术语设置较高权重(8-10)。

### Q: 文件上传失败？

A: 检查文件格式是否支持，以及文件大小是否超过限制。

## 📝 更新日志

### v1.0.0 (2025-07-08)

- ✅ 完成核心ASR引擎集成
- ✅ 实现热词管理CRUD功能
- ✅ 完成前端E2E测试框架
- ✅ 用户认证系统上线
- ✅ RAG热词预测服务

## 📄 许可证

本项目采用 MIT 许可证 - 查看 [LICENSE](LICENSE) 文件了解详情。

---

**注意**: 本系统仅供学习和研究使用，生产环境使用前请进行充分测试。
```

--------------------------------------------------------------------------------

File: asr_system_frontend/env.example
```text
# 前端环境变量配置模板
# 请复制此文件为.env并填入真实值

# API服务器地址
VITE_API_BASE_URL=http://localhost:8000

# 应用名称
VITE_APP_NAME=支持热词预测的语音识别系统

# 应用版本
VITE_APP_VERSION=1.0.0

# 开发模式
VITE_DEV_MODE=true

# 文件上传限制（MB）
VITE_MAX_FILE_SIZE=100

# 支持的音频格式
VITE_SUPPORTED_AUDIO_FORMATS=.wav,.mp3,.m4a,.flac,.aac,.ogg

# 热词最大数量
VITE_MAX_HOTWORDS=1000

# 实时转写WebSocket地址
VITE_WS_BASE_URL=ws://localhost:8000

# 日志级别
VITE_LOG_LEVEL=info
```

--------------------------------------------------------------------------------

File: asr_system_frontend/index.html
```html
<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>支持热词预测的语音识别系统</title>
    <meta name="description" content="极大无关组 - 支持热词预测的语音识别系统" />
    <link rel="icon" type="image/svg+xml" href="/favicon.svg" />
    <style>
      body {
        background: #121212;
        color: #e0e0e0;
        min-height: 100vh;
        margin: 0;
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
      }
    </style>
  </head>
  <body>
    <div id="app"></div>
    <script type="module" src="/src/main.js"></script>
  </body>
</html>
```

--------------------------------------------------------------------------------

File: asr_system_frontend/postcss.config.js
```javascript
module.exports = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
};
```

--------------------------------------------------------------------------------

File: asr_system_frontend/.eslintrc.js
```javascript
module.exports = {
  root: true,
  env: {
    node: true,
  },
  extends: [
    'plugin:vue/vue3-essential',
    'eslint:recommended',
    'prettier',
  ],
  parserOptions: {
    ecmaVersion: 2020,
    sourceType: 'module',
  },
  rules: {
    'vue/multi-word-component-names': 0,
  },
};
```

--------------------------------------------------------------------------------

File: asr_system_frontend/playwright.config.ts
```typescript
import { defineConfig, devices } from '@playwright/test';

/**
 * @see https://playwright.dev/docs/test-configuration
 */
export default defineConfig({
  testDir: './tests/e2e',
  /* Run tests in files in parallel */
  fullyParallel: true,
  /* Fail the build on CI if you accidentally left test.only in the source code. */
  forbidOnly: !!process.env.CI,
  /* Retry on CI only */
  retries: process.env.CI ? 2 : 0,
  /* Opt out of parallel tests on CI. */
  workers: process.env.CI ? 1 : undefined,
  /* Reporter to use. See https://playwright.dev/docs/test-reporters */
  reporter: 'html',
  /* Shared settings for all the projects below. See https://playwright.dev/docs/api/class-testoptions. */
  use: {
    /* Base URL to use in actions like `await page.goto('/')`. */
    baseURL: 'http://localhost:2956',

    /* Collect trace when retrying the failed test. See https://playwright.dev/docs/trace-viewer */
    trace: 'on-first-retry',
    
    /* Take screenshot only when test fails */
    screenshot: 'only-on-failure',
    
    /* Record video only when test fails */
    video: 'retain-on-failure',
  },

  /* Configure projects for major browsers */
  projects: [
    {
      name: 'chromium',
      use: { ...devices['Desktop Chrome'] },
    },

    {
      name: 'firefox',
      use: { ...devices['Desktop Firefox'] },
    },

    {
      name: 'webkit',
      use: { ...devices['Desktop Safari'] },
    },

    /* Test against mobile viewports. */
    {
      name: 'Mobile Chrome',
      use: { ...devices['Pixel 5'] },
    },
    {
      name: 'Mobile Safari',
      use: { ...devices['iPhone 12'] },
    },
  ],

  /* Run your local dev server before starting the tests */
  webServer: {
    command: 'npm run dev',
    url: 'http://localhost:2956',
    reuseExistingServer: !process.env.CI,
  },
});
```

--------------------------------------------------------------------------------

File: asr_system_frontend/tailwind.config.js
```javascript
module.exports = {
  content: [
    './index.html',
    './src/**/*.{vue,js,ts,jsx,tsx}'
  ],
  theme: {
    extend: {},
  },
  plugins: [],
};
```

--------------------------------------------------------------------------------

File: asr_system_frontend/.prettierrc
```text
{
  "singleQuote": true,
  "semi": true,
  "trailingComma": "es5"
}
```

--------------------------------------------------------------------------------

File: asr_system_frontend/vite.config.js
```javascript
import { defineConfig } from 'vite';
import vue from '@vitejs/plugin-vue';

// 从环境变量获取端口配置
const FRONTEND_PORT = process.env.FRONTEND_PORT || 2956;
const BACKEND_PORT = process.env.BACKEND_PORT || 8080;
const BACKEND_HOST = process.env.BACKEND_HOST || 'localhost';

export default defineConfig({
  plugins: [vue()],
  server: {
    port: FRONTEND_PORT,
    strictPort: true, // 如果端口被占用，不要尝试下一个端口
    proxy: {
      '^/api': {
        target: `http://${BACKEND_HOST}:${BACKEND_PORT}`,
        changeOrigin: true
      },
      '^/auth': {
        target: `http://${BACKEND_HOST}:${BACKEND_PORT}`,
        changeOrigin: true
      },
      '^/asr': {
        target: `http://${BACKEND_HOST}:${BACKEND_PORT}`,
        changeOrigin: true
      },
      '^/ws': {
        target: `ws://${BACKEND_HOST}:${BACKEND_PORT}`,
        changeOrigin: true,
        ws: true
      }
    }
  },
  define: {
    'process.env': {
      VITE_API_BASE_URL: JSON.stringify(`http://${BACKEND_HOST}:${BACKEND_PORT}`),
      VITE_WS_BASE_URL: JSON.stringify(`ws://${BACKEND_HOST}:${BACKEND_PORT}`)
    }
  }
});
```

--------------------------------------------------------------------------------

File: asr_system_frontend/README.md
```markdown
# ASR System 前端

## 本地开发

1. 安装依赖
   ```
   npm install
   ```
2. 启动开发服务器
   ```
   npm run dev
   ```
3. 生产环境打包
   ```
   npm run build
   ```

## 代码规范

- 使用 ESLint/Prettier 统一代码风格
- 组件开发建议参考 Element Plus 官方文档
```

--------------------------------------------------------------------------------

File: asr_system_frontend/tests/e2e/features.spec.ts
```typescript
import { test, expect } from '@playwright/test';

test.describe('核心功能测试', () => {
  // 登录测试用户
  test.beforeEach(async ({ page }) => {
    await page.goto('/login');
    await page.fill('input[placeholder*="用户名"]', 'testuser');
    await page.fill('input[placeholder*="密码"]', 'password123');
    await page.click('button:has-text("登录")');
    
    // 等待登录成功
    await page.waitForURL(/\/dashboard|\//, { timeout: 10000 });
  });

  test('热词管理功能', async ({ page }) => {
    // 导航到热词管理页面
    await page.click('text=热词管理');
    await expect(page).toHaveURL(/\/hotwords/);
    
    // 验证页面元素
    await expect(page.locator('text=添加热词')).toBeVisible();
    await expect(page.locator('text=批量导入')).toBeVisible();
    
    // 添加新热词
    await page.click('button:has-text("添加热词")');
    
    // 填写热词表单
    await page.fill('input[placeholder*="热词"]', '机器学习');
    
    // 设置权重 - 找到滑块并设置
    const slider = page.locator('.el-slider__runway');
    if (await slider.isVisible()) {
      await slider.click({ position: { x: 80, y: 0 } }); // 点击滑块位置设置权重
    }
    
    // 保存热词
    await page.click('button:has-text("添加")');
    
    // 验证热词添加成功
    await expect(page.locator('text=机器学习')).toBeVisible({ timeout: 5000 });
    
    // 测试搜索功能
    await page.fill('input[placeholder*="搜索热词"]', '机器');
    await expect(page.locator('text=机器学习')).toBeVisible();
    
    // 清空搜索
    await page.fill('input[placeholder*="搜索热词"]', '');
  });

  test('文件转写功能页面', async ({ page }) => {
    // 导航到文件转写页面
    await page.click('text=文件转写');
    await expect(page).toHaveURL(/\/transcription/);
    
    // 验证页面元素
    await expect(page.locator('text=音频文件上传')).toBeVisible();
    await expect(page.locator('text=热词设置')).toBeVisible();
    
    // 验证文件上传区域
    await expect(page.locator('.el-upload-dragger')).toBeVisible();
    
    // 验证热词开关
    await expect(page.locator('.el-switch')).toBeVisible();
    
    // 测试热词开关切换
    const hotwordSwitch = page.locator('.el-switch');
    await hotwordSwitch.click();
    
    // 验证热词管理链接
    await expect(page.locator('text=管理我的热词')).toBeVisible();
  });

  test('任务详情页面导航', async ({ page }) => {
    // 导航到首页
    await page.goto('/');
    
    // 如果有任务列表，测试点击查看详情
    const taskLinks = page.locator('text=查看详情');
    const taskCount = await taskLinks.count();
    
    if (taskCount > 0) {
      await taskLinks.first().click();
      
      // 验证进入任务详情页面
      await expect(page).toHaveURL(/\/task\//);
      await expect(page.locator('text=任务详情')).toBeVisible();
    }
  });

  test('导航功能测试', async ({ page }) => {
    // 测试各页面间的导航
    const pages = [
      { text: '首页', url: '/' },
      { text: '文件转写', url: '/transcription' },
      { text: '热词管理', url: '/hotwords' }
    ];

    for (const testPage of pages) {
      if (await page.locator(`text=${testPage.text}`).isVisible()) {
        await page.click(`text=${testPage.text}`);
        await expect(page).toHaveURL(new RegExp(testPage.url.replace('/', '\\/')));
        
        // 验证页面加载完成
        await page.waitForLoadState('networkidle');
      }
    }
  });

  test('响应式设计测试', async ({ page }) => {
    // 测试不同屏幕尺寸
    const viewports = [
      { width: 1920, height: 1080 }, // 桌面
      { width: 768, height: 1024 },  // 平板
      { width: 375, height: 667 }    // 手机
    ];

    for (const viewport of viewports) {
      await page.setViewportSize(viewport);
      
      // 验证页面在不同尺寸下正常显示
      await page.goto('/');
      await expect(page.locator('header')).toBeVisible();
      
      // 在小屏幕上可能有汉堡菜单
      if (viewport.width < 768) {
        // 检查是否有移动端菜单
        const mobileMenu = page.locator('.mobile-menu');
        if (await mobileMenu.isVisible()) {
          await mobileMenu.click();
        }
      }
    }
  });
});
```

--------------------------------------------------------------------------------

File: asr_system_frontend/tests/e2e/auth.spec.ts
```typescript
import { test, expect } from '@playwright/test';

test.describe('用户认证流程', () => {
  const testUser = {
    username: `testuser_${Date.now()}`,
    password: 'password123'
  };

  test('用户注册流程', async ({ page }) => {
    await page.goto('/register');
    
    // 填写注册表单
    await page.fill('input[placeholder*="用户名"]', testUser.username);
    await page.fill('input[placeholder*="密码"]', testUser.password);
    
    // 提交注册
    await page.click('button:has-text("注册")');
    
    // 验证注册成功 - 可能跳转到登录页面或显示成功消息
    await expect(page.locator('text=注册成功')).toBeVisible({ timeout: 10000 });
  });

  test('用户登录流程', async ({ page }) => {
    await page.goto('/login');
    
    // 填写登录表单
    await page.fill('input[placeholder*="用户名"]', testUser.username);
    await page.fill('input[placeholder*="密码"]', testUser.password);
    
    // 提交登录
    await page.click('button:has-text("登录")');
    
    // 验证登录成功 - 跳转到主页面
    await expect(page).toHaveURL(/\/dashboard|\/$/);
    
    // 验证用户信息显示
    await expect(page.locator(`text=${testUser.username}`)).toBeVisible({ timeout: 10000 });
  });

  test('登录失败处理', async ({ page }) => {
    await page.goto('/login');
    
    // 使用错误密码登录
    await page.fill('input[placeholder*="用户名"]', 'wronguser');
    await page.fill('input[placeholder*="密码"]', 'wrongpassword');
    
    await page.click('button:has-text("登录")');
    
    // 验证错误消息显示
    await expect(page.locator('text=用户名或密码错误')).toBeVisible({ timeout: 5000 });
  });

  test('完整用户流程：注册->登录->访问功能', async ({ page }) => {
    const uniqueUser = {
      username: `e2euser_${Date.now()}`,
      password: 'test123456'
    };

    // 步骤1：注册
    await page.goto('/register');
    await page.fill('input[placeholder*="用户名"]', uniqueUser.username);
    await page.fill('input[placeholder*="密码"]', uniqueUser.password);
    await page.click('button:has-text("注册")');
    
    // 等待注册成功
    await expect(page.locator('text=注册成功')).toBeVisible({ timeout: 10000 });

    // 步骤2：登录
    await page.goto('/login');
    await page.fill('input[placeholder*="用户名"]', uniqueUser.username);
    await page.fill('input[placeholder*="密码"]', uniqueUser.password);
    await page.click('button:has-text("登录")');
    
    // 等待进入主页面
    await page.waitForURL(/\/dashboard|\//, { timeout: 10000 });

    // 步骤3：验证可以访问功能页面
    if (await page.locator('text=文件转写').isVisible()) {
      await page.click('text=文件转写');
      await expect(page.locator('text=音频文件上传')).toBeVisible({ timeout: 5000 });
    }

    if (await page.locator('text=热词管理').isVisible()) {
      await page.click('text=热词管理');
      await expect(page.locator('text=添加热词')).toBeVisible({ timeout: 5000 });
    }
  });
});
```

--------------------------------------------------------------------------------

File: asr_system_frontend/tests/e2e/hotwords.spec.ts
```typescript
import { test, expect } from '@playwright/test';

// 测试前的准备工作
test.beforeEach(async ({ page }) => {
  // 访问登录页面
  await page.goto('/login');
  
  // 执行登录
  await page.fill('input[placeholder="请输入用户名/邮箱"]', 'testuser');
  await page.fill('input[placeholder="请输入密码"]', 'testpass123');
  
  // 获取并输入验证码
  const captchaText = await page.textContent('.captcha-box');
  await page.fill('input[placeholder="输入验证码"]', captchaText);
  
  // 点击登录按钮
  await page.click('button:has-text("登录")');
  
  // 等待登录成功，跳转到主页
  await page.waitForURL('/');
  
  // 导航到热词管理页面
  await page.goto('/hotwords');
  await page.waitForLoadState('networkidle');
});

test.describe('热词管理功能测试', () => {
  
  test('页面加载和基本元素显示', async ({ page }) => {
    // 检查页面标题
    await expect(page.locator('h1')).toContainText('热词管理');
    
    // 检查主要按钮是否存在
    await expect(page.locator('button:has-text("添加热词")')).toBeVisible();
    await expect(page.locator('button:has-text("批量导入")')).toBeVisible();
    await expect(page.locator('button:has-text("批量删除")')).toBeVisible();
    
    // 检查搜索框
    await expect(page.locator('input[placeholder="搜索热词..."]')).toBeVisible();
    
    // 检查热词列表表格
    await expect(page.locator('.el-table')).toBeVisible();
  });
  
  test('添加热词功能', async ({ page }) => {
    // 点击添加热词按钮
    await page.click('button:has-text("添加热词")');
    
    // 等待对话框出现
    await expect(page.locator('.el-dialog')).toBeVisible();
    await expect(page.locator('.el-dialog__title')).toContainText('添加热词');
    
    // 填写热词信息
    await page.fill('.el-dialog input[placeholder="请输入热词"]', '测试热词');
    
    // 设置权重滑块 - 点击滑块的特定位置来设置权重
    const slider = page.locator('.el-slider__runway');
    const sliderBox = await slider.boundingBox();
    // 点击滑块的80%位置（对应权重8）
    await slider.click({ 
      position: { 
        x: sliderBox.width * 0.8, 
        y: sliderBox.height / 2 
      } 
    });
    
    // 保存热词
    await page.click('.el-dialog button:has-text("保存")');
    
    // 等待对话框关闭
    await expect(page.locator('.el-dialog')).toBeHidden();
    
    // 验证热词已添加到列表中
    await expect(page.locator('.el-table').locator('td').filter({ hasText: '测试热词' })).toBeVisible();
    
    // 验证成功消息
    await expect(page.locator('.el-message--success')).toBeVisible();
  });
  
  test('搜索热词功能', async ({ page }) => {
    // 先添加几个热词
    const testWords = ['搜索测试1', '搜索测试2', '其他热词'];
    
    for (const word of testWords) {
      await page.click('button:has-text("添加热词")');
      await page.fill('.el-dialog input[placeholder="请输入热词"]', word);
      await page.click('.el-dialog button:has-text("保存")');
      await page.waitForTimeout(500); // 等待添加完成
    }
    
    // 使用搜索功能
    await page.fill('input[placeholder="搜索热词..."]', '搜索测试');
    
    // 等待搜索结果
    await page.waitForTimeout(1000);
    
    // 验证搜索结果
    await expect(page.locator('.el-table').locator('td').filter({ hasText: '搜索测试1' })).toBeVisible();
    await expect(page.locator('.el-table').locator('td').filter({ hasText: '搜索测试2' })).toBeVisible();
    await expect(page.locator('.el-table').locator('td').filter({ hasText: '其他热词' })).toBeHidden();
    
    // 清空搜索
    await page.fill('input[placeholder="搜索热词..."]', '');
    await page.waitForTimeout(1000);
    
    // 验证所有热词都显示
    await expect(page.locator('.el-table').locator('td').filter({ hasText: '其他热词' })).toBeVisible();
  });
  
  test('编辑热词功能', async ({ page }) => {
    // 先添加一个热词
    await page.click('button:has-text("添加热词")');
    await page.fill('.el-dialog input[placeholder="请输入热词"]', '待编辑热词');
    await page.click('.el-dialog button:has-text("保存")');
    await page.waitForTimeout(500);
    
    // 找到编辑按钮并点击
    const editButton = page.locator('.el-table').locator('tr').filter({ hasText: '待编辑热词' }).locator('button').filter({ hasText: '编辑' });
    await editButton.click();
    
    // 等待编辑对话框出现
    await expect(page.locator('.el-dialog')).toBeVisible();
    await expect(page.locator('.el-dialog__title')).toContainText('编辑热词');
    
    // 修改热词内容
    await page.fill('.el-dialog input[placeholder="请输入热词"]', '已编辑热词');
    
    // 保存修改
    await page.click('.el-dialog button:has-text("保存")');
    
    // 等待对话框关闭
    await expect(page.locator('.el-dialog')).toBeHidden();
    
    // 验证修改成功
    await expect(page.locator('.el-table').locator('td').filter({ hasText: '已编辑热词' })).toBeVisible();
    await expect(page.locator('.el-table').locator('td').filter({ hasText: '待编辑热词' })).toBeHidden();
    
    // 验证成功消息
    await expect(page.locator('.el-message--success')).toBeVisible();
  });
  
  test('删除热词功能', async ({ page }) => {
    // 先添加一个热词
    await page.click('button:has-text("添加热词")');
    await page.fill('.el-dialog input[placeholder="请输入热词"]', '待删除热词');
    await page.click('.el-dialog button:has-text("保存")');
    await page.waitForTimeout(500);
    
    // 找到删除按钮并点击
    const deleteButton = page.locator('.el-table').locator('tr').filter({ hasText: '待删除热词' }).locator('button').filter({ hasText: '删除' });
    await deleteButton.click();
    
    // 等待确认对话框出现
    await expect(page.locator('.el-message-box')).toBeVisible();
    await expect(page.locator('.el-message-box__content')).toContainText('确定要删除热词');
    
    // 确认删除
    await page.click('.el-message-box button:has-text("确定")');
    
    // 验证热词已被删除
    await expect(page.locator('.el-table').locator('td').filter({ hasText: '待删除热词' })).toBeHidden();
    
    // 验证成功消息
    await expect(page.locator('.el-message--success')).toBeVisible();
  });
  
  test('批量删除功能', async ({ page }) => {
    // 先添加几个热词
    const testWords = ['批量删除1', '批量删除2', '保留热词'];
    
    for (const word of testWords) {
      await page.click('button:has-text("添加热词")');
      await page.fill('.el-dialog input[placeholder="请输入热词"]', word);
      await page.click('.el-dialog button:has-text("保存")');
      await page.waitForTimeout(500);
    }
    
    // 选中要删除的热词
    await page.check('.el-table').locator('tr').filter({ hasText: '批量删除1' }).locator('.el-checkbox__input');
    await page.check('.el-table').locator('tr').filter({ hasText: '批量删除2' }).locator('.el-checkbox__input');
    
    // 点击批量删除按钮
    await page.click('button:has-text("批量删除")');
    
    // 等待确认对话框
    await expect(page.locator('.el-message-box')).toBeVisible();
    await expect(page.locator('.el-message-box__content')).toContainText('确定要删除选中的');
    
    // 确认删除
    await page.click('.el-message-box button:has-text("确定")');
    
    // 验证热词已被删除
    await expect(page.locator('.el-table').locator('td').filter({ hasText: '批量删除1' })).toBeHidden();
    await expect(page.locator('.el-table').locator('td').filter({ hasText: '批量删除2' })).toBeHidden();
    await expect(page.locator('.el-table').locator('td').filter({ hasText: '保留热词' })).toBeVisible();
  });
  
  test('批量导入功能', async ({ page }) => {
    // 点击批量导入按钮
    await page.click('button:has-text("批量导入")');
    
    // 等待导入对话框出现
    await expect(page.locator('.el-dialog')).toBeVisible();
    await expect(page.locator('.el-dialog__title')).toContainText('批量导入热词');
    
    // 创建测试文件内容
    const csvContent = `导入热词1,5
导入热词2,8
导入热词3,3`;
    
    // 使用文件上传
    const fileInput = page.locator('.el-dialog input[type="file"]');
    
    // 创建一个模拟的文件
    await fileInput.setInputFiles({
      name: 'test_hotwords.csv',
      mimeType: 'text/csv',
      buffer: Buffer.from(csvContent)
    });
    
    // 点击导入按钮
    await page.click('.el-dialog button:has-text("导入")');
    
    // 等待导入完成
    await page.waitForTimeout(2000);
    
    // 验证导入成功消息
    await expect(page.locator('.el-message--success')).toBeVisible();
    
    // 验证导入的热词出现在列表中
    await expect(page.locator('.el-table').locator('td').filter({ hasText: '导入热词1' })).toBeVisible();
    await expect(page.locator('.el-table').locator('td').filter({ hasText: '导入热词2' })).toBeVisible();
    await expect(page.locator('.el-table').locator('td').filter({ hasText: '导入热词3' })).toBeVisible();
  });
  
  test('热词权重显示和排序', async ({ page }) => {
    // 添加不同权重的热词
    const testWords = [
      { word: '高权重热词', weight: 90 },
      { word: '低权重热词', weight: 10 },
      { word: '中等权重热词', weight: 50 }
    ];
    
    for (const { word, weight } of testWords) {
      await page.click('button:has-text("添加热词")');
      await page.fill('.el-dialog input[placeholder="请输入热词"]', word);
      
      // 设置权重
      const slider = page.locator('.el-slider__runway');
      const sliderBox = await slider.boundingBox();
      await slider.click({ 
        position: { 
          x: sliderBox.width * (weight / 100), 
          y: sliderBox.height / 2 
        } 
      });
      
      await page.click('.el-dialog button:has-text("保存")');
      await page.waitForTimeout(500);
    }
    
    // 验证权重显示
    await expect(page.locator('.el-table').locator('tr').filter({ hasText: '高权重热词' })).toBeVisible();
    await expect(page.locator('.el-table').locator('tr').filter({ hasText: '低权重热词' })).toBeVisible();
    await expect(page.locator('.el-table').locator('tr').filter({ hasText: '中等权重热词' })).toBeVisible();
    
    // 检查权重标签是否正确显示
    const highWeightRow = page.locator('.el-table').locator('tr').filter({ hasText: '高权重热词' });
    await expect(highWeightRow.locator('.el-tag')).toBeVisible();
  });
  
  test('表单验证功能', async ({ page }) => {
    // 点击添加热词按钮
    await page.click('button:has-text("添加热词")');
    
    // 不输入任何内容直接保存
    await page.click('.el-dialog button:has-text("保存")');
    
    // 验证表单验证信息显示
    await expect(page.locator('.el-form-item__error')).toBeVisible();
    
    // 输入空的热词
    await page.fill('.el-dialog input[placeholder="请输入热词"]', '   ');
    await page.click('.el-dialog button:has-text("保存")');
    
    // 验证仍然有错误信息
    await expect(page.locator('.el-form-item__error')).toBeVisible();
    
    // 输入正确的热词
    await page.fill('.el-dialog input[placeholder="请输入热词"]', '有效热词');
    await page.click('.el-dialog button:has-text("保存")');
    
    // 验证保存成功
    await expect(page.locator('.el-dialog')).toBeHidden();
    await expect(page.locator('.el-message--success')).toBeVisible();
  });
  
  test('响应式设计测试', async ({ page }) => {
    // 测试移动端视图
    await page.setViewportSize({ width: 375, height: 667 });
    
    // 验证页面在移动端仍然可用
    await expect(page.locator('h1')).toContainText('热词管理');
    await expect(page.locator('button:has-text("添加热词")')).toBeVisible();
    
    // 测试添加热词在移动端的表现
    await page.click('button:has-text("添加热词")');
    await expect(page.locator('.el-dialog')).toBeVisible();
    
    // 恢复桌面视图
    await page.setViewportSize({ width: 1280, height: 720 });
  });
  
  test('错误处理测试', async ({ page }) => {
    // 模拟网络错误情况
    await page.route('**/hotwords', (route) => {
      if (route.request().method() === 'POST') {
        route.fulfill({
          status: 500,
          body: JSON.stringify({ detail: '服务器内部错误' })
        });
      } else {
        route.continue();
      }
    });
    
    // 尝试添加热词
    await page.click('button:has-text("添加热词")');
    await page.fill('.el-dialog input[placeholder="请输入热词"]', '错误测试热词');
    await page.click('.el-dialog button:has-text("保存")');
    
    // 验证错误消息显示
    await expect(page.locator('.el-message--error')).toBeVisible();
    
    // 验证对话框仍然打开（用户可以重试）
    await expect(page.locator('.el-dialog')).toBeVisible();
  });
  
});

test.describe('热词管理权限测试', () => {
  
  test('未登录用户无法访问热词管理', async ({ page }) => {
    // 清除登录状态
    await page.evaluate(() => localStorage.removeItem('token'));
    
    // 尝试访问热词管理页面
    await page.goto('/hotwords');
    
    // 验证被重定向到登录页面
    await expect(page).toHaveURL('/login');
  });
  
});
```

--------------------------------------------------------------------------------

File: asr_system_frontend/tests/e2e/smoke.spec.ts
```typescript
import { test, expect } from '@playwright/test';

test.describe('应用冒烟测试', () => {
  test('应用正常加载', async ({ page }) => {
    await page.goto('/');
    
    // 验证页面标题
    await expect(page).toHaveTitle(/语音识别系统/);
    
    // 验证页面包含关键元素
    await expect(page.locator('text=登录')).toBeVisible();
  });

  test('登录页面正常加载', async ({ page }) => {
    await page.goto('/login');
    
    // 验证登录表单存在
    await expect(page.locator('input[type="text"]')).toBeVisible();
    await expect(page.locator('input[type="password"]')).toBeVisible();
    await expect(page.locator('button:has-text("登录")')).toBeVisible();
  });

  test('注册页面正常加载', async ({ page }) => {
    await page.goto('/register');
    
    // 验证注册表单存在
    await expect(page.locator('input[type="text"]')).toBeVisible();
    await expect(page.locator('input[type="password"]')).toBeVisible();
    await expect(page.locator('button:has-text("注册")')).toBeVisible();
  });
});
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/main.js
```javascript
import { createApp } from 'vue';
import App from './App.vue';
import router from './router';
import ElementPlus from 'element-plus';
import 'element-plus/dist/index.css';
import './assets/css/main.css';
import axios from 'axios';

// 移除硬编码的baseURL配置
// axios.defaults.baseURL = 'http://localhost:8000';
axios.defaults.headers.common['Content-Type'] = 'application/json';

// 添加请求拦截器，自动添加token
axios.interceptors.request.use(
  config => {
    const token = localStorage.getItem('token');
    if (token) {
      config.headers['Authorization'] = `Bearer ${token}`;
    }
    return config;
  },
  error => {
    return Promise.reject(error);
  }
);

const app = createApp(App);
app.use(router);
app.use(ElementPlus);
app.mount('#app');
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/App.vue
```text
<template>
  <router-view />
</template>

<script setup>
// 根组件无需逻辑
</script>

<style>
html, body, #app {
  height: 100%;
  margin: 0;
  padding: 0;
}
</style>
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/assets/css/main.css
```css
@tailwind base;
@tailwind components;
@tailwind utilities;
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/views/RealtimeTranscription.vue
```text
<template>
  <div class="min-h-screen bg-gray-900 text-gray-200">
    <header class="bg-gray-800 py-4 shadow-md">
      <div class="container mx-auto px-4 flex justify-between items-center">
        <h1 class="text-xl font-bold text-blue-400">录音转写</h1>
        <el-button type="primary" @click="$router.push('/')">返回首页</el-button>
      </div>
    </header>
    
    <main class="container mx-auto py-8 px-4 max-w-6xl">
      <div class="grid grid-cols-1 lg:grid-cols-3 gap-6">
        <!-- 左侧：控制面板 (UI保持原样) -->
        <div class="lg:col-span-1">
          <el-card class="bg-gray-800 border-none shadow-lg">
            <template #header>
              <div class="flex items-center">
                <el-icon class="mr-2"><microphone /></el-icon>
                <span>录音控制</span>
              </div>
            </template>
            
            <div class="space-y-4 p-2">
              <!-- 录音控制按钮 -->
              <div class="flex flex-col gap-3">
                <el-button 
                  :type="isRecording ? 'danger' : 'primary'"
                  :disabled="isLoading"
                  :loading="isLoading"
                  @click="toggleRecording"
                  size="large"
                  class="w-full"
                >
                  <el-icon class="mr-2">
                    <component :is="isRecording ? 'VideoPause' : 'VideoPlay'" />
                  </el-icon>
                  {{ buttonText }}
                </el-button>
              </div>

              <!-- 状态和时长显示 -->
              <div class="bg-gray-700 p-3 rounded text-center">
                <div class="text-sm text-gray-400">当前状态</div>
                <div class="text-lg font-semibold mt-1" :class="statusClass">
                  {{ statusText }}
                </div>
                <div v-if="isRecording" class="text-sm text-gray-400 mt-2">
                  录音时长: <span class="font-mono">{{ formatTime(recordingDuration) }}</span>
                </div>
              </div>

            </div>
          </el-card>
        </div>
        
        <!-- 右侧：转写结果 (UI保持原样) -->
        <div class="lg:col-span-2">
          <el-card class="bg-gray-800 border-none shadow-lg">
            <template #header>
              <div class="flex items-center justify-between">
                <div class="flex items-center">
                  <el-icon class="mr-2"><document /></el-icon>
                  <span>转写结果</span>
                </div>
                <div class="flex gap-2">
                  <el-button size="small" @click="clearResult" :disabled="isLoading">清空结果</el-button>
                  <el-button size="small" @click="exportResult" :disabled="!transcriptionResult || isLoading">导出文本</el-button>
                </div>
              </div>
            </template>
            
            <div 
              class="bg-gray-700 p-4 rounded min-h-[400px] max-h-[500px] overflow-y-auto"
            >
              <!-- 加载状态 -->
              <div v-if="isLoading" class="flex flex-col items-center justify-center h-full text-center text-gray-400">
                <el-icon class="is-loading text-4xl mb-4 text-blue-400"><loading /></el-icon>
                <p>正在努力转写中，请稍候...</p>
              </div>
              <!-- 空状态 -->
              <div v-else-if="!transcriptionResult" class="flex flex-col items-center justify-center h-full text-center text-gray-400">
                <el-icon class="text-5xl mb-2"><files /></el-icon>
                <p>点击“开始录音”，结束后结果将显示在这里</p>
              </div>
              <!-- 显示结果 -->
              <div v-else class="text-white text-lg leading-relaxed whitespace-pre-wrap">
                {{ transcriptionResult }}
              </div>
            </div>
          </el-card>
        </div>
      </div>
    </main>
  </div>
</template>

<script setup>
import { ref, computed, onUnmounted } from 'vue';
import { ElMessage } from 'element-plus';
import { Microphone, Document, VideoPlay, VideoPause, Loading, Files } from '@element-plus/icons-vue';

// --- 状态管理 ---
const isRecording = ref(false);
const isLoading = ref(false);
const mediaRecorder = ref(null);
const audioChunks = ref([]);
const transcriptionResult = ref('');
const recordingDuration = ref(0);
let recordingTimer = null;

// --- UI 计算属性 ---
const buttonText = computed(() => {
  if (isLoading.value) return '正在转写...';
  return isRecording.value ? '停止录音' : '开始录音';
});

const statusText = computed(() => {
  if (isLoading.value) return '正在处理';
  if (isRecording.value) return '正在录音';
  return '空闲';
});

const statusClass = computed(() => {
  if (isLoading.value) return 'text-blue-400';
  if (isRecording.value) return 'text-red-400';
  return 'text-green-400';
});

// --- 生命周期钩子 ---
onUnmounted(() => {
  if (mediaRecorder.value && mediaRecorder.value.state !== 'inactive') {
    mediaRecorder.value.stop();
  }
  if (recordingTimer) {
    clearInterval(recordingTimer);
  }
});

// --- 核心功能函数 (与上一版相同，但现在会驱动这个UI) ---

const toggleRecording = () => {
  if (!isRecording.value) {
    startRecording();
  } else {
    stopRecording();
  }
};

const startRecording = async () => {
  if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
    ElMessage.error('您的浏览器不支持录音功能。');
    return;
  }
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    
    audioChunks.value = [];
    transcriptionResult.value = '';
    
    mediaRecorder.value = new MediaRecorder(stream, { mimeType: 'audio/webm' });

    mediaRecorder.value.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunks.value.push(event.data);
      }
    };

    mediaRecorder.value.onstop = () => {
      transcribeAudio();
      stream.getTracks().forEach(track => track.stop());
    };

    mediaRecorder.value.start();
    isRecording.value = true;

    recordingDuration.value = 0;
    recordingTimer = setInterval(() => {
      recordingDuration.value++;
    }, 1000);

  } catch (error) {
    console.error('无法开始录音:', error);
    ElMessage.error('无法启动录音功能，请检查麦克风权限。');
  }
};

const stopRecording = () => {
  if (mediaRecorder.value && mediaRecorder.value.state === 'recording') {
    mediaRecorder.value.stop();
    isRecording.value = false;
    clearInterval(recordingTimer);
  }
};

const transcribeAudio = async () => {
  if (audioChunks.value.length === 0) {
    ElMessage.warning('录音内容过短，未进行转写。');
    return;
  }

  isLoading.value = true;
  transcriptionResult.value = '';

  const audioBlob = new Blob(audioChunks.value, { type: 'audio/webm' });
  const formData = new FormData();
  formData.append('file', audioBlob, `recording-${Date.now()}.webm`);

  try {
    const response = await fetch('/api/asr/transcribe/file', {
      method: 'POST',
      body: formData,
    });

    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(errorData.detail || '转写请求失败');
    }

    const data = await response.json();
    transcriptionResult.value = data.result || '未能识别出任何内容。';
    ElMessage.success('转写完成！');

  } catch (error) {
    console.error('转写失败:', error);
    ElMessage.error('转写失败: ' + error.message);
    transcriptionResult.value = `错误: ${error.message}`;
  } finally {
    isLoading.value = false;
  }
};

// --- 辅助UI函数 ---

const formatTime = (seconds) => {
  const m = String(Math.floor(seconds / 60)).padStart(2, '0');
  const s = String(seconds % 60).padStart(2, '0');
  return `${m}:${s}`;
};

const clearResult = () => {
  transcriptionResult.value = '';
};

const exportResult = () => {
  if (!transcriptionResult.value) {
    ElMessage.warning('没有可导出的结果');
    return;
  }
  const blob = new Blob([transcriptionResult.value], { type: 'text/plain;charset=utf-8' });
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = `录音转写结果.txt`;
  document.body.appendChild(a);
  a.click();
  document.body.removeChild(a);
  URL.revokeObjectURL(url);
};
</script>

<style scoped>
:deep(.el-card) {
  background-color: #374151;
  border: none;
}
:deep(.el-card__header) {
  background-color: rgba(17, 24, 39, 0.4);
  padding: 12px 16px;
}
</style>
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/views/FileTranscription.vue
```text
<template>
  <div class="min-h-screen bg-gray-900 text-gray-200">
    <header class="bg-gray-800 py-4 shadow-md">
      <div class="container mx-auto px-4">
        <div class="flex items-center justify-between">
          <h1 class="text-xl font-bold text-blue-400">音频转写</h1>
          <el-button type="primary" plain @click="goBack">返回</el-button>
        </div>
      </div>
    </header>
    
    <main class="container mx-auto py-8 px-4 max-w-4xl">
      <el-card class="bg-gray-800 border-none shadow-lg">
        <template #header>
          <div class="flex items-center">
            <span>上传音频文件</span>
          </div>
        </template>
        
        <div class="space-y-6">
          <!-- 文件上传区域 -->
          <div>
            <el-upload
              ref="uploadRef"
              class="upload-demo"
              drag
              :auto-upload="false"
              :on-change="handleFileChange"
              accept=".mp3,.wav,.m4a,.flac"
              :limit="1"
            >
              <el-icon class="el-icon--upload"><upload-filled /></el-icon>
              <div class="el-upload__text">
                将音频文件拖到此处，或<em>点击上传</em>
              </div>
              <template #tip>
                <div class="el-upload__tip text-gray-400">
                  支持 MP3、WAV、M4A、FLAC 格式
                </div>
              </template>
            </el-upload>
          </div>
          
          <!-- 提交按钮 -->
          <div class="flex justify-center">
            <el-button
              type="primary"
              :loading="uploading"
              @click="submitTranscription"
            >
              开始转写
            </el-button>
          </div>
        </div>
      </el-card>
      
      <!-- 转写结果 -->
      <el-card v-if="result" class="bg-gray-800 border-none shadow-lg mt-6">
        <template #header>
          <span>转写结果</span>
        </template>
        <div class="terminal-output">
          <pre class="whitespace-pre-wrap text-green-400 font-mono text-sm">{{ result }}</pre>
        </div>
      </el-card>

      <!-- 终端输出 -->
      <el-card v-if="terminalOutput" class="bg-gray-800 border-none shadow-lg mt-6">
        <template #header>
          <span>终端输出</span>
        </template>
        <div class="terminal-output">
          <pre class="whitespace-pre-wrap text-green-400 font-mono text-sm">{{ terminalOutput }}</pre>
        </div>
      </el-card>
    </main>
  </div>
</template>

<script setup>
import { ref } from 'vue';
import { ElMessage } from 'element-plus';
import { UploadFilled } from '@element-plus/icons-vue';
import { useRouter } from 'vue-router';

const router = useRouter();
const uploadRef = ref();
const selectedFile = ref(null);
const uploading = ref(false);
const result = ref('');
const terminalOutput = ref('');

function goBack() {
  router.back();
}

function handleFileChange(file) {
  selectedFile.value = file.raw;
}

async function submitTranscription() {
  if (!selectedFile.value) {
    ElMessage.error('请先选择要转写的音频文件');
    return;
  }
  
  try {
    uploading.value = true;
    
    const formData = new FormData();
    formData.append('file', selectedFile.value);
    
    const response = await fetch('/api/asr/transcribe/file', {
      method: 'POST',
      body: formData
    });
    
    if (!response.ok) {
      throw new Error('转写失败');
    }
    
    const data = await response.json();
    result.value = data.result;
    terminalOutput.value = data.terminal_output;
    ElMessage.success('转写完成');
    
  } catch (error) {
    console.error('转写失败:', error);
    ElMessage.error('转写失败: ' + error.message);
  } finally {
    uploading.value = false;
  }
}
</script>

<style scoped>
:deep(.el-card) {
  background-color: #374151;
  border: none;
  box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
}

:deep(.el-card__header) {
  background-color: rgba(17, 24, 39, 0.4);
  padding: 12px 16px;
  border-bottom: 1px solid rgba(75, 85, 99, 0.4);
}

:deep(.el-upload) {
  border: 2px dashed #4b5563;
  border-radius: 8px;
  cursor: pointer;
  position: relative;
  overflow: hidden;
  transition: all 0.3s ease;
  background-color: rgba(17, 24, 39, 0.2);
}

:deep(.el-upload:hover) {
  border-color: #3b82f6;
  transform: translateY(-1px);
}

:deep(.el-upload-dragger) {
  background-color: transparent;
  border: none;
  padding: 40px 20px;
}

:deep(.el-upload-dragger:hover) {
  background-color: rgba(107, 114, 128, 0.1);
}

:deep(.el-upload__text) {
  color: #9ca3af;
  margin-top: 16px;
}

:deep(.el-upload__text em) {
  color: #3b82f6;
  font-style: normal;
  font-weight: 500;
}

:deep(.el-button) {
  transition: all 0.3s ease;
}

:deep(.el-button:hover) {
  transform: translateY(-1px);
  box-shadow: 0 4px 6px -1px rgba(59, 130, 246, 0.1);
}

.terminal-output {
  background-color: rgba(17, 24, 39, 0.6);
  border-radius: 6px;
  padding: 16px;
  margin-top: 8px;
}

.terminal-output pre {
  margin: 0;
  line-height: 1.5;
}
</style>
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/views/HotwordManagement.vue
```text
<template>
  <div class="min-h-screen bg-gray-900 text-gray-200">
    <header class="bg-gray-800 py-4 shadow-md">
      <div class="container mx-auto px-4 flex justify-between items-center">
        <h1 class="text-xl font-bold text-blue-400">热词管理</h1>
        <el-button type="primary" @click="$router.push('/')">返回首页</el-button>
      </div>
    </header>
    
    <main class="container mx-auto py-8 px-4 max-w-6xl">
      <!-- 操作工具栏 -->
      <el-card class="bg-gray-800 border-none shadow-lg mb-6">
        <div class="flex flex-col sm:flex-row gap-4 items-start sm:items-center justify-between">
          <div class="flex flex-col sm:flex-row gap-4 items-start sm:items-center">
            <el-button type="primary" @click="showAddDialog = true">
              <el-icon><plus /></el-icon>
              添加热词
            </el-button>
            <el-button type="success" @click="showImportDialog = true">
              <el-icon><upload /></el-icon>
              批量导入
            </el-button>
            <el-button type="danger" :disabled="selectedRows.length === 0" @click="batchDelete">
              <el-icon><delete /></el-icon>
              批量删除 ({{ selectedRows.length }})
            </el-button>
          </div>
          <div class="flex gap-4 items-center">
            <span class="text-sm text-gray-400">共 {{ total }} 个热词</span>
            <el-input
              v-model="searchKeyword"
              placeholder="搜索热词..."
              prefix-icon="Search"
              clearable
              @input="handleSearch"
              class="w-64"
            />
          </div>
        </div>
      </el-card>
      
      <!-- 热词列表 -->
      <el-card class="bg-gray-800 border-none shadow-lg">
        <el-table
          v-loading="loading"
          :data="filteredHotwords"
          style="width: 100%"
          @selection-change="handleSelectionChange"
          :empty-text="hotwords.length === 0 ? '暂无热词，点击添加按钮创建' : '没有匹配的热词'"
        >
          <el-table-column type="selection" width="55" />
          <el-table-column prop="word" label="热词" min-width="200">
            <template #default="scope">
              <span class="font-medium">{{ scope.row.word }}</span>
            </template>
          </el-table-column>
          <el-table-column prop="weight" label="权重" width="120">
            <template #default="scope">
              <el-tag :type="getWeightType(scope.row.weight)" size="small">
                {{ scope.row.weight }}
              </el-tag>
            </template>
          </el-table-column>
          <el-table-column prop="created_at" label="创建时间" width="180">
            <template #default="scope">
              {{ formatDate(scope.row.created_at) }}
            </template>
          </el-table-column>
          <el-table-column label="操作" width="160">
            <template #default="scope">
              <div class="flex gap-2">
                <el-button type="primary" size="small" @click="editHotword(scope.row)">
                  编辑
                </el-button>
                <el-button type="danger" size="small" @click="deleteHotword(scope.row)">
                  删除
                </el-button>
              </div>
            </template>
          </el-table-column>
        </el-table>
      </el-card>
      
      <!-- 添加/编辑热词对话框 -->
      <el-dialog
        v-model="showAddDialog"
        :title="editingHotword ? '编辑热词' : '添加热词'"
        width="500px"
        :close-on-click-modal="false"
      >
        <el-form
          ref="hotwordFormRef"
          :model="hotwordForm"
          :rules="hotwordRules"
          label-width="80px"
        >
          <el-form-item label="热词" prop="word">
            <el-input
              v-model="hotwordForm.word"
              placeholder="请输入热词"
              maxlength="255"
              show-word-limit
            />
          </el-form-item>
          <el-form-item label="权重" prop="weight">
            <el-slider
              v-model="hotwordForm.weight"
              :min="1"
              :max="10"
              :marks="weightMarks"
              show-tooltip
            />
            <div class="text-sm text-gray-400 mt-2">
              权重越高，识别优先级越高（建议：常用词1-5，专业术语6-10）
            </div>
          </el-form-item>
        </el-form>
        
        <template #footer>
          <div class="dialog-footer">
            <el-button @click="showAddDialog = false">取消</el-button>
            <el-button type="primary" @click="saveHotword" :loading="saving">
              {{ editingHotword ? '更新' : '添加' }}
            </el-button>
          </div>
        </template>
      </el-dialog>
      
      <!-- 批量导入对话框 -->
      <el-dialog
        v-model="showImportDialog"
        title="批量导入热词"
        width="600px"
        :close-on-click-modal="false"
      >
        <div class="space-y-4">
          <div class="bg-blue-900 p-4 rounded-lg">
            <h4 class="font-semibold mb-2">导入格式说明：</h4>
            <ul class="text-sm space-y-1">
              <li>• 支持 CSV 和 TXT 格式文件</li>
              <li>• CSV 格式：每行一个热词，格式为 "热词,权重"（权重可选，默认为5）</li>
              <li>• TXT 格式：每行一个热词</li>
              <li>• 示例：机器学习,8</li>
              <li>• 最多可导入100个热词（包含现有热词）</li>
            </ul>
          </div>
          
          <el-upload
            ref="importUploadRef"
            :auto-upload="false"
            :on-change="handleImportFileChange"
            :before-remove="handleImportFileRemove"
            accept=".csv,.txt"
            :limit="1"
            drag
          >
            <el-icon class="el-icon--upload"><upload-filled /></el-icon>
            <div class="el-upload__text">
              将文件拖到此处，或<em>点击上传</em>
            </div>
            <template #tip>
              <div class="el-upload__tip">
                只能上传 CSV/TXT 文件，且不超过 1MB
              </div>
            </template>
          </el-upload>
          
          <div v-if="importPreview.length > 0" class="bg-gray-700 p-4 rounded-lg">
            <h4 class="font-semibold mb-2">预览（前10条）：</h4>
            <div class="space-y-1 text-sm">
              <div v-for="(item, index) in importPreview.slice(0, 10)" :key="index" class="flex justify-between">
                <span>{{ item.word }}</span>
                <span class="text-gray-400">权重: {{ item.weight }}</span>
              </div>
              <div v-if="importPreview.length > 10" class="text-gray-400">
                ...还有 {{ importPreview.length - 10 }} 条
              </div>
            </div>
          </div>
        </div>
        
        <template #footer>
          <div class="dialog-footer">
            <el-button @click="showImportDialog = false">取消</el-button>
            <el-button 
              type="primary" 
              @click="submitImport" 
              :disabled="importPreview.length === 0"
              :loading="importing"
            >
              导入 {{ importPreview.length }} 个热词
            </el-button>
          </div>
        </template>
      </el-dialog>
    </main>
  </div>
</template>

<script setup>
import { ref, reactive, computed, onMounted } from 'vue';
import { useRouter } from 'vue-router';
import { ElMessage, ElMessageBox } from 'element-plus';
import { Plus, Upload, Delete, UploadFilled } from '@element-plus/icons-vue';
import { hotwordAPI } from '../services/api';

const router = useRouter();

// 数据状态
const hotwords = ref([]);
const loading = ref(false);
const saving = ref(false);
const importing = ref(false);
const total = ref(0);
const selectedRows = ref([]);
const searchKeyword = ref('');

// 对话框状态
const showAddDialog = ref(false);
const showImportDialog = ref(false);
const editingHotword = ref(null);

// 表单数据
const hotwordForm = reactive({
  word: '',
  weight: 5
});

const importPreview = ref([]);
const importFile = ref(null);

// 表单验证规则
const hotwordRules = {
  word: [
    { required: true, message: '请输入热词', trigger: 'blur' },
    { min: 1, max: 255, message: '热词长度应在1-255字符之间', trigger: 'blur' }
  ],
  weight: [
    { required: true, message: '请选择权重', trigger: 'change' },
    { type: 'number', min: 1, max: 10, message: '权重必须在1-10之间', trigger: 'change' }
  ]
};

// 权重滑块标记
const weightMarks = {
  1: '低',
  5: '中',
  10: '高'
};

// 计算属性
const filteredHotwords = computed(() => {
  if (!searchKeyword.value) return hotwords.value;
  const keyword = searchKeyword.value.toLowerCase();
  return hotwords.value.filter(item => 
    item.word.toLowerCase().includes(keyword)
  );
});

onMounted(() => {
  loadHotwords();
});

// 加载热词列表
async function loadHotwords() {
  try {
    loading.value = true;
    const result = await hotwordAPI.getUserHotwords(0, 100);
    hotwords.value = result;
    total.value = result.length;
  } catch (error) {
    console.error('加载热词失败:', error);
    ElMessage.error('加载热词失败: ' + (error.response?.data?.detail || error.message));
  } finally {
    loading.value = false;
  }
}

// 表格选择变化
function handleSelectionChange(selection) {
  selectedRows.value = selection;
}

// 搜索处理
function handleSearch() {
  // 搜索是响应式的，由computed自动处理
}

// 编辑热词
function editHotword(hotword) {
  editingHotword.value = hotword;
  hotwordForm.word = hotword.word;
  hotwordForm.weight = hotword.weight;
  showAddDialog.value = true;
}

// 保存热词
async function saveHotword() {
  const hotwordFormRef = ref();
  if (!hotwordFormRef.value) return;
  
  try {
    await hotwordFormRef.value.validate();
    saving.value = true;
    
    if (editingHotword.value) {
      // 更新热词
      await hotwordAPI.updateHotword(editingHotword.value.id, {
        word: hotwordForm.word,
        weight: hotwordForm.weight
      });
      ElMessage.success('热词更新成功');
    } else {
      // 添加热词
      await hotwordAPI.createHotword(hotwordForm.word, hotwordForm.weight);
      ElMessage.success('热词添加成功');
    }
    
    showAddDialog.value = false;
    resetForm();
    loadHotwords();
  } catch (error) {
    console.error('保存热词失败:', error);
    ElMessage.error('保存失败: ' + (error.response?.data?.detail || error.message));
  } finally {
    saving.value = false;
  }
}

// 删除热词
async function deleteHotword(hotword) {
  try {
    await ElMessageBox.confirm(
      `确定要删除热词 "${hotword.word}" 吗？`,
      '确认删除',
      {
        confirmButtonText: '确定',
        cancelButtonText: '取消',
        type: 'warning'
      }
    );
    
    await hotwordAPI.deleteHotword(hotword.id);
    ElMessage.success('热词删除成功');
    loadHotwords();
  } catch (error) {
    if (error !== 'cancel') {
      console.error('删除热词失败:', error);
      ElMessage.error('删除失败: ' + (error.response?.data?.detail || error.message));
    }
  }
}

// 批量删除
async function batchDelete() {
  if (selectedRows.value.length === 0) return;
  
  try {
    await ElMessageBox.confirm(
      `确定要删除选中的 ${selectedRows.value.length} 个热词吗？`,
      '确认批量删除',
      {
        confirmButtonText: '确定',
        cancelButtonText: '取消',
        type: 'warning'
      }
    );
    
    // 并行删除所有选中的热词
    await Promise.all(
      selectedRows.value.map(hotword => hotwordAPI.deleteHotword(hotword.id))
    );
    
    ElMessage.success(`成功删除 ${selectedRows.value.length} 个热词`);
    selectedRows.value = [];
    loadHotwords();
  } catch (error) {
    if (error !== 'cancel') {
      console.error('批量删除失败:', error);
      ElMessage.error('批量删除失败: ' + (error.response?.data?.detail || error.message));
    }
  }
}

// 处理导入文件变化
function handleImportFileChange(file) {
  importFile.value = file.raw;
  parseImportFile(file.raw);
}

function handleImportFileRemove() {
  importFile.value = null;
  importPreview.value = [];
}

// 解析导入文件
async function parseImportFile(file) {
  try {
    const text = await file.text();
    const lines = text.split('\n').filter(line => line.trim());
    const preview = [];
    
    for (const line of lines) {
      const trimmed = line.trim();
      if (!trimmed) continue;
      
      let word, weight = 5;
      
      // 尝试解析CSV格式
      if (trimmed.includes(',')) {
        const parts = trimmed.split(',');
        word = parts[0].trim();
        if (parts[1]) {
          const w = parseInt(parts[1].trim());
          if (w >= 1 && w <= 10) {
            weight = w;
          }
        }
      } else {
        word = trimmed;
      }
      
      if (word) {
        preview.push({ word, weight });
      }
    }
    
    importPreview.value = preview;
  } catch (error) {
    console.error('解析文件失败:', error);
    ElMessage.error('文件解析失败');
    importPreview.value = [];
  }
}

// 提交导入
async function submitImport() {
  if (!importFile.value) {
    ElMessage.error('请选择要导入的文件');
    return;
  }
  
  try {
    importing.value = true;
    const result = await hotwordAPI.importHotwords(importFile.value);
    
    ElMessage.success(
      `导入完成：成功添加 ${result.added_count} 个热词，跳过 ${result.skipped_count} 个重复热词`
    );
    
    showImportDialog.value = false;
    importFile.value = null;
    importPreview.value = [];
    loadHotwords();
  } catch (error) {
    console.error('导入失败:', error);
    ElMessage.error('导入失败: ' + (error.response?.data?.detail || error.message));
  } finally {
    importing.value = false;
  }
}

// 重置表单
function resetForm() {
  editingHotword.value = null;
  hotwordForm.word = '';
  hotwordForm.weight = 5;
}

// 工具函数
function getWeightType(weight) {
  if (weight <= 3) return 'info';
  if (weight <= 6) return 'warning';
  return 'success';
}

function formatDate(dateString) {
  const date = new Date(dateString);
  return date.toLocaleString('zh-CN');
}
</script>

<style scoped>
:deep(.el-card) {
  background-color: #374151;
  border: none;
}

:deep(.el-card__header) {
  background-color: rgba(17, 24, 39, 0.4);
  padding: 12px 16px;
}

:deep(.el-table) {
  background-color: transparent !important;
}

:deep(.el-table th.el-table__cell) {
  background-color: #1f2937 !important;
}

:deep(.el-table tr) {
  background-color: #374151 !important;
}

:deep(.el-table--striped .el-table__body tr.el-table__row--striped td.el-table__cell) {
  background-color: #4b5563 !important;
}

:deep(.el-table__body tr:hover > td.el-table__cell) {
  background-color: #6b7280 !important;
}

:deep(.el-dialog) {
  background-color: #374151;
}

:deep(.el-dialog__header) {
  background-color: #1f2937;
  margin: 0;
  padding: 16px 20px;
}

:deep(.el-dialog__body) {
  padding: 20px;
}

:deep(.el-upload) {
  border: 2px dashed #4b5563;
  border-radius: 6px;
}

:deep(.el-upload:hover) {
  border-color: #3b82f6;
}

:deep(.el-upload-dragger) {
  background-color: #4b5563;
  border: none;
}

:deep(.el-upload-dragger:hover) {
  background-color: #6b7280;
}

:deep(.el-slider__runway) {
  background-color: #4b5563;
}

:deep(.el-slider__button) {
  border-color: #3b82f6;
}

:deep(.el-form-item__label) {
  color: #d1d5db;
}
</style>
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/views/Dashboard.vue
```text
<template>
  <div class="min-h-screen bg-gray-900 text-gray-200">
    <header class="bg-gray-800 py-4 shadow-md">
      <div class="container mx-auto px-4 flex justify-between items-center">
        <h1 class="text-xl font-bold text-blue-400">支持热词预测的语音识别系统</h1>
        <div class="flex items-center gap-4">
          <span>{{ username }}</span>
          <el-button type="danger" size="small" @click="logout">退出登录</el-button>
        </div>
      </div>
    </header>
    
    <main class="container mx-auto py-8 px-4">
      <h2 class="text-2xl font-bold mb-6">欢迎使用语音识别系统</h2>
      
      <div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-10">
        <el-card class="bg-gray-800 border-none shadow-lg hover:shadow-xl transition-all">
          <template #header>
            <div class="flex items-center">
              <i class="el-icon-microphone mr-2"></i>
              <span>离线文件转写</span>
            </div>
          </template>
          <div class="text-gray-400">
            上传音频文件，系统会自动进行转写并返回文本结果。
          </div>
          <el-button type="primary" class="mt-4 w-full" @click="$router.push('/transcribe')">开始转写</el-button>
        </el-card>
        
        <el-card class="bg-gray-800 border-none shadow-lg hover:shadow-xl transition-all">
          <template #header>
            <div class="flex items-center">
              <i class="el-icon-video-play mr-2"></i>
              <span>实时语音转写</span>
            </div>
          </template>
          <div class="text-gray-400">
            使用麦克风进行实时录音，系统会即时转写您的语音内容。
          </div>
          <el-button type="success" class="mt-4 w-full" @click="$router.push('/realtime')">开始实时转写</el-button>
        </el-card>
        
        <el-card class="bg-gray-800 border-none shadow-lg hover:shadow-xl transition-all">
          <template #header>
            <div class="flex items-center">
              <i class="el-icon-s-order mr-2"></i>
              <span>热词管理</span>
            </div>
          </template>
          <div class="text-gray-400">
            添加和管理您的专业领域词汇，提高语音识别准确率。
          </div>
          <el-button type="warning" class="mt-4 w-full" @click="$router.push('/hotwords')">管理热词</el-button>
        </el-card>
      </div>
    </main>
  </div>
</template>

<script setup>
import { ref, onMounted } from 'vue';
import { useRouter } from 'vue-router';
import { authAPI } from '../services/api';
import { ElMessage } from 'element-plus';

const router = useRouter();
const username = ref('用户');

onMounted(async () => {
  try {
    // 获取当前用户信息
    const userData = await authAPI.getCurrentUser();
    username.value = userData.username;
  } catch (err) {
    console.error('加载数据失败', err);
    if (err.response?.status === 401) {
      ElMessage.error('登录已过期，请重新登录');
      logout();
    }
  }
});

function logout() {
  localStorage.removeItem('token');
  router.push('/login');
}
</script>

<style scoped>
:deep(.el-card) {
  background-color: #374151;
  border: none;
}

:deep(.el-card__header) {
  background-color: rgba(17, 24, 39, 0.4);
  padding: 12px 16px;
}
</style>
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/views/Auth/RegisterPage.vue
```text
<template>
  <div class="min-h-screen flex items-center justify-center bg-gray-900">
    <div class="w-full max-w-md p-8 bg-gray-800 rounded-lg shadow-lg border border-gray-700">
      <h1 class="text-3xl font-bold text-center text-blue-400 mb-8">用户注册</h1>
      <el-form :model="form" ref="registerForm" class="space-y-4">
        <el-form-item prop="username">
          <el-input v-model="form.username" placeholder="请输入用户名" prefix-icon="el-icon-user" size="large" clearable />
        </el-form-item>
        <el-form-item prop="password">
          <el-input v-model="form.password" type="password" placeholder="请输入密码" prefix-icon="el-icon-lock" size="large" show-password clearable />
        </el-form-item>
        <el-form-item prop="confirmPassword">
          <el-input v-model="form.confirmPassword" type="password" placeholder="请再次输入密码" size="large" show-password clearable />
        </el-form-item>
        <div v-if="errorMsg" class="text-red-500 text-sm text-center mb-2">{{ errorMsg }}</div>
        <el-form-item>
          <el-button type="primary" size="large" class="w-full" @click="onSubmit" :loading="loading">注册</el-button>
        </el-form-item>
        <div class="text-sm text-center mt-4">
          已有账号？<router-link to="/login" class="text-blue-400 hover:underline">立即登录</router-link>
        </div>
      </el-form>
    </div>
  </div>
</template>

<script setup>
import { ref } from 'vue';
import { useRouter } from 'vue-router';
import { authAPI } from '../../services/api';
import { ElMessage } from 'element-plus';

const router = useRouter();
const form = ref({ username: '', password: '', confirmPassword: '' });
const errorMsg = ref('');
const loading = ref(false);

async function onSubmit() {
  if (!form.value.username || !form.value.password || !form.value.confirmPassword) {
    errorMsg.value = '所有字段均为必填项。';
    return;
  }
  if (form.value.password !== form.value.confirmPassword) {
    errorMsg.value = '两次输入的密码不一致。';
    return;
  }
  
  loading.value = true;
  errorMsg.value = '';
  
  try {
    await authAPI.register(form.value.username, form.value.password);
    ElMessage({
      message: '注册成功！将返回登录页面。',
      type: 'success'
    });
    router.push('/login');
  } catch (err) {
    errorMsg.value = err.response?.data?.detail || '注册失败';
  } finally {
    loading.value = false;
  }
}
</script>

<style scoped>
</style>
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/views/Auth/LoginPage.vue
```text
<template>
  <div class="min-h-screen flex items-center justify-center bg-gray-900">
    <div class="w-full max-w-md p-8 bg-gray-800 rounded-lg shadow-lg border border-gray-700">
      <h1 class="text-3xl font-bold text-center text-blue-400 mb-8">系统登录</h1>
      <el-form :model="form" ref="loginForm" class="space-y-4">
        <el-form-item prop="username">
          <el-input v-model="form.username" placeholder="请输入用户名/邮箱" prefix-icon="el-icon-user" size="large" clearable />
        </el-form-item>
        <el-form-item prop="password">
          <el-input v-model="form.password" type="password" placeholder="请输入密码" prefix-icon="el-icon-lock" size="large" show-password clearable />
        </el-form-item>
        <el-form-item>
          <div class="flex items-center gap-2">
            <el-input v-model="form.captcha" placeholder="输入验证码" maxlength="4" class="w-1/2" />
            <div class="captcha-box flex-1 h-12 flex items-center justify-center rounded bg-gray-900 border border-yellow-400 text-yellow-400 text-lg font-mono tracking-widest cursor-pointer select-none" @click="generateCaptcha" :title="'点击刷新'">{{ captcha }}</div>
          </div>
        </el-form-item>
        <div v-if="errorMsg" class="text-red-500 text-sm text-center mb-2">{{ errorMsg }}</div>
        <el-form-item>
          <el-button type="primary" size="large" class="w-full" @click="onSubmit" :loading="loading">登录</el-button>
        </el-form-item>
        <div class="text-sm text-center mt-4">
          还没有账号？<router-link to="/register" class="text-blue-400 hover:underline">立即注册</router-link>
        </div>
      </el-form>
    </div>
  </div>
</template>

<script setup>
import { ref } from 'vue';
import { useRouter } from 'vue-router';
import { authAPI } from '../../services/api';

const router = useRouter();
const form = ref({ username: '', password: '', captcha: '' });
const errorMsg = ref('');
const captcha = ref('');
const loading = ref(false);

function generateCaptcha() {
  const chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789';
  let result = '';
  for (let i = 0; i < 4; i++) {
    result += chars.charAt(Math.floor(Math.random() * chars.length));
  }
  captcha.value = result;
}

async function onSubmit() {
  if (!form.value.username || !form.value.password || !form.value.captcha) {
    errorMsg.value = '所有字段均为必填项。';
    return;
  }
  if (form.value.captcha.toUpperCase() !== captcha.value) {
    errorMsg.value = '验证码不正确。';
    generateCaptcha();
    return;
  }

  loading.value = true;
  errorMsg.value = '';

  try {
    const res = await authAPI.login(form.value.username, form.value.password);
    localStorage.setItem('token', res.access_token);
    router.push('/');
  } catch (err) {
    errorMsg.value = err.response?.data?.detail || '登录失败，请检查用户名和密码';
    generateCaptcha();
  } finally {
    loading.value = false;
  }
}

generateCaptcha();
</script>

<style scoped>
.captcha-box {
  min-width: 80px;
  height: 48px;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 1.5rem;
  font-family: 'Courier New', Courier, monospace;
  letter-spacing: 5px;
  user-select: none;
  cursor: pointer;
  background-color: #18181b;
  border: 1px solid #facc15;
  color: #facc15;
}
</style>
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/services/api.js
```javascript
import axios from 'axios';

// 配置axios基础URL - 使用相对路径，依赖vite的代理配置
axios.defaults.withCredentials = true;  // 允许跨域请求携带凭证

// WebSocket URL配置 - 使用相对路径
const WS_BASE_URL = '';  // 空字符串表示使用相对路径

// 请求拦截器：添加认证token
// 确保拦截器正常工作
axios.interceptors.request.use(config => {
  const token = localStorage.getItem('token');
  config.headers.Authorization = `Bearer ${token}`; // 需要确认token存在
  return config;
});

// 响应拦截器：处理401错误
axios.interceptors.response.use(
  (response) => {
    return response;
  },
  (error) => {
    if (error.response && error.response.status === 401) {
      // Token过期或无效，清除本地存储并跳转到登录页
      localStorage.removeItem('token');
      localStorage.removeItem('user');
      window.location.href = '/login';
    }
    return Promise.reject(error);
  }
);

// Auth API
export const authAPI = {
  login: async (username, password) => {
    const formData = new FormData();
    formData.append('username', username);
    formData.append('password', password);
    const response = await axios.post('/auth/token', formData, {
      headers: {
        'Content-Type': 'multipart/form-data'
      }
    });
    return response.data;
  },
  
  register: async (username, password) => {
    const formData = new FormData();
    formData.append('username', username);
    formData.append('password', password);
    const response = await axios.post('/auth/register', formData, {
      headers: {
        'Content-Type': 'multipart/form-data'
      }
    });
    return response.data;
  },
  
  getCurrentUser: async () => {
    const response = await axios.get('/auth/me');
    return response.data;
  }
};

// Transcription API
export const transcriptionAPI = {
  submitTask: async (file, hotwordListId = null) => {
    const formData = new FormData();
    formData.append('file', file);
    if (hotwordListId) {
      formData.append('hotword_list_id', hotwordListId);
    }
    
    const response = await axios.post('/asr/transcribe/file', formData, {
      headers: {
        'Content-Type': 'multipart/form-data'
      }
    });
    
    return response.data;
  }
};

// Hotwords API
export const hotwordAPI = {
  createHotword: async (word, weight) => {
    const response = await axios.post('/hotwords', { word, weight });
    return response.data;
  },
  
  getUserHotwords: async (skip = 0, limit = 100) => {
    const response = await axios.get(`/hotwords?skip=${skip}&limit=${limit}`);
    return response.data;
  },
  
  updateHotword: async (hotwordId, data) => {
    const response = await axios.put(`/hotwords/${hotwordId}`, data);
    return response.data;
  },
  
  deleteHotword: async (hotwordId) => {
    const response = await axios.delete(`/hotwords/${hotwordId}`);
    return response.data;
  },
  
  importHotwords: async (file) => {
    const formData = new FormData();
    formData.append('file', file);
    
    const response = await axios.post('/hotwords/import', formData, {
      headers: {
        'Content-Type': 'multipart/form-data'
      }
    });
    
    return response.data;
  }
};

// Realtime API (WebSocket 相关工具函数)
export const realtimeAPI = {
  getWebSocketUrl: () => {
    const token = localStorage.getItem('token');
    return `${WS_BASE_URL}/ws/asr/transcribe/realtime?token=${token}`;
  },
  
  // 心跳检测
  sendHeartbeat: (websocket) => {
    if (websocket && websocket.readyState === WebSocket.OPEN) {
      websocket.send(JSON.stringify({
        type: 'ping',
        timestamp: Date.now()
      }));
    }
  },
  
  // 发送命令
  sendCommand: (websocket, command) => {
    if (websocket && websocket.readyState === WebSocket.OPEN) {
      websocket.send(JSON.stringify(command));
    }
  }
};
```

--------------------------------------------------------------------------------

File: asr_system_frontend/src/router/index.js
```javascript
import { createRouter, createWebHistory } from 'vue-router';
import LoginPage from '../views/Auth/LoginPage.vue';
import RegisterPage from '../views/Auth/RegisterPage.vue';
import Dashboard from '../views/Dashboard.vue';
import FileTranscription from '../views/FileTranscription.vue';
import RealtimeTranscription from '../views/RealtimeTranscription.vue';
import HotwordManagement from '../views/HotwordManagement.vue';

const routes = [
  { path: '/login', component: LoginPage },
  { path: '/register', component: RegisterPage },
  { path: '/', component: Dashboard },
  { path: '/transcribe', component: FileTranscription },
  { path: '/realtime', component: RealtimeTranscription },
  { path: '/hotwords', component: HotwordManagement },
];

const router = createRouter({
  history: createWebHistory(),
  routes,
});

router.beforeEach((to, from, next) => {
  const publicPages = ['/login', '/register'];
  const authRequired = !publicPages.includes(to.path);
  const token = localStorage.getItem('token');
  if (authRequired && !token) {
    return next('/login');
  }
  next();
});

export default router;
```

--------------------------------------------------------------------------------

File: test/test_hotwords.py
```python
import pytest
import sys
import os

# 添加项目根目录到Python路径
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from asr_system_backend.app.main import app
from asr_system_backend.app.database import Base, get_db
from asr_system_backend.app.models import User, Hotword
from asr_system_backend.app.auth_service import get_password_hash
import tempfile

# 创建测试数据库
SQLALCHEMY_DATABASE_URL = "sqlite:///./test.db"
engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False})
TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# 创建数据库表
Base.metadata.create_all(bind=engine)

def override_get_db():
    try:
        db = TestingSessionLocal()
        yield db
    finally:
        db.close()

# 覆盖依赖
app.dependency_overrides[get_db] = override_get_db

client = TestClient(app)

@pytest.fixture
def test_user():
    """创建测试用户"""
    db = TestingSessionLocal()
    try:
        # 清理现有测试数据
        db.query(Hotword).delete()
        db.query(User).delete()
        db.commit()
        
        # 创建测试用户
        user = User(
            username="testuser",
            hashed_password=get_password_hash("testpass123")
        )
        db.add(user)
        db.commit()
        db.refresh(user)
        
        return user
    finally:
        db.close()

@pytest.fixture
def auth_headers(test_user):
    """获取认证头"""
    response = client.post("/auth/login", json={
        "username": "testuser",
        "password": "testpass123"
    })
    assert response.status_code == 200
    token = response.json()["access_token"]
    return {"Authorization": f"Bearer {token}"}

class TestHotwordAPI:
    """热词管理API测试"""
    
    def test_create_hotword(self, auth_headers):
        """测试创建热词"""
        response = client.post("/hotwords", json={
            "word": "测试热词",
            "weight": 8
        }, headers=auth_headers)
        
        assert response.status_code == 200
        data = response.json()
        assert data["word"] == "测试热词"
        assert data["weight"] == 8
        assert "id" in data
        assert "created_at" in data
    
    def test_create_hotword_invalid_weight(self, auth_headers):
        """测试创建热词 - 无效权重"""
        response = client.post("/hotwords", json={
            "word": "测试热词",
            "weight": 15  # 超出范围
        }, headers=auth_headers)
        
        assert response.status_code == 422
    
    def test_create_duplicate_hotword(self, auth_headers):
        """测试创建重复热词"""
        # 创建第一个热词
        client.post("/hotwords", json={
            "word": "重复热词",
            "weight": 5
        }, headers=auth_headers)
        
        # 尝试创建相同的热词
        response = client.post("/hotwords", json={
            "word": "重复热词",
            "weight": 6
        }, headers=auth_headers)
        
        assert response.status_code == 409
        assert "热词已存在" in response.json()["detail"]
    
    def test_get_user_hotwords(self, auth_headers):
        """测试获取用户热词列表"""
        # 创建几个热词
        for i in range(3):
            client.post("/hotwords", json={
                "word": f"热词{i}",
                "weight": 5
            }, headers=auth_headers)
        
        response = client.get("/hotwords", headers=auth_headers)
        
        assert response.status_code == 200
        data = response.json()
        assert len(data) == 3
        assert all("word" in item for item in data)
    
    def test_get_user_hotwords_pagination(self, auth_headers):
        """测试热词列表分页"""
        # 创建5个热词
        for i in range(5):
            client.post("/hotwords", json={
                "word": f"分页热词{i}",
                "weight": 5
            }, headers=auth_headers)
        
        # 测试分页
        response = client.get("/hotwords?skip=0&limit=2", headers=auth_headers)
        assert response.status_code == 200
        data = response.json()
        assert len(data) == 2
        
        response = client.get("/hotwords?skip=2&limit=2", headers=auth_headers)
        assert response.status_code == 200
        data = response.json()
        assert len(data) == 2
    
    def test_update_hotword(self, auth_headers):
        """测试更新热词"""
        # 创建热词
        response = client.post("/hotwords", json={
            "word": "原始热词",
            "weight": 5
        }, headers=auth_headers)
        hotword_id = response.json()["id"]
        
        # 更新热词
        response = client.put(f"/hotwords/{hotword_id}", json={
            "word": "更新热词",
            "weight": 8
        }, headers=auth_headers)
        
        assert response.status_code == 200
        data = response.json()
        assert data["word"] == "更新热词"
        assert data["weight"] == 8
    
    def test_update_nonexistent_hotword(self, auth_headers):
        """测试更新不存在的热词"""
        response = client.put("/hotwords/nonexistent", json={
            "word": "更新热词",
            "weight": 8
        }, headers=auth_headers)
        
        assert response.status_code == 404
    
    def test_delete_hotword(self, auth_headers):
        """测试删除热词"""
        # 创建热词
        response = client.post("/hotwords", json={
            "word": "待删除热词",
            "weight": 5
        }, headers=auth_headers)
        hotword_id = response.json()["id"]
        
        # 删除热词
        response = client.delete(f"/hotwords/{hotword_id}", headers=auth_headers)
        assert response.status_code == 200
        
        # 验证热词已被删除
        response = client.get("/hotwords", headers=auth_headers)
        data = response.json()
        assert not any(hw["id"] == hotword_id for hw in data)
    
    def test_delete_nonexistent_hotword(self, auth_headers):
        """测试删除不存在的热词"""
        response = client.delete("/hotwords/nonexistent", headers=auth_headers)
        assert response.status_code == 404
    
    def test_bulk_import_hotwords_csv(self, auth_headers):
        """测试批量导入热词 - CSV格式"""
        # 创建临时CSV文件
        csv_content = """热词1,5
热词2,8
热词3,3
"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            f.write(csv_content)
            temp_file = f.name
        
        try:
            # 上传CSV文件
            with open(temp_file, 'rb') as f:
                response = client.post("/hotwords/import", 
                    files={"file": ("hotwords.csv", f, "text/csv")},
                    headers=auth_headers
                )
            
            assert response.status_code == 200
            data = response.json()
            assert data["added_count"] == 3
            assert data["skipped_count"] == 0
            
            # 验证热词已导入
            response = client.get("/hotwords", headers=auth_headers)
            hotwords = response.json()
            assert len(hotwords) == 3
            
        finally:
            os.unlink(temp_file)
    
    def test_bulk_import_hotwords_with_duplicates(self, auth_headers):
        """测试批量导入热词 - 包含重复项"""
        # 先创建一个热词
        client.post("/hotwords", json={
            "word": "已存在热词",
            "weight": 5
        }, headers=auth_headers)
        
        # 创建包含重复热词的CSV文件
        csv_content = """已存在热词,8
新热词1,6
新热词2,7
"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            f.write(csv_content)
            temp_file = f.name
        
        try:
            # 上传CSV文件
            with open(temp_file, 'rb') as f:
                response = client.post("/hotwords/import", 
                    files={"file": ("hotwords.csv", f, "text/csv")},
                    headers=auth_headers
                )
            
            assert response.status_code == 200
            data = response.json()
            assert data["added_count"] == 2  # 只添加了两个新热词
            assert data["skipped_count"] == 1  # 跳过了一个重复热词
            
        finally:
            os.unlink(temp_file)
    
    def test_bulk_import_invalid_file_format(self, auth_headers):
        """测试批量导入 - 无效文件格式"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            f.write("invalid content")
            temp_file = f.name
        
        try:
            # 上传无效格式文件
            with open(temp_file, 'rb') as f:
                response = client.post("/hotwords/import", 
                    files={"file": ("hotwords.pdf", f, "application/pdf")},
                    headers=auth_headers
                )
            
            assert response.status_code == 422
            
        finally:
            os.unlink(temp_file)
    
    def test_hotword_access_control(self, auth_headers):
        """测试热词访问控制"""
        # 创建另一个用户
        db = TestingSessionLocal()
        try:
            user2 = User(
                username="testuser2",
                hashed_password=get_password_hash("testpass123")
            )
            db.add(user2)
            db.commit()
        finally:
            db.close()
        
        # 获取第二个用户的token
        response = client.post("/auth/login", json={
            "username": "testuser2",
            "password": "testpass123"
        })
        user2_token = response.json()["access_token"]
        user2_headers = {"Authorization": f"Bearer {user2_token}"}
        
        # 用户1创建热词
        response = client.post("/hotwords", json={
            "word": "用户1热词",
            "weight": 5
        }, headers=auth_headers)
        hotword_id = response.json()["id"]
        
        # 用户2尝试访问用户1的热词
        response = client.put(f"/hotwords/{hotword_id}", json={
            "word": "恶意修改",
            "weight": 10
        }, headers=user2_headers)
        
        assert response.status_code == 403
        
        # 用户2尝试删除用户1的热词
        response = client.delete(f"/hotwords/{hotword_id}", headers=user2_headers)
        assert response.status_code == 403
    
    def test_hotword_limit(self, auth_headers):
        """测试热词数量限制"""
        # 创建100个热词（达到限制）
        for i in range(100):
            response = client.post("/hotwords", json={
                "word": f"限制测试热词{i}",
                "weight": 5
            }, headers=auth_headers)
            
            # 前100个应该成功
            if i < 100:
                assert response.status_code == 200
        
        # 尝试创建第101个热词
        response = client.post("/hotwords", json={
            "word": "超限热词",
            "weight": 5
        }, headers=auth_headers)
        
        assert response.status_code == 400
        assert "热词数量已达上限" in response.json()["detail"]

class TestHotwordAuthentication:
    """热词API认证测试"""
    
    def test_access_without_auth(self):
        """测试未认证访问"""
        response = client.get("/hotwords")
        assert response.status_code == 401
        
        response = client.post("/hotwords", json={
            "word": "测试热词",
            "weight": 5
        })
        assert response.status_code == 401
    
    def test_access_with_invalid_token(self):
        """测试无效token访问"""
        headers = {"Authorization": "Bearer invalid_token"}
        
        response = client.get("/hotwords", headers=headers)
        assert response.status_code == 401
        
        response = client.post("/hotwords", json={
            "word": "测试热词",
            "weight": 5
        }, headers=headers)
        assert response.status_code == 401

# 清理测试数据
def teardown_module():
    """测试模块清理"""
    if os.path.exists("test.db"):
        os.remove("test.db")
```

--------------------------------------------------------------------------------

File: test/test_rag.py
```python
import pytest
import sys
import os

# 添加项目根目录到Python路径
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from asr_system_backend.app.main import app
from asr_system_backend.app.database import Base, get_db
from asr_system_backend.app.models import User, Hotword
from asr_system_backend.app.auth_service import get_password_hash
import tempfile
import time

# 创建测试数据库
SQLALCHEMY_DATABASE_URL = "sqlite:///./test_rag.db"
engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False})
TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# 创建数据库表
Base.metadata.create_all(bind=engine)

def override_get_db():
    try:
        db = TestingSessionLocal()
        yield db
    finally:
        db.close()

# 覆盖依赖
app.dependency_overrides[get_db] = override_get_db

client = TestClient(app)

@pytest.fixture
def test_user():
    """创建测试用户"""
    db = TestingSessionLocal()
    try:
        # 清理现有测试数据
        db.query(Hotword).delete()
        db.query(User).delete()
        db.commit()
        
        # 创建测试用户
        user = User(
            username="raguser",
            hashed_password=get_password_hash("ragpass123")
        )
        db.add(user)
        db.commit()
        db.refresh(user)
        
        return user
    finally:
        db.close()

@pytest.fixture
def auth_headers(test_user):
    """获取认证头"""
    response = client.post("/auth/login", json={
        "username": "raguser",
        "password": "ragpass123"
    })
    assert response.status_code == 200
    token = response.json()["access_token"]
    return {"Authorization": f"Bearer {token}"}

@pytest.fixture
def sample_hotwords(auth_headers):
    """创建示例热词数据"""
    hotwords = [
        {"word": "机器学习", "weight": 8},
        {"word": "深度学习", "weight": 9},
        {"word": "人工智能", "weight": 7},
        {"word": "神经网络", "weight": 6},
        {"word": "自然语言处理", "weight": 8},
        {"word": "计算机视觉", "weight": 7},
        {"word": "语音识别", "weight": 9},
        {"word": "数据挖掘", "weight": 5},
        {"word": "算法优化", "weight": 6},
        {"word": "模式识别", "weight": 7}
    ]
    
    created_hotwords = []
    for hotword_data in hotwords:
        response = client.post("/hotwords", json=hotword_data, headers=auth_headers)
        if response.status_code == 200:
            created_hotwords.append(response.json())
    
    # 等待索引构建完成
    time.sleep(2)
    
    return created_hotwords

class TestRAGHealthCheck:
    """RAG服务健康检查测试"""
    
    def test_health_check(self):
        """测试RAG服务健康检查"""
        response = client.get("/rag/health")
        assert response.status_code == 200
        
        data = response.json()
        assert "status" in data
        assert "service" in data
        assert "version" in data
        assert "initialized" in data
        assert data["service"] == "RAG Vector Search Engine"

class TestRAGIndexManagement:
    """RAG索引管理测试"""
    
    def test_get_index_stats_empty(self, auth_headers):
        """测试获取空索引统计信息"""
        response = client.get("/rag/index/stats", headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert "user_id" in data
        assert "total_hotwords" in data
        assert "index_dimension" in data
        assert "is_initialized" in data
        assert data["total_hotwords"] == 0
    
    def test_get_index_stats_with_data(self, auth_headers, sample_hotwords):
        """测试获取有数据的索引统计信息"""
        response = client.get("/rag/index/stats", headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert data["total_hotwords"] == len(sample_hotwords)
        assert data["index_dimension"] == 384
        assert data["is_initialized"] == True
    
    def test_rebuild_index(self, auth_headers, sample_hotwords):
        """测试重建索引"""
        response = client.post("/rag/index/rebuild", headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert data["success"] == True
        assert "索引重建成功" in data["message"]
        assert "details" in data
        assert data["details"]["hotword_count"] == len(sample_hotwords)

class TestRAGVectorSearch:
    """RAG向量搜索测试"""
    
    def test_vector_search_basic(self, auth_headers, sample_hotwords):
        """测试基础向量搜索"""
        search_request = {
            "query": "机器学习算法",
            "top_k": 5,
            "threshold": 0.3
        }
        
        response = client.post("/rag/search", json=search_request, headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert "query" in data
        assert "results" in data
        assert "total_found" in data
        assert "processing_time_ms" in data
        assert data["query"] == search_request["query"]
        assert isinstance(data["results"], list)
        assert data["processing_time_ms"] > 0
    
    def test_vector_search_with_results(self, auth_headers, sample_hotwords):
        """测试向量搜索返回结果"""
        search_request = {
            "query": "深度学习",
            "top_k": 3,
            "threshold": 0.1
        }
        
        response = client.post("/rag/search", json=search_request, headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert len(data["results"]) > 0
        
        # 验证结果结构
        for result in data["results"]:
            assert "word" in result
            assert "weight" in result
            assert "similarity" in result
            assert "rank" in result
            assert 0 <= result["similarity"] <= 1
            assert 1 <= result["weight"] <= 10
    
    def test_vector_search_high_threshold(self, auth_headers, sample_hotwords):
        """测试高阈值搜索"""
        search_request = {
            "query": "完全不相关的查询内容xyz123",
            "top_k": 5,
            "threshold": 0.9
        }
        
        response = client.post("/rag/search", json=search_request, headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        # 高阈值应该返回很少或没有结果
        assert data["total_found"] >= 0
    
    def test_vector_search_parameter_validation(self, auth_headers):
        """测试搜索参数验证"""
        # 测试无效的top_k
        invalid_request = {
            "query": "测试",
            "top_k": 100,  # 超过最大值
            "threshold": 0.5
        }
        
        response = client.post("/rag/search", json=invalid_request, headers=auth_headers)
        assert response.status_code == 422
        
        # 测试无效的threshold
        invalid_request = {
            "query": "测试",
            "top_k": 5,
            "threshold": 1.5  # 超过最大值
        }
        
        response = client.post("/rag/search", json=invalid_request, headers=auth_headers)
        assert response.status_code == 422

class TestRAGSuggestions:
    """RAG热词建议测试"""
    
    def test_get_suggestions_basic(self, auth_headers, sample_hotwords):
        """测试基础热词建议"""
        response = client.get("/rag/suggestions?partial_text=机器&max_suggestions=5", headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert "partial_text" in data
        assert "suggestions" in data
        assert "count" in data
        assert data["partial_text"] == "机器"
        assert isinstance(data["suggestions"], list)
        assert data["count"] == len(data["suggestions"])
    
    def test_get_suggestions_prefix_match(self, auth_headers, sample_hotwords):
        """测试前缀匹配建议"""
        response = client.get("/rag/suggestions?partial_text=深度&max_suggestions=3", headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        # 应该包含"深度学习"
        assert any("深度" in suggestion for suggestion in data["suggestions"])
    
    def test_get_suggestions_empty_input(self, auth_headers, sample_hotwords):
        """测试空输入的建议"""
        response = client.get("/rag/suggestions?partial_text=&max_suggestions=5", headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert data["count"] == 0
        assert len(data["suggestions"]) == 0
    
    def test_get_suggestions_no_match(self, auth_headers, sample_hotwords):
        """测试无匹配的建议"""
        response = client.get("/rag/suggestions?partial_text=xyz123&max_suggestions=5", headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        # 可能返回0个建议或基于语义相似度的建议
        assert data["count"] >= 0

class TestRAGBulkOperations:
    """RAG批量操作测试"""
    
    def test_bulk_add_hotwords(self, auth_headers):
        """测试批量添加热词"""
        bulk_request = {
            "words": [
                {"word": "区块链技术", "weight": 7},
                {"word": "量子计算", "weight": 8},
                {"word": "边缘计算", "weight": 6}
            ]
        }
        
        response = client.post("/rag/index/bulk-add", json=bulk_request, headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert data["success"] == True
        assert "details" in data
        assert data["details"]["added"] == 3
        assert data["details"]["skipped"] == 0
    
    def test_bulk_add_with_duplicates(self, auth_headers, sample_hotwords):
        """测试批量添加包含重复项的热词"""
        bulk_request = {
            "words": [
                {"word": "机器学习", "weight": 7},  # 重复项
                {"word": "新技术", "weight": 8},    # 新项
                {"word": "深度学习", "weight": 9}   # 重复项
            ]
        }
        
        response = client.post("/rag/index/bulk-add", json=bulk_request, headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert data["success"] == True
        assert data["details"]["added"] == 1  # 只有"新技术"被添加
        assert data["details"]["skipped"] == 2  # 两个重复项被跳过
    
    def test_bulk_add_empty_words(self, auth_headers):
        """测试批量添加空词汇"""
        bulk_request = {
            "words": [
                {"word": "", "weight": 7},
                {"word": "   ", "weight": 8},
                {"word": "有效词汇", "weight": 6}
            ]
        }
        
        response = client.post("/rag/index/bulk-add", json=bulk_request, headers=auth_headers)
        assert response.status_code == 200
        
        data = response.json()
        assert data["success"] == True
        assert data["details"]["added"] == 1  # 只有"有效词汇"被添加
        assert data["details"]["skipped"] == 2  # 两个空词汇被跳过

class TestRAGModelInfo:
    """RAG模型信息测试"""
    
    def test_get_model_info(self):
        """测试获取模型信息"""
        response = client.get("/rag/model/info")
        assert response.status_code == 200
        
        data = response.json()
        
        if "status" in data and data["status"] == "not_initialized":
            # 如果服务未初始化，这是正常的
            assert "message" in data
        else:
            # 如果服务已初始化，验证模型信息
            assert "model_name" in data
            assert "dimension" in data
            assert "languages" in data
            assert "description" in data
            assert "performance" in data
            assert data["model_name"] == "sentence-transformers/all-MiniLM-L6-v2"
            assert data["dimension"] == 384

class TestRAGAuthentication:
    """RAG认证测试"""
    
    def test_search_without_auth(self):
        """测试未认证的搜索请求"""
        search_request = {
            "query": "测试查询",
            "top_k": 5,
            "threshold": 0.5
        }
        
        response = client.post("/rag/search", json=search_request)
        assert response.status_code == 401
    
    def test_index_stats_without_auth(self):
        """测试未认证的索引统计请求"""
        response = client.get("/rag/index/stats")
        assert response.status_code == 401
    
    def test_suggestions_without_auth(self):
        """测试未认证的建议请求"""
        response = client.get("/rag/suggestions?partial_text=测试")
        assert response.status_code == 401
    
    def test_with_invalid_token(self):
        """测试无效token"""
        headers = {"Authorization": "Bearer invalid_token"}
        
        response = client.get("/rag/index/stats", headers=headers)
        assert response.status_code == 401

class TestRAGPerformance:
    """RAG性能测试"""
    
    def test_search_performance(self, auth_headers, sample_hotwords):
        """测试搜索性能"""
        search_request = {
            "query": "机器学习和人工智能",
            "top_k": 5,
            "threshold": 0.3
        }
        
        start_time = time.time()
        response = client.post("/rag/search", json=search_request, headers=auth_headers)
        end_time = time.time()
        
        assert response.status_code == 200
        
        data = response.json()
        # 验证响应时间合理（应该在几百毫秒内）
        response_time_ms = (end_time - start_time) * 1000
        assert response_time_ms < 5000  # 5秒内完成
        
        # 验证API返回的处理时间
        assert data["processing_time_ms"] > 0
        assert data["processing_time_ms"] < 5000
    
    def test_multiple_searches(self, auth_headers, sample_hotwords):
        """测试多次搜索的稳定性"""
        queries = [
            "机器学习",
            "深度学习",
            "人工智能",
            "神经网络",
            "算法"
        ]
        
        for query in queries:
            search_request = {
                "query": query,
                "top_k": 3,
                "threshold": 0.3
            }
            
            response = client.post("/rag/search", json=search_request, headers=auth_headers)
            assert response.status_code == 200
            
            data = response.json()
            assert "results" in data
            assert "processing_time_ms" in data

# 清理测试数据
def teardown_module():
    """测试模块清理"""
    if os.path.exists("test_rag.db"):
        os.remove("test_rag.db")
```

--------------------------------------------------------------------------------

File: test/test_auth.py
```python
# File: test/test_auth.py

import pytest
from fastapi.testclient import TestClient
from asr_system_backend.app.main import app

client = TestClient(app)

@pytest.fixture(scope="module")
def test_user():
    return {
        "username": "testuser",
        "password": "testpassword123"
    }

def test_register_success(test_user):
    resp = client.post("/auth/register", json=test_user)
    assert resp.status_code == 200 or resp.status_code == 409  # 已注册也算通过
    data = resp.json()
    if resp.status_code == 200:
        assert data["username"] == test_user["username"]
        assert "user_id" in data
        assert "created_at" in data

def test_register_duplicate(test_user):
    resp = client.post("/auth/register", json=test_user)
    assert resp.status_code == 409
    assert resp.json()["detail"] == "用户名已存在"

def test_login_success(test_user):
    resp = client.post("/auth/login", json=test_user)
    assert resp.status_code == 200
    data = resp.json()
    assert "access_token" in data
    assert data["token_type"] == "bearer"

def test_login_wrong_password(test_user):
    resp = client.post("/auth/login", json={"username": test_user["username"], "password": "wrongpass"})
    assert resp.status_code == 401
    assert resp.json()["detail"] == "用户名或密码错误"

def test_login_nonexistent_user():
    resp = client.post("/auth/login", json={"username": "nouser", "password": "any"})
    assert resp.status_code == 401
    assert resp.json()["detail"] == "用户名或密码错误"

def test_login_and_get_token(test_user):
    resp = client.post("/auth/login", json=test_user)
    assert resp.status_code == 200
    data = resp.json()
    assert "access_token" in data
    token = data["access_token"]
    # 用token访问/me
    me_resp = client.get("/auth/me", headers={"Authorization": f"Bearer {token}"})
    assert me_resp.status_code == 200
    me_data = me_resp.json()
    assert me_data["username"] == test_user["username"]
    assert "user_id" in me_data
    assert "created_at" in me_data

def test_me_with_invalid_token():
    resp = client.get("/auth/me", headers={"Authorization": "Bearer invalidtoken"})
    assert resp.status_code == 401
    assert resp.json()["detail"] == "无效的认证凭据"

def test_me_without_token():
    resp = client.get("/auth/me")
    assert resp.status_code == 401
```

--------------------------------------------------------------------------------

File: .github/workflows/ci.yml
```yaml
name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  backend:
    runs-on: ubuntu-latest
    # 设置此 Job 中所有 run 命令的默认工作目录
    defaults:
      run:
        working-directory: ./asr_system_backend

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies and run checks
        run: |
          pip install -r requirements.txt
          # 建议移除 || true，让 lint 失败时构建也失败
          flake8 app
          alembic upgrade head
          pytest

  # frontend job 保持不变，也可以用类似的方法优化
  frontend:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./asr_system_frontend
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          # 缓存 npm 包，加快后续构建速度
          cache: 'npm'
          cache-dependency-path: 'asr_system_frontend/package-lock.json'

      - name: Install, Lint, and Build
        run: |
          npm install
          # 同样建议移除 || true
          npm run lint
          npm run build
```

--------------------------------------------------------------------------------

File: models/iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/.mv
```text
Revision:v2.0.4,CreatedAt:1705996149
```

--------------------------------------------------------------------------------

File: models/iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/am.mvn
```text
<Nnet> 
<Splice> 560 560
[ 0 ]
<AddShift> 560 560 
<LearnRateCoef> 0 [ -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 ]
<Rescale> 560 560
<LearnRateCoef> 0 [ 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 ]
</Nnet>
```

--------------------------------------------------------------------------------

File: models/iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/seg_dict  (Skipped, size > 200KB)

--------------------------------------------------------------------------------

File: models/iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/config.yaml
```yaml
# This is an example that demonstrates how to configure a model file.
# You can modify the configuration according to your own requirements.

# to print the register_table:
# from funasr.utils.register import registry_tables
# registry_tables.print()

# network architecture
model: SeacoParaformer
model_conf:
    ctc_weight: 0.0
    lsm_weight: 0.1
    length_normalized_loss: true
    predictor_weight: 1.0
    predictor_bias: 1
    sampling_ratio: 0.75
    inner_dim: 512
    bias_encoder_type: lstm
    bias_encoder_bid: false
    seaco_lsm_weight: 0.1
    seaco_length_normal: true
    train_decoder: false
    NO_BIAS: 8377

# encoder
encoder: SANMEncoder
encoder_conf:
    output_size: 512
    attention_heads: 4
    linear_units: 2048
    num_blocks: 50
    dropout_rate: 0.1
    positional_dropout_rate: 0.1
    attention_dropout_rate: 0.1
    input_layer: pe
    pos_enc_class: SinusoidalPositionEncoder
    normalize_before: true
    kernel_size: 11
    sanm_shfit: 0
    selfattention_layer_type: sanm

# decoder
decoder: ParaformerSANMDecoder
decoder_conf:
    attention_heads: 4
    linear_units: 2048
    num_blocks: 16
    dropout_rate: 0.1
    positional_dropout_rate: 0.1
    self_attention_dropout_rate: 0.1
    src_attention_dropout_rate: 0.1
    att_layer_num: 16
    kernel_size: 11
    sanm_shfit: 0

# seaco decoder
seaco_decoder: ParaformerSANMDecoder
seaco_decoder_conf:
    attention_heads: 4
    linear_units: 1024
    num_blocks: 4
    dropout_rate: 0.1
    positional_dropout_rate: 0.1
    self_attention_dropout_rate: 0.1
    src_attention_dropout_rate: 0.1
    kernel_size: 21
    sanm_shfit: 0
    use_output_layer: false
    wo_input_layer: true

predictor: CifPredictorV3
predictor_conf:
    idim: 512
    threshold: 1.0
    l_order: 1
    r_order: 1
    tail_threshold: 0.45
    smooth_factor2: 0.25
    noise_threshold2: 0.01
    upsample_times: 3
    use_cif1_cnn: false
    upsample_type: cnn_blstm

# frontend related
frontend: WavFrontend
frontend_conf:
    fs: 16000
    window: hamming
    n_mels: 80
    frame_length: 25
    frame_shift: 10
    lfr_m: 7
    lfr_n: 6
    dither: 0.0

specaug: SpecAugLFR
specaug_conf:
    apply_time_warp: false
    time_warp_window: 5
    time_warp_mode: bicubic
    apply_freq_mask: true
    freq_mask_width_range:
    - 0
    - 30
    lfr_rate: 6
    num_freq_mask: 1
    apply_time_mask: true
    time_mask_width_range:
    - 0
    - 12
    num_time_mask: 1

train_conf:
  accum_grad: 1
  grad_clip: 5
  max_epoch: 150
  val_scheduler_criterion:
      - valid
      - acc
  best_model_criterion:
  -   - valid
      - acc
      - max
  keep_nbest_models: 10
  log_interval: 50

optim: adam
optim_conf:
   lr: 0.0005
scheduler: warmuplr
scheduler_conf:
   warmup_steps: 30000

dataset: AudioDataset
dataset_conf:
    index_ds: IndexDSJsonl
    batch_sampler: DynamicBatchLocalShuffleSampler
    batch_type: example # example or length
    batch_size: 1 # if batch_type is example, batch_size is the numbers of samples; if length, batch_size is source_token_len+target_token_len;
    max_token_length: 2048 # filter samples if source_token_len+target_token_len > max_token_length,
    buffer_size: 500
    shuffle: True
    num_workers: 0

tokenizer: CharTokenizer
tokenizer_conf:
  unk_symbol: <unk>
  split_with_space: true


ctc_conf:
    dropout_rate: 0.0
    ctc_type: builtin
    reduce: true
    ignore_nan_grad: true
normalize: null
```

--------------------------------------------------------------------------------

File: models/iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/README.md
```markdown
---
tasks:
- auto-speech-recognition
domain:
- audio
model-type:
- Non-autoregressive
frameworks:
- pytorch
backbone:
- transformer/conformer
metrics:
- CER
license: Apache License 2.0
language: 
- cn
tags:
- FunASR
- Paraformer
- Alibaba
- ICASSP2024
- Hotword
datasets:
  train:
  - 50,000 hour industrial Mandarin task
  test:
  - AISHELL-1-hotword dev/test
indexing:
   results:
   - task:
       name: Automatic Speech Recognition
     dataset:
       name: 50,000 hour industrial Mandarin task
       type: audio    # optional
       args: 16k sampling rate, 8404 characters  # optional
     metrics:
       - type: CER
         value: 8.53%  # float
         description: greedy search, withou lm, avg.
         args: default
       - type: RTF
         value: 0.0251  # float
         description: GPU inference on V100
         args: batch_size=1
widgets:
  - task: auto-speech-recognition
    inputs:
      - type: audio
        name: input
        title: 音频
    parameters:
      - name: hotword
        title: 热词
        type: string
    examples:
      - name: 1
        title: 示例1
        inputs:
          - name: input
            data: git://example/asr_example.wav
        parameters:
          - name: hotword
            value: 魔搭
    inferencespec:
      cpu: 8 #CPU数量
      memory: 4096
---

# Paraformer-large模型介绍

## Highlights
Paraformer-large热词版模型支持热词定制功能：实现热词定制化功能，基于提供的热词列表进行激励增强，提升热词的召回率和准确率。


## <strong>[FunASR开源项目介绍](https://github.com/alibaba-damo-academy/FunASR)</strong>
<strong>[FunASR](https://github.com/alibaba-damo-academy/FunASR)</strong>希望在语音识别的学术研究和工业应用之间架起一座桥梁。通过发布工业级语音识别模型的训练和微调，研究人员和开发人员可以更方便地进行语音识别模型的研究和生产，并推动语音识别生态的发展。让语音识别更有趣！

[**github仓库**](https://github.com/alibaba-damo-academy/FunASR) 
|  [**最新动态**](https://github.com/alibaba-damo-academy/FunASR#whats-new) 
| [**环境安装**](https://github.com/alibaba-damo-academy/FunASR#installation)
| [**服务部署**](https://www.funasr.com)
| [**模型库**](https://github.com/alibaba-damo-academy/FunASR/tree/main/model_zoo)
| [**联系我们**](https://github.com/alibaba-damo-academy/FunASR#contact)


## 模型原理介绍

SeACoParaformer是阿里巴巴语音实验室提出的新一代热词定制化非自回归语音识别模型。相比于上一代基于CLAS的热词定制化方案，SeACoParaformer解耦了热词模块与ASR模型，通过后验概率融合的方式进行热词激励，使激励过程可见可控，并且热词召回率显著提升。

<p align="center">
<img src="fig/seaco.png" alt="SeACoParaformer模型结构"  width="380" />


SeACoParaformer的模型结构与训练流程如上图所示，通过引入bias encoder进行热词embedding提取，bias decoder进行注意力建模，SeACoParaformer能够捕捉到Predictor输出和Decoder输出的信息与热词的相关性，并且预测与ASR结果同步的热词输出。通过后验概率的融合，实现热词激励。与ContextualParaformer相比，SeACoParaformer有明显的效果提升，如下图所示：

<p align="center">
<img src="fig/res.png" alt="SeACoParaformer模型结构"  width="700" />

更详细的细节见：
- 论文： [SeACo-Paraformer: A Non-Autoregressive ASR System with Flexible and Effective Hotword Customization Ability](https://arxiv.org/abs/2308.03266)


## 基于ModelScope进行推理

- 推理支持音频格式如下：
  - wav文件路径，例如：data/test/audios/asr_example.wav
  - pcm文件路径，例如：data/test/audios/asr_example.pcm
  - wav文件url，例如：https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav
  - wav二进制数据，格式bytes，例如：用户直接从文件里读出bytes数据或者是麦克风录出bytes数据。
  - 已解析的audio音频，例如：audio, rate = soundfile.read("asr_example_zh.wav")，类型为numpy.ndarray或者torch.Tensor。
  - wav.scp文件，需符合如下要求：

```sh
cat wav.scp
asr_example1  data/test/audios/asr_example1.wav
asr_example2  data/test/audios/asr_example2.wav
...
```

- 若输入格式wav文件url，api调用方式可参考如下范例：

```python
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks

inference_pipeline = pipeline(
    task=Tasks.auto_speech_recognition,
    model='iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch', model_revision="v2.0.4")

rec_result = inference_pipeline('https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav', hotword='达摩院 魔搭')
print(rec_result)
```

- 输入音频为pcm格式，调用api时需要传入音频采样率参数audio_fs，例如：

```python
rec_result = inference_pipeline('https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.pcm', fs=16000, hotword='达摩院 魔搭')
```

- 输入音频为wav格式，api调用方式可参考如下范例:

```python
rec_result = inference_pipeline('asr_example_zh.wav', hotword='达摩院 魔搭')
```

- 若输入格式为文件wav.scp(注：文件名需要以.scp结尾)，可添加 output_dir 参数将识别结果写入文件中，api调用方式可参考如下范例:

```python
inference_pipeline("wav.scp", output_dir='./output_dir', hotword='达摩院 魔搭')
```
识别结果输出路径结构如下：

```sh
tree output_dir/
output_dir/
└── 1best_recog
    ├── score
    └── text

1 directory, 3 files
```

score：识别路径得分

text：语音识别结果文件


- 若输入音频为已解析的audio音频，api调用方式可参考如下范例：

```python
import soundfile

waveform, sample_rate = soundfile.read("asr_example_zh.wav")
rec_result = inference_pipeline(waveform, hotword='达摩院 魔搭')
```

- ASR、VAD、PUNC模型自由组合

可根据使用需求对VAD和PUNC标点模型进行自由组合，使用方式如下：
```python
inference_pipeline = pipeline(
    task=Tasks.auto_speech_recognition,
    model='iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch', model_revision="v2.0.4",
    vad_model='iic/speech_fsmn_vad_zh-cn-16k-common-pytorch', vad_model_revision="v2.0.4",
    punc_model='iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch', punc_model_revision="v2.0.3",
    # spk_model="iic/speech_campplus_sv_zh-cn_16k-common",
    # spk_model_revision="v2.0.2",
)
```
若不使用PUNC模型，可配置punc_model=None，或不传入punc_model参数，如需加入LM模型，可增加配置lm_model='iic/speech_transformer_lm_zh-cn-common-vocab8404-pytorch'，并设置lm_weight和beam_size参数。

## 基于FunASR进行推理

下面为快速上手教程，测试音频（[中文](https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/vad_example.wav)，[英文](https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_en.wav)）

### 可执行命令行
在命令行终端执行：

```shell
funasr +model=paraformer-zh +vad_model="fsmn-vad" +punc_model="ct-punc" +input=vad_example.wav
```

注：支持单条音频文件识别，也支持文件列表，列表为kaldi风格wav.scp：`wav_id   wav_path`

### python示例
#### 非实时语音识别
```python
from funasr import AutoModel
# paraformer-zh is a multi-functional asr model
# use vad, punc, spk or not as you need
model = AutoModel(model="paraformer-zh", model_revision="v2.0.4",
                  vad_model="fsmn-vad", vad_model_revision="v2.0.4",
                  punc_model="ct-punc-c", punc_model_revision="v2.0.4",
                  # spk_model="cam++", spk_model_revision="v2.0.2",
                  )
res = model.generate(input=f"{model.model_path}/example/asr_example.wav", 
            batch_size_s=300, 
            hotword='魔搭')
print(res)
```
注：`model_hub`：表示模型仓库，`ms`为选择modelscope下载，`hf`为选择huggingface下载。

#### 实时语音识别

```python
from funasr import AutoModel

chunk_size = [0, 10, 5] #[0, 10, 5] 600ms, [0, 8, 4] 480ms
encoder_chunk_look_back = 4 #number of chunks to lookback for encoder self-attention
decoder_chunk_look_back = 1 #number of encoder chunks to lookback for decoder cross-attention

model = AutoModel(model="paraformer-zh-streaming", model_revision="v2.0.4")

import soundfile
import os

wav_file = os.path.join(model.model_path, "example/asr_example.wav")
speech, sample_rate = soundfile.read(wav_file)
chunk_stride = chunk_size[1] * 960 # 600ms

cache = {}
total_chunk_num = int(len((speech)-1)/chunk_stride+1)
for i in range(total_chunk_num):
    speech_chunk = speech[i*chunk_stride:(i+1)*chunk_stride]
    is_final = i == total_chunk_num - 1
    res = model.generate(input=speech_chunk, cache=cache, is_final=is_final, chunk_size=chunk_size, encoder_chunk_look_back=encoder_chunk_look_back, decoder_chunk_look_back=decoder_chunk_look_back)
    print(res)
```

注：`chunk_size`为流式延时配置，`[0,10,5]`表示上屏实时出字粒度为`10*60=600ms`，未来信息为`5*60=300ms`。每次推理输入为`600ms`（采样点数为`16000*0.6=960`），输出为对应文字，最后一个语音片段输入需要设置`is_final=True`来强制输出最后一个字。

#### 语音端点检测（非实时）
```python
from funasr import AutoModel

model = AutoModel(model="fsmn-vad", model_revision="v2.0.4")

wav_file = f"{model.model_path}/example/asr_example.wav"
res = model.generate(input=wav_file)
print(res)
```

#### 语音端点检测（实时）
```python
from funasr import AutoModel

chunk_size = 200 # ms
model = AutoModel(model="fsmn-vad", model_revision="v2.0.4")

import soundfile

wav_file = f"{model.model_path}/example/vad_example.wav"
speech, sample_rate = soundfile.read(wav_file)
chunk_stride = int(chunk_size * sample_rate / 1000)

cache = {}
total_chunk_num = int(len((speech)-1)/chunk_stride+1)
for i in range(total_chunk_num):
    speech_chunk = speech[i*chunk_stride:(i+1)*chunk_stride]
    is_final = i == total_chunk_num - 1
    res = model.generate(input=speech_chunk, cache=cache, is_final=is_final, chunk_size=chunk_size)
    if len(res[0]["value"]):
        print(res)
```

#### 标点恢复
```python
from funasr import AutoModel

model = AutoModel(model="ct-punc", model_revision="v2.0.4")

res = model.generate(input="那今天的会就到这里吧 happy new year 明年见")
print(res)
```

#### 时间戳预测
```python
from funasr import AutoModel

model = AutoModel(model="fa-zh", model_revision="v2.0.4")

wav_file = f"{model.model_path}/example/asr_example.wav"
text_file = f"{model.model_path}/example/text.txt"
res = model.generate(input=(wav_file, text_file), data_type=("sound", "text"))
print(res)
```

更多详细用法（[示例](https://github.com/alibaba-damo-academy/FunASR/tree/main/examples/industrial_data_pretraining)）


## 微调

详细用法（[示例](https://github.com/alibaba-damo-academy/FunASR/tree/main/examples/industrial_data_pretraining)）


## 相关论文以及引用信息

```BibTeX
@article{shi2023seaco,
  title={SeACo-Paraformer: A Non-Autoregressive ASR System with Flexible and Effective Hotword Customization Ability},
  author={Shi, Xian and Yang, Yexin and Li, Zerui and Zhang, Shiliang},
  journal={arXiv preprint arXiv:2308.03266 (accepted by ICASSP2024)},
  year={2023}
}
```
```

--------------------------------------------------------------------------------

File: models/damo/speech_fsmn_vad_zh-cn-16k-common-onnx/.mv
```text
Revision:v2.0.4,CreatedAt:1714031199
```

--------------------------------------------------------------------------------

File: models/damo/speech_fsmn_vad_zh-cn-16k-common-onnx/am.mvn
```text
<Nnet>
<Splice> 400 400
[ 0 ]
<AddShift> 400 400
<LearnRateCoef> 0 [ -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 -8.311879 -8.600912 -9.615928 -10.43595 -11.21292 -11.88333 -12.36243 -12.63706 -12.8818 -12.83066 -12.89103 -12.95666 -13.19763 -13.40598 -13.49113 -13.5546 -13.55639 -13.51915 -13.68284 -13.53289 -13.42107 -13.65519 -13.50713 -13.75251 -13.76715 -13.87408 -13.73109 -13.70412 -13.56073 -13.53488 -13.54895 -13.56228 -13.59408 -13.62047 -13.64198 -13.66109 -13.62669 -13.58297 -13.57387 -13.4739 -13.53063 -13.48348 -13.61047 -13.64716 -13.71546 -13.79184 -13.90614 -14.03098 -14.18205 -14.35881 -14.48419 -14.60172 -14.70591 -14.83362 -14.92122 -15.00622 -15.05122 -15.03119 -14.99028 -14.92302 -14.86927 -14.82691 -14.7972 -14.76909 -14.71356 -14.61277 -14.51696 -14.42252 -14.36405 -14.30451 -14.23161 -14.19851 -14.16633 -14.15649 -14.10504 -13.99518 -13.79562 -13.3996 -12.7767 -11.71208 ]
<Rescale> 400 400
<LearnRateCoef> 0 [ 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 0.155775 0.154484 0.1527379 0.1518718 0.1506028 0.1489256 0.147067 0.1447061 0.1436307 0.1443568 0.1451849 0.1455157 0.1452821 0.1445717 0.1439195 0.1435867 0.1436018 0.1438781 0.1442086 0.1448844 0.1454756 0.145663 0.146268 0.1467386 0.1472724 0.147664 0.1480913 0.1483739 0.1488841 0.1493636 0.1497088 0.1500379 0.1502916 0.1505389 0.1506787 0.1507102 0.1505992 0.1505445 0.1505938 0.1508133 0.1509569 0.1512396 0.1514625 0.1516195 0.1516156 0.1515561 0.1514966 0.1513976 0.1512612 0.151076 0.1510596 0.1510431 0.151077 0.1511168 0.1511917 0.151023 0.1508045 0.1505885 0.1503493 0.1502373 0.1501726 0.1500762 0.1500065 0.1499782 0.150057 0.1502658 0.150469 0.1505335 0.1505505 0.1505328 0.1504275 0.1502438 0.1499674 0.1497118 0.1494661 0.1493102 0.1493681 0.1495501 0.1499738 0.1509654 ]
</Nnet>
```

--------------------------------------------------------------------------------

File: models/damo/speech_fsmn_vad_zh-cn-16k-common-onnx/model_quant.onnx  (Skipped, size > 200KB)

--------------------------------------------------------------------------------

File: models/damo/speech_fsmn_vad_zh-cn-16k-common-onnx/config.yaml
```yaml
frontend: WavFrontendOnline
frontend_conf:
    fs: 16000
    window: hamming
    n_mels: 80
    frame_length: 25
    frame_shift: 10
    dither: 0.0
    lfr_m: 5
    lfr_n: 1

model: FsmnVADStreaming
model_conf:
    sample_rate: 16000
    detect_mode: 1 
    snr_mode: 0
    max_end_silence_time: 800
    max_start_silence_time: 3000
    do_start_point_detection: True
    do_end_point_detection: True
    window_size_ms: 200
    sil_to_speech_time_thres: 150
    speech_to_sil_time_thres: 150
    speech_2_noise_ratio: 1.0
    do_extend: 1
    lookback_time_start_point: 200
    lookahead_time_end_point: 100
    max_single_segment_time: 60000
    snr_thres: -100.0
    noise_frame_num_used_for_snr: 100
    decibel_thres: -100.0
    speech_noise_thres: 0.6
    fe_prior_thres: 0.0001
    silence_pdf_num: 1
    sil_pdf_ids: [0]
    speech_noise_thresh_low: -0.1
    speech_noise_thresh_high: 0.3
    output_frame_probs: False
    frame_in_ms: 10
    frame_length_ms: 25
    
encoder: FSMN
encoder_conf:
    input_dim: 400
    input_affine_dim: 140
    fsmn_layers: 4
    linear_dim: 250
    proj_dim: 128
    lorder: 20
    rorder: 0
    lstride: 1
    rstride: 0
    output_affine_dim: 140
    output_dim: 248
```

--------------------------------------------------------------------------------

File: models/damo/speech_fsmn_vad_zh-cn-16k-common-onnx/README.md
```markdown
---
tasks:
- voice-activity-detection
domain:
- audio
model-type:
- VAD model
frameworks:
- onnx
backbone:
- fsmn
metrics:
- f1_score
license: Apache License 2.0
language: 
- cn
tags:
- FunASR
- FSMN
- Alibaba
- Online
datasets:
  train:
  - 20,000 hour industrial Mandarin task
  test:
  - 20,000 hour industrial Mandarin task
widgets:
  - task: voice-activity-detection
    inputs:
      - type: audio
        name: input
        title: 音频
    examples:
      - name: 1
        title: 示例1
        inputs:
          - name: input
            data: git://example/vad_example.wav 
    inferencespec:
      cpu: 1 #CPU数量
      memory: 4096
---

# FSMN-Monophone VAD 模型介绍

[//]: # (FSMN-Monophone VAD 模型)

## Highlights
模型为[FSMN-Monophone VAD](https://www.modelscope.cn/models/damo/speech_fsmn_vad_zh-cn-16k-common-pytorch/summary)的onnx量化导出版本，可以直接用来做生产部署，一键部署教程（[点击此处](https://github.com/alibaba-damo-academy/FunASR/blob/main/runtime/readme_cn.md)）



## <strong>[ModelScope-FunASR](https://github.com/alibaba-damo-academy/FunASR)</strong>
<strong>[FunASR](https://github.com/alibaba-damo-academy/FunASR)</strong>提供可便捷本地或者云端服务器部署的离线文件转写服务，内核为FunASR已开源runtime-SDK。 集成了达摩院语音实验室在Modelscope社区开源的语音端点检测(VAD)、Paraformer-large语音识别(ASR)、标点恢复(PUNC) 等相关能力，拥有完整的语音识别链路，可以将几十个小时的音频或视频识别成带标点的文字，而且支持上百路请求同时进行转写。

[**最新动态**](https://github.com/alibaba-damo-academy/FunASR#whats-new) 
| [**环境安装**](https://github.com/alibaba-damo-academy/FunASR#installation)
| [**介绍文档**](https://alibaba-damo-academy.github.io/FunASR/en/index.html)
| [**服务部署**](https://github.com/alibaba-damo-academy/FunASR/blob/main/runtime/readme_cn.md)
| [**模型库**](https://github.com/alibaba-damo-academy/FunASR/blob/main/docs/model_zoo/modelscope_models.md)
| [**联系我们**](https://github.com/alibaba-damo-academy/FunASR#contact)

## 快速上手
### docker安装
如果您已安装docker，忽略本步骤！!
通过下述命令在服务器上安装docker：
```shell
curl -O https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/shell/install_docker.sh；
sudo bash install_docker.sh
```
docker安装失败请参考 [Docker Installation](https://alibaba-damo-academy.github.io/FunASR/en/installation/docker.html)

### 镜像启动
通过下述命令拉取并启动FunASR runtime的docker镜像（[获取最新镜像版本](https://github.com/alibaba-damo-academy/FunASR/blob/main/runtime/docs/SDK_advanced_guide_offline_zh.md)）：

```shell
sudo docker pull \
  registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-cpu-0.3.0
mkdir -p ./funasr-runtime-resources/models
sudo docker run -p 10095:10095 -it --privileged=true \
  -v $PWD/funasr-runtime-resources/models:/workspace/models \
  registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-cpu-0.3.0
```

### 服务端启动

docker启动之后，启动 funasr-wss-server服务程序：
```shell
cd FunASR/runtime
nohup bash run_server.sh \
  --download-model-dir /workspace/models \
  --vad-dir damo/speech_fsmn_vad_zh-cn-16k-common-onnx \
  --model-dir damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-onnx  \
  --punc-dir damo/punc_ct-transformer_cn-en-common-vocab471067-large-onnx \
  --lm-dir damo/speech_ngram_lm_zh-cn-ai-wesp-fst \
  --itn-dir thuduj12/fst_itn_zh \
  --hotword /workspace/models/hotwords.txt > log.out 2>&1 &
```

### 客户端测试与使用

运行上面安装指令后，会在./funasr-runtime-resources（默认安装目录）中下载客户端测试工具目录samples（[下载点击此处](https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/sample/funasr_samples.tar.gz)），
我们以Python语言客户端为例，进行说明，支持多种音频格式输入（.wav, .pcm, .mp3等），也支持视频输入(.mp4等)，以及多文件列表wav.scp输入，其他版本客户端请参考文档（[点击此处](https://alibaba-damo-academy.github.io/FunASR/en/runtime/docs/SDK_tutorial_zh.html#id5)）

```shell
python3 wss_client_asr.py --host "127.0.0.1" --port 10095 --mode offline --audio_in "../audio/asr_example.wav"
```

更详细用法介绍（[点击此处](https://github.com/alibaba-damo-academy/FunASR/blob/main/runtime/docs/SDK_tutorial_zh.md)）


## 相关论文以及引用信息

```BibTeX
@inproceedings{zhang2018deep,
  title={Deep-FSMN for large vocabulary continuous speech recognition},
  author={Zhang, Shiliang and Lei, Ming and Yan, Zhijie and Dai, Lirong},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5869--5873},
  year={2018},
  organization={IEEE}
}
```
```

--------------------------------------------------------------------------------

File: models/damo/speech_fsmn_vad_zh-cn-16k-common-onnx/quickstart.md
```markdown
---
<!-- 该部分为参数配置部分 -->

---
<!-- 公共内容部分  -->

用法请参考文档（[一键部署](https://github.com/alibaba-damo-academy/FunASR/blob/main/funasr/runtime/readme_cn.md)）

---
<!-- 在线使用独有内容部分 -->

---
<!-- 本地使用独有内容部分 -->
```

--------------------------------------------------------------------------------

File: client/funasr_realtime_chunk_client.py
```python
# File: client/funasr_realtime_chunk_client.py
# 这是一个专门用于处理实时音频片段的新脚本

import asyncio
import argparse
import json
import logging
import os
import websockets
import wave

# 只报告严重错误，保持输出干净
logging.basicConfig(level=logging.CRITICAL)

# 定义全局变量来存储最终结果
final_result = ""
# 使用 asyncio.Event 来同步任务，确保在获取结果前任务已完成
is_done = asyncio.Event()

async def process_audio_chunk(websocket, audio_path):
    """读取WAV文件，并将其发送到FunASR进行识别"""
    try:
        with wave.open(audio_path, "rb") as wav_file:
            sample_rate = wav_file.getframerate()
            audio_bytes = wav_file.readframes(wav_file.getnframes())
    except Exception as e:
        logging.error(f"无法读取临时WAV文件: {e}")
        is_done.set()
        return

    # FunASR的WebSocket连接配置
    config = {
        "mode": "offline",
        "chunk_size": [5, 10, 5],
        "wav_name": "realtime_chunk",
        "is_speaking": True,
        "hotwords": "",
        "itn": True,
        "audio_fs": sample_rate,
    }

    try:
        # 发送配置
        await websocket.send(json.dumps(config))
        # 发送音频数据
        await websocket.send(audio_bytes)
        # 发送结束标记
        await websocket.send(json.dumps({"is_speaking": False}))

        # 等待并接收结果
        while not is_done.is_set():
            response = await asyncio.wait_for(websocket.recv(), timeout=10.0)
            response_data = json.loads(response)
            
            # 我们只关心包含最终文本的'offline'模式结果
            if response_data.get("mode") == "offline" and "text" in response_data:
                global final_result
                final_result = response_data["text"]
                break # 收到结果后即可退出循环
    except Exception as e:
        logging.error(f"与FunASR通信时出错: {e}")
    finally:
        # 确保is_done事件被设置，以允许主程序退出
        is_done.set()

async def main(host, port, audio_path):
    """主函数，建立连接并处理音频"""
    uri = f"ws://{host}:{port}"
    try:
        # 连接到FunASR的WebSocket服务
        async with websockets.connect(uri, subprotocols=["binary"], ping_interval=None) as websocket:
            await process_audio_chunk(websocket, audio_path)
    except Exception as e:
        logging.error(f"无法连接到FunASR WebSocket服务于 {uri}: {e}")
        is_done.set()


if __name__ == "__main__":
    # 从命令行接收必要的参数
    parser = argparse.ArgumentParser(description="FunASR实时音频块识别客户端")
    parser.add_argument("--host", default="127.0.0.1", help="FunASR服务地址")
    parser.add_argument("--port", type=int, default=10095, help="FunASR服务端口")
    parser.add_argument("--audio_in", required=True, help="输入的WAV音频文件路径")
    args = parser.parse_args()

    # 运行主异步函数
    asyncio.run(main(args.host, args.port, args.audio_in))
    
    # 确保只打印最终的、纯净的文本结果
    print(final_result, end='')
```

--------------------------------------------------------------------------------

File: client/test_demo.ps1
```powershell
python ./client/funasr_wss_client.py       --host "127.0.0.1"       --port 10095       --mode offline       --audio_in "./client/BAC009S0764W0179.wav"
```

--------------------------------------------------------------------------------

File: client/funasr_wss_client.py
```python
# -*- encoding: utf-8 -*-
import os
import time
import websockets, ssl
import asyncio

# import threading
import argparse
import json
import traceback
from multiprocessing import Process

# from funasr.fileio.datadir_writer import DatadirWriter

import logging

logging.basicConfig(level=logging.ERROR)

parser = argparse.ArgumentParser()
parser.add_argument(
    "--host", type=str, default="localhost", required=False, help="host ip, localhost, 0.0.0.0"
)
parser.add_argument("--port", type=int, default=10095, required=False, help="grpc server port")
parser.add_argument("--chunk_size", type=str, default="5, 10, 5", help="chunk")
parser.add_argument("--encoder_chunk_look_back", type=int, default=4, help="chunk")
parser.add_argument("--decoder_chunk_look_back", type=int, default=0, help="chunk")
parser.add_argument("--chunk_interval", type=int, default=10, help="chunk")
parser.add_argument(
    "--hotword",
    type=str,
    default="",
    help="hotword file path, one hotword perline (e.g.:阿里巴巴 20)",
)
parser.add_argument("--audio_in", type=str, default=None, help="audio_in")
parser.add_argument("--audio_fs", type=int, default=16000, help="audio_fs")
parser.add_argument(
    "--send_without_sleep",
    action="store_true",
    default=True,
    help="if audio_in is set, send_without_sleep",
)
parser.add_argument("--thread_num", type=int, default=1, help="thread_num")
parser.add_argument("--words_max_print", type=int, default=10000, help="chunk")
parser.add_argument("--output_dir", type=str, default=None, help="output_dir")
parser.add_argument("--ssl", type=int, default=1, help="1 for ssl connect, 0 for no ssl")
parser.add_argument("--use_itn", type=int, default=1, help="1 for using itn, 0 for not itn")
parser.add_argument("--mode", type=str, default="2pass", help="offline, online, 2pass")

args = parser.parse_args()
args.chunk_size = [int(x) for x in args.chunk_size.split(",")]
print(args)
# voices = asyncio.Queue()
from queue import Queue

voices = Queue()
offline_msg_done = False

if args.output_dir is not None:
    # if os.path.exists(args.output_dir):
    #     os.remove(args.output_dir)

    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir)


async def record_microphone():
    is_finished = False
    import pyaudio

    # print("2")
    global voices
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    chunk_size = 60 * args.chunk_size[1] / args.chunk_interval
    CHUNK = int(RATE / 1000 * chunk_size)

    p = pyaudio.PyAudio()

    stream = p.open(
        format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK
    )
    # hotwords
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        if os.path.exists(args.hotword):
            f_scp = open(args.hotword)
            hot_lines = f_scp.readlines()
            for line in hot_lines:
                words = line.strip().split(" ")
                if len(words) < 2:
                    print("Please checkout format of hotwords")
                    continue
                try:
                    fst_dict[" ".join(words[:-1])] = int(words[-1])
                except ValueError:
                    print("Please checkout format of hotwords")
            hotword_msg = json.dumps(fst_dict)
        else:
            hotword_msg = args.hotword

    use_itn = True
    if args.use_itn == 0:
        use_itn = False

    message = json.dumps(
        {
            "mode": args.mode,
            "chunk_size": args.chunk_size,
            "chunk_interval": args.chunk_interval,
            "encoder_chunk_look_back": args.encoder_chunk_look_back,
            "decoder_chunk_look_back": args.decoder_chunk_look_back,
            "wav_name": "microphone",
            "is_speaking": True,
            "hotwords": hotword_msg,
            "itn": use_itn,
        }
    )
    # voices.put(message)
    await websocket.send(message)
    while True:
        data = stream.read(CHUNK)
        message = data
        # voices.put(message)
        await websocket.send(message)
        await asyncio.sleep(0.005)


async def record_from_scp(chunk_begin, chunk_size):
    global voices
    is_finished = False
    if args.audio_in.endswith(".scp"):
        f_scp = open(args.audio_in)
        wavs = f_scp.readlines()
    else:
        wavs = [args.audio_in]

    # hotwords
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        if os.path.exists(args.hotword):
            f_scp = open(args.hotword)
            hot_lines = f_scp.readlines()
            for line in hot_lines:
                words = line.strip().split(" ")
                if len(words) < 2:
                    print("Please checkout format of hotwords")
                    continue
                try:
                    fst_dict[" ".join(words[:-1])] = int(words[-1])
                except ValueError:
                    print("Please checkout format of hotwords")
            hotword_msg = json.dumps(fst_dict)
        else:
            hotword_msg = args.hotword
        print(hotword_msg)

    sample_rate = args.audio_fs
    wav_format = "pcm"
    use_itn = True
    if args.use_itn == 0:
        use_itn = False

    if chunk_size > 0:
        wavs = wavs[chunk_begin : chunk_begin + chunk_size]
    for wav in wavs:
        wav_splits = wav.strip().split()

        wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
        wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
        if not len(wav_path.strip()) > 0:
            continue
        if wav_path.endswith(".pcm"):
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()
        elif wav_path.endswith(".wav"):
            import wave

            with wave.open(wav_path, "rb") as wav_file:
                params = wav_file.getparams()
                sample_rate = wav_file.getframerate()
                frames = wav_file.readframes(wav_file.getnframes())
                audio_bytes = bytes(frames)
        else:
            wav_format = "others"
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()

        stride = int(60 * args.chunk_size[1] / args.chunk_interval / 1000 * sample_rate * 2)
        chunk_num = (len(audio_bytes) - 1) // stride + 1
        # print(stride)

        # send first time
        message = json.dumps(
            {
                "mode": args.mode,
                "chunk_size": args.chunk_size,
                "chunk_interval": args.chunk_interval,
                "encoder_chunk_look_back": args.encoder_chunk_look_back,
                "decoder_chunk_look_back": args.decoder_chunk_look_back,
                "audio_fs": sample_rate,
                "wav_name": wav_name,
                "wav_format": wav_format,
                "is_speaking": True,
                "hotwords": hotword_msg,
                "itn": use_itn,
            }
        )

        # voices.put(message)
        await websocket.send(message)
        is_speaking = True
        for i in range(chunk_num):

            beg = i * stride
            data = audio_bytes[beg : beg + stride]
            message = data
            # voices.put(message)
            await websocket.send(message)
            if i == chunk_num - 1:
                is_speaking = False
                message = json.dumps({"is_speaking": is_speaking})
                # voices.put(message)
                await websocket.send(message)

            sleep_duration = (
                0.001
                if args.mode == "offline"
                else 60 * args.chunk_size[1] / args.chunk_interval / 1000
            )

            await asyncio.sleep(sleep_duration)

    if not args.mode == "offline":
        await asyncio.sleep(2)
    # offline model need to wait for message recved

    if args.mode == "offline":
        global offline_msg_done
        while not offline_msg_done:
            await asyncio.sleep(1)

    await websocket.close()


async def message(id):
    global websocket, voices, offline_msg_done
    text_print = ""
    text_print_2pass_online = ""
    text_print_2pass_offline = ""
    if args.output_dir is not None:
        ibest_writer = open(
            os.path.join(args.output_dir, "text.{}".format(id)), "a", encoding="utf-8"
        )
    else:
        ibest_writer = None
    try:
        while True:

            meg = await websocket.recv()
            meg = json.loads(meg)
            wav_name = meg.get("wav_name", "demo")
            text = meg["text"]
            timestamp = ""
            offline_msg_done = meg.get("is_final", False)
            if "timestamp" in meg:
                timestamp = meg["timestamp"]

            if ibest_writer is not None:
                if timestamp != "":
                    text_write_line = "{}\t{}\t{}\n".format(wav_name, text, timestamp)
                else:
                    text_write_line = "{}\t{}\n".format(wav_name, text)
                ibest_writer.write(text_write_line)

            if "mode" not in meg:
                continue
            if meg["mode"] == "online":
                text_print += "{}".format(text)
                text_print = text_print[-args.words_max_print :]
                os.system("clear")
                print("\rpid" + str(id) + ": " + text_print)
            elif meg["mode"] == "offline":
                if timestamp != "":
                    text_print += "{} timestamp: {}".format(text, timestamp)
                else:
                    text_print += "{}".format(text)

                # text_print = text_print[-args.words_max_print:]
                # os.system('clear')
                print("\rpid" + str(id) + ": " + wav_name + ": " + text_print)
                offline_msg_done = True
            else:
                if meg["mode"] == "2pass-online":
                    text_print_2pass_online += "{}".format(text)
                    text_print = text_print_2pass_offline + text_print_2pass_online
                else:
                    text_print_2pass_online = ""
                    text_print = text_print_2pass_offline + "{}".format(text)
                    text_print_2pass_offline += "{}".format(text)
                text_print = text_print[-args.words_max_print :]
                os.system("clear")
                print("\rpid" + str(id) + ": " + text_print)
                # offline_msg_done=True

    except Exception as e:
        print("Exception:", e)
        # traceback.print_exc()
        # await websocket.close()


async def ws_client(id, chunk_begin, chunk_size):
    if args.audio_in is None:
        chunk_begin = 0
        chunk_size = 1
    global websocket, voices, offline_msg_done

    for i in range(chunk_begin, chunk_begin + chunk_size):
        offline_msg_done = False
        voices = Queue()
        if args.ssl == 1:
            ssl_context = ssl.SSLContext()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE
            uri = "wss://{}:{}".format(args.host, args.port)
        else:
            uri = "ws://{}:{}".format(args.host, args.port)
            ssl_context = None
        print("connect to", uri)
        async with websockets.connect(
            uri, subprotocols=["binary"], ping_interval=None, ssl=ssl_context
        ) as websocket:
            if args.audio_in is not None:
                task = asyncio.create_task(record_from_scp(i, 1))
            else:
                task = asyncio.create_task(record_microphone())
            task3 = asyncio.create_task(message(str(id) + "_" + str(i)))  # processid+fileid
            await asyncio.gather(task, task3)
    exit(0)


def one_thread(id, chunk_begin, chunk_size):
    asyncio.get_event_loop().run_until_complete(ws_client(id, chunk_begin, chunk_size))
    asyncio.get_event_loop().run_forever()


if __name__ == "__main__":
    # for microphone
    if args.audio_in is None:
        p = Process(target=one_thread, args=(0, 0, 0))
        p.start()
        p.join()
        print("end")
    else:
        # calculate the number of wavs for each preocess
        if args.audio_in.endswith(".scp"):
            f_scp = open(args.audio_in)
            wavs = f_scp.readlines()
        else:
            wavs = [args.audio_in]
        for wav in wavs:
            wav_splits = wav.strip().split()
            wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
            wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
            audio_type = os.path.splitext(wav_path)[-1].lower()

        total_len = len(wavs)
        if total_len >= args.thread_num:
            chunk_size = int(total_len / args.thread_num)
            remain_wavs = total_len - chunk_size * args.thread_num
        else:
            chunk_size = 1
            remain_wavs = 0

        process_list = []
        chunk_begin = 0
        for i in range(args.thread_num):
            now_chunk_size = chunk_size
            if remain_wavs > 0:
                now_chunk_size = chunk_size + 1
                remain_wavs = remain_wavs - 1
            # process i handle wavs at chunk_begin and size of now_chunk_size
            p = Process(target=one_thread, args=(i, chunk_begin, now_chunk_size))
            chunk_begin = chunk_begin + now_chunk_size
            p.start()
            process_list.append(p)

        for i in process_list:
            p.join()

        print("end")
```

--------------------------------------------------------------------------------

File: client/test_demo.sh
```shell
python ./client/funasr_wss_client.py       --host "127.0.0.1"       --port 10095       --mode offline       --audio_in "./client/BAC009S0764W0179.wav"
```

--------------------------------------------------------------------------------

File: client/asr_system_backend/client/funasr_wss_client.py
```python
# -*- encoding: utf-8 -*-
import os
import time
import websockets, ssl
import asyncio

# import threading
import argparse
import json
import traceback
from multiprocessing import Process

# from funasr.fileio.datadir_writer import DatadirWriter

import logging

logging.basicConfig(level=logging.ERROR)

parser = argparse.ArgumentParser()
parser.add_argument(
    "--host", type=str, default="localhost", required=False, help="host ip, localhost, 0.0.0.0"
)
parser.add_argument("--port", type=int, default=10095, required=False, help="grpc server port")
parser.add_argument("--chunk_size", type=str, default="5, 10, 5", help="chunk")
parser.add_argument("--encoder_chunk_look_back", type=int, default=4, help="chunk")
parser.add_argument("--decoder_chunk_look_back", type=int, default=0, help="chunk")
parser.add_argument("--chunk_interval", type=int, default=10, help="chunk")
parser.add_argument(
    "--hotword",
    type=str,
    default="",
    help="hotword file path, one hotword perline (e.g.:阿里巴巴 20)",
)
parser.add_argument("--audio_in", type=str, default=None, help="audio_in")
parser.add_argument("--audio_fs", type=int, default=16000, help="audio_fs")
parser.add_argument(
    "--send_without_sleep",
    action="store_true",
    default=True,
    help="if audio_in is set, send_without_sleep",
)
parser.add_argument("--thread_num", type=int, default=1, help="thread_num")
parser.add_argument("--words_max_print", type=int, default=10000, help="chunk")
parser.add_argument("--output_dir", type=str, default=None, help="output_dir")
parser.add_argument("--ssl", type=int, default=1, help="1 for ssl connect, 0 for no ssl")
parser.add_argument("--use_itn", type=int, default=1, help="1 for using itn, 0 for not itn")
parser.add_argument("--mode", type=str, default="2pass", help="offline, online, 2pass")

args = parser.parse_args()
args.chunk_size = [int(x) for x in args.chunk_size.split(",")]
print(args)
# voices = asyncio.Queue()
from queue import Queue

voices = Queue()
offline_msg_done = False

if args.output_dir is not None:
    # if os.path.exists(args.output_dir):
    #     os.remove(args.output_dir)

    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir)


async def record_microphone():
    is_finished = False
    import pyaudio

    # print("2")
    global voices
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    chunk_size = 60 * args.chunk_size[1] / args.chunk_interval
    CHUNK = int(RATE / 1000 * chunk_size)

    p = pyaudio.PyAudio()

    stream = p.open(
        format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK
    )
    # hotwords
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        if os.path.exists(args.hotword):
            f_scp = open(args.hotword)
            hot_lines = f_scp.readlines()
            for line in hot_lines:
                words = line.strip().split(" ")
                if len(words) < 2:
                    print("Please checkout format of hotwords")
                    continue
                try:
                    fst_dict[" ".join(words[:-1])] = int(words[-1])
                except ValueError:
                    print("Please checkout format of hotwords")
            hotword_msg = json.dumps(fst_dict)
        else:
            hotword_msg = args.hotword

    use_itn = True
    if args.use_itn == 0:
        use_itn = False

    message = json.dumps(
        {
            "mode": args.mode,
            "chunk_size": args.chunk_size,
            "chunk_interval": args.chunk_interval,
            "encoder_chunk_look_back": args.encoder_chunk_look_back,
            "decoder_chunk_look_back": args.decoder_chunk_look_back,
            "wav_name": "microphone",
            "is_speaking": True,
            "hotwords": hotword_msg,
            "itn": use_itn,
        }
    )
    # voices.put(message)
    await websocket.send(message)
    while True:
        data = stream.read(CHUNK)
        message = data
        # voices.put(message)
        await websocket.send(message)
        await asyncio.sleep(0.005)


async def record_from_scp(chunk_begin, chunk_size):
    global voices
    is_finished = False
    if args.audio_in.endswith(".scp"):
        f_scp = open(args.audio_in)
        wavs = f_scp.readlines()
    else:
        wavs = [args.audio_in]

    # hotwords
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        if os.path.exists(args.hotword):
            f_scp = open(args.hotword)
            hot_lines = f_scp.readlines()
            for line in hot_lines:
                words = line.strip().split(" ")
                if len(words) < 2:
                    print("Please checkout format of hotwords")
                    continue
                try:
                    fst_dict[" ".join(words[:-1])] = int(words[-1])
                except ValueError:
                    print("Please checkout format of hotwords")
            hotword_msg = json.dumps(fst_dict)
        else:
            hotword_msg = args.hotword
        print(hotword_msg)

    sample_rate = args.audio_fs
    wav_format = "pcm"
    use_itn = True
    if args.use_itn == 0:
        use_itn = False

    if chunk_size > 0:
        wavs = wavs[chunk_begin : chunk_begin + chunk_size]
    for wav in wavs:
        wav_splits = wav.strip().split()

        wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
        wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
        if not len(wav_path.strip()) > 0:
            continue
        if wav_path.endswith(".pcm"):
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()
        elif wav_path.endswith(".wav"):
            import wave

            with wave.open(wav_path, "rb") as wav_file:
                params = wav_file.getparams()
                sample_rate = wav_file.getframerate()
                frames = wav_file.readframes(wav_file.getnframes())
                audio_bytes = bytes(frames)
        else:
            wav_format = "others"
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()

        stride = int(60 * args.chunk_size[1] / args.chunk_interval / 1000 * sample_rate * 2)
        chunk_num = (len(audio_bytes) - 1) // stride + 1
        # print(stride)

        # send first time
        message = json.dumps(
            {
                "mode": args.mode,
                "chunk_size": args.chunk_size,
                "chunk_interval": args.chunk_interval,
                "encoder_chunk_look_back": args.encoder_chunk_look_back,
                "decoder_chunk_look_back": args.decoder_chunk_look_back,
                "audio_fs": sample_rate,
                "wav_name": wav_name,
                "wav_format": wav_format,
                "is_speaking": True,
                "hotwords": hotword_msg,
                "itn": use_itn,
            }
        )

        # voices.put(message)
        await websocket.send(message)
        is_speaking = True
        for i in range(chunk_num):

            beg = i * stride
            data = audio_bytes[beg : beg + stride]
            message = data
            # voices.put(message)
            await websocket.send(message)
            if i == chunk_num - 1:
                is_speaking = False
                message = json.dumps({"is_speaking": is_speaking})
                # voices.put(message)
                await websocket.send(message)

            sleep_duration = (
                0.001
                if args.mode == "offline"
                else 60 * args.chunk_size[1] / args.chunk_interval / 1000
            )

            await asyncio.sleep(sleep_duration)

    if not args.mode == "offline":
        await asyncio.sleep(2)
    # offline model need to wait for message recved

    if args.mode == "offline":
        global offline_msg_done
        while not offline_msg_done:
            await asyncio.sleep(1)

    await websocket.close()


async def message(id):
    global websocket, voices, offline_msg_done
    text_print = ""
    text_print_2pass_online = ""
    text_print_2pass_offline = ""
    if args.output_dir is not None:
        ibest_writer = open(
            os.path.join(args.output_dir, "text.{}".format(id)), "a", encoding="utf-8"
        )
    else:
        ibest_writer = None
    try:
        while True:

            meg = await websocket.recv()
            meg = json.loads(meg)
            wav_name = meg.get("wav_name", "demo")
            text = meg["text"]
            timestamp = ""
            offline_msg_done = meg.get("is_final", False)
            if "timestamp" in meg:
                timestamp = meg["timestamp"]

            if ibest_writer is not None:
                if timestamp != "":
                    text_write_line = "{}\t{}\t{}\n".format(wav_name, text, timestamp)
                else:
                    text_write_line = "{}\t{}\n".format(wav_name, text)
                ibest_writer.write(text_write_line)

            if "mode" not in meg:
                continue
            if meg["mode"] == "online":
                text_print += "{}".format(text)
                text_print = text_print[-args.words_max_print :]
                os.system("clear")
                print("\rpid" + str(id) + ": " + text_print)
            elif meg["mode"] == "offline":
                if timestamp != "":
                    text_print += "{} timestamp: {}".format(text, timestamp)
                else:
                    text_print += "{}".format(text)

                # text_print = text_print[-args.words_max_print:]
                # os.system('clear')
                print("\rpid" + str(id) + ": " + wav_name + ": " + text_print)
                offline_msg_done = True
            else:
                if meg["mode"] == "2pass-online":
                    text_print_2pass_online += "{}".format(text)
                    text_print = text_print_2pass_offline + text_print_2pass_online
                else:
                    text_print_2pass_online = ""
                    text_print = text_print_2pass_offline + "{}".format(text)
                    text_print_2pass_offline += "{}".format(text)
                text_print = text_print[-args.words_max_print :]
                os.system("clear")
                print("\rpid" + str(id) + ": " + text_print)
                # offline_msg_done=True

    except Exception as e:
        print("Exception:", e)
        # traceback.print_exc()
        # await websocket.close()


async def ws_client(id, chunk_begin, chunk_size):
    if args.audio_in is None:
        chunk_begin = 0
        chunk_size = 1
    global websocket, voices, offline_msg_done

    for i in range(chunk_begin, chunk_begin + chunk_size):
        offline_msg_done = False
        voices = Queue()
        if args.ssl == 1:
            ssl_context = ssl.SSLContext()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE
            uri = "wss://{}:{}".format(args.host, args.port)
        else:
            uri = "ws://{}:{}".format(args.host, args.port)
            ssl_context = None
        print("connect to", uri)
        async with websockets.connect(
            uri, subprotocols=["binary"], ping_interval=None, ssl=ssl_context
        ) as websocket:
            if args.audio_in is not None:
                task = asyncio.create_task(record_from_scp(i, 1))
            else:
                task = asyncio.create_task(record_microphone())
            task3 = asyncio.create_task(message(str(id) + "_" + str(i)))  # processid+fileid
            await asyncio.gather(task, task3)
    exit(0)


def one_thread(id, chunk_begin, chunk_size):
    asyncio.get_event_loop().run_until_complete(ws_client(id, chunk_begin, chunk_size))
    asyncio.get_event_loop().run_forever()


if __name__ == "__main__":
    # for microphone
    if args.audio_in is None:
        p = Process(target=one_thread, args=(0, 0, 0))
        p.start()
        p.join()
        print("end")
    else:
        # calculate the number of wavs for each preocess
        if args.audio_in.endswith(".scp"):
            f_scp = open(args.audio_in)
            wavs = f_scp.readlines()
        else:
            wavs = [args.audio_in]
        for wav in wavs:
            wav_splits = wav.strip().split()
            wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
            wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
            audio_type = os.path.splitext(wav_path)[-1].lower()

        total_len = len(wavs)
        if total_len >= args.thread_num:
            chunk_size = int(total_len / args.thread_num)
            remain_wavs = total_len - chunk_size * args.thread_num
        else:
            chunk_size = 1
            remain_wavs = 0

        process_list = []
        chunk_begin = 0
        for i in range(args.thread_num):
            now_chunk_size = chunk_size
            if remain_wavs > 0:
                now_chunk_size = chunk_size + 1
                remain_wavs = remain_wavs - 1
            # process i handle wavs at chunk_begin and size of now_chunk_size
            p = Process(target=one_thread, args=(i, chunk_begin, now_chunk_size))
            chunk_begin = chunk_begin + now_chunk_size
            p.start()
            process_list.append(p)

        for i in process_list:
            p.join()

        print("end")
```

--------------------------------------------------------------------------------

File: asr_system_backend/env.example
```text
# ASR系统环境变量配置模板
# 请复制此文件为.env并填入真实值

# 数据库配置
DATABASE_URL=sqlite:///./asr_system.db

# JWT安全配置
JWT_SECRET_KEY=your_jwt_secret_key_here_please_change_this
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=60

# ASR引擎配置
ASR_MODEL_SIZE=base
ASR_LANGUAGE=zh
ASR_ENABLE_GPU=true
ASR_MAX_FILE_SIZE_MB=100
ASR_PROCESSING_TIMEOUT=300

# 文件存储配置
UPLOAD_DIR=uploads
TEMP_DIR=temp

# RAG服务配置
RAG_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
RAG_SIMILARITY_THRESHOLD=0.5

# 日志配置
LOG_LEVEL=INFO
LOG_FILE=app.log

# 性能配置
BACKGROUND_TASK_WORKERS=2

# OpenAI API配置（如果使用OpenAI Whisper API）
# OPENAI_API_KEY=your_openai_api_key_here

# 阿里云配置（如果使用阿里云服务）
# ALIYUN_ACCESS_KEY_ID=your_access_key_id
# ALIYUN_ACCESS_KEY_SECRET=your_access_key_secret

# 百度AI配置（如果使用百度语音识别）
# BAIDU_APP_ID=your_baidu_app_id
# BAIDU_API_KEY=your_baidu_api_key
# BAIDU_SECRET_KEY=your_baidu_secret_key

# 开发模式配置
DEBUG=true
DEVELOPMENT=true
```

--------------------------------------------------------------------------------

File: asr_system_backend/setup.py
```python
# File: asr_system_backend/setup.py
from setuptools import setup, find_packages

setup(
    name="asr_system_backend",  # <-- 把这里的连字符改成下划线！
    version="0.1.0",
    packages=find_packages(),
)
```

--------------------------------------------------------------------------------

File: asr_system_backend/alembic.ini
```ini
# A generic, single database configuration.

[alembic]
# path to migration scripts.
# this is typically a path given in POSIX (e.g. forward slashes)
# format, relative to the token %(here)s which refers to the location of this
# ini file
script_location = %(here)s/alembic

# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s
# Uncomment the line below if you want the files to be prepended with date and time
# see https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file
# for all available tokens
# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.  for multiple paths, the path separator
# is defined by "path_separator" below.
prepend_sys_path = .


# timezone to use when rendering the date within the migration file
# as well as the filename.
# If specified, requires the python>=3.9 or backports.zoneinfo library and tzdata library.
# Any required deps can installed by adding `alembic[tz]` to the pip requirements
# string value is passed to ZoneInfo()
# leave blank for localtime
# timezone =

# max length of characters to apply to the "slug" field
# truncate_slug_length = 40

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; This defaults
# to <script_location>/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path.
# The path separator used here should be the separator specified by "path_separator"
# below.
# version_locations = %(here)s/bar:%(here)s/bat:%(here)s/alembic/versions

# path_separator; This indicates what character is used to split lists of file
# paths, including version_locations and prepend_sys_path within configparser
# files such as alembic.ini.
# The default rendered in new alembic.ini files is "os", which uses os.pathsep
# to provide os-dependent path splitting.
#
# Note that in order to support legacy alembic.ini files, this default does NOT
# take place if path_separator is not present in alembic.ini.  If this
# option is omitted entirely, fallback logic is as follows:
#
# 1. Parsing of the version_locations option falls back to using the legacy
#    "version_path_separator" key, which if absent then falls back to the legacy
#    behavior of splitting on spaces and/or commas.
# 2. Parsing of the prepend_sys_path option falls back to the legacy
#    behavior of splitting on spaces, commas, or colons.
#
# Valid values for path_separator are:
#
# path_separator = :
# path_separator = ;
# path_separator = space
# path_separator = newline
#
# Use os.pathsep. Default configuration used for new projects.
path_separator = os

# set to 'true' to search source files recursively
# in each "version_locations" directory
# new in Alembic version 1.10
# recursive_version_locations = false

# the output encoding used when revision files
# are written from script.py.mako
# output_encoding = utf-8

# database URL.  This is consumed by the user-maintained env.py script only.
# other means of configuring database URLs may be customized within the env.py
# file.
sqlalchemy.url = sqlite:///./test_ci.db


[post_write_hooks]
# post_write_hooks defines scripts or Python functions that are run
# on newly generated revision scripts.  See the documentation for further
# detail and examples

# format using "black" - use the console_scripts runner, against the "black" entrypoint
# hooks = black
# black.type = console_scripts
# black.entrypoint = black
# black.options = -l 79 REVISION_SCRIPT_FILENAME

# lint with attempts to fix using "ruff" - use the exec runner, execute a binary
# hooks = ruff
# ruff.type = exec
# ruff.executable = %(here)s/.venv/bin/ruff
# ruff.options = check --fix REVISION_SCRIPT_FILENAME

# Logging configuration.  This is also consumed by the user-maintained
# env.py script only.
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARNING
handlers = console
qualname =

[logger_sqlalchemy]
level = WARNING
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S
```

--------------------------------------------------------------------------------

File: asr_system_backend/.gitignore
```text
# Python
__pycache__/
*.py[cod]
*.pyo
*.pyd

# Virtualenv
venv/
.venv/
ENV/

# SQLite database
*.db
*.sqlite3

# Alembic
alembic/versions/

# VSCode
.vscode/

# OS files
.DS_Store
Thumbs.db
```

--------------------------------------------------------------------------------

File: asr_system_backend/init_db.py
```python
#!/usr/bin/env python3
"""
数据库初始化脚本
用于创建数据库表结构和初始数据
"""

import os
import sys
from pathlib import Path

# 添加项目根目录到Python路径
sys.path.insert(0, str(Path(__file__).parent))

from app.database import Base, engine, SessionLocal
from app.models import User, Hotword, TranscriptionTask, TranscriptionSegment
from app.config import get_settings
import logging

# 配置日志
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_tables():
    """创建所有数据表"""
    try:
        logger.info("正在创建数据库表...")
        Base.metadata.create_all(bind=engine)
        logger.info("✅ 数据库表创建成功")
        return True
    except Exception as e:
        logger.error(f"❌ 数据库表创建失败: {e}")
        return False

def create_sample_data():
    """创建示例数据（可选）"""
    try:
        db = SessionLocal()
        
        # 检查是否已有数据
        user_count = db.query(User).count()
        if user_count > 0:
            logger.info("数据库中已有用户数据，跳过示例数据创建")
            return True
        
        logger.info("创建示例数据...")
        
        # 这里可以添加示例数据创建逻辑
        # 但为了安全，我们暂时不创建任何示例数据
        
        logger.info("✅ 示例数据创建完成")
        return True
        
    except Exception as e:
        logger.error(f"❌ 示例数据创建失败: {e}")
        return False
    finally:
        db.close()

def verify_database():
    """验证数据库连接和表结构"""
    try:
        db = SessionLocal()
        
        # 测试每个表
        tables = [User, Hotword, TranscriptionTask, TranscriptionSegment]
        for table in tables:
            count = db.query(table).count()
            logger.info(f"表 {table.__tablename__}: {count} 条记录")
        
        logger.info("✅ 数据库验证成功")
        return True
        
    except Exception as e:
        logger.error(f"❌ 数据库验证失败: {e}")
        return False
    finally:
        db.close()

def main():
    """主函数"""
    logger.info("=" * 50)
    logger.info("ASR系统数据库初始化")
    logger.info("=" * 50)
    
    settings = get_settings()
    logger.info(f"数据库URL: {settings.DATABASE_URL}")
    
    # 创建必要的目录
    upload_dir = Path(settings.UPLOAD_DIR)
    temp_dir = Path(settings.TEMP_DIR)
    
    upload_dir.mkdir(exist_ok=True)
    temp_dir.mkdir(exist_ok=True)
    
    logger.info(f"上传目录: {upload_dir.absolute()}")
    logger.info(f"临时目录: {temp_dir.absolute()}")
    
    # 初始化数据库
    success = True
    success &= create_tables()
    success &= create_sample_data()
    success &= verify_database()
    
    if success:
        logger.info("🎉 数据库初始化完成！")
        logger.info("现在可以启动应用程序了:")
        logger.info("uvicorn app.main:app --reload --host 0.0.0.0 --port 8000")
    else:
        logger.error("❌ 数据库初始化失败")
        sys.exit(1)

if __name__ == "__main__":
    main()
```

--------------------------------------------------------------------------------

File: asr_system_backend/README.md
```markdown
## 用户认证API说明

### 注册
POST /auth/register
- 参数：username, password
- 返回：用户信息

### 登录
POST /auth/login
- 参数：username, password
- 返回：access_token（JWT令牌）

### 获取当前用户
GET /auth/me
- Header: Authorization: Bearer <access_token>
- 返回：当前用户信息

## 本地运行
1. 安装依赖：pip install -r requirements.txt
2. 启动服务：uvicorn app.main:app --reload
3. 访问API文档：http://localhost:8000/docs 

### 数据库迁移操作

1. 生成迁移脚本（如有模型变更）：
   ```
   alembic revision --autogenerate -m "描述"
   ```
2. 应用迁移到数据库：
   ```
   alembic upgrade head
   ```
3. 回滚迁移（如需）：
   ```
   alembic downgrade -1
   ```

### CI/CD 说明

- 本项目已集成 GitHub Actions 自动化流程，包含后端依赖安装、代码风格检查、数据库迁移、自动化测试，前端依赖安装、代码风格检查、构建等环节。
- 每次 push 或 PR 到 main 分支时自动触发。
- 详见 `.github/workflows/ci.yml`.
```

--------------------------------------------------------------------------------

File: asr_system_backend/alembic/README
```text
Generic single-database configuration.
```

--------------------------------------------------------------------------------

File: asr_system_backend/alembic/env.py
```python
from logging.config import fileConfig

from sqlalchemy import engine_from_config
from sqlalchemy import pool

from alembic import context

from app.database import Base  # 新增

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# add your model's MetaData object here
# for 'autogenerate' support
# from myapp import mymodel
# target_metadata = mymodel.Base.metadata
target_metadata = Base.metadata  # 修改此行

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.


def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    """
    connectable = engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection, target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
```

--------------------------------------------------------------------------------

File: asr_system_backend/alembic/script.py.mako
```text
"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
${imports if imports else ""}

# revision identifiers, used by Alembic.
revision: str = ${repr(up_revision)}
down_revision: Union[str, Sequence[str], None] = ${repr(down_revision)}
branch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}
depends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}


def upgrade() -> None:
    """Upgrade schema."""
    ${upgrades if upgrades else "pass"}


def downgrade() -> None:
    """Downgrade schema."""
    ${downgrades if downgrades else "pass"}
```

--------------------------------------------------------------------------------

File: asr_system_backend/alembic/versions/928c19ceeb23_add_terminal_output_field.py
```python
"""add terminal output field

Revision ID: 928c19ceeb23
Revises: 
Create Date: 2025-07-17 00:01:07.710107

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '928c19ceeb23'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/services.py
```python
import os
import subprocess
from datetime import datetime
from sqlalchemy.orm import Session
from . import models
from .config import get_settings

settings = get_settings()

class TranscriptionService:
    @staticmethod
    def process_transcription_task(db: Session, task_id: str, file_path: str, hotword_list_id: str = None):
        """处理转写任务"""
        try:
            # 更新任务状态
            task = db.query(models.TranscriptionTask).filter(models.TranscriptionTask.id == task_id).first()
            if not task:
                return
            
            task.status = "processing"
            db.commit()
            
            # 调用本地客户端进行转写
            client_path = os.path.join(os.path.dirname(__file__), "client", "funasr_wss_client.py")
            cmd = ["python", client_path, "--host", "localhost", "--port", "10095", "--mode", "offline", "--audio_in", file_path]
            
            # 执行命令并捕获输出
            process = subprocess.run(cmd, capture_output=True, text=True)
            terminal_output = process.stdout + process.stderr
            
            # 更新任务状态和输出
            task.status = "completed" if process.returncode == 0 else "failed"
            task.terminal_output = terminal_output
            task.completed_at = datetime.utcnow()
            db.commit()
            
            # 清理临时文件
            try:
                os.remove(file_path)
            except:
                pass
                
        except Exception as e:
            # 更新任务状态为失败
            task = db.query(models.TranscriptionTask).filter(models.TranscriptionTask.id == task_id).first()
            if task:
                task.status = "failed"
                task.terminal_output = str(e)
                task.completed_at = datetime.utcnow()
                db.commit()
            
            # 清理临时文件
            try:
                os.remove(file_path)
            except:
                pass
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/config.py
```python
import os
from typing import Optional
from dotenv import load_dotenv

# 加载环境变量
load_dotenv()

class Settings:
    """应用配置设置"""
    
    # 数据库配置
    DATABASE_URL: str = os.getenv("DATABASE_URL", "sqlite:///./asr_system.db")
    
    # JWT配置
    JWT_SECRET_KEY: str = os.getenv("JWT_SECRET_KEY", "!!!secret_key!!!")
    JWT_ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = int(os.getenv("ACCESS_TOKEN_EXPIRE_MINUTES", "60"))
    
    # ASR引擎配置
    ASR_MODEL_SIZE: str = os.getenv("ASR_MODEL_SIZE", "base")  # tiny, base, small, medium, large
    ASR_LANGUAGE: str = os.getenv("ASR_LANGUAGE", "zh")  # 默认语言
    ASR_ENABLE_GPU: bool = os.getenv("ASR_ENABLE_GPU", "true").lower() == "true"
    ASR_MAX_FILE_SIZE_MB: int = int(os.getenv("ASR_MAX_FILE_SIZE_MB", "100"))
    ASR_SUPPORTED_FORMATS: list = [".wav", ".mp3", ".m4a", ".flac", ".aac", ".ogg"]
    
    # 文件存储配置
    UPLOAD_DIR: str = os.getenv("UPLOAD_DIR", "uploads")
    TEMP_DIR: str = os.getenv("TEMP_DIR", "temp")
    MAX_UPLOAD_SIZE: int = ASR_MAX_FILE_SIZE_MB * 1024 * 1024  # 转换为字节
    
    # RAG服务配置
    RAG_MODEL_NAME: str = os.getenv("RAG_MODEL_NAME", "sentence-transformers/all-MiniLM-L6-v2")
    RAG_VECTOR_DIMENSION: int = 384
    RAG_SIMILARITY_THRESHOLD: float = float(os.getenv("RAG_SIMILARITY_THRESHOLD", "0.5"))
    
    # 日志配置
    LOG_LEVEL: str = os.getenv("LOG_LEVEL", "INFO")
    LOG_FILE: Optional[str] = os.getenv("LOG_FILE", None)
    
    # CORS配置
    CORS_ORIGINS = [
        origin.strip()
        for origin in os.getenv(
            "CORS_ORIGINS",
            "http://localhost:2956,http://127.0.0.1:2956,http://0.0.0.0:2956"
        ).split(",")
    ]
    
    # 性能配置
    BACKGROUND_TASK_WORKERS: int = int(os.getenv("BACKGROUND_TASK_WORKERS", "2"))
    ASR_PROCESSING_TIMEOUT: int = int(os.getenv("ASR_PROCESSING_TIMEOUT", "300"))  # 5分钟
    
    def __init__(self):
        # 确保上传目录存在
        os.makedirs(self.UPLOAD_DIR, exist_ok=True)
        os.makedirs(self.TEMP_DIR, exist_ok=True)
    
    @property
    def asr_model_config(self) -> dict:
        """获取ASR模型配置"""
        return {
            "model_size": self.ASR_MODEL_SIZE,
            "language": self.ASR_LANGUAGE,
            "enable_gpu": self.ASR_ENABLE_GPU,
            "max_file_size_mb": self.ASR_MAX_FILE_SIZE_MB,
            "supported_formats": self.ASR_SUPPORTED_FORMATS,
            "processing_timeout": self.ASR_PROCESSING_TIMEOUT
        }
    
    @property
    def rag_config(self) -> dict:
        """获取RAG服务配置"""
        return {
            "model_name": self.RAG_MODEL_NAME,
            "vector_dimension": self.RAG_VECTOR_DIMENSION,
            "similarity_threshold": self.RAG_SIMILARITY_THRESHOLD
        }

# 全局配置实例
settings = Settings()

def get_settings() -> Settings:
    """获取应用配置"""
    return settings
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/asr_engine.py
```python
import os
import logging
import asyncio
import websockets
import json
import wave
from typing import List, Dict, Optional
from datetime import datetime
from .config import get_settings

logger = logging.getLogger(__name__)
settings = get_settings()

class ASREngine:
    def __init__(self):
        """初始化ASR引擎"""
        self.host = "127.0.0.1"  # FunASR服务地址
        self.port = 10095       # FunASR服务端口
        self.initialized = True  # FunASR服务是独立的Docker容器，不需要初始化
    
    def initialize(self):
        """FunASR服务是独立的Docker容器，不需要初始化"""
        pass
    
    async def _transcribe_with_funasr(self, audio_file_path: str) -> Dict:
        """使用FunASR WebSocket客户端进行转写"""
        try:
            # 读取音频文件
            with wave.open(audio_file_path, 'rb') as wav_file:
                audio_bytes = wav_file.readframes(wav_file.getnframes())
                sample_rate = wav_file.getframerate()
            
            # 连接WebSocket服务器
            uri = f"ws://{self.host}:{self.port}"
            logger.info(f"正在连接FunASR服务: {uri}")
            
            async with websockets.connect(uri, ping_interval=None) as websocket:
                # 发送初始配置
                config = {
                    "mode": "offline",
                    "chunk_size": [5, 10, 5],
                    "chunk_interval": 10,
                    "wav_name": os.path.basename(audio_file_path),
                    "is_speaking": True,
                    "audio_fs": sample_rate,
                    "wav_format": "wav",
                    "hotwords": "",
                    "itn": True
                }
                await websocket.send(json.dumps(config))
                logger.info("已发送配置信息")
                
                # 发送音频数据
                await websocket.send(audio_bytes)
                logger.info("已发送音频数据")
                
                # 发送结束标记
                await websocket.send(json.dumps({"is_speaking": False}))
                logger.info("已发送结束标记")
                
                # 接收转写结果
                while True:
                    try:
                        result = await websocket.recv()
                        logger.info(f"收到结果: {result}")
                        
                        if isinstance(result, str):
                            try:
                                # 尝试解析JSON结果
                                json_result = json.loads(result)
                                if "text" in json_result:
                                    text = json_result["text"]
                                else:
                                    # 如果不是JSON或没有text字段，使用原始文本
                                    text = result.split(": ")[-1].strip()
                                
                                # 构建标准格式的结果
                                formatted_result = {
                                    "text": text,
                                    "language": "zh",
                                    "segments": [{
                                        "segment_id": 0,
                                        "start_time": 0,
                                        "end_time": 0,  # FunASR离线模式不提供时间戳
                                        "text": text,
                                        "confidence": 1.0  # FunASR离线模式不提供置信度
                                    }],
                                    "duration": 0,  # FunASR离线模式不提供时长
                                    "processing_time": datetime.now().isoformat()
                                }
                                return formatted_result
                            except json.JSONDecodeError:
                                continue
                    except websockets.exceptions.ConnectionClosed:
                        break
                
                raise ValueError("未收到有效的转写结果")
                    
        except Exception as e:
            logger.error(f"FunASR转写失败: {str(e)}")
            raise
    
    async def _transcribe_with_funasr(self, audio_stream):
        uri = f"ws://{self.host}:{self.port}"
        async with websockets.connect(uri) as ws:
            # 发送实时音频流
            while True:
                chunk = await audio_stream.read(640)  # 40ms的16kHz 16bit音频
                if not chunk:
                    break
                await ws.send(chunk)
                # 接收转写结果
                result = await ws.recv()
                yield json.loads(result)
    
    def transcribe_audio(self, audio_file_path: str, language: str = "zh") -> Dict:
        """转写音频文件"""
        if not os.path.exists(audio_file_path):
            raise FileNotFoundError(f"音频文件不存在: {audio_file_path}")
            
        # 创建事件循环并运行WebSocket客户端
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            result = loop.run_until_complete(self._transcribe_with_funasr(audio_file_path))
            return result
        finally:
            loop.close()
    
    def get_supported_formats(self) -> List[str]:
        """获取支持的音频格式"""
        return [".wav"]  # 目前只支持WAV格式
    
    def validate_audio_file(self, file_path: str) -> bool:
        """验证音频文件是否有效"""
        try:
            # 检查文件扩展名
            _, ext = os.path.splitext(file_path.lower())
            if ext not in self.get_supported_formats():
                return False
            
            # 尝试打开WAV文件
            with wave.open(file_path, 'rb') as wav_file:
                return wav_file.getnframes() > 0
                
        except Exception:
            return False

# 全局ASR引擎实例
asr_engine = ASREngine()

def get_asr_engine() -> ASREngine:
    """获取ASR引擎实例"""
    return asr_engine
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/auth_service.py
```python
from datetime import datetime, timedelta
from typing import Optional
from jose import JWTError, jwt
from passlib.context import CryptContext
from fastapi import HTTPException, status
from .config import get_settings

settings = get_settings()

# 密码哈希上下文
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

def verify_password(plain_password: str, hashed_password: str) -> bool:
    """验证密码"""
    return pwd_context.verify(plain_password, hashed_password)

def get_password_hash(password: str) -> str:
    """生成密码哈希"""
    return pwd_context.hash(password)

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None) -> str:
    """创建JWT访问令牌"""
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, settings.JWT_SECRET_KEY, algorithm=settings.JWT_ALGORITHM)
    return encoded_jwt

def decode_access_token(token: str) -> dict:
    """解码JWT访问令牌"""
    try:
        payload = jwt.decode(token, settings.JWT_SECRET_KEY, algorithms=[settings.JWT_ALGORITHM])
        return payload
    except JWTError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="无效的令牌",
            headers={"WWW-Authenticate": "Bearer"},
        ) 

async def get_current_user_from_token(token: str):
    """从令牌中获取当前用户"""
    from .models import User
    from .database import get_db
    from sqlalchemy.orm import Session
    from fastapi import Depends

    payload = decode_access_token(token)
    username: str = payload.get("sub")
    if username is None:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="无效的认证凭据",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    db = next(get_db())
    user = db.query(User).filter(User.username == username).first()
    if user is None:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="用户不存在",
            headers={"WWW-Authenticate": "Bearer"},
        )
    return user
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/__init__.py
```python

```

--------------------------------------------------------------------------------

File: asr_system_backend/app/models.py
```python
from sqlalchemy import Column, Integer, String, DateTime, create_engine
from datetime import datetime
from app.database import DATABASE_URL  # 现在可以正确导入
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

Base = declarative_base()
DATABASE_URL = "sqlite:///asr_system.db"

engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

class User(Base):
    __tablename__ = "users"
    id = Column(Integer, primary_key=True, index=True)
    username = Column(String, unique=True)
    hashed_password = Column(String)
    created_at = Column(DateTime, default=datetime.now)  # 确保这里使用正确
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/schemas.py
```python
from pydantic import BaseModel, Field, field_validator, ConfigDict
from typing import Optional, List
from datetime import datetime

# 用户相关模型
class UserBase(BaseModel):
    username: str = Field(..., min_length=3, max_length=50)

class UserCreate(UserBase):
    password: str = Field(..., min_length=6)

class UserLogin(BaseModel):
    username: str
    password: str

class UserOut(BaseModel):
    id: str
    username: str
    created_at: datetime

    class Config:
        from_attributes = True

# 令牌相关模型
class Token(BaseModel):
    access_token: str
    token_type: str

class TokenData(BaseModel):
    username: Optional[str] = None

# 热词相关模型
class HotwordBase(BaseModel):
    word: str = Field(..., min_length=1, max_length=255)
    weight: int = Field(5, ge=1, le=10)

class HotwordCreate(HotwordBase):
    pass

class HotwordUpdate(HotwordBase):
    word: Optional[str] = None
    weight: Optional[int] = None

    @field_validator('word')
    def word_not_empty(cls, v):
        if v is not None and len(v.strip()) == 0:
            raise ValueError('词汇不能为空')
        return v
    
    @field_validator('weight')
    def weight_in_range(cls, v):
        if v is not None and (v < 1 or v > 10):
            raise ValueError('权重必须在1-10之间')
        return v

class HotwordOut(BaseModel):
    id: str
    word: str
    weight: int
    created_at: datetime

    class Config:
        from_attributes = True

# 转写相关模型
class TranscriptionTaskBase(BaseModel):
    filename: str

class TranscriptionTaskCreate(TranscriptionTaskBase):
    pass

class TranscriptionTaskOut(BaseModel):
    id: str
    filename: str
    status: str
    created_at: datetime
    completed_at: Optional[datetime] = None
    error_message: Optional[str] = None

    class Config:
        from_attributes = True

class TranscriptionSegmentOut(BaseModel):
    id: str
    segment_id: int
    start_time: float
    end_time: float
    text: str
    confidence: float

    class Config:
        from_attributes = True

class TranscriptionTaskWithSegments(TranscriptionTaskOut):
    segments: List[TranscriptionSegmentOut] = []
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/rag_service.py
```python
import os
import json
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from typing import List, Dict, Optional, Tuple
from sqlalchemy.orm import Session
from . import models
import logging
import pickle
from datetime import datetime
from .config import get_settings

logger = logging.getLogger(__name__)
settings = get_settings()

class RAGService:
    def __init__(self):
        self.model = None
        self.index = None
        self.hotword_embeddings = {}
        self.hotword_metadata = {}
        self.dimension = 384  # sentence-transformers/all-MiniLM-L6-v2 的维度
        self.initialized = False
        self.index_dir = os.path.join(settings.TEMP_DIR, "rag_indices")
        
        # 确保索引目录存在
        os.makedirs(self.index_dir, exist_ok=True)
        
    def initialize(self):
        """初始化RAG服务，加载预训练模型"""
        try:
            # 加载轻量级的多语言模型
            logger.info("正在加载句子嵌入模型...")
            self.model = SentenceTransformer(settings.RAG_MODEL_NAME)
            self.dimension = self.model.get_sentence_embedding_dimension()
            
            # 创建FAISS索引 (使用余弦相似度)
            self.index = faiss.IndexFlatIP(self.dimension)
            
            self.initialized = True
            logger.info(f"RAG服务初始化成功 (模型: {settings.RAG_MODEL_NAME}, 维度: {self.dimension})")
        except Exception as e:
            logger.error(f"RAG服务初始化失败: {str(e)}")
            self.initialized = False
    
    def save_user_index(self, user_id: str) -> bool:
        """保存用户索引到文件"""
        try:
            if user_id not in self.hotword_metadata:
                logger.warning(f"用户 {user_id} 的索引不存在，无法保存")
                return False
                
            index_file = os.path.join(self.index_dir, f"user_{user_id}.index")
            metadata_file = os.path.join(self.index_dir, f"user_{user_id}.metadata")
            
            # 保存FAISS索引
            user_embeddings = self.hotword_embeddings.get(user_id)
            if user_embeddings is not None:
                # 创建临时索引只包含该用户的向量
                temp_index = faiss.IndexFlatIP(self.dimension)
                temp_index.add(user_embeddings)
                faiss.write_index(temp_index, index_file)
                
            # 保存元数据
            metadata = self.hotword_metadata[user_id].copy()
            metadata['last_updated'] = datetime.now().isoformat()
            metadata['dimension'] = self.dimension
            
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
                
            logger.info(f"用户 {user_id} 的索引已保存到文件")
            return True
            
        except Exception as e:
            logger.error(f"保存用户索引失败: {str(e)}")
            return False
    
    def load_user_index(self, user_id: str) -> bool:
        """从文件加载用户索引"""
        try:
            index_file = os.path.join(self.index_dir, f"user_{user_id}.index")
            metadata_file = os.path.join(self.index_dir, f"user_{user_id}.metadata")
            
            # 检查文件是否存在
            if not os.path.exists(index_file) or not os.path.exists(metadata_file):
                logger.info(f"用户 {user_id} 的索引文件不存在")
                return False
                
            # 加载元数据
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
                
            # 验证维度兼容性
            if metadata.get('dimension', 0) != self.dimension:
                logger.warning(f"用户 {user_id} 的索引维度不匹配，需要重建")
                return False
                
            # 加载FAISS索引
            temp_index = faiss.read_index(index_file)
            embeddings = np.zeros((temp_index.ntotal, self.dimension), dtype=np.float32)
            temp_index.reconstruct_n(0, temp_index.ntotal, embeddings)
            
            # 恢复到服务中
            self.hotword_embeddings[user_id] = embeddings
            self.hotword_metadata[user_id] = metadata
            
            # 重建全局索引
            self._rebuild_global_index()
            
            logger.info(f"用户 {user_id} 的索引已从文件加载，包含 {len(metadata.get('words', []))} 个热词")
            return True
            
        except Exception as e:
            logger.error(f"加载用户索引失败: {str(e)}")
            return False
    
    def _rebuild_global_index(self):
        """重建全局FAISS索引"""
        try:
            self.index.reset()
            
            for user_id, embeddings in self.hotword_embeddings.items():
                if embeddings is not None and len(embeddings) > 0:
                    self.index.add(embeddings)
                    
            logger.debug("全局索引重建完成")
            
        except Exception as e:
            logger.error(f"重建全局索引失败: {str(e)}")
    
    def build_user_hotword_index(self, db: Session, user_id: str) -> bool:
        """为特定用户构建热词索引"""
        if not self.initialized:
            self.initialize()
            
        if not self.initialized:
            return False
            
        try:
            # 尝试从文件加载现有索引
            if self.load_user_index(user_id):
                # 检查数据库中的热词是否有更新
                db_hotwords = db.query(models.Hotword).filter(
                    models.Hotword.user_id == user_id
                ).all()
                
                db_words = {hw.word: hw.weight for hw in db_hotwords}
                cached_words = {word: weight for word, weight in zip(
                    self.hotword_metadata[user_id]['words'],
                    self.hotword_metadata[user_id]['weights']
                )}
                
                # 如果数据一致，直接使用缓存的索引
                if db_words == cached_words:
                    logger.info(f"用户 {user_id} 的索引已是最新，无需重建")
                    return True
            
            # 获取用户的所有热词
            hotwords = db.query(models.Hotword).filter(
                models.Hotword.user_id == user_id
            ).all()
            
            if not hotwords:
                logger.info(f"用户 {user_id} 没有热词，跳过索引构建")
                # 清理可能存在的旧索引
                if user_id in self.hotword_embeddings:
                    del self.hotword_embeddings[user_id]
                if user_id in self.hotword_metadata:
                    del self.hotword_metadata[user_id]
                return True
            
            # 提取热词文本和权重
            hotword_texts = [hw.word for hw in hotwords]
            hotword_weights = [hw.weight for hw in hotwords]
            
            # 生成嵌入向量
            logger.info(f"正在为用户 {user_id} 生成 {len(hotword_texts)} 个热词的向量嵌入...")
            embeddings = self.model.encode(hotword_texts, normalize_embeddings=True)
            
            # 更新内存中的数据
            self.hotword_embeddings[user_id] = embeddings
            self.hotword_metadata[user_id] = {
                'words': hotword_texts,
                'weights': hotword_weights,
                'ids': [hw.id for hw in hotwords]
            }
            
            # 重建全局索引
            self._rebuild_global_index()
            
            # 保存到文件
            self.save_user_index(user_id)
            
            logger.info(f"为用户 {user_id} 构建了包含 {len(hotwords)} 个热词的索引")
            return True
            
        except Exception as e:
            logger.error(f"构建用户热词索引失败: {str(e)}")
            return False
    
    def predict_hotwords(self, text: str, user_id: str, top_k: int = 5, threshold: float = 0.5) -> List[Dict]:
        """根据输入文本预测相关热词"""
        if not self.initialized:
            logger.warning("RAG服务未初始化")
            return []
            
        if user_id not in self.hotword_metadata:
            logger.warning(f"用户 {user_id} 的热词索引不存在")
            return []
            
        try:
            # 对输入文本进行编码
            query_embedding = self.model.encode([text], normalize_embeddings=True)
            
            # 在FAISS索引中搜索
            similarities, indices = self.index.search(query_embedding, min(top_k, len(self.hotword_metadata[user_id]['words'])))
            
            # 构建结果
            predictions = []
            metadata = self.hotword_metadata[user_id]
            
            for i, (similarity, idx) in enumerate(zip(similarities[0], indices[0])):
                if similarity >= threshold:  # 只返回相似度超过阈值的结果
                    predictions.append({
                        'word': metadata['words'][idx],
                        'weight': metadata['weights'][idx],
                        'similarity': float(similarity),
                        'rank': i + 1
                    })
            
            # 按权重和相似度排序
            predictions.sort(key=lambda x: (x['weight'] * x['similarity']), reverse=True)
            
            return predictions[:top_k]
            
        except Exception as e:
            logger.error(f"热词预测失败: {str(e)}")
            return []
    
    def enhance_transcription_with_hotwords(self, transcription_text: str, user_id: str) -> Dict:
        """使用热词增强转写结果"""
        if not transcription_text:
            return {
                'enhanced_text': transcription_text,
                'hotwords_detected': [],
                'confidence_boost': 1.0
            }
        
        try:
            # 预测相关热词
            predicted_hotwords = self.predict_hotwords(transcription_text, user_id, top_k=10, threshold=0.3)
            
            enhanced_text = transcription_text
            detected_hotwords = []
            confidence_boost = 1.0
            
            # 检查是否有热词在转写文本中
            for hotword_info in predicted_hotwords:
                word = hotword_info['word']
                if word.lower() in transcription_text.lower():
                    detected_hotwords.append(hotword_info)
                    # 根据热词权重提升置信度
                    confidence_boost += (hotword_info['weight'] / 10) * 0.1
            
            # 应用简单的热词替换增强（在实际应用中可能更复杂）
            for hotword_info in detected_hotwords:
                word = hotword_info['word']
                # 确保正确的大小写
                enhanced_text = enhanced_text.replace(word.lower(), word)
                enhanced_text = enhanced_text.replace(word.upper(), word)
            
            return {
                'enhanced_text': enhanced_text,
                'hotwords_detected': detected_hotwords,
                'confidence_boost': min(confidence_boost, 2.0),  # 最大提升2倍
                'predicted_hotwords': predicted_hotwords[:5]  # 返回前5个预测热词
            }
            
        except Exception as e:
            logger.error(f"转写增强失败: {str(e)}")
            return {
                'enhanced_text': transcription_text,
                'hotwords_detected': [],
                'confidence_boost': 1.0
            }
    
    def get_hotword_suggestions(self, partial_text: str, user_id: str, max_suggestions: int = 5) -> List[str]:
        """根据部分输入文本获取热词建议"""
        if not partial_text or len(partial_text) < 2:
            return []
            
        if user_id not in self.hotword_metadata:
            return []
            
        try:
            # 预测相关热词
            predictions = self.predict_hotwords(partial_text, user_id, top_k=max_suggestions * 2, threshold=0.2)
            
            # 过滤出以部分文本开头的热词或相似的热词
            suggestions = []
            metadata = self.hotword_metadata[user_id]
            
            # 首先添加前缀匹配的热词
            for word in metadata['words']:
                if word.lower().startswith(partial_text.lower()) and len(suggestions) < max_suggestions:
                    suggestions.append(word)
            
            # 然后添加语义相似的热词
            for pred in predictions:
                if pred['word'] not in suggestions and len(suggestions) < max_suggestions:
                    suggestions.append(pred['word'])
            
            return suggestions[:max_suggestions]
            
        except Exception as e:
            logger.error(f"获取热词建议失败: {str(e)}")
            return []
    
    def clear_user_index(self, user_id: str) -> bool:
        """清除用户索引"""
        try:
            # 从内存中删除
            if user_id in self.hotword_embeddings:
                del self.hotword_embeddings[user_id]
            if user_id in self.hotword_metadata:
                del self.hotword_metadata[user_id]
                
            # 删除文件
            index_file = os.path.join(self.index_dir, f"user_{user_id}.index")
            metadata_file = os.path.join(self.index_dir, f"user_{user_id}.metadata")
            
            for file_path in [index_file, metadata_file]:
                if os.path.exists(file_path):
                    os.remove(file_path)
                    
            # 重建全局索引
            self._rebuild_global_index()
            
            logger.info(f"用户 {user_id} 的索引已清除")
            return True
            
        except Exception as e:
            logger.error(f"清除用户索引失败: {str(e)}")
            return False
    
    def get_service_stats(self) -> Dict:
        """获取RAG服务统计信息"""
        try:
            total_users = len(self.hotword_metadata)
            total_hotwords = sum(len(meta.get('words', [])) for meta in self.hotword_metadata.values())
            
            return {
                'initialized': self.initialized,
                'model_name': settings.RAG_MODEL_NAME if self.initialized else None,
                'dimension': self.dimension if self.initialized else 0,
                'total_users_indexed': total_users,
                'total_hotwords': total_hotwords,
                'index_dir': self.index_dir,
                'memory_usage_mb': self._estimate_memory_usage()
            }
            
        except Exception as e:
            logger.error(f"获取服务统计失败: {str(e)}")
            return {'error': str(e)}
    
    def _estimate_memory_usage(self) -> float:
        """估算内存使用量（MB）"""
        try:
            total_size = 0
            
            # 估算嵌入向量的大小
            for embeddings in self.hotword_embeddings.values():
                if embeddings is not None:
                    total_size += embeddings.nbytes
                    
            # 估算元数据的大小
            for metadata in self.hotword_metadata.values():
                total_size += len(str(metadata).encode('utf-8'))
                
            return total_size / (1024 * 1024)  # 转换为MB
            
        except Exception as e:
            logger.error(f"估算内存使用量失败: {str(e)}")
            return 0.0

# 全局RAG服务实例
rag_service = RAGService()

def get_rag_service() -> RAGService:
    """获取RAG服务实例"""
    return rag_service
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/main.py
```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
# 1. 导入我们所有需要的路由模块
from .routers import transcription, auth, realtime_websocket, polling_ws_realtime
from .models import Base, engine
from .config import get_settings

# 初始化数据库
Base.metadata.create_all(bind=engine)

app = FastAPI(title="语音识别系统API")
settings = get_settings()

# CORS中间件配置
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # 允许所有源，用于开发环境
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# 文件路径: asr_system_backend/app/main.py
# ...
# 包含路由
app.include_router(auth.router, tags=["认证"])
app.include_router(transcription.router, tags=["转写"]) 
# 确保这一行是存在的
app.include_router(realtime_websocket.router, tags=["实时转写"])
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/database.py
```python
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, declarative_base

# 将变量名改为DATABASE_URL
DATABASE_URL = "sqlite:///./asr_system.db"

engine = create_engine(
    DATABASE_URL,  # 使用新变量名
    connect_args={"check_same_thread": False}
)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

Base = declarative_base()

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/transcription.py
```python
from fastapi import APIRouter, UploadFile, File, HTTPException
import os
import subprocess
import logging

# 配置日志
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

router = APIRouter(
    prefix="/api/asr",
    tags=["transcription"]
)

@router.post("/transcribe/file")
async def transcribe_file(file: UploadFile = File(...)):
    """
    上传音频文件并返回转写结果
    """
    try:
        # 获取项目根目录
        current_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        root_dir = os.path.dirname(current_dir)  # 回到asr-system目录
        
        logger.info(f"Processing file: {file.filename}")
        
        # 临时文件路径
        file_path = os.path.join(root_dir, "client", f"temp_{file.filename}")
        temp_script = os.path.join(root_dir, "client", "temp_test.sh")
        
        # 保存上传的文件
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        logger.info(f"Saved file to: {file_path}")
        
        # 修改test_demo.sh中的音频文件路径
        demo_script = os.path.join(root_dir, "client", "test_demo.sh")
        with open(demo_script, "r") as f:
            script_content = f.read()
        
        # 替换音频文件路径
        script_content = script_content.replace("BAC009S0764W0179.wav", f"temp_{file.filename}")
        
        # 保存临时脚本
        with open(temp_script, "w") as f:
            f.write(script_content)
        
        # 设置脚本可执行权限
        os.chmod(temp_script, 0o755)
        logger.info("Created and configured temporary script")
        
        # 执行脚本
        os.chdir(root_dir)  # 切换到项目根目录
        logger.info(f"Executing script from directory: {root_dir}")
        result = subprocess.run([f"./client/temp_test.sh"], shell=True, capture_output=True, text=True)
        output = result.stdout + result.stderr
        logger.info("Script execution completed")
        
        # 解析结果
        transcription = ""
        for line in output.split("\n"):
            if "pid0_0: demo:" in line:
                transcription = line.split("pid0_0: demo:")[-1].strip()
                logger.info(f"Found transcription: {transcription}")
                break
        
        if not transcription:
            logger.warning("No transcription found in output")
            logger.debug(f"Full output: {output}")
            
        return {
            "result": transcription
        }
        
    except Exception as e:
        logger.error(f"Error processing file: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
        
    finally:
        # 清理临时文件
        if os.path.exists(file_path):
            os.remove(file_path)
        if os.path.exists(temp_script):
            os.remove(temp_script)
        logger.info("Cleaned up temporary files")
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/chat.py
```python
# 文件: asr_system_backend/app/routers/chat.py

import logging
from fastapi import APIRouter, HTTPException, status, Depends
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import dashscope
from ..config import get_settings

# 配置日志和路由
logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/chat", tags=["Chat"])
settings = get_settings()

# 定义请求体模型
class ChatRequest(BaseModel):
    prompt: str

# 定义一个异步生成器，用于流式传输数据
async def stream_generator(prompt: str):
    """
    调用DeepSeek API并以流式方式返回结果
    """
    # 从配置中获取API Key
    api_key = settings.DASHSCOPE_API_KEY
    if not api_key:
        logger.error("DashScope API Key 未配置")
        # 直接在流中返回错误信息
        yield "Error: Server's API Key is not configured."
        return

    dashscope.api_key = api_key

    try:
        # 调用DeepSeek模型的流式生成接口
        responses = dashscope.Generation.call(
            model='deepseek-v2-chat',
            prompt=prompt,
            stream=True,
            incremental_output=True # 增量输出，实现打字机效果
        )

        for resp in responses:
            if resp.status_code == 200:
                content = resp.output.choices[0]['message']['content']
                yield content # 将每个增量内容块发送给前端
            else:
                error_msg = f"Error: code: {resp.status_code}, message: {resp.message}"
                logger.error(error_msg)
                yield error_msg
                break
    except Exception as e:
        logger.error(f"调用DashScope API时出错: {e}")
        yield f"Error: An exception occurred while calling the AI service."

# 定义流式API端点
@router.post("/stream")
async def stream_chat(request: ChatRequest):
    """
    接收前端的Prompt，并以流式方式返回DeepSeek模型的响应
    """
    if not request.prompt:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Prompt不能为空"
        )
    
    return StreamingResponse(stream_generator(request.prompt), media_type="text/event-stream")
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/hotword.py
```python
from fastapi import APIRouter, Depends, HTTPException, status, UploadFile, File, Form
from sqlalchemy.orm import Session
from typing import List
from .. import schemas, models
from ..database import get_db
from .auth import get_current_user
from ..rag_service import get_rag_service
import csv
from io import StringIO

router = APIRouter(
    prefix="/hotwords",
    tags=["hotwords"]
)

@router.post("", response_model=schemas.HotwordOut)
def create_hotword(
    hotword_in: schemas.HotwordCreate,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    创建新的热词
    """
    # 查询用户当前的热词数量，检查是否达到上限（假设上限为100）
    count = db.query(models.Hotword).filter(models.Hotword.user_id == current_user.id).count()
    if count >= 100:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="热词数量已达上限（100个）"
        )
    
    # 检查是否已存在相同的热词
    existing = db.query(models.Hotword).filter(
        models.Hotword.user_id == current_user.id,
        models.Hotword.word == hotword_in.word
    ).first()
    
    if existing:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail="热词已存在"
        )
    
    # 创建新热词
    db_hotword = models.Hotword(
        user_id=current_user.id,
        word=hotword_in.word,
        weight=hotword_in.weight
    )
    db.add(db_hotword)
    db.commit()
    db.refresh(db_hotword)
    
    # 重建用户的RAG索引
    try:
        rag_service = get_rag_service()
        if rag_service.initialized:
            rag_service.build_user_hotword_index(db, current_user.id)
    except Exception as e:
        print(f"重建RAG索引失败: {str(e)}")
    
    return db_hotword

@router.get("", response_model=List[schemas.HotwordOut])
def get_user_hotwords(
    skip: int = 0,
    limit: int = 100,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    获取用户的热词列表
    """
    hotwords = db.query(models.Hotword).filter(
        models.Hotword.user_id == current_user.id
    ).offset(skip).limit(limit).all()
    
    return hotwords

@router.put("/{hotword_id}", response_model=schemas.HotwordOut)
def update_hotword(
    hotword_id: str,
    hotword_in: schemas.HotwordUpdate,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    更新热词
    """
    # 查找热词
    hotword = db.query(models.Hotword).filter(models.Hotword.id == hotword_id).first()
    
    # 处理错误情况
    if not hotword:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="热词不存在"
        )
    
    # 确认权限
    if hotword.user_id != current_user.id:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="无权修改此热词"
        )
    
    # 如果要更改词本身，检查是否会导致重复
    if hotword_in.word is not None and hotword_in.word != hotword.word:
        existing = db.query(models.Hotword).filter(
            models.Hotword.user_id == current_user.id,
            models.Hotword.word == hotword_in.word
        ).first()
        if existing:
            raise HTTPException(
                status_code=status.HTTP_409_CONFLICT,
                detail="热词已存在"
            )
        hotword.word = hotword_in.word
    
    # 更新权重
    if hotword_in.weight is not None:
        hotword.weight = hotword_in.weight
    
    db.commit()
    db.refresh(hotword)
    
    # 重建用户的RAG索引
    try:
        rag_service = get_rag_service()
        if rag_service.initialized:
            rag_service.build_user_hotword_index(db, current_user.id)
    except Exception as e:
        print(f"重建RAG索引失败: {str(e)}")
    
    return hotword

@router.delete("/{hotword_id}")
def delete_hotword(
    hotword_id: str,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    删除热词
    """
    # 查找热词
    hotword = db.query(models.Hotword).filter(models.Hotword.id == hotword_id).first()
    
    # 处理错误情况
    if not hotword:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="热词不存在"
        )
    
    # 确认权限
    if hotword.user_id != current_user.id:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="无权删除此热词"
        )
    
    # 删除热词
    db.delete(hotword)
    db.commit()
    
    # 重建用户的RAG索引
    try:
        rag_service = get_rag_service()
        if rag_service.initialized:
            rag_service.build_user_hotword_index(db, current_user.id)
    except Exception as e:
        print(f"重建RAG索引失败: {str(e)}")
    
    return {"message": "热词已成功删除"}

@router.post("/import", response_model=dict)
async def bulk_import_hotwords(
    file: UploadFile = File(...),
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    批量导入热词
    """
    # 文件类型验证
    if not file.filename.endswith(('.csv', '.txt')):
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail="只支持CSV或TXT格式文件"
        )
    
    # 读取并解析文件
    content = await file.read()
    
    # 尝试解析CSV
    added_count = 0
    skipped_count = 0
    
    try:
        text = content.decode('utf-8')
        csv_reader = csv.reader(StringIO(text))
        
        # 查询用户当前热词数量
        current_count = db.query(models.Hotword).filter(models.Hotword.user_id == current_user.id).count()
        max_allowed = 100
        remaining = max_allowed - current_count
        
        if remaining <= 0:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="热词数量已达上限（100个）"
            )
        
        # 开始导入
        for row in csv_reader:
            # 检查是否已达到上限
            if added_count >= remaining:
                break
                
            # 跳过空行或格式错误行
            if not row:
                continue
            
            word = row[0].strip()
            if not word:
                continue
                
            # 尝试获取权重
            weight = 5  # 默认权重
            if len(row) > 1:
                try:
                    w = int(row[1].strip())
                    if 1 <= w <= 10:
                        weight = w
                except ValueError:
                    pass
            
            # 检查是否已存在
            existing = db.query(models.Hotword).filter(
                models.Hotword.user_id == current_user.id,
                models.Hotword.word == word
            ).first()
            
            if existing:
                skipped_count += 1
                continue
            
            # 创建新热词
            db_hotword = models.Hotword(
                user_id=current_user.id,
                word=word,
                weight=weight
            )
            db.add(db_hotword)
            added_count += 1
        
        # 提交事务
        db.commit()
        
        # 重建用户的RAG索引
        try:
            rag_service = get_rag_service()
            if rag_service.initialized:
                rag_service.build_user_hotword_index(db, current_user.id)
        except Exception as e:
            print(f"重建RAG索引失败: {str(e)}")
        
        return {
            "added_count": added_count,
            "skipped_count": skipped_count
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail=f"文件解析错误: {str(e)}"
        )
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/polling_ws_realtime.py
```python
# 文件路径: asr_system_backend/app/routers/polling_ws_realtime.py
# 功能: 为新的“轮询式WebSocket”实时转写功能提供后端服务。

import asyncio
import logging
import os
import subprocess
import uuid
from fastapi import APIRouter, WebSocket, WebSocketDisconnect, Depends, Query
from sqlalchemy.orm import Session

from ..database import get_db
from ..models import User
from ..auth_service import decode_access_token

# --- 日志和路由配置 ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
# 创建一个全新的路由器实例
router = APIRouter()

# --- 新的、独立的连接管理器 ---
class PollingConnectionManager:
    """为新功能创建一个独立的连接管理器，避免与现有功能混淆。"""
    def __init__(self):
        self.active_connections: dict[str, WebSocket] = {}

    async def connect(self, websocket: WebSocket, client_id: str):
        await websocket.accept()
        self.active_connections[client_id] = websocket
        logger.info(f"[Polling WS] 客户端 {client_id} 已连接。")

    def disconnect(self, client_id: str):
        if client_id in self.active_connections:
            del self.active_connections[client_id]
            logger.info(f"[Polling WS] 客户端 {client_id} 已断开。")

    async def send_json(self, client_id: str, data: dict):
        if client_id in self.active_connections:
            await self.active_connections[client_id].send_json(data)

polling_manager = PollingConnectionManager()


# --- WebSocket认证 (可复用，但为清晰起见，我们放在这里) ---
async def get_current_user_from_polling_ws(token: str = Query(...), db: Session = Depends(get_db)):
    try:
        payload = decode_access_token(token)
        username: str = payload.get("sub")
        if not username: return None
        user = db.query(User).filter(User.username == username).first()
        return user
    except Exception:
        return None


# --- 音频处理核心函数 (与上次提供的逻辑相同) ---
async def process_polling_chunk(client_id: str, audio_data: bytes):
    temp_id = str(uuid.uuid4())
    webm_path = f"/tmp/{temp_id}.webm"
    wav_path = f"/tmp/{temp_id}.wav"
    
    try:
        with open(webm_path, "wb") as f:
            f.write(audio_data)

        command = f"ffmpeg -i {webm_path} -ar 16000 -ac 1 -y {wav_path}"
        process = await asyncio.create_subprocess_shell(command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
        _, stderr = await process.communicate()

        if process.returncode != 0:
            logger.error(f"[Polling WS] FFmpeg转换失败: {stderr.decode()}")
            await polling_manager.send_json(client_id, {"type": "error", "message": "音频格式处理失败"})
            return

        root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..'))
        client_script_path = os.path.join(root_dir, "client", "funasr_wss_client.py")
        
        transcribe_command = ["python", client_script_path, "--host", "127.0.0.1", "--port", "10095", "--mode", "offline", "--audio_in", wav_path]
        
        transcribe_process = await asyncio.create_subprocess_exec(*transcribe_command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
        transcribe_stdout, transcribe_stderr = await transcribe_process.communicate()
        output = transcribe_stdout.decode() + transcribe_stderr.decode()
        
        transcription = ""
        for line in output.split("\n"):
            if "pid0_0: demo:" in line:
                transcription = line.split("pid0_0: demo:")[-1].strip()
                break
        
        logger.info(f"[Polling WS] 客户端 {client_id} 的转写结果: '{transcription}'")

        if transcription:
            await polling_manager.send_json(client_id, {
                "type": "polling_transcription_result", # 使用新的类型以区分
                "text": transcription
            })

    except Exception as e:
        logger.error(f"[Polling WS] 处理音频块时出错: {e}")
        await polling_manager.send_json(client_id, {"type": "error", "message": "服务器处理音频时出错"})
    finally:
        if os.path.exists(webm_path): os.remove(webm_path)
        if os.path.exists(wav_path): os.remove(wav_path)


# --- 新的WebSocket端点定义 ---
@router.websocket("/ws/asr/transcribe/polling_realtime") # <--- 注意，这是全新的URL
async def websocket_polling_endpoint(
    websocket: WebSocket,
    token: str = Query(...),
    db: Session = Depends(get_db)
):
    user = await get_current_user_from_polling_ws(token, db)
    if not user:
        await websocket.close(code=1008, reason="认证失败")
        return

    client_id = str(uuid.uuid4())
    await polling_manager.connect(websocket, client_id)
    
    try:
        await polling_manager.send_json(client_id, {"type": "polling_connection_established"})
        
        while True:
            audio_data = await websocket.receive_bytes()
            asyncio.create_task(process_polling_chunk(client_id, audio_data))

    except WebSocketDisconnect:
        polling_manager.disconnect(client_id)
    except Exception as e:
        logger.error(f"[Polling WS] 连接 ({client_id}) 出现意外错误: {e}")
        polling_manager.disconnect(client_id)
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/auth.py
```python
from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm
from sqlalchemy.orm import Session
from ..models import SessionLocal, User
from ..auth_service import verify_password, get_password_hash, create_access_token, decode_access_token
from ..config import get_settings

router = APIRouter(prefix="/auth", tags=["认证"])
settings = get_settings()

oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/auth/token")

# 依赖项：获取数据库会话
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

@router.post("/register")
def register(form_data: OAuth2PasswordRequestForm = Depends(), db: Session = Depends(get_db)):
    # 检查用户是否已存在
    db_user = db.query(User).filter(User.username == form_data.username).first()
    if db_user:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="用户名已存在"
        )
    
    # 创建新用户
    hashed_password = get_password_hash(form_data.password)
    db_user = User(username=form_data.username, hashed_password=hashed_password)
    db.add(db_user)
    db.commit()
    db.refresh(db_user)
    
    # 生成访问令牌
    access_token = create_access_token(
        data={"sub": db_user.username}
    )
    return {"access_token": access_token, "token_type": "bearer"}

@router.post("/token")
def login(form_data: OAuth2PasswordRequestForm = Depends(), db: Session = Depends(get_db)):
    # 验证用户
    user = db.query(User).filter(User.username == form_data.username).first()
    if not user or not verify_password(form_data.password, user.hashed_password):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="用户名或密码错误",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    # 生成访问令牌
    access_token = create_access_token(
        data={"sub": user.username}
    )
    return {"access_token": access_token, "token_type": "bearer"}

# 获取当前用户
async def get_current_user(token: str = Depends(oauth2_scheme), db: Session = Depends(get_db)):
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="无效的认证凭证",
        headers={"WWW-Authenticate": "Bearer"},
    )
    try:
        payload = decode_access_token(token)
        username: str = payload.get("sub")
        if username is None:
            raise credentials_exception
    except:
        raise credentials_exception
    
    user = db.query(User).filter(User.username == username).first()
    if user is None:
        raise credentials_exception
    return user

@router.get("/me")
async def read_users_me(current_user: User = Depends(get_current_user)):
    return {
        "username": current_user.username,
        "created_at": current_user.created_at.isoformat()
    }
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/rag.py
```python
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List, Dict, Optional, Any
from pydantic import BaseModel, Field
from .. import models
from ..database import get_db
from .auth import get_current_user
from ..rag_service import get_rag_service
import logging
import json
import os

logger = logging.getLogger(__name__)
router = APIRouter(
    prefix="/rag",
    tags=["rag"]
)

# Pydantic模型定义
class VectorSearchRequest(BaseModel):
    query: str = Field(..., description="搜索查询文本")
    top_k: int = Field(5, ge=1, le=50, description="返回结果数量")
    threshold: float = Field(0.3, ge=0.0, le=1.0, description="相似度阈值")

class VectorSearchResult(BaseModel):
    word: str
    weight: int
    similarity: float
    rank: int

class VectorSearchResponse(BaseModel):
    query: str
    results: List[VectorSearchResult]
    total_found: int
    processing_time_ms: float

class IndexStatsResponse(BaseModel):
    user_id: str
    total_hotwords: int
    index_dimension: int
    is_initialized: bool
    last_updated: Optional[str] = None

class BulkAddRequest(BaseModel):
    words: List[Dict[str, Any]] = Field(..., description="热词列表，格式：[{'word': 'xxx', 'weight': 5}]")

class IndexManagementResponse(BaseModel):
    success: bool
    message: str
    details: Optional[Dict] = None

@router.get("/health", summary="RAG服务健康检查")
def health_check():
    """RAG服务健康检查"""
    rag_service = get_rag_service()
    return {
        "status": "healthy" if rag_service.initialized else "initializing",
        "service": "RAG Vector Search Engine",
        "version": "1.0.0",
        "initialized": rag_service.initialized
    }

@router.post("/search", response_model=VectorSearchResponse, summary="向量相似度搜索")
def vector_search(
    request: VectorSearchRequest,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    基于向量相似度的热词搜索
    
    使用FAISS进行高效的向量检索，支持语义相似度匹配
    """
    import time
    start_time = time.time()
    
    try:
        rag_service = get_rag_service()
        
        # 确保RAG服务已初始化
        if not rag_service.initialized:
            rag_service.initialize()
            
        # 确保用户索引已构建
        if current_user.id not in rag_service.hotword_metadata:
            rag_service.build_user_hotword_index(db, current_user.id)
        
        # 执行向量搜索
        predictions = rag_service.predict_hotwords(
            request.query, 
            current_user.id, 
            top_k=request.top_k, 
            threshold=request.threshold
        )
        
        # 构建响应
        results = [
            VectorSearchResult(
                word=pred["word"],
                weight=pred["weight"],
                similarity=pred["similarity"],
                rank=pred["rank"]
            )
            for pred in predictions
        ]
        
        processing_time = (time.time() - start_time) * 1000
        
        return VectorSearchResponse(
            query=request.query,
            results=results,
            total_found=len(results),
            processing_time_ms=round(processing_time, 2)
        )
        
    except Exception as e:
        logger.error(f"向量搜索失败: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"搜索失败: {str(e)}"
        )

@router.get("/index/stats", response_model=IndexStatsResponse, summary="获取索引统计信息")
def get_index_stats(
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """获取用户热词索引的统计信息"""
    try:
        rag_service = get_rag_service()
        
        # 获取用户热词数量
        hotword_count = db.query(models.Hotword).filter(
            models.Hotword.user_id == current_user.id
        ).count()
        
        # 检查索引状态
        has_index = current_user.id in rag_service.hotword_metadata
        
        return IndexStatsResponse(
            user_id=current_user.id,
            total_hotwords=hotword_count,
            index_dimension=rag_service.dimension if rag_service.initialized else 0,
            is_initialized=rag_service.initialized and has_index,
            last_updated=None  # TODO: 可以添加时间戳跟踪
        )
        
    except Exception as e:
        logger.error(f"获取索引统计失败: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"获取统计信息失败: {str(e)}"
        )

@router.post("/index/rebuild", response_model=IndexManagementResponse, summary="重建用户索引")
def rebuild_index(
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """重建用户的热词向量索引"""
    try:
        rag_service = get_rag_service()
        
        # 确保RAG服务已初始化
        if not rag_service.initialized:
            rag_service.initialize()
            
        # 重建索引
        success = rag_service.build_user_hotword_index(db, current_user.id)
        
        if success:
            hotword_count = len(rag_service.hotword_metadata.get(current_user.id, {}).get('words', []))
            return IndexManagementResponse(
                success=True,
                message=f"索引重建成功，包含 {hotword_count} 个热词",
                details={
                    "user_id": current_user.id,
                    "hotword_count": hotword_count,
                    "dimension": rag_service.dimension
                }
            )
        else:
            return IndexManagementResponse(
                success=False,
                message="索引重建失败"
            )
            
    except Exception as e:
        logger.error(f"重建索引失败: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"重建索引失败: {str(e)}"
        )

@router.post("/index/bulk-add", response_model=IndexManagementResponse, summary="批量添加热词到索引")
def bulk_add_to_index(
    request: BulkAddRequest,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    批量添加热词到向量索引
    
    这是一个高级功能，允许直接向索引添加词条而不通过常规的热词管理API
    """
    try:
        rag_service = get_rag_service()
        
        # 确保RAG服务已初始化
        if not rag_service.initialized:
            rag_service.initialize()
            
        added_count = 0
        skipped_count = 0
        
        for word_data in request.words:
            word = word_data.get("word", "").strip()
            weight = word_data.get("weight", 5)
            
            if not word:
                skipped_count += 1
                continue
                
            # 检查是否已存在
            existing = db.query(models.Hotword).filter(
                models.Hotword.user_id == current_user.id,
                models.Hotword.word == word
            ).first()
            
            if existing:
                skipped_count += 1
                continue
                
            # 添加到数据库
            db_hotword = models.Hotword(
                user_id=current_user.id,
                word=word,
                weight=weight
            )
            db.add(db_hotword)
            added_count += 1
            
        # 提交数据库更改
        db.commit()
        
        # 重建索引
        if added_count > 0:
            rag_service.build_user_hotword_index(db, current_user.id)
            
        return IndexManagementResponse(
            success=True,
            message=f"批量添加完成：新增 {added_count} 个，跳过 {skipped_count} 个",
            details={
                "added": added_count,
                "skipped": skipped_count,
                "total_processed": len(request.words)
            }
        )
        
    except Exception as e:
        logger.error(f"批量添加失败: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"批量添加失败: {str(e)}"
        )

@router.get("/suggestions", summary="获取热词建议")
def get_suggestions(
    partial_text: str,
    max_suggestions: int = 5,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    根据部分输入文本获取热词建议
    
    结合前缀匹配和语义相似度，提供智能的热词补全建议
    """
    try:
        rag_service = get_rag_service()
        
        # 确保RAG服务已初始化
        if not rag_service.initialized:
            rag_service.initialize()
            
        # 确保用户索引已构建
        if current_user.id not in rag_service.hotword_metadata:
            rag_service.build_user_hotword_index(db, current_user.id)
            
        # 获取建议
        suggestions = rag_service.get_hotword_suggestions(
            partial_text, 
            current_user.id, 
            max_suggestions
        )
        
        return {
            "partial_text": partial_text,
            "suggestions": suggestions,
            "count": len(suggestions)
        }
        
    except Exception as e:
        logger.error(f"获取建议失败: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"获取建议失败: {str(e)}"
        )

@router.get("/model/info", summary="获取模型信息")
def get_model_info():
    """获取当前使用的向量化模型信息"""
    try:
        rag_service = get_rag_service()
        
        if not rag_service.initialized:
            return {
                "status": "not_initialized",
                "message": "RAG服务未初始化"
            }
            
        model_info = {
            "model_name": "sentence-transformers/all-MiniLM-L6-v2",
            "dimension": rag_service.dimension,
            "max_sequence_length": 256,  # 模型的最大序列长度
            "languages": ["zh", "en", "multilingual"],
            "description": "轻量级多语言句子嵌入模型，适合中英文混合场景",
            "performance": {
                "embedding_speed": "~1000 sentences/sec (CPU)",
                "model_size": "~90MB",
                "accuracy": "适中，平衡速度与准确性"
            }
        }
        
        return model_info
        
    except Exception as e:
        logger.error(f"获取模型信息失败: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"获取模型信息失败: {str(e)}"
        )
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/realtime_websocket.py
```python
# 文件路径: asr_system_backend/app/routers/realtime_websocket.py
# 功能: 接收前端通过WebSocket发送的实时音频流，拼接处理后返回转写结果。

import asyncio
import logging
import os
import subprocess
import uuid
from datetime import datetime, timedelta
from fastapi import APIRouter, WebSocket, WebSocketDisconnect, Depends, Query
from sqlalchemy.orm import Session

from ..database import get_db
from ..models import User
from ..auth_service import decode_access_token

# --- 日志和路由配置 ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
router = APIRouter()

# --- 存储每个连接的音频缓冲区和状态 ---
# 使用字典来管理多个并发连接，key是唯一的client_id
client_buffers: dict[str, bytearray] = {}
client_last_processed_time: dict[str, datetime] = {}
PROCESSING_INTERVAL_SECONDS = 5 # 每隔5秒处理一次累积的音频

# --- WebSocket连接管理器 ---
class ConnectionManager:
    def __init__(self):
        self.active_connections: dict[str, WebSocket] = {}

    async def connect(self, websocket: WebSocket, client_id: str):
        await websocket.accept()
        self.active_connections[client_id] = websocket
        # 初始化该连接的缓冲区和时间戳
        client_buffers[client_id] = bytearray()
        client_last_processed_time[client_id] = datetime.now()
        logger.info(f"客户端 {client_id} 已连接，并已创建音频缓冲区。")

    def disconnect(self, client_id: str):
        # 清理资源
        if client_id in self.active_connections:
            del self.active_connections[client_id]
        if client_id in client_buffers:
            del client_buffers[client_id]
        if client_id in client_last_processed_time:
            del client_last_processed_time[client_id]
        logger.info(f"客户端 {client_id} 已断开，相关资源已清理。")

    async def send_json(self, client_id: str, data: dict):
        if client_id in self.active_connections:
            await self.active_connections[client_id].send_json(data)

manager = ConnectionManager()

# --- WebSocket认证 ---
async def get_current_user_from_ws_token(token: str, db: Session):
    try:
        payload = decode_access_token(token)
        username: str = payload.get("sub")
        if not username: return None
        return db.query(User).filter(User.username == username).first()
    except Exception:
        return None

# --- 音频处理核心函数 ---
async def process_accumulated_audio(client_id: str):
    """
    处理指定客户端累积的音频数据。
    这个函数会被定时调用或者在接收到新数据时触发检查。
    """
    # 检查缓冲区中是否有数据
    if client_id not in client_buffers or len(client_buffers[client_id]) == 0:
        return

    # 复制缓冲区内容进行处理，并清空原缓冲区
    audio_data_to_process = client_buffers[client_id]
    client_buffers[client_id] = bytearray()
    
    # 更新处理时间戳
    client_last_processed_time[client_id] = datetime.now()
    
    logger.info(f"开始处理客户端 {client_id} 的 {len(audio_data_to_process)} 字节音频数据。")

    # 后续逻辑与之前的实现完全一致：保存、转换、调用脚本、返回结果、清理
    temp_id = str(uuid.uuid4())
    webm_path = f"/tmp/{temp_id}.webm"
    wav_path = f"/tmp/{temp_id}.wav"
    
    try:
        with open(webm_path, "wb") as f:
            f.write(audio_data_to_process)

        command = f"ffmpeg -i {webm_path} -ar 16000 -ac 1 -y {wav_path}"
        process = await asyncio.create_subprocess_shell(command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
        _, stderr = await process.communicate()

        if process.returncode != 0:
            error_message = f"FFmpeg转换失败: {stderr.decode()}"
            logger.error(error_message)
            await manager.send_json(client_id, {"type": "error", "message": "音频格式处理失败"})
            return

        root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..'))
        client_script_path = os.path.join(root_dir, "client", "funasr_wss_client.py")
        
        transcribe_command = ["python", client_script_path, "--host", "127.0.0.1", "--port", "10095", "--mode", "offline", "--audio_in", wav_path]
        
        transcribe_process = await asyncio.create_subprocess_exec(*transcribe_command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
        transcribe_stdout, _ = await transcribe_process.communicate()
        output = transcribe_stdout.decode()
        
        transcription = ""
        for line in output.split("\n"):
            if "pid0_0: demo:" in line:
                transcription = line.split("pid0_0: demo:")[-1].strip()
                break
        
        logger.info(f"客户端 {client_id} 的转写结果: '{transcription}'")

        if transcription:
            await manager.send_json(client_id, {
                "type": "transcription_result",
                "data": {
                    "text": transcription,
                    "confidence": 0.95,
                    "hotwords_detected": [],
                    "confidence_boost": 1.0,
                    "timestamp": datetime.now().isoformat()
                }
            })

    except Exception as e:
        logger.error(f"处理累积音频时出错: {e}")
        await manager.send_json(client_id, {"type": "error", "message": "服务器处理音频时出错"})
    finally:
        if os.path.exists(webm_path): os.remove(webm_path)
        if os.path.exists(wav_path): os.remove(wav_path)

# --- WebSocket端点定义 ---
@router.websocket("/ws/asr/transcribe/realtime")
async def websocket_endpoint(
    websocket: WebSocket,
    token: str = Query(...),
    db: Session = Depends(get_db)
):
    """
    处理实时语音转写的WebSocket端点。
    这个版本会累积音频数据，并按固定时间间隔进行处理。
    """
    user = await get_current_user_from_ws_token(token, db)
    if not user:
        await websocket.close(code=1008, reason="认证失败")
        return

    client_id = str(uuid.uuid4())
    await manager.connect(websocket, client_id)
    
    try:
        await manager.send_json(client_id, {"type": "connection_established", "user_id": user.username})
        await manager.send_json(client_id, {"type": "ready"})
        
        while True:
            # 1. 接收前端发送的一小块音频数据
            audio_data = await websocket.receive_bytes()
            
            # 2. 将接收到的数据追加到该客户端的缓冲区
            if client_id in client_buffers:
                client_buffers[client_id].extend(audio_data)

            # 3. 检查是否达到了处理时间
            now = datetime.now()
            last_processed = client_last_processed_time.get(client_id, now)
            
            if now - last_processed >= timedelta(seconds=PROCESSING_INTERVAL_SECONDS):
                # 如果距离上次处理已超过5秒，则立即处理累积的音频
                # 使用create_task使其在后台运行，不阻塞接收下一块数据
                asyncio.create_task(process_accumulated_audio(client_id))

    except WebSocketDisconnect:
        # 客户端断开连接时，处理最后剩余的音频数据
        logger.info(f"客户端 {client_id} 正在断开连接，处理剩余音频...")
        await process_accumulated_audio(client_id)
        manager.disconnect(client_id)
    except Exception as e:
        logger.error(f"WebSocket连接出现意外错误 ({client_id}): {e}")
        manager.disconnect(client_id)
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/__init__.py
```python

```

--------------------------------------------------------------------------------

File: asr_system_backend/app/routers/realtime.py
```python
import asyncio
import json
import logging
from typing import Dict, List
from fastapi import APIRouter, WebSocket, WebSocketDisconnect, Depends, HTTPException, Query
from fastapi.security import HTTPAuthorizationCredentials, HTTPBearer
from sqlalchemy.orm import Session
from .. import models
from ..database import get_db
from ..asr_engine import get_asr_engine
from ..rag_service import get_rag_service
from ..auth_service import decode_access_token
import numpy as np
import wave
import io
import tempfile
import os

logger = logging.getLogger(__name__)
router = APIRouter()

# 存储活动的WebSocket连接
active_connections: Dict[str, WebSocket] = {}

class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
        self.user_connections: Dict[str, str] = {}  # user_id -> connection_id
        
    async def connect(self, websocket: WebSocket, user_id: str, connection_id: str):
        """接受WebSocket连接"""
        await websocket.accept()
        self.active_connections[connection_id] = websocket
        self.user_connections[user_id] = connection_id
        logger.info(f"用户 {user_id} 建立WebSocket连接 {connection_id}")
        
    def disconnect(self, connection_id: str):
        """断开WebSocket连接"""
        if connection_id in self.active_connections:
            websocket = self.active_connections[connection_id]
            del self.active_connections[connection_id]
            
            # 移除用户连接映射
            for user_id, conn_id in list(self.user_connections.items()):
                if conn_id == connection_id:
                    del self.user_connections[user_id]
                    break
                    
            logger.info(f"WebSocket连接 {connection_id} 已断开")
            
    async def send_message(self, connection_id: str, message: dict):
        """发送消息到指定连接"""
        if connection_id in self.active_connections:
            websocket = self.active_connections[connection_id]
            try:
                await websocket.send_text(json.dumps(message))
            except Exception as e:
                logger.error(f"发送消息失败: {str(e)}")
                self.disconnect(connection_id)

manager = ConnectionManager()

async def get_current_user_ws(token: str, db: Session = Depends(get_db)):
    """WebSocket认证中间件"""
    try:
        # 解码JWT token
        payload = decode_access_token(token)
        user_id = payload.get("sub")
        
        if not user_id:
            raise HTTPException(status_code=401, detail="无效的token")
            
        # 从数据库获取用户信息
        user = db.query(models.User).filter(models.User.id == user_id).first()
        if not user:
            raise HTTPException(status_code=401, detail="用户不存在")
            
        return user
    except Exception as e:
        logger.error(f"WebSocket认证失败: {str(e)}")
        raise HTTPException(status_code=401, detail="认证失败")

@router.websocket("/ws/asr/transcribe/realtime")
async def websocket_realtime_transcribe(
    websocket: WebSocket,
    token: str = Query(...),
    db: Session = Depends(get_db)
):
    """实时语音转写WebSocket端点"""
    connection_id = f"conn_{hash(websocket)}"
    
    try:
        # 认证用户
        user = await get_current_user_ws(token, db)
        
        # 建立连接
        await manager.connect(websocket, user.id, connection_id)
        
        # 发送连接成功消息
        await manager.send_message(connection_id, {
            "type": "connection_established",
            "message": "WebSocket连接已建立",
            "user_id": user.id
        })
        
        # 初始化ASR引擎
        asr_engine = get_asr_engine()
        if not asr_engine.initialized:
            asr_engine.initialize()
            
        # 初始化RAG服务
        rag_service = get_rag_service()
        if not rag_service.initialized:
            rag_service.initialize()
            
        # 为用户构建热词索引
        rag_service.build_user_hotword_index(db, user.id)
        
        # 音频数据缓冲区
        audio_buffer = bytearray()
        sample_rate = 16000  # 默认采样率
        chunk_duration = 2.0  # 2秒一个处理块
        chunk_size = int(sample_rate * chunk_duration * 2)  # 16-bit PCM
        
        await manager.send_message(connection_id, {
            "type": "ready",
            "message": "实时转写服务已准备就绪",
            "config": {
                "sample_rate": sample_rate,
                "chunk_duration": chunk_duration,
                "supported_formats": ["PCM", "WAV"]
            }
        })
        
        while True:
            # 接收音频数据
            data = await websocket.receive()
            
            if data["type"] == "websocket.receive":
                if "bytes" in data:
                    # 处理二进制音频数据
                    audio_data = data["bytes"]
                    audio_buffer.extend(audio_data)
                    
                    # 当缓冲区积累足够数据时进行转写
                    if len(audio_buffer) >= chunk_size:
                        # 提取音频块
                        chunk_data = bytes(audio_buffer[:chunk_size])
                        audio_buffer = audio_buffer[chunk_size:]
                        
                        # 异步处理音频转写
                        asyncio.create_task(
                            process_audio_chunk(
                                chunk_data,
                                connection_id,
                                user.id,
                                asr_engine,
                                rag_service,
                                db,
                                sample_rate
                            )
                        )
                        
                elif "text" in data:
                    # 处理文本命令
                    try:
                        command = json.loads(data["text"])
                        await handle_command(command, connection_id, user.id, db)
                    except json.JSONDecodeError:
                        await manager.send_message(connection_id, {
                            "type": "error",
                            "message": "无效的JSON格式"
                        })
                        
    except WebSocketDisconnect:
        logger.info(f"WebSocket连接 {connection_id} 主动断开")
        manager.disconnect(connection_id)
    except Exception as e:
        logger.error(f"WebSocket错误: {str(e)}")
        await manager.send_message(connection_id, {
            "type": "error",
            "message": f"服务器内部错误: {str(e)}"
        })
        manager.disconnect(connection_id)

async def process_audio_chunk(
    audio_data: bytes,
    connection_id: str,
    user_id: str,
    asr_engine,
    rag_service,
    db: Session,
    sample_rate: int
):
    """处理音频块的异步任务"""
    try:
        # 将音频数据写入临时文件
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
            # 创建WAV文件头
            wav_buffer = io.BytesIO()
            with wave.open(wav_buffer, 'wb') as wav_file:
                wav_file.setnchannels(1)  # 单声道
                wav_file.setsampwidth(2)  # 16-bit
                wav_file.setframerate(sample_rate)
                wav_file.writeframes(audio_data)
            
            # 写入临时文件
            temp_file.write(wav_buffer.getvalue())
            temp_file_path = temp_file.name
            
        try:
            # 使用ASR引擎转写音频
            transcription_result = asr_engine.transcribe_audio(temp_file_path)
            
            # 提取转写文本
            transcription_text = transcription_result.get("text", "").strip()
            
            if transcription_text:
                # 使用RAG服务增强转写结果
                enhanced_result = rag_service.enhance_transcription_with_hotwords(
                    transcription_text, user_id
                )
                
                # 发送转写结果
                await manager.send_message(connection_id, {
                    "type": "transcription_result",
                    "data": {
                        "text": enhanced_result["enhanced_text"],
                        "original_text": transcription_text,
                        "confidence_boost": enhanced_result["confidence_boost"],
                        "hotwords_detected": enhanced_result["hotwords_detected"],
                        "predicted_hotwords": enhanced_result.get("predicted_hotwords", []),
                        "segments": transcription_result.get("segments", []),
                        "timestamp": transcription_result.get("processing_time")
                    }
                })
            else:
                # 发送静音检测结果
                await manager.send_message(connection_id, {
                    "type": "silence_detected",
                    "message": "检测到静音"
                })
                
        finally:
            # 清理临时文件
            if os.path.exists(temp_file_path):
                os.remove(temp_file_path)
                
    except Exception as e:
        logger.error(f"音频处理失败: {str(e)}")
        await manager.send_message(connection_id, {
            "type": "error",
            "message": f"音频处理失败: {str(e)}"
        })

async def handle_command(command: dict, connection_id: str, user_id: str, db: Session):
    """处理WebSocket命令"""
    try:
        command_type = command.get("type")
        
        if command_type == "ping":
            await manager.send_message(connection_id, {
                "type": "pong",
                "timestamp": command.get("timestamp")
            })
            
        elif command_type == "get_hotwords":
            # 获取用户热词列表
            hotwords = db.query(models.Hotword).filter(
                models.Hotword.user_id == user_id
            ).all()
            
            await manager.send_message(connection_id, {
                "type": "hotwords_list",
                "data": [
                    {
                        "id": hw.id,
                        "word": hw.word,
                        "weight": hw.weight
                    }
                    for hw in hotwords
                ]
            })
            
        elif command_type == "update_config":
            # 更新实时转写配置
            config = command.get("config", {})
            await manager.send_message(connection_id, {
                "type": "config_updated",
                "message": "配置已更新",
                "config": config
            })
            
        else:
            await manager.send_message(connection_id, {
                "type": "error",
                "message": f"未知命令类型: {command_type}"
            })
            
    except Exception as e:
        logger.error(f"命令处理失败: {str(e)}")
        await manager.send_message(connection_id, {
            "type": "error",
            "message": f"命令处理失败: {str(e)}"
        })
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/realtime_asr/funasr_client.py
```python
"""
FunASR 实时客户端
负责与 FunASR 服务器建立 WebSocket 连接并进行实时音频转写
"""

import json
import asyncio
import websockets
import logging
from typing import Optional, Dict, Any

logger = logging.getLogger(__name__)

class FunASRRealtimeClient:
    """FunASR 实时转写客户端"""
    
    def __init__(self, host: str = "127.0.0.1", port: int = 10095):
        """
        初始化 FunASR 实时客户端
        
        Args:
            host: FunASR 服务器地址
            port: FunASR 服务器端口
        """
        self.host = host
        self.port = port
        self.ws: Optional[websockets.WebSocketClientProtocol] = None
        self.is_connected = False
        self.task_id: Optional[str] = None
        
    async def connect(self) -> bool:
        """
        连接到 FunASR 服务器
        
        Returns:
            bool: 连接是否成功
        """
        try:
            ws_url = f"ws://{self.host}:{self.port}/ws/decode"
            self.ws = await websockets.connect(ws_url)
            self.is_connected = True
            
            # 发送启动命令
            start_command = {
                "mode": "online",
                "chunk_size": 3200,  # 200ms @ 16kHz
                "chunk_interval": 200,  # 每200ms发送一次
                "wav_format": True,  # 使用 WAV 格式
                "audio_fs": 16000,  # 采样率
                "audio_channels": 1,  # 单声道
                "audio_bits": 16,  # 16位
            }
            
            await self.ws.send(json.dumps(start_command))
            response = await self.ws.recv()
            response_data = json.loads(response)
            
            if response_data.get("status") == 0:
                self.task_id = response_data.get("task_id")
                logger.info(f"Connected to FunASR server, task_id: {self.task_id}")
                return True
            else:
                logger.error(f"Failed to start streaming: {response_data}")
                return False
                
        except Exception as e:
            logger.error(f"Failed to connect to FunASR server: {e}")
            self.is_connected = False
            return False
            
    async def send_audio(self, audio_chunk: bytes) -> Dict[str, Any]:
        """
        发送音频数据到 FunASR 服务器
        
        Args:
            audio_chunk: 音频数据块
            
        Returns:
            Dict[str, Any]: 识别结果
        """
        if not self.is_connected or not self.ws:
            raise ConnectionError("Not connected to FunASR server")
            
        try:
            # 发送音频数据
            await self.ws.send(audio_chunk)
            
            # 接收识别结果
            response = await self.ws.recv()
            result = json.loads(response)
            
            return {
                "text": result.get("text", ""),
                "is_final": result.get("is_final", False),
                "confidence": result.get("confidence", 0.0),
                "segments": result.get("segments", []),
                "status": result.get("status", -1)
            }
            
        except Exception as e:
            logger.error(f"Error while sending audio data: {e}")
            raise
            
    async def stop(self) -> None:
        """停止转写并关闭连接"""
        if self.ws:
            try:
                # 发送结束命令
                end_command = {
                    "end": True,
                    "task_id": self.task_id
                }
                await self.ws.send(json.dumps(end_command))
                
                # 等待最后的结果
                response = await self.ws.recv()
                logger.info(f"Final response: {response}")
                
            except Exception as e:
                logger.error(f"Error while stopping transcription: {e}")
            
            finally:
                await self.ws.close()
                self.ws = None
                self.is_connected = False
                self.task_id = None
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/realtime_asr/realtime_handler.py
```python
import numpy as np
import torch
from transformers import WhisperProcessor, WhisperForConditionalGeneration
import io
import wave
from typing import Optional
import asyncio
import soundfile as sf
import tempfile
import subprocess
import os

class RealtimeASRHandler:
    def __init__(self):
        # 初始化Whisper模型
        self.processor = WhisperProcessor.from_pretrained("openai/whisper-small")
        self.model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-small")
        if torch.cuda.is_available():
            self.model = self.model.to("cuda")
        
        # 音频缓冲设置
        self.sample_rate = 16000  # Whisper期望的采样率
        self.audio_buffer = np.array([], dtype=np.float32)
        self.buffer_size = self.sample_rate * 3  # 3秒的音频缓冲
        
        # 转写设置
        self.is_processing = False
        self.last_transcription = ""

    async def process_audio(self, audio_data: bytes) -> Optional[str]:
        try:
            # 将webm音频数据转换为numpy数组
            audio_array = await self._convert_webm_to_array(audio_data)
            if audio_array is None:
                return None
            
            # 添加到缓冲区
            self.audio_buffer = np.append(self.audio_buffer, audio_array)
            
            # 如果缓冲区达到指定大小，进行处理
            if len(self.audio_buffer) >= self.buffer_size and not self.is_processing:
                self.is_processing = True
                try:
                    # 处理音频并获取转写结果
                    transcription = await self._transcribe_audio()
                    self.last_transcription = transcription
                    
                    # 清除已处理的音频数据，保留最后0.5秒以实现平滑过渡
                    overlap_samples = int(0.5 * self.sample_rate)
                    self.audio_buffer = self.audio_buffer[-overlap_samples:]
                    
                finally:
                    self.is_processing = False
                
                return self.last_transcription
            
            return None
            
        except Exception as e:
            print(f"处理音频时出错: {str(e)}")
            return None

    async def _convert_webm_to_array(self, audio_data: bytes) -> Optional[np.ndarray]:
        try:
            # 创建临时文件来存储音频数据
            with tempfile.NamedTemporaryFile(suffix='.webm', delete=False) as webm_file:
                webm_file.write(audio_data)
                webm_path = webm_file.name

            # 创建临时WAV文件
            wav_path = webm_path + '.wav'
            
            # 使用ffmpeg将webm转换为wav
            cmd = [
                'ffmpeg',
                '-i', webm_path,
                '-ar', str(self.sample_rate),
                '-ac', '1',
                '-f', 'wav',
                wav_path,
                '-y'
            ]
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            await process.communicate()
            
            if process.returncode == 0:
                # 读取转换后的WAV文件
                audio_array, _ = sf.read(wav_path)
                return audio_array.astype(np.float32)
            else:
                print("音频转换失败")
                return None
                
        except Exception as e:
            print(f"转换音频格式时出错: {str(e)}")
            return None
            
        finally:
            # 清理临时文件
            try:
                os.unlink(webm_path)
                os.unlink(wav_path)
            except:
                pass

    async def _transcribe_audio(self) -> str:
        # 在事件循环中运行转写任务
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, self._run_transcription)

    def _run_transcription(self) -> str:
        try:
            # 准备输入特征
            input_features = self.processor(
                self.audio_buffer, 
                sampling_rate=self.sample_rate, 
                return_tensors="pt"
            ).input_features
            
            if torch.cuda.is_available():
                input_features = input_features.to("cuda")
            
            # 生成转写
            predicted_ids = self.model.generate(input_features)
            transcription = self.processor.batch_decode(
                predicted_ids, 
                skip_special_tokens=True
            )[0]
            
            return transcription.strip()
        except Exception as e:
            print(f"转写过程出错: {str(e)}")
            return ""

    async def cleanup(self):
        # 清理资源
        self.audio_buffer = np.array([], dtype=np.float32)
        self.is_processing = False
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/realtime_asr/__init__.py
```python
"""
实时语音转写模块
提供WebSocket服务，支持实时音频流转写功能
"""

# from .realtime_handler import RealtimeTranscriptionHandler
# 只导入实际用到的内容
from .funasr_client import FunASRRealtimeClient

__all__ = ['FunASRRealtimeClient']
```

--------------------------------------------------------------------------------

File: asr_system_backend/app/realtime_asr/routes.py
```python
"""
实时转写路由
处理实时转写相关的 WebSocket 请求
"""

from fastapi import APIRouter, WebSocket, Query
from .realtime_handler import RealtimeTranscriptionHandler

router = APIRouter()
handler = RealtimeTranscriptionHandler()

@router.websocket("/ws/asr/transcribe/realtime")
async def websocket_endpoint(
    websocket: WebSocket,
    token: str = Query(..., description="用户认证令牌")
):
    """
    实时转写 WebSocket 端点
    
    Args:
        websocket: WebSocket 连接
        token: 用户认证令牌
    """
    await handler.handle_client(websocket, token)
```

--------------------------------------------------------------------------------

File: asr_system_backend/client/funasr_wss_client.py
```python
# -*- encoding: utf-8 -*-
import os
import time
import websockets, ssl
import asyncio

# import threading
import argparse
import json
import traceback
from multiprocessing import Process

# from funasr.fileio.datadir_writer import DatadirWriter

import logging

logging.basicConfig(level=logging.ERROR)

parser = argparse.ArgumentParser()
parser.add_argument(
    "--host", type=str, default="localhost", required=False, help="host ip, localhost, 0.0.0.0"
)
parser.add_argument("--port", type=int, default=10095, required=False, help="grpc server port")
parser.add_argument("--chunk_size", type=str, default="5, 10, 5", help="chunk")
parser.add_argument("--encoder_chunk_look_back", type=int, default=4, help="chunk")
parser.add_argument("--decoder_chunk_look_back", type=int, default=0, help="chunk")
parser.add_argument("--chunk_interval", type=int, default=10, help="chunk")
parser.add_argument(
    "--hotword",
    type=str,
    default="",
    help="hotword file path, one hotword perline (e.g.:阿里巴巴 20)",
)
parser.add_argument("--audio_in", type=str, default=None, help="audio_in")
parser.add_argument("--audio_fs", type=int, default=16000, help="audio_fs")
parser.add_argument(
    "--send_without_sleep",
    action="store_true",
    default=True,
    help="if audio_in is set, send_without_sleep",
)
parser.add_argument("--thread_num", type=int, default=1, help="thread_num")
parser.add_argument("--words_max_print", type=int, default=10000, help="chunk")
parser.add_argument("--output_dir", type=str, default=None, help="output_dir")
parser.add_argument("--ssl", type=int, default=1, help="1 for ssl connect, 0 for no ssl")
parser.add_argument("--use_itn", type=int, default=1, help="1 for using itn, 0 for not itn")
parser.add_argument("--mode", type=str, default="2pass", help="offline, online, 2pass")

args = parser.parse_args()
args.chunk_size = [int(x) for x in args.chunk_size.split(",")]
print(args)
# voices = asyncio.Queue()
from queue import Queue

voices = Queue()
offline_msg_done = False

if args.output_dir is not None:
    # if os.path.exists(args.output_dir):
    #     os.remove(args.output_dir)

    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir)


async def record_microphone():
    is_finished = False
    import pyaudio

    # print("2")
    global voices
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    chunk_size = 60 * args.chunk_size[1] / args.chunk_interval
    CHUNK = int(RATE / 1000 * chunk_size)

    p = pyaudio.PyAudio()

    stream = p.open(
        format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK
    )
    # hotwords
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        if os.path.exists(args.hotword):
            f_scp = open(args.hotword)
            hot_lines = f_scp.readlines()
            for line in hot_lines:
                words = line.strip().split(" ")
                if len(words) < 2:
                    print("Please checkout format of hotwords")
                    continue
                try:
                    fst_dict[" ".join(words[:-1])] = int(words[-1])
                except ValueError:
                    print("Please checkout format of hotwords")
            hotword_msg = json.dumps(fst_dict)
        else:
            hotword_msg = args.hotword

    use_itn = True
    if args.use_itn == 0:
        use_itn = False

    message = json.dumps(
        {
            "mode": args.mode,
            "chunk_size": args.chunk_size,
            "chunk_interval": args.chunk_interval,
            "encoder_chunk_look_back": args.encoder_chunk_look_back,
            "decoder_chunk_look_back": args.decoder_chunk_look_back,
            "wav_name": "microphone",
            "is_speaking": True,
            "hotwords": hotword_msg,
            "itn": use_itn,
        }
    )
    # voices.put(message)
    await websocket.send(message)
    while True:
        data = stream.read(CHUNK)
        message = data
        # voices.put(message)
        await websocket.send(message)
        await asyncio.sleep(0.005)


async def record_from_scp(chunk_begin, chunk_size):
    global voices
    is_finished = False
    if args.audio_in.endswith(".scp"):
        f_scp = open(args.audio_in)
        wavs = f_scp.readlines()
    else:
        wavs = [args.audio_in]

    # hotwords
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        if os.path.exists(args.hotword):
            f_scp = open(args.hotword)
            hot_lines = f_scp.readlines()
            for line in hot_lines:
                words = line.strip().split(" ")
                if len(words) < 2:
                    print("Please checkout format of hotwords")
                    continue
                try:
                    fst_dict[" ".join(words[:-1])] = int(words[-1])
                except ValueError:
                    print("Please checkout format of hotwords")
            hotword_msg = json.dumps(fst_dict)
        else:
            hotword_msg = args.hotword
        print(hotword_msg)

    sample_rate = args.audio_fs
    wav_format = "pcm"
    use_itn = True
    if args.use_itn == 0:
        use_itn = False

    if chunk_size > 0:
        wavs = wavs[chunk_begin : chunk_begin + chunk_size]
    for wav in wavs:
        wav_splits = wav.strip().split()

        wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
        wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
        if not len(wav_path.strip()) > 0:
            continue
        if wav_path.endswith(".pcm"):
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()
        elif wav_path.endswith(".wav"):
            import wave

            with wave.open(wav_path, "rb") as wav_file:
                params = wav_file.getparams()
                sample_rate = wav_file.getframerate()
                frames = wav_file.readframes(wav_file.getnframes())
                audio_bytes = bytes(frames)
        else:
            wav_format = "others"
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()

        stride = int(60 * args.chunk_size[1] / args.chunk_interval / 1000 * sample_rate * 2)
        chunk_num = (len(audio_bytes) - 1) // stride + 1
        # print(stride)

        # send first time
        message = json.dumps(
            {
                "mode": args.mode,
                "chunk_size": args.chunk_size,
                "chunk_interval": args.chunk_interval,
                "encoder_chunk_look_back": args.encoder_chunk_look_back,
                "decoder_chunk_look_back": args.decoder_chunk_look_back,
                "audio_fs": sample_rate,
                "wav_name": wav_name,
                "wav_format": wav_format,
                "is_speaking": True,
                "hotwords": hotword_msg,
                "itn": use_itn,
            }
        )

        # voices.put(message)
        await websocket.send(message)
        is_speaking = True
        for i in range(chunk_num):

            beg = i * stride
            data = audio_bytes[beg : beg + stride]
            message = data
            # voices.put(message)
            await websocket.send(message)
            if i == chunk_num - 1:
                is_speaking = False
                message = json.dumps({"is_speaking": is_speaking})
                # voices.put(message)
                await websocket.send(message)

            sleep_duration = (
                0.001
                if args.mode == "offline"
                else 60 * args.chunk_size[1] / args.chunk_interval / 1000
            )

            await asyncio.sleep(sleep_duration)

    if not args.mode == "offline":
        await asyncio.sleep(2)
    # offline model need to wait for message recved

    if args.mode == "offline":
        global offline_msg_done
        while not offline_msg_done:
            await asyncio.sleep(1)

    await websocket.close()


async def message(id):
    global websocket, voices, offline_msg_done
    text_print = ""
    text_print_2pass_online = ""
    text_print_2pass_offline = ""
    if args.output_dir is not None:
        ibest_writer = open(
            os.path.join(args.output_dir, "text.{}".format(id)), "a", encoding="utf-8"
        )
    else:
        ibest_writer = None
    try:
        while True:

            meg = await websocket.recv()
            meg = json.loads(meg)
            wav_name = meg.get("wav_name", "demo")
            text = meg["text"]
            timestamp = ""
            offline_msg_done = meg.get("is_final", False)
            if "timestamp" in meg:
                timestamp = meg["timestamp"]

            if ibest_writer is not None:
                if timestamp != "":
                    text_write_line = "{}\t{}\t{}\n".format(wav_name, text, timestamp)
                else:
                    text_write_line = "{}\t{}\n".format(wav_name, text)
                ibest_writer.write(text_write_line)

            if "mode" not in meg:
                continue
            if meg["mode"] == "online":
                text_print += "{}".format(text)
                text_print = text_print[-args.words_max_print :]
                os.system("clear")
                print("\rpid" + str(id) + ": " + text_print)
            elif meg["mode"] == "offline":
                if timestamp != "":
                    text_print += "{} timestamp: {}".format(text, timestamp)
                else:
                    text_print += "{}".format(text)

                # text_print = text_print[-args.words_max_print:]
                # os.system('clear')
                print("\rpid" + str(id) + ": " + wav_name + ": " + text_print)
                offline_msg_done = True
            else:
                if meg["mode"] == "2pass-online":
                    text_print_2pass_online += "{}".format(text)
                    text_print = text_print_2pass_offline + text_print_2pass_online
                else:
                    text_print_2pass_online = ""
                    text_print = text_print_2pass_offline + "{}".format(text)
                    text_print_2pass_offline += "{}".format(text)
                text_print = text_print[-args.words_max_print :]
                os.system("clear")
                print("\rpid" + str(id) + ": " + text_print)
                # offline_msg_done=True

    except Exception as e:
        print("Exception:", e)
        # traceback.print_exc()
        # await websocket.close()


async def ws_client(id, chunk_begin, chunk_size):
    if args.audio_in is None:
        chunk_begin = 0
        chunk_size = 1
    global websocket, voices, offline_msg_done

    for i in range(chunk_begin, chunk_begin + chunk_size):
        offline_msg_done = False
        voices = Queue()
        if args.ssl == 1:
            ssl_context = ssl.SSLContext()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE
            uri = "wss://{}:{}".format(args.host, args.port)
        else:
            uri = "ws://{}:{}".format(args.host, args.port)
            ssl_context = None
        print("connect to", uri)
        async with websockets.connect(
            uri, subprotocols=["binary"], ping_interval=None, ssl=ssl_context
        ) as websocket:
            if args.audio_in is not None:
                task = asyncio.create_task(record_from_scp(i, 1))
            else:
                task = asyncio.create_task(record_microphone())
            task3 = asyncio.create_task(message(str(id) + "_" + str(i)))  # processid+fileid
            await asyncio.gather(task, task3)
    exit(0)


def one_thread(id, chunk_begin, chunk_size):
    asyncio.get_event_loop().run_until_complete(ws_client(id, chunk_begin, chunk_size))
    asyncio.get_event_loop().run_forever()


if __name__ == "__main__":
    # for microphone
    if args.audio_in is None:
        p = Process(target=one_thread, args=(0, 0, 0))
        p.start()
        p.join()
        print("end")
    else:
        # calculate the number of wavs for each preocess
        if args.audio_in.endswith(".scp"):
            f_scp = open(args.audio_in)
            wavs = f_scp.readlines()
        else:
            wavs = [args.audio_in]
        for wav in wavs:
            wav_splits = wav.strip().split()
            wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
            wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
            audio_type = os.path.splitext(wav_path)[-1].lower()

        total_len = len(wavs)
        if total_len >= args.thread_num:
            chunk_size = int(total_len / args.thread_num)
            remain_wavs = total_len - chunk_size * args.thread_num
        else:
            chunk_size = 1
            remain_wavs = 0

        process_list = []
        chunk_begin = 0
        for i in range(args.thread_num):
            now_chunk_size = chunk_size
            if remain_wavs > 0:
                now_chunk_size = chunk_size + 1
                remain_wavs = remain_wavs - 1
            # process i handle wavs at chunk_begin and size of now_chunk_size
            p = Process(target=one_thread, args=(i, chunk_begin, now_chunk_size))
            chunk_begin = chunk_begin + now_chunk_size
            p.start()
            process_list.append(p)

        for i in process_list:
            p.join()

        print("end")
```

--------------------------------------------------------------------------------

File: asr_system_backend/asr_system_backend/app/client/funasr_wss_client.py
```python
# -*- encoding: utf-8 -*-
import os
import time
import websockets, ssl
import asyncio

# import threading
import argparse
import json
import traceback
from multiprocessing import Process

# from funasr.fileio.datadir_writer import DatadirWriter

import logging

logging.basicConfig(level=logging.ERROR)

parser = argparse.ArgumentParser()
parser.add_argument(
    "--host", type=str, default="localhost", required=False, help="host ip, localhost, 0.0.0.0"
)
parser.add_argument("--port", type=int, default=10095, required=False, help="grpc server port")
parser.add_argument("--chunk_size", type=str, default="5, 10, 5", help="chunk")
parser.add_argument("--encoder_chunk_look_back", type=int, default=4, help="chunk")
parser.add_argument("--decoder_chunk_look_back", type=int, default=0, help="chunk")
parser.add_argument("--chunk_interval", type=int, default=10, help="chunk")
parser.add_argument(
    "--hotword",
    type=str,
    default="",
    help="hotword file path, one hotword perline (e.g.:阿里巴巴 20)",
)
parser.add_argument("--audio_in", type=str, default=None, help="audio_in")
parser.add_argument("--audio_fs", type=int, default=16000, help="audio_fs")
parser.add_argument(
    "--send_without_sleep",
    action="store_true",
    default=True,
    help="if audio_in is set, send_without_sleep",
)
parser.add_argument("--thread_num", type=int, default=1, help="thread_num")
parser.add_argument("--words_max_print", type=int, default=10000, help="chunk")
parser.add_argument("--output_dir", type=str, default=None, help="output_dir")
parser.add_argument("--ssl", type=int, default=1, help="1 for ssl connect, 0 for no ssl")
parser.add_argument("--use_itn", type=int, default=1, help="1 for using itn, 0 for not itn")
parser.add_argument("--mode", type=str, default="2pass", help="offline, online, 2pass")

args = parser.parse_args()
args.chunk_size = [int(x) for x in args.chunk_size.split(",")]
print(args)
# voices = asyncio.Queue()
from queue import Queue

voices = Queue()
offline_msg_done = False

if args.output_dir is not None:
    # if os.path.exists(args.output_dir):
    #     os.remove(args.output_dir)

    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir)


async def record_microphone():
    is_finished = False
    import pyaudio

    # print("2")
    global voices
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    chunk_size = 60 * args.chunk_size[1] / args.chunk_interval
    CHUNK = int(RATE / 1000 * chunk_size)

    p = pyaudio.PyAudio()

    stream = p.open(
        format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK
    )
    # hotwords
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        if os.path.exists(args.hotword):
            f_scp = open(args.hotword)
            hot_lines = f_scp.readlines()
            for line in hot_lines:
                words = line.strip().split(" ")
                if len(words) < 2:
                    print("Please checkout format of hotwords")
                    continue
                try:
                    fst_dict[" ".join(words[:-1])] = int(words[-1])
                except ValueError:
                    print("Please checkout format of hotwords")
            hotword_msg = json.dumps(fst_dict)
        else:
            hotword_msg = args.hotword

    use_itn = True
    if args.use_itn == 0:
        use_itn = False

    message = json.dumps(
        {
            "mode": args.mode,
            "chunk_size": args.chunk_size,
            "chunk_interval": args.chunk_interval,
            "encoder_chunk_look_back": args.encoder_chunk_look_back,
            "decoder_chunk_look_back": args.decoder_chunk_look_back,
            "wav_name": "microphone",
            "is_speaking": True,
            "hotwords": hotword_msg,
            "itn": use_itn,
        }
    )
    # voices.put(message)
    await websocket.send(message)
    while True:
        data = stream.read(CHUNK)
        message = data
        # voices.put(message)
        await websocket.send(message)
        await asyncio.sleep(0.005)


async def record_from_scp(chunk_begin, chunk_size):
    global voices
    is_finished = False
    if args.audio_in.endswith(".scp"):
        f_scp = open(args.audio_in)
        wavs = f_scp.readlines()
    else:
        wavs = [args.audio_in]

    # hotwords
    fst_dict = {}
    hotword_msg = ""
    if args.hotword.strip() != "":
        if os.path.exists(args.hotword):
            f_scp = open(args.hotword)
            hot_lines = f_scp.readlines()
            for line in hot_lines:
                words = line.strip().split(" ")
                if len(words) < 2:
                    print("Please checkout format of hotwords")
                    continue
                try:
                    fst_dict[" ".join(words[:-1])] = int(words[-1])
                except ValueError:
                    print("Please checkout format of hotwords")
            hotword_msg = json.dumps(fst_dict)
        else:
            hotword_msg = args.hotword
        print(hotword_msg)

    sample_rate = args.audio_fs
    wav_format = "pcm"
    use_itn = True
    if args.use_itn == 0:
        use_itn = False

    if chunk_size > 0:
        wavs = wavs[chunk_begin : chunk_begin + chunk_size]
    for wav in wavs:
        wav_splits = wav.strip().split()

        wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
        wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
        if not len(wav_path.strip()) > 0:
            continue
        if wav_path.endswith(".pcm"):
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()
        elif wav_path.endswith(".wav"):
            import wave

            with wave.open(wav_path, "rb") as wav_file:
                params = wav_file.getparams()
                sample_rate = wav_file.getframerate()
                frames = wav_file.readframes(wav_file.getnframes())
                audio_bytes = bytes(frames)
        else:
            wav_format = "others"
            with open(wav_path, "rb") as f:
                audio_bytes = f.read()

        stride = int(60 * args.chunk_size[1] / args.chunk_interval / 1000 * sample_rate * 2)
        chunk_num = (len(audio_bytes) - 1) // stride + 1
        # print(stride)

        # send first time
        message = json.dumps(
            {
                "mode": args.mode,
                "chunk_size": args.chunk_size,
                "chunk_interval": args.chunk_interval,
                "encoder_chunk_look_back": args.encoder_chunk_look_back,
                "decoder_chunk_look_back": args.decoder_chunk_look_back,
                "audio_fs": sample_rate,
                "wav_name": wav_name,
                "wav_format": wav_format,
                "is_speaking": True,
                "hotwords": hotword_msg,
                "itn": use_itn,
            }
        )

        # voices.put(message)
        await websocket.send(message)
        is_speaking = True
        for i in range(chunk_num):

            beg = i * stride
            data = audio_bytes[beg : beg + stride]
            message = data
            # voices.put(message)
            await websocket.send(message)
            if i == chunk_num - 1:
                is_speaking = False
                message = json.dumps({"is_speaking": is_speaking})
                # voices.put(message)
                await websocket.send(message)

            sleep_duration = (
                0.001
                if args.mode == "offline"
                else 60 * args.chunk_size[1] / args.chunk_interval / 1000
            )

            await asyncio.sleep(sleep_duration)

    if not args.mode == "offline":
        await asyncio.sleep(2)
    # offline model need to wait for message recved

    if args.mode == "offline":
        global offline_msg_done
        while not offline_msg_done:
            await asyncio.sleep(1)

    await websocket.close()


async def message(id):
    global websocket, voices, offline_msg_done
    text_print = ""
    text_print_2pass_online = ""
    text_print_2pass_offline = ""
    if args.output_dir is not None:
        ibest_writer = open(
            os.path.join(args.output_dir, "text.{}".format(id)), "a", encoding="utf-8"
        )
    else:
        ibest_writer = None
    try:
        while True:

            meg = await websocket.recv()
            meg = json.loads(meg)
            wav_name = meg.get("wav_name", "demo")
            text = meg["text"]
            timestamp = ""
            offline_msg_done = meg.get("is_final", False)
            if "timestamp" in meg:
                timestamp = meg["timestamp"]

            if ibest_writer is not None:
                if timestamp != "":
                    text_write_line = "{}\t{}\t{}\n".format(wav_name, text, timestamp)
                else:
                    text_write_line = "{}\t{}\n".format(wav_name, text)
                ibest_writer.write(text_write_line)

            if "mode" not in meg:
                continue
            if meg["mode"] == "online":
                text_print += "{}".format(text)
                text_print = text_print[-args.words_max_print :]
                os.system("clear")
                print("\rpid" + str(id) + ": " + text_print)
            elif meg["mode"] == "offline":
                if timestamp != "":
                    text_print += "{} timestamp: {}".format(text, timestamp)
                else:
                    text_print += "{}".format(text)

                # text_print = text_print[-args.words_max_print:]
                # os.system('clear')
                print("\rpid" + str(id) + ": " + wav_name + ": " + text_print)
                offline_msg_done = True
            else:
                if meg["mode"] == "2pass-online":
                    text_print_2pass_online += "{}".format(text)
                    text_print = text_print_2pass_offline + text_print_2pass_online
                else:
                    text_print_2pass_online = ""
                    text_print = text_print_2pass_offline + "{}".format(text)
                    text_print_2pass_offline += "{}".format(text)
                text_print = text_print[-args.words_max_print :]
                os.system("clear")
                print("\rpid" + str(id) + ": " + text_print)
                # offline_msg_done=True

    except Exception as e:
        print("Exception:", e)
        # traceback.print_exc()
        # await websocket.close()


async def ws_client(id, chunk_begin, chunk_size):
    if args.audio_in is None:
        chunk_begin = 0
        chunk_size = 1
    global websocket, voices, offline_msg_done

    for i in range(chunk_begin, chunk_begin + chunk_size):
        offline_msg_done = False
        voices = Queue()
        if args.ssl == 1:
            ssl_context = ssl.SSLContext()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE
            uri = "wss://{}:{}".format(args.host, args.port)
        else:
            uri = "ws://{}:{}".format(args.host, args.port)
            ssl_context = None
        print("connect to", uri)
        async with websockets.connect(
            uri, subprotocols=["binary"], ping_interval=None, ssl=ssl_context
        ) as websocket:
            if args.audio_in is not None:
                task = asyncio.create_task(record_from_scp(i, 1))
            else:
                task = asyncio.create_task(record_microphone())
            task3 = asyncio.create_task(message(str(id) + "_" + str(i)))  # processid+fileid
            await asyncio.gather(task, task3)
    exit(0)


def one_thread(id, chunk_begin, chunk_size):
    asyncio.get_event_loop().run_until_complete(ws_client(id, chunk_begin, chunk_size))
    asyncio.get_event_loop().run_forever()


if __name__ == "__main__":
    # for microphone
    if args.audio_in is None:
        p = Process(target=one_thread, args=(0, 0, 0))
        p.start()
        p.join()
        print("end")
    else:
        # calculate the number of wavs for each preocess
        if args.audio_in.endswith(".scp"):
            f_scp = open(args.audio_in)
            wavs = f_scp.readlines()
        else:
            wavs = [args.audio_in]
        for wav in wavs:
            wav_splits = wav.strip().split()
            wav_name = wav_splits[0] if len(wav_splits) > 1 else "demo"
            wav_path = wav_splits[1] if len(wav_splits) > 1 else wav_splits[0]
            audio_type = os.path.splitext(wav_path)[-1].lower()

        total_len = len(wavs)
        if total_len >= args.thread_num:
            chunk_size = int(total_len / args.thread_num)
            remain_wavs = total_len - chunk_size * args.thread_num
        else:
            chunk_size = 1
            remain_wavs = 0

        process_list = []
        chunk_begin = 0
        for i in range(args.thread_num):
            now_chunk_size = chunk_size
            if remain_wavs > 0:
                now_chunk_size = chunk_size + 1
                remain_wavs = remain_wavs - 1
            # process i handle wavs at chunk_begin and size of now_chunk_size
            p = Process(target=one_thread, args=(i, chunk_begin, now_chunk_size))
            chunk_begin = chunk_begin + now_chunk_size
            p.start()
            process_list.append(p)

        for i in process_list:
            p.join()

        print("end")
```

--------------------------------------------------------------------------------

File: sql/0001_initial_schema.sql
```sql
-- 文件名: 0001_initial_schema.sql
-- 描述: 创建项目所需的全部核心表结构（PostgreSQL版）

-- 1. 创建自定义ENUM类型，用于任务状态
CREATE TYPE task_status AS ENUM ('pending', 'processing', 'completed', 'failed');

-- 2. 创建 users 表
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(255) NOT NULL UNIQUE,
    hashed_password VARCHAR(255) NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP
);
COMMENT ON TABLE users IS '存储系统用户信息';

-- 3. 创建 hotwords 表
CREATE TABLE hotwords (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    word VARCHAR(255) NOT NULL,
    weight INTEGER NOT NULL DEFAULT 5 CHECK (weight >= 1 AND weight <= 10),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
    UNIQUE (user_id, word)
);
COMMENT ON TABLE hotwords IS '存储用户自定义的热词';
CREATE INDEX idx_hotwords_user_id ON hotwords(user_id);

-- 4. 创建 transcription_tasks 表
CREATE TABLE transcription_tasks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    status task_status NOT NULL DEFAULT 'pending',
    error_message TEXT,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP WITH TIME ZONE
);
COMMENT ON TABLE transcription_tasks IS '记录语音转写任务';
CREATE INDEX idx_tasks_user_id ON transcription_tasks(user_id);
CREATE INDEX idx_tasks_status ON transcription_tasks(status);

-- 5. 创建 transcription_segments 表
CREATE TABLE transcription_segments (
    id BIGSERIAL PRIMARY KEY,
    task_id UUID NOT NULL REFERENCES transcription_tasks(id) ON DELETE CASCADE,
    start_time FLOAT NOT NULL,
    end_time FLOAT NOT NULL,
    text TEXT NOT NULL,
    confidence FLOAT
);
COMMENT ON TABLE transcription_segments IS '存储结构化的转写结果分段';
CREATE INDEX idx_segments_task_id ON transcription_segments(task_id);
```

--------------------------------------------------------------------------------

File: .git/config
```text
[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
[remote "origin"]
	url = git@github.com:Miki-Riako/asr-system.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "main"]
	remote = origin
	merge = refs/heads/main
	vscode-merge-base = origin/main
```

--------------------------------------------------------------------------------

File: .git/packed-refs
```text
# pack-refs with: peeled fully-peeled sorted 
e076f06e191466160a18c4129749553ce100258b refs/remotes/origin/main
```

--------------------------------------------------------------------------------

File: .git/ORIG_HEAD
```text
6481a932458e144c6fc11d7cd8c3e1deae2083e9
```

--------------------------------------------------------------------------------

File: .git/COMMIT_EDITMSG
```text
commit
```

--------------------------------------------------------------------------------

File: .git/description
```text
Unnamed repository; edit this file 'description' to name the repository.
```

--------------------------------------------------------------------------------

File: .git/FETCH_HEAD
```text
6724e78d9de92025ea2292ac1af3abb3293c8fd7		branch 'main' of github.com:Miki-Riako/asr-system
```

--------------------------------------------------------------------------------

File: .git/HEAD
```text
ref: refs/heads/main
```

--------------------------------------------------------------------------------

File: .git/logs/HEAD
```text
0000000000000000000000000000000000000000 e076f06e191466160a18c4129749553ce100258b ght <ght0719@qq.com> 1751858378 +0800	clone: from github.com:Miki-Riako/asr-system.git
e076f06e191466160a18c4129749553ce100258b 7b03493583299eb0c1c69523a15e58c293be855a ght <ght0719@qq.com> 1751859594 +0800	pull: Fast-forward
7b03493583299eb0c1c69523a15e58c293be855a 2a0f6dae50abdc215cbaecb360b28950d316672c ght <ght0719@qq.com> 1752461771 +0800	pull: Fast-forward
2a0f6dae50abdc215cbaecb360b28950d316672c 2a0f6dae50abdc215cbaecb360b28950d316672c ght <ght0719@qq.com> 1752590635 +0800	reset: moving to HEAD
2a0f6dae50abdc215cbaecb360b28950d316672c 380f44c7fd1c86822b3fbdf073274421c621e9ee ght <ght0719@qq.com> 1752675833 +0800	reset: moving to HEAD~1
380f44c7fd1c86822b3fbdf073274421c621e9ee 1254ba52a2eda6ca6d949d3583ead8317d7a6e8c ght <ght0719@qq.com> 1752675851 +0800	reset: moving to HEAD~1
1254ba52a2eda6ca6d949d3583ead8317d7a6e8c 2a0f6dae50abdc215cbaecb360b28950d316672c ght <ght0719@qq.com> 1752675914 +0800	pull: Fast-forward
2a0f6dae50abdc215cbaecb360b28950d316672c 471c9e993f5a04345d621245862ef4e06dc969d2 ght <ght0719@qq.com> 1752688313 +0800	commit: 转写
471c9e993f5a04345d621245862ef4e06dc969d2 3eb26444660cd32b7ada80e490c927676e0725fe ght <ght0719@qq.com> 1752693197 +0800	commit: commit
3eb26444660cd32b7ada80e490c927676e0725fe da063928fee9b5544dfa01ba1647a072f04f7115 ght <ght0719@qq.com> 1752719908 +0800	commit: commit
da063928fee9b5544dfa01ba1647a072f04f7115 3eb26444660cd32b7ada80e490c927676e0725fe ght <ght0719@qq.com> 1752721726 +0800	reset: moving to HEAD~1
3eb26444660cd32b7ada80e490c927676e0725fe 471c9e993f5a04345d621245862ef4e06dc969d2 ght <ght0719@qq.com> 1752721732 +0800	reset: moving to HEAD~1
471c9e993f5a04345d621245862ef4e06dc969d2 2a0f6dae50abdc215cbaecb360b28950d316672c ght <ght0719@qq.com> 1752721736 +0800	reset: moving to HEAD~1
2a0f6dae50abdc215cbaecb360b28950d316672c 32bf3540ec39caf599c7a3d1410d1735e5dd676f ght <ght0719@qq.com> 1752721819 +0800	commit: update
32bf3540ec39caf599c7a3d1410d1735e5dd676f c754c505ee78fb4535c05269acd33ebc2fbf8661 ght <ght0719@qq.com> 1752721829 +0800	commit: update
c754c505ee78fb4535c05269acd33ebc2fbf8661 09894afad25a2ddf6a20c338d7a766b2fa842fec ght <ght0719@qq.com> 1752752300 +0800	pull: Fast-forward
09894afad25a2ddf6a20c338d7a766b2fa842fec a3c308bb7e5d81b3eb68858d3b0a8d14e5178e1d ght <ght0719@qq.com> 1752760723 +0800	commit: 网页报错改好
a3c308bb7e5d81b3eb68858d3b0a8d14e5178e1d e106eb2cd515bc83e8e1123ff617a54b481a7b0b ght <ght0719@qq.com> 1752760891 +0800	commit: update
e106eb2cd515bc83e8e1123ff617a54b481a7b0b e106eb2cd515bc83e8e1123ff617a54b481a7b0b ght <ght0719@qq.com> 1752768200 +0800	reset: moving to origin/main
e106eb2cd515bc83e8e1123ff617a54b481a7b0b 6724e78d9de92025ea2292ac1af3abb3293c8fd7 ght <ght0719@qq.com> 1752771217 +0800	commit: commit
6724e78d9de92025ea2292ac1af3abb3293c8fd7 6481a932458e144c6fc11d7cd8c3e1deae2083e9 ght <ght0719@qq.com> 1752771732 +0800	commit: commit
6481a932458e144c6fc11d7cd8c3e1deae2083e9 6481a932458e144c6fc11d7cd8c3e1deae2083e9 ght <ght0719@qq.com> 1752773646 +0800	reset: moving to origin/main
```

--------------------------------------------------------------------------------

File: .git/logs/refs/heads/main
```text
0000000000000000000000000000000000000000 e076f06e191466160a18c4129749553ce100258b ght <ght0719@qq.com> 1751858378 +0800	clone: from github.com:Miki-Riako/asr-system.git
e076f06e191466160a18c4129749553ce100258b 7b03493583299eb0c1c69523a15e58c293be855a ght <ght0719@qq.com> 1751859594 +0800	pull: Fast-forward
7b03493583299eb0c1c69523a15e58c293be855a 2a0f6dae50abdc215cbaecb360b28950d316672c ght <ght0719@qq.com> 1752461771 +0800	pull: Fast-forward
2a0f6dae50abdc215cbaecb360b28950d316672c 380f44c7fd1c86822b3fbdf073274421c621e9ee ght <ght0719@qq.com> 1752675833 +0800	reset: moving to HEAD~1
380f44c7fd1c86822b3fbdf073274421c621e9ee 1254ba52a2eda6ca6d949d3583ead8317d7a6e8c ght <ght0719@qq.com> 1752675851 +0800	reset: moving to HEAD~1
1254ba52a2eda6ca6d949d3583ead8317d7a6e8c 2a0f6dae50abdc215cbaecb360b28950d316672c ght <ght0719@qq.com> 1752675914 +0800	pull: Fast-forward
2a0f6dae50abdc215cbaecb360b28950d316672c 471c9e993f5a04345d621245862ef4e06dc969d2 ght <ght0719@qq.com> 1752688313 +0800	commit: 转写
471c9e993f5a04345d621245862ef4e06dc969d2 3eb26444660cd32b7ada80e490c927676e0725fe ght <ght0719@qq.com> 1752693197 +0800	commit: commit
3eb26444660cd32b7ada80e490c927676e0725fe da063928fee9b5544dfa01ba1647a072f04f7115 ght <ght0719@qq.com> 1752719908 +0800	commit: commit
da063928fee9b5544dfa01ba1647a072f04f7115 3eb26444660cd32b7ada80e490c927676e0725fe ght <ght0719@qq.com> 1752721726 +0800	reset: moving to HEAD~1
3eb26444660cd32b7ada80e490c927676e0725fe 471c9e993f5a04345d621245862ef4e06dc969d2 ght <ght0719@qq.com> 1752721732 +0800	reset: moving to HEAD~1
471c9e993f5a04345d621245862ef4e06dc969d2 2a0f6dae50abdc215cbaecb360b28950d316672c ght <ght0719@qq.com> 1752721736 +0800	reset: moving to HEAD~1
2a0f6dae50abdc215cbaecb360b28950d316672c 32bf3540ec39caf599c7a3d1410d1735e5dd676f ght <ght0719@qq.com> 1752721819 +0800	commit: update
32bf3540ec39caf599c7a3d1410d1735e5dd676f c754c505ee78fb4535c05269acd33ebc2fbf8661 ght <ght0719@qq.com> 1752721829 +0800	commit: update
c754c505ee78fb4535c05269acd33ebc2fbf8661 09894afad25a2ddf6a20c338d7a766b2fa842fec ght <ght0719@qq.com> 1752752300 +0800	pull: Fast-forward
09894afad25a2ddf6a20c338d7a766b2fa842fec a3c308bb7e5d81b3eb68858d3b0a8d14e5178e1d ght <ght0719@qq.com> 1752760723 +0800	commit: 网页报错改好
a3c308bb7e5d81b3eb68858d3b0a8d14e5178e1d e106eb2cd515bc83e8e1123ff617a54b481a7b0b ght <ght0719@qq.com> 1752760891 +0800	commit: update
e106eb2cd515bc83e8e1123ff617a54b481a7b0b 6724e78d9de92025ea2292ac1af3abb3293c8fd7 ght <ght0719@qq.com> 1752771217 +0800	commit: commit
6724e78d9de92025ea2292ac1af3abb3293c8fd7 6481a932458e144c6fc11d7cd8c3e1deae2083e9 ght <ght0719@qq.com> 1752771732 +0800	commit: commit
```

--------------------------------------------------------------------------------

File: .git/logs/refs/remotes/origin/main
```text
e076f06e191466160a18c4129749553ce100258b 7b03493583299eb0c1c69523a15e58c293be855a ght <ght0719@qq.com> 1751859594 +0800	pull: fast-forward
7b03493583299eb0c1c69523a15e58c293be855a 380f44c7fd1c86822b3fbdf073274421c621e9ee ght <ght0719@qq.com> 1752460094 +0800	pull: fast-forward
380f44c7fd1c86822b3fbdf073274421c621e9ee 2a0f6dae50abdc215cbaecb360b28950d316672c ght <ght0719@qq.com> 1752461771 +0800	pull: fast-forward
2a0f6dae50abdc215cbaecb360b28950d316672c c754c505ee78fb4535c05269acd33ebc2fbf8661 ght <ght0719@qq.com> 1752722056 +0800	update by push
c754c505ee78fb4535c05269acd33ebc2fbf8661 09894afad25a2ddf6a20c338d7a766b2fa842fec ght <ght0719@qq.com> 1752752300 +0800	pull: fast-forward
09894afad25a2ddf6a20c338d7a766b2fa842fec e106eb2cd515bc83e8e1123ff617a54b481a7b0b ght <ght0719@qq.com> 1752760916 +0800	update by push
e106eb2cd515bc83e8e1123ff617a54b481a7b0b 6724e78d9de92025ea2292ac1af3abb3293c8fd7 ght <ght0719@qq.com> 1752771352 +0800	update by push
6724e78d9de92025ea2292ac1af3abb3293c8fd7 6481a932458e144c6fc11d7cd8c3e1deae2083e9 ght <ght0719@qq.com> 1752771751 +0800	update by push
```

--------------------------------------------------------------------------------

File: .git/logs/refs/remotes/origin/HEAD
```text
0000000000000000000000000000000000000000 e076f06e191466160a18c4129749553ce100258b ght <ght0719@qq.com> 1751858378 +0800	clone: from github.com:Miki-Riako/asr-system.git
```

--------------------------------------------------------------------------------

File: .git/hooks/pre-merge-commit.sample
```text
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup
test -x "$GIT_DIR/hooks/pre-commit" &&
        exec "$GIT_DIR/hooks/pre-commit"
:
```

--------------------------------------------------------------------------------

File: .git/hooks/commit-msg.sample
```text
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}
```

--------------------------------------------------------------------------------

File: .git/hooks/fsmonitor-watchman.sample
```text
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 2) and last update token
# formatted as a string and outputs to stdout a new update token and
# all files that have been modified since the update token. Paths must
# be relative to the root of the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $last_update_token) = @ARGV;

# Uncomment for debugging
# print STDERR "$0 $version $last_update_token\n";

# Check the hook interface version
if ($version ne 2) {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree = get_working_dir();

my $retry = 1;

my $json_pkg;
eval {
	require JSON::XS;
	$json_pkg = "JSON::XS";
	1;
} or do {
	require JSON::PP;
	$json_pkg = "JSON::PP";
};

launch_watchman();

sub launch_watchman {
	my $o = watchman_query();
	if (is_work_tree_watched($o)) {
		output_result($o->{clock}, @{$o->{files}});
	}
}

sub output_result {
	my ($clockid, @files) = @_;

	# Uncomment for debugging watchman output
	# open (my $fh, ">", ".git/watchman-output.out");
	# binmode $fh, ":utf8";
	# print $fh "$clockid\n@files\n";
	# close $fh;

	binmode STDOUT, ":utf8";
	print $clockid;
	print "\0";
	local $, = "\0";
	print @files;
}

sub watchman_clock {
	my $response = qx/watchman clock "$git_work_tree"/;
	die "Failed to get clock id on '$git_work_tree'.\n" .
		"Falling back to scanning...\n" if $? != 0;

	return $json_pkg->new->utf8->decode($response);
}

sub watchman_query {
	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	or die "open2() failed: $!\n" .
	"Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $last_update_token but not from the .git folder.
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	if (substr($last_update_token, 0, 1) eq "c") {
		$last_update_token = "\"$last_update_token\"";
	}
	my $query = <<"	END";
		["query", "$git_work_tree", {
			"since": $last_update_token,
			"fields": ["name"],
			"expression": ["not", ["dirname", ".git"]]
		}]
	END

	# Uncomment for debugging the watchman query
	# open (my $fh, ">", ".git/watchman-query.json");
	# print $fh $query;
	# close $fh;

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	# Uncomment for debugging the watch response
	# open ($fh, ">", ".git/watchman-response.json");
	# print $fh $response;
	# close $fh;

	die "Watchman: command returned no output.\n" .
	"Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	"Falling back to scanning...\n" unless $response =~ /^\{/;

	return $json_pkg->new->utf8->decode($response);
}

sub is_work_tree_watched {
	my ($output) = @_;
	my $error = $output->{error};
	if ($retry > 0 and $error and $error =~ m/unable to resolve root .* directory (.*) is not watched/) {
		$retry--;
		my $response = qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;
		$output = $json_pkg->new->utf8->decode($response);
		$error = $output->{error};
		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		# Uncomment for debugging watchman output
		# open (my $fh, ">", ".git/watchman-output.out");
		# close $fh;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		my $o = watchman_clock();
		$error = $output->{error};

		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		output_result($o->{clock}, ("/"));
		$last_update_token = $o->{clock};

		eval { launch_watchman() };
		return 0;
	}

	die "Watchman: $error.\n" .
	"Falling back to scanning...\n" if $error;

	return 1;
}

sub get_working_dir {
	my $working_dir;
	if ($^O =~ 'msys' || $^O =~ 'cygwin') {
		$working_dir = Win32::GetCwd();
		$working_dir =~ tr/\\/\//;
	} else {
		require Cwd;
		$working_dir = Cwd::cwd();
	}

	return $working_dir;
}
```

--------------------------------------------------------------------------------

File: .git/hooks/prepare-commit-msg.sample
```text
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi
```

--------------------------------------------------------------------------------

File: .git/hooks/post-update.sample
```text
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info
```

--------------------------------------------------------------------------------

File: .git/hooks/update.sample
```text
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --type=bool hooks.allowunannotated)
allowdeletebranch=$(git config --type=bool hooks.allowdeletebranch)
denycreatebranch=$(git config --type=bool hooks.denycreatebranch)
allowdeletetag=$(git config --type=bool hooks.allowdeletetag)
allowmodifytag=$(git config --type=bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0
```

--------------------------------------------------------------------------------

File: .git/hooks/pre-rebase.sample
```text
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END
```

--------------------------------------------------------------------------------

File: .git/hooks/applypatch-msg.sample
```text
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:
```

--------------------------------------------------------------------------------

File: .git/hooks/pre-receive.sample
```text
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi
```

--------------------------------------------------------------------------------

File: .git/hooks/pre-applypatch.sample
```text
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:
```

--------------------------------------------------------------------------------

File: .git/hooks/push-to-checkout.sample
```text
#!/bin/sh

# An example hook script to update a checked-out tree on a git push.
#
# This hook is invoked by git-receive-pack(1) when it reacts to git
# push and updates reference(s) in its repository, and when the push
# tries to update the branch that is currently checked out and the
# receive.denyCurrentBranch configuration variable is set to
# updateInstead.
#
# By default, such a push is refused if the working tree and the index
# of the remote repository has any difference from the currently
# checked out commit; when both the working tree and the index match
# the current commit, they are updated to match the newly pushed tip
# of the branch. This hook is to be used to override the default
# behaviour; however the code below reimplements the default behaviour
# as a starting point for convenient modification.
#
# The hook receives the commit with which the tip of the current
# branch is going to be updated:
commit=$1

# It can exit with a non-zero status to refuse the push (when it does
# so, it must not modify the index or the working tree).
die () {
	echo >&2 "$*"
	exit 1
}

# Or it can make any necessary changes to the working tree and to the
# index to bring them to the desired state when the tip of the current
# branch is updated to the new commit, and exit with a zero status.
#
# For example, the hook can simply run git read-tree -u -m HEAD "$1"
# in order to emulate git fetch that is run in the reverse direction
# with git push, as the two-tree form of git read-tree -u -m is
# essentially the same as git switch or git checkout that switches
# branches while keeping the local changes in the working tree that do
# not interfere with the difference between the branches.

# The below is a more-or-less exact translation to shell of the C code
# for the default behaviour for git's push-to-checkout hook defined in
# the push_to_deploy() function in builtin/receive-pack.c.
#
# Note that the hook will be executed from the repository directory,
# not from the working tree, so if you want to perform operations on
# the working tree, you will have to adapt your code accordingly, e.g.
# by adding "cd .." or using relative paths.

if ! git update-index -q --ignore-submodules --refresh
then
	die "Up-to-date check failed"
fi

if ! git diff-files --quiet --ignore-submodules --
then
	die "Working directory has unstaged changes"
fi

# This is a rough translation of:
#
#   head_has_history() ? "HEAD" : EMPTY_TREE_SHA1_HEX
if git cat-file -e HEAD 2>/dev/null
then
	head=HEAD
else
	head=$(git hash-object -t tree --stdin </dev/null)
fi

if ! git diff-index --quiet --cached --ignore-submodules $head --
then
	die "Working directory has staged changes"
fi

if ! git read-tree -u -m "$commit"
then
	die "Could not update working tree to new HEAD"
fi
```

--------------------------------------------------------------------------------

File: .git/hooks/pre-commit.sample
```text
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --type=bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --
```

--------------------------------------------------------------------------------

File: .git/hooks/pre-push.sample
```text
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local oid> <remote ref> <remote oid>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')

while read local_ref local_oid remote_ref remote_oid
do
	if test "$local_oid" = "$zero"
	then
		# Handle delete
		:
	else
		if test "$remote_oid" = "$zero"
		then
			# New branch, examine all commits
			range="$local_oid"
		else
			# Update to existing branch, examine new commits
			range="$remote_oid..$local_oid"
		fi

		# Check for WIP commit
		commit=$(git rev-list -n 1 --grep '^WIP' "$range")
		if test -n "$commit"
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0
```

--------------------------------------------------------------------------------

File: .git/info/exclude
```text
# git ls-files --others --exclude-from=.git/info/exclude
# Lines that start with '#' are comments.
# For a project mostly in C, the following would be a good set of
# exclude patterns (uncomment them if you want to use them):
# *.[oa]
# *~
```

--------------------------------------------------------------------------------

File: .git/refs/heads/main
```text
6481a932458e144c6fc11d7cd8c3e1deae2083e9
```

--------------------------------------------------------------------------------

File: .git/refs/remotes/origin/main
```text
6481a932458e144c6fc11d7cd8c3e1deae2083e9
```

--------------------------------------------------------------------------------

File: .git/refs/remotes/origin/HEAD
```text
ref: refs/remotes/origin/main
```

--------------------------------------------------------------------------------

File: .git/objects/pack/pack-c0cb4203b59cbe1ffaf0d18b14609b2efc8cb131.pack  (Skipped, size > 200KB)

--------------------------------------------------------------------------------

File: .git/objects/fb/19e07f2870b09b08226a42d7d5d6d26a3f3a16  (Skipped, size > 200KB)

--------------------------------------------------------------------------------

File: .git/objects/08/c4f60b4d7be7949d5d3e7b8b8fc78455c56e2e  (Skipped, size > 200KB)

--------------------------------------------------------------------------------

